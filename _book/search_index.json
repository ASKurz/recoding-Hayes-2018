[
["index.html", "Recoding Introduction to Mediation, Moderation, and Conditional Process Analysis version 1.1.0 Welcome Why this? My assumptions about you How to use and understand this project Times change and so do we", " Recoding Introduction to Mediation, Moderation, and Conditional Process Analysis version 1.1.0 A Solomon Kurz 2019-12-20 Welcome Andrew Hayes’s Introduction to Mediation, Moderation, and Conditional Process Analysis text, the second edition of which just came out, has become a staple in social science graduate education. Both editions of his text have been from a frequentist OLS perspective. This project is an effort to connect his work with the Bayesian paradigm. Herein I refit his models with my favorite R package for Bayesian regression, Bürkner’s brms. I also prefer data wrangling and plotting using the tidyverse, which you might learn about here or here). But to be clear, this project is not meant to stand alone. It’s a supplement to the textbook. The source code of the project is available here. This project is powered by the great Yihui Xie’s bookdown package which makes it easy to turn R markdown files into HTML, PDF, and EPUB. You can learn more here. While you’re at it, also check out this great guide to R Markdown. Why this? I’m not a statistician and I have no formal background in computer science. But I met a great statistics mentor in grad school who was enthusiastic, knowledgeable, and very generous with his time. In one of his stats electives, we used Hayes’s first edition text and I learned a lot in that semester. Yet a large portion of my training has been out of the classroom, working with messy real-world data, and looking online for help. One of the great resources I happened on was idre, the UCLA Institute for Digital Education. They perform a variety of services, but I benefited the most from was their portfolio of richly annotated textbook examples. Their online tutorials are among the earliest inspirations for this project. More so than my old statistics seminar lecture notes, high-quality and freely-available resources like this are where most of my day-to-day data analysis skills come from. We need more resources like this. Hayes’s work has become influential in many corners of the academy, including my own–psychology. His PROCESS macro has been aimed at SPSS and SAS users, which is understandable given their popularity in the social sciences. Over the past few years, I’ve moved away from proprietary programs like SPSS to R. R free, open source, and I find it a more flexible and useful tool for data analysis. In fairness, Hayes expanded his second edition to include R code, which is a great move forward. But his work is done from a frequentist OLS perspective and there have been a lot of exciting developments in the world of applied Bayesian statistics. If you’re an R user and want to learn about Bayesian data analysis, I think Bürkner’s brms is the best package around. It’s flexible, uses reasonably-approachable syntax, has sensible defaults, and offers a wide array of post-processing convenience functions. In addition, the R code in Hayes’s second edition does not leverage the power of the tidyverse. The purpose of this project is to connect Hayes’s insights into regression with the Bayesian paradigm. We’ll do so within the free and open-source R ecosystem, highlighting the Bayesian brms package, and using functions from the tidyverse and friends (e.g., tidybayes) to streamline our code. My assumptions about you If you’re looking at this project, I’m guessing you’re either a graduate student or a post-graduate academic or researcher of some sort, which comes with the presumption you have at least a 101-level foundation in statistics. If you’re rusty, check out Legler and Roback’s free bookdown text, Broadening Your Statistical Horizons or Navarro’s free Learning Statistics with R. I’m also presuming you are at least vaguely familiar with Bayesian statistics. For those totally new to Bayesian regression and HMC estimation, look at this paper, watch a few of these engaging lectures, or even start with my other project based on this excellent text. I’m also presuming a basic working fluency in R and a vague idea about what the tidyverse is. If you’re totally new to R, consider starting with Peng’s R Programming for Data Science. And the best introduction to the tidyvese-style of data analysis I’ve found is Grolemund and Wickham’s R for Data Science. That said, you do not need to be totally fluent in statistics or R. Otherwise why would you need this project, anyway? IMO, the most important things are curiosity, a willingness to try, and persistent tinkering. I love this stuff. Hopefully you will, too. How to use and understand this project This project is not meant to stand alone. It’s a supplement to the second edition of Hayes’s text. I follow the structure of his text, chapter by chapter, translating his analyses into brms and tidyverse code. However, many of the sections in the text are composed entirely of equations and prose, leaving us nothing to translate. When we run into those sections, the corresponding sections in this project will be sparse or blank. I imagine students might reference this project as they progress through Hayes’s text. I also imagine working data analysts might use this project in conjunction with Hayes’s text as they flip to the specific sections that seem relevant to solving their data challenges. I reproduce the bulk of the figures in the text, too. The plots in the first few chapters are the closest to those in the text. However, I’m passionate about data visualization and like to play around with color palettes, formatting templates, and other conventions quite a bit. As a result, the plots in each chapter have their own look and feel. I also like to highlight some of the unique strengths Bayesian analyses brings to the table, such as the ease with which you can depict uncertainty with density plots, interval ribbons around regression lines, and spaghetti plots. For more on some of these topics, chapters 3, 7, and 28 in R4DS, Healy’s Data Visualization: A practical introduction, or Wickham’s ggplot2: Elegant Graphics for Data Analysis. In this project, I use a handful of formatting conventions gleaned from R4DS and R Markdown: The Definitive Guide. I put R and R packages (e.g., tidybayes) in boldface. R code blocks and their output appear in a gray background. E.g., 2 + 2 ## [1] 4 Functions are in a typewriter font and followed by parentheses, all atop a gray background (e.g., brm()). When I want to make explicit what packages a given function comes from, I insert the double-colon operator :: between the package name and the function (e.g., tidyr::gather()). R objects, such as data or function arguments, are in typewriter font atop a gray background (e.g., d or size = 2). Hyperlinks are denoted by their typical blue-colored font. Times change and so do we I released the 1.0.0 version of this book in July of 2018. This 1.1.0 version includes a lot of changes. Most notably, all models have been refit with brms 2.10.3, the introduction to Bayesian information criteria now reflects the updates introduced in brms 2.10.0, I have updated the multivariate model code with the mvbind() and mvbf() functions, I have made greater use of the handy tidybayes package for post-processing models, I have updated and simplified a lot of the tidyverse code, all fit objects have sequential names and are now saved in .rda files in the fits folder on GitHub, I have substantially increased the amount of Hayes quotes, I added more statistical formulas throughout the text, I added a version of Chapter 14, which includes warnings about relying on cross-sectional mediation, and the various R objects enjoy simpler and more standardized names. It’s unclear what future versions of this book may hold. Candidates include more talk about model priors, examples of multilevel mediation, examples of longitudinal mediation, and sterner warnings against cross-sectional mediation. We’ll see. In the meantime, feel free to make suggestions or report typos and coding goofs here. "],
["introduction.html", "1 Introduction References Session info", " 1 Introduction Since there’s no code or data plots in this chapter, there’s nothing to translate. Enjoy an old video of Hayes promoting conditional process analysis, instead. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_3.6.0 magrittr_1.5 tools_3.6.0 htmltools_0.4.0 ## [5] Rcpp_1.0.2 stringi_1.4.3 rmarkdown_1.13 knitr_1.23 ## [9] stringr_1.4.0 xfun_0.10 digest_0.6.21 rlang_0.4.1 ## [13] evaluate_0.14 "],
["fundamentals-of-linear-regression.html", "2 Fundamentals of Linear Regression 2.1 Correlation and prediction 2.2 The simple linear regression model 2.3 Alternative explanations for association 2.4 Multiple linear regression 2.5 Measures of model fit 2.6 Statistical inference 2.7 Multicategorical antecedent variables 2.8 Assumptions for interpretation and statistical inference Reference Session info Footnote", " 2 Fundamentals of Linear Regression Linear regression is the foundation of most of the methods [Hayes described in his] book, so a solid understanding of the fundamentals of linear regression is essential. I assume that most readers have been exposed to linear regression in some form before discovering this book, and so some of the material will be review. Even so, I encourage everyone to read this chapter. (p. 30) Since we’re adding Bayes and the tidyverse into the mix, walking through this chapter will be double important, for us. 2.1 Correlation and prediction Here we load a couple necessary packages, load the data, and take a peek. library(tidyverse) glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) ## Observations: 815 ## Variables: 7 ## $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1.0, 2.6, … ## $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.67, 3.00, … ## $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.67, 2.00, … ## $ ideology &lt;dbl&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, 5, 4, 5, … ## $ age &lt;dbl&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 38, 63, 71… ## $ sex &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, … ## $ partyid &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1, 1, … If you are new to tidyverse-style syntax, possibly the oddest component is the pipe (i.e., %&gt;%). I’m not going to explain the %&gt;% in this project, but you might learn more about in this brief clip, starting around minute 21:25 in this talk by Wickham, or in section 5.6.1 from Grolemund and Wickham’s R for Data Science. Really, all of chapter 5 of R4DS is great for new R and new tidyverse users, and their chapter 3 is a nice introduction to plotting with ggplot2. Here is our version of Figure 2.1. glbwarm %&gt;% group_by(negemot, govact) %&gt;% count() %&gt;% ggplot(aes(x = negemot, y = govact, size = n)) + geom_point(show.legend = F) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + theme_bw() There are other ways to handle the overplotting issue, such as jittering. glbwarm %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + theme_bw() The cor() function is a simple way to compute a Pearson’s correlation coefficient. cor(glbwarm$negemot, glbwarm$govact) ## [1] 0.5777458 If you want more plentiful output, the cor.test() function returns a \\(t\\)-value, the degrees of freedom, the corresponding \\(p\\)-value and the 95% confidence intervals, in addition to the Pearson’s correlation coefficient. cor.test(glbwarm$negemot, glbwarm$govact) ## ## Pearson&#39;s product-moment correlation ## ## data: glbwarm$negemot and glbwarm$govact ## t = 20.183, df = 813, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.5301050 0.6217505 ## sample estimates: ## cor ## 0.5777458 To get the Bayesian version, we’ll open our focal statistical package, Bürkner’s brms. [And I’ll briefly note that you could also do many of these analyses with other packages, such as blavaan or rstanarm. I just prefer brms.] library(brms) We’ll start simple and just use the default priors and settings, but with the addition of parallel sampling via cores = 4. model2.1 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot, govact) ~ 1, cores = 4) We can examine a summary of the output with the print() function. print(model2.1) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot ~ 1 ## govact ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemot_Intercept 3.56 0.05 3.46 3.66 1.00 3586 3085 ## govact_Intercept 4.59 0.05 4.50 4.68 1.00 3742 3188 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemot 1.53 0.04 1.46 1.61 1.00 3276 2964 ## sigma_govact 1.36 0.03 1.30 1.43 1.00 3209 2825 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemot,govact) 0.58 0.02 0.53 0.62 1.00 3496 2476 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In regression models, we typically use predictor variables to explain variation in our criterion variables. It’s pretty much never the case that our predictors explain all the variation. The variation that’s left over is often called residual variation, residual variance, residuals, error, or even \\(\\epsilon\\). Throughout the text, Hayes typically referred to it as \\(e\\). More formally, when we use likelihood-based estimators, such as maximum likelihood (popular with multilevel modeling and structural equation modeling) or Bayesian estimators, we express the models for our criterion variables in terms of likelihood functions. Probably the most common likelihood function, and the one consistent with the models in Hayes’s text, is the Gaussian likelihood. With that likelihood we say our criterion variable \\(y_i\\) is normally distributed with a mean \\(\\mu\\) and standard deviation \\(\\sigma\\). We might express that formally as \\[ y_i \\sim \\text{Normal} (\\mu, \\sigma), \\] where \\(\\sim\\) stands for “is distributed as” and \\(i\\) indexes the \\(i^\\text{th}\\) row in the data. When we add predictors to the model, they are typically used to model the mean \\(\\mu\\). Thus, in the case there we have a sole predictor \\(x_i\\) which varies across participants, we’d expand our model formula to \\[\\begin{align*} y_i &amp; \\sim \\text{Normal} (\\mu_i, \\sigma) \\\\ \\mu_i &amp; = \\beta_0 + \\beta_1 x_i, \\end{align*}\\] where \\(\\beta_0\\) is the intercept and \\(\\beta_1\\) is the slope for predictor \\(x\\), which varies across cases. In this formulation, \\(\\sigma\\) is the standard deviation after accounting for the systemic variation explained by \\(x_i\\). That is, it’s the residual variance (i.e., \\(\\epsilon\\)), but in a standard-deviation metric. Why in a standard deviation metric?, you ask. There are technical reasons why brms expresses it as a standard deviation which I’m not going to go into, here. Just beware that whereas many frequentist software packages express the residual variation in a variance metric, it’s expressed in a standard-deviation metric in brms. Just go with it and move on. Within the brms framework, \\(\\sigma\\) of the Gaussian likelihood is considered a “family-specific” parameter. As it turns out, there are many other fine likelihood functions in addition to the Gaussian and not all of them have a \\(\\sigma\\) parameter. For example, there is no \\(\\sigma\\) for the Poisson 1 distribution, which is popular likelihood function for count variables. Because Bürkner made the brms package capable of a variety of likelihood functions, it behooved him to give this section of the output a generic name. When you have a regression model with multiple Gaussian criterion variables, those variables will typically have some degree of covariation. It’s often termed residual covariance, particularly within the structural equation modeling paradigm 2. But when you have an intercept-only regression model with multiple variables, that residual covariance is just a covariance. And when you express those variation parameters in terms of standard deviations \\(\\sigma\\), their covariance is expressed as a correlation \\(\\rho\\). Since our multivariate model is of two variables, we have one \\(\\rho\\) parameter for the \\(\\sigma\\)s, rescor(negemot,govact), which is our Bayesian analogue to the Pearson’s correlation. To learn more about the multivariate syntax in brms, click here or execute vignette(&quot;brms_multivariate&quot;). Or just hold your horses until we get into mediation. All of our mediation models will use one version of the multivariate syntax or another. But to clarify the output, above: ‘Estimate’ = the posterior mean, analogous to the frequentist point estimate, ‘Est.Error’ = the posterior \\(SD\\), analogous to the frequentist standard error, ‘l-95% CI’ = the lower-level of the percentile-based 95% Bayesian credible interval, and ‘u-95% CI’ = the upper-level of the same. 2.2 The simple linear regression model Here is how one might get the simple OLS coefficients in base R with the lm() function. (model2.2 &lt;- lm(data = glbwarm, govact ~ 1 + negemot)) ## ## Call: ## lm(formula = govact ~ 1 + negemot, data = glbwarm) ## ## Coefficients: ## (Intercept) negemot ## 2.7573 0.5142 For more detailed output, put the model object model2.2 into the summary() function. summary(model2.2) ## ## Call: ## lm(formula = govact ~ 1 + negemot, data = glbwarm) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.3285 -0.6731 0.1018 0.7554 3.2142 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.75732 0.09866 27.95 &lt;2e-16 *** ## negemot 0.51424 0.02548 20.18 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.111 on 813 degrees of freedom ## Multiple R-squared: 0.3338, Adjusted R-squared: 0.333 ## F-statistic: 407.3 on 1 and 813 DF, p-value: &lt; 2.2e-16 Here’s the Bayesian model in brms. model2.3 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot, cores = 4) There are several ways to get a brms model summary. A go-to is with the summary() function, just like we did with our OLS model. summary(model2.3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 2.76 0.10 2.56 2.95 1.00 3899 2636 ## negemot 0.51 0.03 0.47 0.56 1.00 3976 2642 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.11 0.03 1.06 1.17 1.00 3833 3304 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The print() function works very much the same way. To get a more focused look, you can use the posterior_summary() function: posterior_summary(model2.3) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 2.7586363 0.09823326 2.5641513 2.9473085 ## b_negemot 0.5138856 0.02515461 0.4651076 0.5638099 ## sigma 1.1129151 0.02782781 1.0607317 1.1688957 ## lp__ -1248.6113700 1.22961873 -1251.8462595 -1247.2203071 That also yields the log posterior, lp__, which you can learn more about here or here. We won’t focus on the lp__ directly in this project. But its influence will be lurking in the shadows. But anyways, the Q2.5 and Q97.5, are the lower- and upper-levels of the 95% credible intervals. The Q prefix stands for quantile (see this thread). In this case, these are a renamed version of the l-95% CI and u-95% CI columns from our summary() output. To make a quick plot of the regression line, one can use the convenient brms::conditional_effects() function. conditional_effects(model2.3) If you want to customize that output, you might nest it in plot(). plot(conditional_effects(model2.3), points = T, point_args = c(height = .05, width = .05, alpha = 1/2, size = 1/3)) It’s also useful to be able to work with the output of a brms model directly. For our first step, we’ll put our posterior draws into a data frame with the posterior_samples() function. post &lt;- posterior_samples(model2.3) head(post) ## b_Intercept b_negemot sigma lp__ ## 1 2.746242 0.5070495 1.060411 -1249.422 ## 2 2.791774 0.5103668 1.136106 -1247.674 ## 3 2.884980 0.4800574 1.081211 -1248.660 ## 4 2.815726 0.4967236 1.098271 -1247.455 ## 5 2.735722 0.5223162 1.083676 -1247.670 ## 6 2.698650 0.5447054 1.100676 -1248.731 Next, we’ll use the fitted() function to simulate model-implied summaries for the expected govact value, given particular predictor values. Our first model only has negemot as a predictor, and we’ll ask for the expected govact values for negemot ranging from 0 to 7. nd &lt;- tibble(negemot = seq(from = 0, to = 7, length.out = 30)) f &lt;- fitted(model2.3, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) head(f) ## Estimate Est.Error Q2.5 Q97.5 negemot ## 1 2.758636 0.09823326 2.564151 2.947309 0.0000000 ## 2 2.882678 0.09270198 2.699714 3.061210 0.2413793 ## 3 3.006719 0.08724263 2.835814 3.175164 0.4827586 ## 4 3.130760 0.08186959 2.971287 3.288608 0.7241379 ## 5 3.254802 0.07660101 3.105377 3.402664 0.9655172 ## 6 3.378843 0.07146002 3.240015 3.517081 1.2068966 The first two columns should look familiar to the output from summary(model2.3), above. The next two columns, Q2.5 and Q97.5, are the lower- and upper-levels of the 95% credible intervals, like we got from posterior_samples(). The final column is the result of the bind_cols(nd) code. Here’s our bespoke version of Figure 2.4. glbwarm %&gt;% group_by(negemot, govact) %&gt;% count() %&gt;% ggplot(aes(x = negemot)) + geom_point(aes(y = govact, size = n), show.legend = F) + geom_ribbon(data = f, aes(ymin = Q2.5, ymax = Q97.5), fill = &quot;grey75&quot;, alpha = 3/4) + geom_line(data = f, aes(y = Estimate)) + annotate(&quot;text&quot;, x = 2.2, y = 7.5, label = &quot;Cases with positive residuals&quot;, color = &quot;red3&quot;) + annotate(&quot;text&quot;, x = 4.75, y = .8, label = &quot;Cases with negative residuals&quot;, color = &quot;blue3&quot;) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + coord_cartesian(xlim = range(glbwarm$negemot)) + theme_bw() Note how that figure is a combination of the original glbwarm data and our f output. 2.2.1 Interpretation of the constant and regression coefficient. “The regression constant is conceptually equivalent to the \\(Y\\)-intercept in the equation for a line. It quantifies the estimated value of \\(Y\\) when \\(X = 0\\)” (p. 39). 2.2.2 The standardized regression model. Thus far, the interpretation of the regression coefficients in a regression model has been couched in unstandardized or raw metric form. Many regression routines will also produce a version of the model in standardized form. The standardized regression model is what results when all variables are first standardized prior to estimation of the model by expressing each measurement in units of standard deviations from the sample mean. (p. 40, emphasis in the original) brms will not produce standardized solutions on the fly. To get them, you will have to manually standardize the variables before entering them into the model. 2.2.3 Simple linear regression with a dichotomous antecedent variable. In the glbwarm data, sex is a dichotomous variable. glbwarm %&gt;% ggplot(aes(x = sex)) + geom_bar() + theme_bw() In these data, sex is coded females = 0, males = 1. Here we add sex to the model. model2.4 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + sex, cores = 4) Check the summary. print(model2.4) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + sex ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.72 0.07 4.59 4.85 1.00 4737 3203 ## sex -0.27 0.10 -0.45 -0.08 1.00 4388 3046 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.36 0.03 1.29 1.43 1.00 4878 3019 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our model summary is very close to that in the text. If you just wanted the coefficients, you might use the fixef() function. fixef(model2.4) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.719 0.067 4.589 4.853 ## sex -0.270 0.096 -0.455 -0.079 Though not necessary, we used the round() function to reduce the number of significant digits in the output. You can get a little more information with the posterior_summary() function. But since Bayesian estimation yields an entire posterior distribution, you can visualize that distribution in any number of ways. Because we’ll be using ggplot2, we’ll need to put the posterior draws into a data frame before plotting. post &lt;- posterior_samples(model2.4) We could summarize the posterior with boxplots post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% pivot_longer(cols = c(male, female)) %&gt;% ggplot(aes(x = name, y = value)) + geom_boxplot(aes(fill = name)) + theme_bw() + theme(legend.position = &quot;none&quot;) or with overlapping density plots post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% pivot_longer(cols = c(male, female)) %&gt;% ggplot(aes(x = value, group = name, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = 3/4) + theme_bw() or even with violin plots with superimposed posterior medians and 95% intervals. post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% pivot_longer(cols = c(male, female)) %&gt;% ggplot(aes(x = name, y = value)) + geom_violin(aes(fill = name), color = &quot;transparent&quot;, alpha = 3/4) + stat_summary(fun.y = median, fun.ymin = function(i){quantile(i, probs = .025)}, fun.ymax = function(i){quantile(i, probs = .975)}) + theme_bw() + theme(legend.position = &quot;none&quot;) For even more ideas, see Matthew Kay’s tidybayes package. As Hayes discussed on page 42, you can also get a sense of the model estimates for women and men with a little addition. Here we continue to use the round() function to simplify the output. # for women round(fixef(model2.4)[1, ], digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## 4.72 0.07 4.59 4.85 # for men round(fixef(model2.4)[1, ] + fixef(model2.4)[2, ], digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## 4.45 0.16 4.13 4.77 Hayes then considered that although the model will always generate the group means, the regression coefficient and regression constant will depend on how the two groups are coded. For instance, suppose females were coded \\(X = −1\\) and males were coded \\(X = 1\\). (p. 42) To follow along, we’ll first recode sex, saving it as sex_recode. glbwarm &lt;- glbwarm %&gt;% mutate(sex_recode = if_else(sex == 0, -1, 1)) Now fit the new model. model2.5 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + sex_recode, cores = 4) Check the primary coefficients. fixef(model2.5) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.584837 0.04871590 4.4879171 4.67992636 ## sex_recode -0.134560 0.04764951 -0.2259731 -0.04023795 They match up well with the results in the middle of page 42. Now the Intercept in the output, what Hayes called \\(i_Y\\) is the unweighted mean of the means, \\((\\overline Y_\\text{male} + \\overline Y_\\text{female}) / 2\\), and the coefficient sex_recode (i.e., what Hayes called \\(b\\)) is one half the difference between those means. Here’s how to work with the posterior draws from this model to reproduce the group mean estimates. posterior_samples(model2.5) %&gt;% transmute(male = b_Intercept + b_sex_recode * 1, female = b_Intercept + b_sex_recode * -1) %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value, group = name, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = 3/4) + theme_bw() You’ll see it looks just like the plot from above. 2.2.3.1 A caution about the standardized regression coefficient. The standardized regression coefficient is a function of both the mean difference and the distribution of the cases across the groups. This is an undesirable property of \\(\\tilde b\\) when \\(X\\) is dichotomous. I recommend that the standardized regression coefficient for a dichotomous antecedent variable not be interpreted or reported. If you desire an index of a mean difference in standard deviation units, I recommend standardizing \\(Y\\) but not the dichotomous \\(X\\) and then interpreting the unstandardized regression coefficient in a model estimating \\(Z_Y\\) from \\(X\\). In such a model, \\(b\\) is a partially standardized regression coefficient. (pp. 43–44, emphasis in the original) Here’s how to fit the partially-standardized model, first with lm(). # standardize the Y glbwarm &lt;- glbwarm %&gt;% mutate(govact_z = (govact - mean(govact)) / sd(govact)) # fit the model lm(data = glbwarm, govact_z ~ 1 + sex) ## ## Call: ## lm(formula = govact_z ~ 1 + sex, data = glbwarm) ## ## Coefficients: ## (Intercept) sex ## 0.09629 -0.19717 Now we’ll fit the model as Bayesians with brms::brm(). model2.6 &lt;- brm(data = glbwarm, family = gaussian, govact_z ~ 1 + sex, cores = 4) fixef(model2.6) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 0.0949203 0.04989422 -0.00281135 0.19336975 ## sex -0.1949099 0.07008134 -0.32958274 -0.05282248 The constant \\(i_Y\\) is the mean standardized \\(Y\\) for females, and \\(b\\) is the mean difference between males and females in standard deviations of \\(Y\\). So men are estimated to differ from women by 0.197 standard deviations in their support for government action. The negative sign for \\(b\\) means males are lower than females, on average, in their support. (p. 44) The result from our Bayesian model was the same as the OLS results up to two decimal places. This will often be the case. One is not more correct. They are the results of using different procedures. 2.2.4 A note on symbolic representations. This section is worthy of repeating in full. A brief digression is in order at this point. It is important when reporting the results of an analysis to define the symbols you use unless there is a strong convention, for a failure to do so can invite confusion. Different uses of \\(b\\) and \\(\\beta\\) in regression analysis are an important case in point. There is much inconsistency in the substantive and methodology literature as to how regression coefficients are symbolized in unstandardized versus standardized form. Some use \\(b\\) or \\(B\\) to refer to the unstandardized regression coefficient and \\(\\beta\\) to refer to the standardized regression coefficient. Others, rather than using \\(\\beta\\), spell it out by referencing “beta weights” or just talk about the “betas.” Some use \\(\\beta\\) to refer to a population regression coefficient, to distinguish it from a sample estimate, others use \\(\\beta\\) as the unstandardized regression weight, and there are still others who use \\(\\hat \\beta\\) to refer to a sample unstandardized regression coefficient and leave the hat off for its corresponding population or “true” value. In this book, I use \\(\\tilde \\beta\\) for the standardized regression weight. Ultimately, the symbols we use are for the most part arbitrary. We can use any symbols we want. My point is that you should not assume others will know what symbols you use mean, for your familiar symbols to represent certain concepts may not be understood as representing those concepts by all. The same applies to terms such as “beta coefficient” or other verbalizations of symbols. Best to define your symbols in advance, or otherwise let your reader know what your symbols mean when used in text and tables. This will help others better understand and interpret your work. (p. 44) 2.3 Alternative explanations for association That “correlation does not imply causation” is etched into the brains of all scientists. If variables \\(X\\) and \\(Y\\) are correlated, that doesn’t mean that \\(X\\) causes \\(Y\\) or that \\(Y\\) causes \\(X\\). The ability to infer cause–effect is not even a statistical matter in the end. Rather, it is the design of one’s study, the data collection procedures one employs, and theoretical plausibility that most directly influence whether a cause–effect claim can be made and with what degree of confidence, not the size or sign of a statistical index of association. (p. 45) On page 46, Hayes produced a couple correlations. Here’s how to get them from base R. cor(glbwarm$sex, glbwarm$negemot) ## [1] -0.1173564 cor(glbwarm$sex, glbwarm$govact) ## [1] -0.09861854 Again, if we wanted to get full Bayesian estimates, we’d fit an intercept-only multivariate model. model2.7 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot, govact, sex) ~ 1, cores = 4) print(model2.7, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot ~ 1 ## govact ~ 1 ## sex ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemot_Intercept 3.557 0.054 3.450 3.663 1.000 5294 3105 ## govact_Intercept 4.586 0.048 4.492 4.680 1.001 5602 3064 ## sex_Intercept 0.489 0.018 0.453 0.523 1.000 7096 2955 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemot 1.533 0.038 1.458 1.609 1.001 4743 3266 ## sigma_govact 1.364 0.034 1.297 1.436 1.000 4588 2923 ## sigma_sex 0.502 0.012 0.478 0.527 1.001 6214 2739 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemot,govact) 0.577 0.024 0.528 0.622 1.001 4639 3367 ## rescor(negemot,sex) -0.116 0.034 -0.184 -0.046 1.000 6996 3104 ## rescor(govact,sex) -0.098 0.034 -0.166 -0.033 1.000 6045 3114 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). For our purposes, the action is in the ‘rescor(\\(i\\), \\(j\\))’ portions of the ‘Family Specific Parameters’ section. Anyway, if you wanted to get all the Pearson’s correlations among the glbwarm variables, rather than piecewise cor() approach, you could use the lowerCor() function from the psych package. psych::lowerCor(glbwarm[, 1:7], digits = 3) ## govact posemt negemt idelgy age sex partyd ## govact 1.000 ## posemot 0.043 1.000 ## negemot 0.578 0.128 1.000 ## ideology -0.418 -0.029 -0.349 1.000 ## age -0.097 0.042 -0.057 0.212 1.000 ## sex -0.099 0.074 -0.117 0.133 0.166 1.000 ## partyid -0.360 -0.036 -0.324 0.619 0.154 0.109 1.000 2.4 Multiple linear regression The simple linear regression model is easily extended to the estimation of a consequent variable using more than one antecedent variable. Including more than one antecedent in a regression model allows you to simultaneously investigate the role of multiple influences on a consequent variable. An additional and important benefit of the multiple regression model is that it provides various measures of partial association that quantify the component of the association between an antecedent and a consequent that is unique to that antecedent relative to other antecedent variables in the model. (p. 48, emphasis in the original) Using Hayes’ notation, the model we’re about follows the basic equation \\[\\hat Y = i_Y + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4 + b_4 X_5.\\] For us, there’s technically more involved because our Bayesian paradigm includes priors, which we’re not focusing on at the moment. Anyway, there’s nothing particularly special about jumping from univariable to multivariable models with brms. You just keep tacking on predictors with the + operator. model2.8 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + posemot + ideology + sex + age, cores = 4) print(model2.8) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + posemot + ideology + sex + age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.06 0.20 3.68 4.45 1.00 5191 3658 ## negemot 0.44 0.03 0.39 0.49 1.00 4980 2981 ## posemot -0.03 0.03 -0.08 0.03 1.00 5830 3143 ## ideology -0.22 0.03 -0.27 -0.17 1.00 4484 3113 ## sex -0.01 0.08 -0.16 0.14 1.00 5623 2719 ## age -0.00 0.00 -0.01 0.00 1.00 5705 3159 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.07 0.03 1.02 1.12 1.00 6039 2837 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Following Hayes on pages 50 and 51, here is the posterior mean (i.e., what you might call the Bayesian point estimate) for someone with negative emotions = 3, positive emotions = 4, ideology = 2, is male (i.e., sex = 1), and is 30 years of age. fixef(model2.8)[1] + fixef(model2.8)[2] * 3 + fixef(model2.8)[3] * 4 + fixef(model2.8)[4] * 2 + fixef(model2.8)[5] * 1 + fixef(model2.8)[6] * 30 ## [1] 4.791801 Here’s the same deal for a man of the same profile, but with one point higher on negemot. fixef(model2.8)[1] + fixef(model2.8)[2] * 4 + fixef(model2.8)[3] * 4 + fixef(model2.8)[4] * 2 + fixef(model2.8)[5] * 1 + fixef(model2.8)[6] * 30 ## [1] 5.232573 If you want a full expression of the model uncertaintly in terms of the shape of the posterior distribution and the 95% intervals, you’ll probably just want to use posterior_samples() and do a little data processing. post &lt;- posterior_samples(model2.8) post &lt;- post %&gt;% mutate(our_posterior = b_Intercept + b_negemot * 4 + b_posemot * 4 + b_ideology * 2 + b_sex * 1 + b_age * 30) # this intermediary step will make it easier to specify the break points and their labels for the x-axis post_summary &lt;- quantile(post$our_posterior, probs = c(.025, .5, .975)) %&gt;% as_tibble() %&gt;% mutate(labels = value %&gt;% round(digits = 3) %&gt;% as.character()) # plot! ggplot(data = post, aes(x = our_posterior)) + geom_density(fill = &quot;black&quot;) + geom_vline(xintercept = post_summary$value, size = c(.5, .75, .5), linetype = c(2, 1, 2), color = &quot;white&quot;) + scale_x_continuous(NULL, breaks = post_summary$value, labels = post_summary$labels) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The expected govact score for a 30-year-old man for\\nwhom negemot and posemot both equal 4 and ideology\\nequals 2. The solid and dashed white vertical lines are the\\nposterior median and 95% intervals, respectively.&quot;) + theme_bw() In the text, Hayes showed that individuals based on these two profiles would be expected to differ by 0.441 (i.e., \\(5.244 - 4.803 = 0.441\\)). That’s fine if you’re only working with OLS point estimates. But a proper Bayesian approach would express the difference in terms of an entire poster distribution, or at least a point estimate accompanied by some sort of intervals. Here we’ll just work with the posterior to create a difference distribution. You could do that with a little deft posterior_samples() wrangling. Here we’ll employ fitted(). nd &lt;- tibble(negemot = c(3, 4), posemot = 4, ideology = 2, sex = 1, age = 30) fitted(model2.8, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% set_names(str_c(&quot;condition_&quot;, letters[1:2])) %&gt;% mutate(difference = condition_b - condition_a) %&gt;% ggplot(aes(x = difference)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + ggtitle(&quot;The posterior density for the difference between\\nthe two conditions.&quot;) + theme_bw() 2.4.1 The standardized regression model. As brms doesn’t automatically give us the standardized coefficients the way OLS output often does, we’ll have to be proactive. One solution is just to standardized the data themselves and then re-fit the model with those standardized variables. That leads us to the issue of how one standardized variables to begin with. Recall that standardizing entails subtracting the mean of a variable from that variable and then dividing that value by the standard deviation. We don’t want to do that by hand. So one handy way is to make a custom function to do that work for us. sandardize &lt;- function(x) { (x - mean(x)) / sd(x) } Go here to learn more about making custom functions in R. Here we’ll employ our custom standardize() function to make standardized versions of our variables. glbwarm &lt;- glbwarm %&gt;% mutate(posemot_z = sandardize(posemot), negemot_z = sandardize(negemot), ideology_z = sandardize(ideology), sex_z = sandardize(sex), age_z = sandardize(age)) Now we’ve got us our standardized variables, let’s fit a standardized model. model2.9 &lt;- brm(data = glbwarm, family = gaussian, govact_z ~ 1 + negemot_z + posemot_z + ideology_z + sex_z + age_z, cores = 4) Here are the newly standardized coefficient summaries, minus the Intercept. fixef(model2.9)[-1, ] %&gt;% round(3) ## Estimate Est.Error Q2.5 Q97.5 ## negemot_z 0.495 0.030 0.436 0.554 ## posemot_z -0.027 0.028 -0.082 0.028 ## ideology_z -0.242 0.030 -0.300 -0.183 ## sex_z -0.004 0.028 -0.058 0.052 ## age_z -0.015 0.029 -0.072 0.041 Our coefficients match up nicely with those on page 52 in the text. Just as with Hayes’s OLS estimates, we should not attempt to interpret the standardized sex_z coefficient from our Bayesian model. Here’s how we’d fit a partially-standardized model–a model in which all variables except for sex are standardized. model2.10 &lt;- update(model2.9, newdata = glbwarm, formula = govact_z ~ 1 + negemot_z + posemot_z + ideology_z + sex + age_z, cores = 4) Notice our use of the update() function. If you want to hastily fit a brms model of the same basic form of a prior model, you can just update some of the parameters of that original fit. In this case, all we did was swap out one of the predictors. To accommodate that change, we used the newdata argument so the model had access to the new variable and then we fed in the new formula. Anyway, here are the coefficient summaries, including the Intercept, for the partially-standardized model. fixef(model2.10) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 0.003 0.039 -0.074 0.078 ## negemot_z 0.495 0.030 0.437 0.554 ## posemot_z -0.027 0.028 -0.081 0.027 ## ideology_z -0.242 0.030 -0.303 -0.183 ## sex -0.008 0.055 -0.116 0.099 ## age_z -0.016 0.028 -0.071 0.041 As Hayes wrote, now sex = -0.008 has a sensible interpretation. “We can say that men and women differ by [-0.008] standard deviations in their support for government action when all other variables in the model are held constant (p. 53).” On page 54, Hayes gave us the equation to transform unstandardized coefficients to standardized ones: \\[ \\tilde b_i = b_i \\left ( \\frac{SD_{X_{i}}}{SD_{Y}} \\right ) \\] Let’s give it a whirl with negemot. # here&#39;s the coefficient for `negemot` from the standardized model, `model2.9` fixef(model2.9)[&quot;negemot_z&quot;, &quot;Estimate&quot;] ## [1] 0.4953418 # here&#39;s the coefficient for `negemot` from the unstandardized model, `model2.8` fixef(model2.8)[&quot;negemot&quot;, &quot;Estimate&quot;] ## [1] 0.4407717 # and here we use Hayes&#39; formula to standardize the unstandardized coefficient fixef(model2.8)[&quot;negemot&quot;, &quot;Estimate&quot;] * (sd(glbwarm$negemot) / sd(glbwarm$govact)) ## [1] 0.4952009 Looks like we got it within rounding error–pretty good! However, that was just the posterior mean, the Bayesian point estimate. If we want to more fully express the uncertainty around the mean–and we do–, we’ll need to work with the posterior draws. # the posterior draws from the unstandardized model posterior_samples(model2.8) %&gt;% # using Hayes&#39; formula to standardize `b_negemot` mutate(`hand-made b_negemot_z` = b_negemot * (sd(glbwarm$negemot) / sd(glbwarm$govact))) %&gt;% # tacking on the `b_negemot_z` column from the standardized `model2.9` models posterior draws bind_cols(posterior_samples(model2.9) %&gt;% select(b_negemot_z)) %&gt;% # converting the data to the long format and grouping by `name` pivot_longer(c(`hand-made b_negemot_z`, b_negemot_z)) %&gt;% group_by(name) %&gt;% # here we summarize the results summarise(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 5 ## name mean sd ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b_negemot_z 0.495 0.03 0.436 0.554 ## 2 hand-made b_negemot_z 0.495 0.029 0.437 0.552 Our summary confirms that we can apply Hayes’s formula to a posterior_samples() column in order to get fuller summary statistics for a hand-converted standardized coefficient. This would be in full compliance with, say, APA recommendations to include 95% intervals with all effect sizes–the standardized regression coefficient being the effect size, here. 2.5 Measures of model fit In the Bayesian world, we don’t tend to appeal to the \\(SS_{residual}\\), the \\(MS_{residual}\\), or the standard error of estimate. We do sometimes, however, appeal to the \\(R^2\\). I’m not going to go into the technical details here, but you should be aware that the Bayesian \\(R^2\\) is not calculated the same as the OLS \\(R^2\\). If you want to dive in, check out the paper by Gelman, Goodrich, Gabry, and Vehtari. Here’s how to get it with brms. bayes_R2(model2.8, summary = T) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.388 0.021 0.347 0.427 It even comes with 95% intervals, which will make the editors at APA journals happy. If you want to go beyond summary statistics and take a look at the full posterior, just set summary = F and data wrangle and plot as usual. bayes_R2(model2.8, summary = F) %&gt;% data.frame() %&gt;% ggplot(aes(x = R2)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Behold: The Bayesian &quot;, italic(&quot;R&quot;)^{2}, &quot; distribution for model 2.8&quot;)), x = NULL) + coord_cartesian(xlim = 0:1) + theme_bw() Another way we examine model fit is with graphical posterior predictive checks. Posterior predictive checking is a very general approach, which you might learn more about here or with a few keyword searches in on Gelman’s blog. One basic way is to use the model in order to simulate data and then compare those data with the original data–the basic idea being that good fitting models should produce data similar to the original data. Recall how we’ve used fitted() to make regression lines and expected values? We’ll, now we’ll use predict() to simulate data based on our models. predict(model2.8, summary = F, nsamples = 3) %&gt;% data.frame() %&gt;% set_names(1:nrow(glbwarm)) %&gt;% mutate(simulation = str_c(&quot;simulation: &quot;, 1:n())) %&gt;% pivot_longer(-simulation, names_to = &quot;row&quot;, values_to = &quot;govact&quot;) %&gt;% bind_cols( bind_rows( glbwarm %&gt;% select(-govact), glbwarm %&gt;% select(-govact), glbwarm %&gt;% select(-govact)) ) %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + coord_cartesian(ylim = 0:9) + theme_bw() + facet_wrap(~simulation, ncol = 3) The question is, do these simulated data sets look like the original data? Let’s see. glbwarm %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + coord_cartesian(ylim = 0:9) + theme_bw() Overall, the simulations aren’t bad. But in all three govact tends to veer above 7.5, which is where the original data appear to be bounded. But otherwise the overall shape is pretty close, at least with respect to negemot. There’s nothing special about three simulations. Three is just more than one and gives you a sense of the variance across simulations. Also, we only examined the model fit with respect to negemot. Since there are other variables in the model, we might also assess the model based on them. Another method is with the brms::pp_check() function, which allows users to access a variety of convenience functions from the bayesplot package. Here we’ll use the default settings and just tack on theme_bw() for aesthetics. pp_check(model2.8) + theme_bw() What we did was simulate 10 data sets worth of govact values, plot their densities (i.e., the thin blue lines) and compare them with the density of the original govact values. What we want is for the thin blue lines to largely align with the thick blue line. Though not perfect, the simulations from our model2.8 did a pretty okay job of reproducing the original govact distribution. For more ideas on this method, see the brms reference manual and this vignette for the bayesplot package. 2.6 Statistical inference Here’s a tidyverse way to do Hayes’ simulation from page 57. We’re just using OLS regression with the lm() function. You could do this with Bayesian HMC estimation, but man would it take a while. For our first step, we’ll define two custom functions. # this first one will use the `sample_n()` function to randomly sample from `glbwarm` make_sample &lt;- function(i) { set.seed(i) sample_n(glbwarm, 50, replace = F) } # this second function will fit our model, the same one from `model2.8`, to each of our subsamples glbwarm_model &lt;- function(df) { lm(govact ~ 1 + negemot + posemot + ideology + sex + age, data = df) } Now we’ll run the simulation, wrangle the output, and plot in one fell swoop. # we need an iteration index, which will double as the values we set our seed with in our `make_sample()` function tibble(iter = 1:1e4) %&gt;% group_by(iter) %&gt;% # inserting our subsamples mutate(sample = map(iter, make_sample)) %&gt;% # fitting our models mutate(model = map(sample, glbwarm_model)) %&gt;% # taking those model results and tidying them with the broom package mutate(broom = map(model, broom::tidy)) %&gt;% # unnesting allows us to access our model results unnest(broom) %&gt;% # we&#39;re only going to focus on the estimates for `negemot` filter(term == &quot;negemot&quot;) %&gt;% # here it is, Figure 2.7 ggplot(aes(x = estimate)) + geom_histogram(binwidth = .025, boundary = 0) + labs(x = &quot;Unstandardized regression coefficient for negemot&quot;, y = &quot;Frequency in 1e4 samples of size 50&quot;) + theme_bw() To learn more about this approach to simulations, see this section of R4DS. 2.6.1 Testing a null hypothesis. As Bayesians, we don’t need to wed ourselves to the null hypothesis. We’re not interested in the probability of the data given the null hypothesis. Bayes’ rule, \\[p(\\theta | D) = \\frac{p(D | \\theta) p(\\theta)}{p(D)},\\] gives us the probability of the model parameters, given the data. Though I acknowledge different researchers might set out to ask different things of their data, I propose we’re generally more interested in determining the most probable parameter values than we are the probabilities tested within the NHST paradigm. posterior_samples(model2.8) %&gt;% ggplot(aes(x = b_negemot)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + geom_vline(xintercept = posterior_interval(model2.8)[&quot;b_negemot&quot;, ], color = &quot;white&quot;, linetype = 2) + scale_x_continuous(breaks = posterior_interval(model2.8)[&quot;b_negemot&quot;, ] %&gt;% as.double(), labels = posterior_interval(model2.8)[&quot;b_negemot&quot;, ] %&gt;% as.double() %&gt;% round(digits = 2) %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The most probable values for our b_negemot parameter are the ones around the peak\\nof the density. For convenience, the dashed lines denote the 95% credible intervals.\\nSure, you could ask yourself, &#39;Is zero within those intervals?&#39; But with such rich output,\\nthat seems like an impoverished question to ask.&quot;) + theme_bw() For more discussion the NHST paradigm and how it compares with variations of Bayesian statistics, check out Kruschke’s text, Doing Bayesian Data Analysis, particularly chapters 10 through 13. I’m currently working on translating all his code for use with brms and the tidyverse. You can find that project, here. 2.6.2 Interval estimation. Within the Bayesian paradigm, we don’t use 95% intervals based on the typical frequentist formula. With the brms package, we typically use percentile-based intervals. Take the 95% credible intervals for the negemot coefficient from model model2.8: posterior_interval(model2.8)[&quot;b_negemot&quot;, ] ## 2.5% 97.5% ## 0.3886650 0.4913098 We can actually get those intervals with the simple use of the base R quantile() function. posterior_samples(model2.8) %&gt;% summarize(the_2.5_percentile = quantile(b_negemot, probs = .025), the_97.5_percentile = quantile(b_negemot, probs = .975)) ## the_2.5_percentile the_97.5_percentile ## 1 0.388665 0.4913098 The consequence of this is that our Bayesian credible intervals aren’t necessarily symmetric, which is fine because the posterior distribution for a given parameter isn’t always symmetric. But not all Bayesian intervals are percentile based. John Kruschke, for example, often recommends highest posterior density intervals in his work. The brms package doesn’t have a convenience function for these, but you can compute them with help from the HDInterval package. library(HDInterval) hdi(posterior_samples(model2.8)[ , &quot;b_negemot&quot;], credMass = .95) ## lower upper ## 0.3877626 0.4903139 ## attr(,&quot;credMass&quot;) ## [1] 0.95 Finally, because Bayesians aren’t bound to the NHST paradigm, we aren’t bound to 95% intervals, either. For example, in both his excellent text and as a default in its accompanying rethinking package, Richard McElreath often uses 89% intervals. Alternatively, Andrew Gelman has publicly advocated for 50% intervals. The most important thing is to express the uncertainty in the posterior in a clearly-specified way. If you’d like, say, 80% intervals in your model summary, you can insert a prob argument into either print() or summary(). print(model2.8, prob = .8) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + posemot + ideology + sex + age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.06 0.20 3.79 4.32 1.00 5191 3658 ## negemot 0.44 0.03 0.41 0.47 1.00 4980 2981 ## posemot -0.03 0.03 -0.06 0.01 1.00 5830 3143 ## ideology -0.22 0.03 -0.25 -0.18 1.00 4484 3113 ## sex -0.01 0.08 -0.11 0.09 1.00 5623 2719 ## age -0.00 0.00 -0.00 0.00 1.00 5705 3159 ## ## Family Specific Parameters: ## Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.07 0.03 1.03 1.10 1.00 6039 2837 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Note how two of our columns changed to ‘l-80% CI’ and ‘u-80% CI’. You can specify custom percentile levels with posterior_summary(): posterior_summary(model2.8, probs = c(.9, .8, .7, .6, .4, .3, .2, .1)) %&gt;% round(digits = 2) ## Estimate Est.Error Q90 Q80 Q70 Q60 Q40 Q30 Q20 Q10 ## b_Intercept 4.06 0.20 4.32 4.22 4.16 4.11 4.01 3.95 3.88 3.79 ## b_negemot 0.44 0.03 0.47 0.46 0.45 0.45 0.43 0.43 0.42 0.41 ## b_posemot -0.03 0.03 0.01 0.00 -0.01 -0.02 -0.03 -0.04 -0.05 -0.06 ## b_ideology -0.22 0.03 -0.18 -0.19 -0.20 -0.21 -0.22 -0.23 -0.24 -0.25 ## b_sex -0.01 0.08 0.09 0.05 0.03 0.01 -0.03 -0.05 -0.07 -0.11 ## b_age 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## sigma 1.07 0.03 1.10 1.09 1.08 1.08 1.06 1.05 1.05 1.03 ## lp__ -1215.89 1.93 -1213.76 -1214.28 -1214.69 -1215.12 -1216.01 -1216.59 -1217.38 -1218.51 And of course, you can use multiple interval summaries when you summarize() the output from posterior_samples(). E.g., posterior_samples(model2.8) %&gt;% select(b_Intercept:b_age) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(`l-95% CI` = quantile(value, probs = .025), `u-95% CI` = quantile(value, probs = .975), `l-50% CI` = quantile(value, probs = .25), `u-50% CI` = quantile(value, probs = .75)) %&gt;% mutate_if(is.double, round, digits = 2) ## # A tibble: 6 x 5 ## key `l-95% CI` `u-95% CI` `l-50% CI` `u-50% CI` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b_age -0.01 0 0 0 ## 2 b_ideology -0.27 -0.17 -0.24 -0.2 ## 3 b_Intercept 3.68 4.45 3.92 4.19 ## 4 b_negemot 0.39 0.49 0.42 0.46 ## 5 b_posemot -0.08 0.03 -0.04 -0.01 ## 6 b_sex -0.16 0.14 -0.06 0.04 Throughout this project, I’m going to be lazy and default to conventional 95% intervals, with occasional appearances of 50% intervals. 2.6.3 Testing a hypothesis about a set of antecedent variables. Here we’ll make use of the update() function to hastily fit our reduced model, model5. model2.11 &lt;- update(model2.8, govact ~ 1 + ideology + sex + age, cores = 4) We can get a look at the \\(R^2\\) summaries for our competing models like this. bayes_R2(model2.8) %&gt;% round(digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.39 0.02 0.35 0.43 bayes_R2(model2.11) %&gt;% round(digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.18 0.02 0.14 0.22 So far it looks like our fuller model, model2.8, explains more variation in the data. If we wanted to look at their distributions, we’d set summary = F in the bayes_R2() function and convert the results to a data frame or tibble. Here we use bind_cols() to put the \\(R^2\\) results for both in the same tibble. r2 &lt;- bayes_R2(model2.8, summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;model2.8&quot;) %&gt;% bind_cols( bayes_R2(model2.11, summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;model2.11&quot;) ) head(r2) ## model2.8 model2.11 ## 1 0.3510849 0.1446630 ## 2 0.3508106 0.1879446 ## 3 0.4224058 0.1598793 ## 4 0.3762641 0.1677146 ## 5 0.4080467 0.1882133 ## 6 0.4080467 0.1538636 With our r2 tibble in hand, we’re ready to plot. r2 %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(italic(R)^2))) + coord_cartesian(xlim = 0:1) + theme_bw() Yep, the \\(R^2\\) distribution for model2.8, the one including the emotion variables, is clearly larger than that for the more parsimonious model2.11. And it’d just take a little more data wrangling to get a formal \\(R^2\\) difference score. r2 %&gt;% mutate(difference = model2.11 - model2.8) %&gt;% ggplot(aes(x = difference)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = -1:0) + labs(title = expression(paste(Delta, italic(R)^{2})), subtitle = expression(paste(&quot;This is the amount the &quot;, italic(R)^{2}, &quot; dropped after pruning the emotion variables from the model.&quot;)), x = NULL) + theme_bw() The \\(R^2\\) approach is popular within the social sciences. But it has its limitations, the first of which is that it doesn’t correct for model complexity. The second is it’s not applicable to a range of models, such as those that do not use the Gaussian likelihood (e.g., logistic regression) or to multilevel models. Happily, information criteria offer a more general framework. The AIC is the most popular information criteria among frequentists. Within the Bayesian world, we have the DIC, the WAIC, and the LOO. The DIC is quickly falling out of favor and is not immediately available with the brms package. However, we can use the WAIC and the LOO, both of which are computed in brms via the loo package. With brms, you can compute the WAIC or LOO values and add them to your model fit object with the add_criterion() function. model2.8 &lt;- add_criterion(model2.8, c(&quot;loo&quot;, &quot;waic&quot;)) model2.11 &lt;- add_criterion(model2.11, c(&quot;loo&quot;, &quot;waic&quot;)) Here’s the main loo-summary output for model4. model2.8$loo ## ## Computed from 4000 by 815 log-likelihood matrix ## ## Estimate SE ## elpd_loo -1214.0 22.7 ## p_loo 7.8 0.7 ## looic 2428.0 45.5 ## ------ ## Monte Carlo SE of elpd_loo is 0.0. ## ## All Pareto k estimates are good (k &lt; 0.5). ## See help(&#39;pareto-k-diagnostic&#39;) for details. You get a wealth of output, more of which can be seen with str(model2.8$loo). For now, notice the “All pareto k estimates are good (k &lt; 0.5).” Pareto \\(k\\) values can be used for diagnostics. Each case in the data gets its own \\(k\\) value and we like it when those \\(k\\)s are low. The makers of the loo package get worried when those \\(k\\)s exceed 0.7 and as a result you will get a warning message when they do. Happily, we have no such warning messages in this example. If you want to work with the \\(k\\) values directly, you can extract them and place them into a data frame like so. model2.8$loo$diagnostics %&gt;% data.frame() %&gt;% head() ## pareto_k n_eff ## 1 0.10023379 5260.883 ## 2 -0.03742048 4716.082 ## 3 0.05058887 5196.898 ## 4 0.07108415 2515.394 ## 5 0.03036345 4785.764 ## 6 -0.01275420 5811.755 The pareto_k values can be used to examine cases that are overly-influential on the model parameters, something akin to a Cook’s \\(D_i\\). See, for example this discussion on stackoverflow.com in which several members of the Stan team weighed in. The issue is also discussed in this paper and in this lecture by Aki Vehtari. But anyway, we’re getting ahead of ourselves. Back to the LOO. Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the values of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower information criteria. With compare_ic(), we can compute a formal difference score between multiple loo objects. loo_compare(model2.8, model2.11) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model2.8 0.0 0.0 -1214.0 22.7 7.8 0.7 2428.0 45.5 ## model2.11 -118.4 15.9 -1332.4 20.6 5.0 0.3 2664.8 41.1 We also get a standard error. Here it looks like model2.8 was substantially better, in terms of LOO-values, than model2.11. For more on the LOO, see the loo reference manual, this handy vignette, or the scholarly papers referenced therein. Also, although McElreath doesn’t discuss the LOO, he does cover the topic in general in his text and in his online lectures on the topic. 2.7 Multicategorical antecedent variables “To include a multicategorical antecedent variable representing \\(g\\) groups in a regression model, it must be represented with \\(g − 1\\) variables using one of a variety of different group coding systems”. (p. 66) This isn’t strictly true, but we digress. Hayes went on… One popular system for coding groups is indicator coding, also known as dummy coding. With indicator coding, \\(g − 1\\) indicator variables containing either a zero or one represent which of the \\(g\\) groups a case belongs in, and these indicator variables are used as antecedents in a regression model. To construct indicator codes, create \\(g − 1\\) variables \\(D_i\\) for each case set to 1 if the case is in group \\(i\\), otherwise set \\(D_i\\) to zero. (p. 66, emphasis in the original) Before we get to that, we should examine our multicategorical antecedent variable, partyid. It’s coded 1 = Democrat 2 = Independent 3 = Repuclican. You can get a count of the cases within a give partyid like this. glbwarm %&gt;% count(partyid) ## # A tibble: 3 x 2 ## partyid n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 359 ## 2 2 192 ## 3 3 264 We can get grouped means for govact like this. glbwarm %&gt;% group_by(partyid) %&gt;% summarize(mean_support_for_governmental_action = mean(govact)) ## # A tibble: 3 x 2 ## partyid mean_support_for_governmental_action ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 5.06 ## 2 2 4.61 ## 3 3 3.92 We can make dummies with the if_else() function. We’ll just go ahead and do that right within the brm() function. model2.12 &lt;- brm(data = glbwarm %&gt;% mutate(Democrat = if_else(partyid == 1, 1, 0), Republican = if_else(partyid == 3, 1, 0)), family = gaussian, govact ~ 1 + Democrat + Republican, chains = 4, cores = 4) Check the results. fixef(model2.12) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.6060751 0.0879319 4.4375924 4.7817712 ## Democrat 0.4591856 0.1109220 0.2426579 0.6762889 ## Republican -0.6801175 0.1165303 -0.9097553 -0.4541862 The intercept is the stand-in for Independents and the other two coefficients are difference scores. The \\(R^2\\) is okay. bayes_R2(model2.12) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.132 0.021 0.092 0.174 There’s no need to compute an \\(F\\)-test on our \\(R^2\\). The posterior mean and it’s 95% intervals are well away from zero. But you could use your bayes_R2(model2.12, summary = F) plotting skills from above to more fully inspect the posterior if you’d like. We could also use information criteria. One method would be to compare the WAIC or LOO value of model2.12 with an intercept-only model. First, we’ll need to fit that model. model2.13 &lt;- update(model2.12, govact ~ 1, chains = 4, cores = 4) Here we’ll compute the WAIC for each, save the results to their fit objects, and them compare them with loo_compare(). model2.12 &lt;- add_criterion(model2.12, &quot;waic&quot;) model2.13 &lt;- add_criterion(model2.13, &quot;waic&quot;) loo_compare(model2.12, model2.13, criterion = &quot;waic&quot;) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic ## model2.12 0.0 0.0 -1353.5 20.1 4.0 0.2 2707.1 40.1 ## model2.13 -55.3 10.4 -1408.9 21.3 2.1 0.1 2817.7 42.7 The WAIC comparison suggests model2.12, the one with the partyid dummies, is an improvement over the simple intercept-only model. Another way to compare the information criteria is with AIC-type weighting. The brms package offers a variety of weighting methods via the model_weights() function. mw &lt;- model_weights(model2.12, model2.13, weights = &quot;waic&quot;) mw ## model2.12 model2.13 ## 1.000000e+00 9.386167e-25 If you’re not a fan of scientific notation, you can put the results in a tibble and look at them on a plot. mw %&gt;% as.data.frame() %&gt;% rownames_to_column() %&gt;% set_names(c(&quot;model&quot;, &quot;WAIC weight&quot;)) %&gt;% ggplot(aes(x = `WAIC weight`, y = model)) + geom_point() + labs(subtitle = &quot;The weights should sum to 1. In this case virtually all the weight is placed\\nin model2.12. Recall, that these are RELATIVE weights. Add another model\\nfit into the mix and the weights might well change.&quot;, y = NULL) + theme_bw() + theme(axis.ticks.y = element_blank()) You could, of course, do all this with the LOO. 2.8 Assumptions for interpretation and statistical inference Regression is a handy tool to have in your statistical toolbox. Its utility as a “general data analytic system” (Cohen, 1968) will be apparent throughout this book. But it is a human invention that isn’t perfect, it can lead you astray if used indiscriminately, and it is founded on some assumptions that aren’t always realistic or likely to be met in the circumstances in which the method is applied. (p. 68) 2.8.1 Linearity. “When using OLS regression to model some consequent variable of interest \\(Y\\), you must be willing to assume that the relationship between the variables in the model are linear in nature, or at least approximately linear” (p. 69) 2.8.2 Normality. The brms package is quite general and allows users to fit models from a variety of likelihoods other than the Gaussian. For example, users can accommodate outliers/extreme values with Student’s t regression. You can do count regression with the Poisson or the negative binomial… For more, see McElreath’s lecture introducing the generalized linear model or Bürkner’s vignette, Parameterization of Response Distributions in brms 2.8.3 Homoscedasticity. The brms package can also accommodate homoscedasticity with distributional modeling. In short, one simply models \\(\\sigma\\) in addition to the mean, \\(\\mu\\). See Bürkner’s handy vignette on the topic. 2.8.4 Independence. The issue of independence is where the multilevel model comes on. See any relevant text, such as Statistical Rethinking or Data Analysis Using Regression and Multilevel/Hierarchical Models. And yes, brms is fully capable of handling multilevel models (see here or here). Reference Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] HDInterval_0.2.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-139 matrixStats_0.55.0 xts_0.11-2 lubridate_1.7.4 threejs_0.3.1 ## [6] httr_1.4.0 rstan_2.19.2 tools_3.6.0 backports_1.1.5 utf8_1.1.4 ## [11] R6_2.4.0 DT_0.9 lazyeval_0.2.2 colorspace_1.4-1 withr_2.1.2 ## [16] mnormt_1.5-5 prettyunits_1.0.2 processx_3.4.1 tidyselect_0.2.5 gridExtra_2.3 ## [21] Brobdingnag_1.2-6 compiler_3.6.0 cli_1.1.0 rvest_0.3.4 xml2_1.2.0 ## [26] shinyjs_1.0 labeling_0.3 colourpicker_1.0 scales_1.0.0 dygraphs_1.1.1.6 ## [31] psych_1.8.12 callr_3.3.2 ggridges_0.5.1 StanHeaders_2.19.0 digest_0.6.21 ## [36] foreign_0.8-71 rmarkdown_1.13 base64enc_0.1-3 pkgconfig_2.0.3 htmltools_0.4.0 ## [41] htmlwidgets_1.5 rlang_0.4.1 readxl_1.3.1 rstudioapi_0.10 shiny_1.3.2 ## [46] generics_0.0.2 zoo_1.8-6 jsonlite_1.6 crosstalk_1.0.0 gtools_3.8.1 ## [51] inline_0.3.15 magrittr_1.5 loo_2.1.0 bayesplot_1.7.0 Matrix_1.2-17 ## [56] munsell_0.5.0 fansi_0.4.0 abind_1.4-5 lifecycle_0.1.0 stringi_1.4.3 ## [61] pkgbuild_1.0.5 plyr_1.8.4 grid_3.6.0 parallel_3.6.0 promises_1.1.0 ## [66] crayon_1.3.4 miniUI_0.1.1.1 lattice_0.20-38 haven_2.1.0 hms_0.4.2 ## [71] ps_1.3.0 zeallot_0.1.0 knitr_1.23 pillar_1.4.2 igraph_1.2.4.1 ## [76] markdown_1.1 shinystan_2.5.0 stats4_3.6.0 reshape2_1.4.3 rstantools_2.0.0 ## [81] glue_1.3.1.9000 evaluate_0.14 modelr_0.1.4 vctrs_0.2.0 httpuv_1.5.2 ## [86] cellranger_1.1.0 gtable_0.3.0 assertthat_0.2.1 xfun_0.10 mime_0.7 ## [91] xtable_1.8-4 broom_0.5.2 coda_0.19-3 later_1.0.0 rsconnect_0.8.15 ## [96] shinythemes_1.1.2 ellipsis_0.3.0 bridgesampling_0.7-2 Footnote Hayes did not cover count regression with the Poisson likelihood in this textbook. If you’d like to learn more, one place to start is with McElreath’s lecture on binomial and Poisson models.↩ We will not be covering structural equation modeling (SEM) in this project. If you’re interested, you might check out this video series by Erin M. Buchanan on SEM within R, particularly with the handy lavaan package.↩ "],
["the-simple-mediation-model.html", "3 The Simple Mediation Model 3.1 The simple mediation model 3.2 Estimation of the direce, indirect, and total effects of \\(X\\) 3.3 Example with dichotomous \\(X\\): The influence of presumed media influence 3.4 Statistical inference 3.5 An example with continuous \\(X\\): Economic stress among small-business owners Reference Session info", " 3 The Simple Mediation Model Hayes closed the opening with: Whereas answering questions about when or for whom is the domain of moderation analysis, questions that ask about how pertain to mediation, the focus of this and the next three chapters. In this chapter, [we’ll explore] the simple mediation model and illustrate using OLS regression-based Bayesian path analysis how the effect of an antecedent variable \\(X\\) on some final consequent \\(Y\\) can be partitioned into two paths of influence, direct and indirect. (p. 78, emphasis in the original) 3.1 The simple mediation model Mediation analysis is a statistical method used to evaluate evidence from studies designed to test hypotheses about how some causal antecedent variable \\(X\\) transmits its effect on a consequent variable \\(Y\\). When thinking about whether a phenomenon or theory you are studying could be conceptualized as a mediation process, it is important to keep in mind that mediation is ultimately a causal explanation. It is assumed that the relationships in the system are causal, and, importantly, that \\(M\\) is causally located between \\(X\\) and \\(Y\\). It must be assumed, if not also empirically substantiated, that \\(X\\) causes \\(M\\), which in turn causes \\(Y\\). \\(M\\) cannot possibly carry \\(X\\)’s effect on \\(Y\\) if \\(M\\) is not located causally between \\(X\\) and \\(Y\\). (pp. 78–81, emphasis in the original) 3.2 Estimation of the direce, indirect, and total effects of \\(X\\) Given the simple three-term mediation model, the statistical model is expressed in the two equations \\[\\begin{align*} M &amp; = i_M + a X + e_M \\\\ Y &amp; = i_Y + c&#39; X + b M + e_Y. \\end{align*}\\] When using OLS software, as Hayes promotes throughout the text, these equations are estimated sequentially. However, the brms package has multivariate capabilities. As such, our results will be from a Bayesian multilevel model that simultaneously computes both equations at once. They are both part of a joint model. And when we consider more advanced models later in the text, our multivariate models will fit even more than two equations at once. None of this is a problem for brms. 3.3 Example with dichotomous \\(X\\): The influence of presumed media influence Here we load a couple necessary packages, load the data, and take a peek. library(tidyverse) pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) glimpse(pmi) ## Observations: 123 ## Variables: 6 ## $ cond &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, … ## $ pmi &lt;dbl&gt; 7.0, 6.0, 5.5, 6.5, 6.0, 5.5, 3.5, 6.0, 4.5, 7.0, 1.0, 6.0, 5.0, 7.0, 7.0, 7.0, 4.5, 3.5, … ## $ import &lt;dbl&gt; 6, 1, 6, 6, 5, 1, 1, 6, 6, 6, 3, 3, 4, 7, 1, 6, 3, 3, 2, 4, 4, 6, 7, 4, 5, 4, 6, 5, 5, 7, … ## $ reaction &lt;dbl&gt; 5.25, 1.25, 5.00, 2.75, 2.50, 1.25, 1.50, 4.75, 4.25, 6.25, 1.25, 2.75, 3.75, 5.00, 4.00, … ## $ gender &lt;dbl&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, … ## $ age &lt;dbl&gt; 51.0, 40.0, 26.0, 21.0, 27.0, 25.0, 23.0, 25.0, 22.0, 24.0, 22.0, 21.0, 23.0, 21.0, 22.0, … You can get the male/female split like so. pmi %&gt;% count(gender) ## # A tibble: 2 x 2 ## gender n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 80 ## 2 1 43 Here is the split by condition. pmi %&gt;% count(cond) ## # A tibble: 2 x 2 ## cond n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 65 ## 2 1 58 Here is how to get the ungrouped mean and \\(SD\\) values for reaction and pmi, as presented in Table 3.1. pmi %&gt;% pivot_longer(c(reaction, pmi)) %&gt;% group_by(name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 pmi 5.60 1.32 ## 2 reaction 3.48 1.55 You might get the mean and \\(SD\\) values for reaction and pmi grouped by cond like this. pmi %&gt;% pivot_longer(c(reaction, pmi)) %&gt;% group_by(cond, name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 4 ## # Groups: cond [2] ## cond name mean sd ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 pmi 5.38 1.34 ## 2 0 reaction 3.25 1.61 ## 3 1 pmi 5.85 1.27 ## 4 1 reaction 3.75 1.45 Let’s load our primary statistical package, brms. library(brms) Before we begin, I should acknowledge that I greatly benefited by this great blog post on path analysis in brms by Jarrett Byrnes. With brms, we handle mediation models using the multivariate syntax. There are a few ways to do this. Let’s start simple. If you look at the path model in Figure 3.3, you’ll note that reaction is predicted by pmi and cond. pmi, in turn, is predicted solely by cond. So we have two regression models, which is just the kind of thing the brms multivariate syntax is for. So first let’s specify both models, which we’ll nest in bf() functions and save as objects. y_model &lt;- bf(reaction ~ 1 + pmi + cond) m_model &lt;- bf(pmi ~ 1 + cond) Now we have our bf() objects in hand, we’ll combine them with the + operator within the brm() function. We’ll also specify set_rescor(FALSE)–we’re not interested in adding a residual correlation between reaction and pmi. model3.1 &lt;- brm(data = pmi, family = gaussian, y_model + m_model + set_rescor(FALSE), cores = 4) Here are our results. print(model3.1) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: reaction ~ 1 + pmi + cond ## pmi ~ 1 + cond ## Data: pmi (Number of observations: 123) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## reaction_Intercept 0.52 0.56 -0.57 1.65 1.00 6426 3230 ## pmi_Intercept 5.38 0.16 5.06 5.70 1.00 6210 2969 ## reaction_pmi 0.51 0.10 0.31 0.70 1.00 6261 2875 ## reaction_cond 0.26 0.26 -0.26 0.77 1.00 6390 3224 ## pmi_cond 0.47 0.24 -0.01 0.95 1.00 6810 3307 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_reaction 1.41 0.09 1.25 1.59 1.00 6351 2500 ## sigma_pmi 1.32 0.08 1.17 1.50 1.00 5592 2827 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). If you compare our model summary with the coefficients in the path model in Figure 3.3, you’ll see our coefficients are the same. The brms summary also includes intercepts and residual variances, which are typically omitted in path diagrams even though they’re still part of the model. If you’re getting lost in all the model output, try taking out the constant and error terms. fixef(model3.1)[3:5, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## reaction_pmi 0.507 0.099 0.310 0.702 ## reaction_cond 0.259 0.261 -0.259 0.769 ## pmi_cond 0.472 0.240 -0.014 0.954 In his Table 3.2, Hayes included the \\(R^2\\) values. Here are ours. bayes_R2(model3.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2reaction 0.210 0.057 0.099 0.321 ## R2pmi 0.039 0.031 0.001 0.116 It’s worth it to actually plot the \\(R^2\\) distributions. # we&#39;ll get our color palette from ggthemes library(ggthemes) bayes_R2(model3.1, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;, alpha = 2/3) + scale_fill_colorblind() + # we got this color palette from the ggthemes package coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for model3.1&quot;)), x = NULL) + theme_classic() We went through the trouble of plotting the \\(R^2\\) distributions because it’s useful to understand that they won’t often be symmetric when they’re near their logical boundaries (i.e., 0 and 1). This is where asymmetric Bayesian credible intervals can really shine. Let’s get down to business and examine the indirect effect, the \\(ab\\) pathway. In our model, \\(a\\) = pmi_cond and \\(b\\) = reaction_pmi. You can isolate them with fixef()[i]. fixef(model3.1)[5 , ] ## Estimate Est.Error Q2.5 Q97.5 ## 0.47213618 0.24020629 -0.01439811 0.95380657 fixef(model3.1)[3 , ] ## Estimate Est.Error Q2.5 Q97.5 ## 0.50699147 0.09885669 0.30960267 0.70221028 So the naive approach would be to just multiply them. (fixef(model3.1)[5 , ] * fixef(model3.1)[3 , ]) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.239 0.024 -0.004 0.670 Now, this does get us the correct ‘Estimate’ (i.e., posterior mean). However, the posterior \\(SD\\) and 95% intervals are off. If you want to do this properly, you need to work with the poster samples themselves. We do that with the posterior_samples() function. post &lt;- posterior_samples(model3.1) glimpse(post) ## Observations: 4,000 ## Variables: 8 ## $ b_reaction_Intercept &lt;dbl&gt; 0.51540720, 0.40541249, 0.63404832, 0.28124422, 0.70300758, 0.72773623, 0.7608… ## $ b_pmi_Intercept &lt;dbl&gt; 5.522656, 5.526570, 5.233996, 5.526494, 5.251560, 5.437609, 5.083563, 5.621216… ## $ b_reaction_pmi &lt;dbl&gt; 0.4454816, 0.5781861, 0.4289168, 0.5859403, 0.4387670, 0.4857291, 0.4548907, 0… ## $ b_reaction_cond &lt;dbl&gt; 1.003075337, -0.051680431, 0.619523421, -0.068325690, 0.567368727, 0.402503624… ## $ b_pmi_cond &lt;dbl&gt; 0.4317949, 0.3282448, 0.6163566, 0.3163480, 0.5319986, 0.2861751, 0.8062659, 0… ## $ sigma_reaction &lt;dbl&gt; 1.470505, 1.307822, 1.488764, 1.324966, 1.528775, 1.278531, 1.310666, 1.465768… ## $ sigma_pmi &lt;dbl&gt; 1.280238, 1.358432, 1.264979, 1.254725, 1.286195, 1.251778, 1.303006, 1.229578… ## $ lp__ &lt;dbl&gt; -436.2352, -433.9475, -434.1470, -433.2939, -433.6824, -433.7403, -433.5189, -… Here we compute the indirect effect, ab. post &lt;- post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi) Now we have ab as a properly computed vector, we can summarize it with the quantile() function. quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.232 -0.006 0.527 And we can even visualize it as a density. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(3)[3]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Our indirect effect, the &quot;, italic(&quot;ab&quot;), &quot; pathway&quot;)), x = NULL) + theme_classic() It’s also worth pointing out that as the indirect effect isn’t perfectly symmetric, its mean and median aren’t quite the same. post %&gt;% summarize(mean = mean(ab), median = median(ab)) %&gt;% round(digits = 3) ## mean median ## 1 0.239 0.232 Their magnitudes are similar, but this asymmetry will be a source of contrast to our estimates and the OLS estimates Hayes reported in the text. This is also something to consider when reporting on central tendency. When the indirect effect–or any other parameter, for that matter–is quite asymmetric, you might prefer reporting the median rather than the mean. On page 90, Hayes computed the adjusted means for \\(Y\\). For both cond == 1 and cond == 0, he computed the expected values for reaction when pmi was at its mean. A natural way to do that in brms is with fitted(). First we’ll put our input values for cond and pmi in a tibble, which we’ll call nd. Then we’ll feed nd into the newdata argument within the fitted() function. nd &lt;- tibble(cond = 1:0, pmi = mean(pmi$pmi)) fitted(model3.1, newdata = nd) ## , , reaction ## ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 3.621530 0.1857745 3.245964 3.989349 ## [2,] 3.362035 0.1815533 3.010791 3.727515 ## ## , , pmi ## ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 5.850008 0.1738619 5.504383 6.192191 ## [2,] 5.377872 0.1632537 5.058797 5.696318 Because model3.1 is a multivariate model, fitted() returned the model-implied summaries for both reaction and pmi. If you just want the adjusted means for reaction, you can use the resp argument within fitted(). fitted(model3.1, newdata = nd, resp = &quot;reaction&quot;) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 3.622 0.186 3.246 3.989 ## [2,] 3.362 0.182 3.011 3.728 Note how this is where the two values in the \\(Y\\) adjusted column in Table 3.1 came from. However, if we want to reproduce how Hayes computed the total effect (i.e., \\(c&#39; + ab\\)), we’ll need to work with the posterior draws themselves, post. Recall, we’ve already saved the indirect effect as a vector, ab. The direct effect, \\(c&#39;\\), is labeled b_reaction_cond within post. To get the total effect, \\(c\\), all we need to is add those vectors together. post &lt;- post %&gt;% mutate(total_effect = b_reaction_cond + ab) Here’s the posterior mean with its quantile-based 95% intervals post %&gt;% summarize(mean = mean(total_effect), ll = quantile(total_effect, prob = .025), ul = quantile(total_effect, prob = .975)) ## mean ll ul ## 1 0.4985056 -0.06307429 1.035278 3.3.1 Estimation of the model in PROCESS for SPSS and SAS. Nothing new for us, here. 3.4 Statistical inference Our approach will not match up neatly with Hayes’s on this topic. 3.4.1 Inference about the total effect of \\(X\\) on \\(Y\\). As we mentioned in Chapter 2, we can indeed focus on rejecting \\(H_0\\) when using Bayesian statistics. I, however, am not a fan of that approach and I will not be focusing on Bayesian \\(p\\)-values. But throughout this project, we will make great efforts to express the (un)certainty in our models with various plots of posterior distributions and summary statistics, such as measures of central tendency (e.g., means) and spread (e.g., percentile-based 95% intervals). So instead of \\(t\\)- and \\(p\\)-values for \\(c&#39;\\), we are going to focus on the distribution. We already gave the mean and 95% intervals, above. Here’s a look at the density. post %&gt;% ggplot(aes(x = total_effect)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(3)[2]) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(italic(c),&quot; (i.e., the total effect)&quot;))) + theme_classic() 3.4.2 Inference about the direct effect of \\(X\\) on \\(Y\\). Like in the last section, we will just look at the posterior distribution for the direct effect (i.e., \\(c&#39;\\), b_reaction_cond). post %&gt;% ggplot(aes(x = b_reaction_cond)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(4)[4]) + geom_vline(xintercept = 0, color = &quot;white&quot;, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Yep, 0 is a credible value for &quot;, italic(&quot;c&quot;), &quot;.&quot;)), x = NULL) + theme_classic() If you wanted to quantify what proportion of the density was less than 0, you could execute something like this. post %&gt;% summarize(proportion_below_zero = mean(b_reaction_cond &lt; 0)) ## proportion_below_zero ## 1 0.158 This is something like a Bayesian \\(p\\)-value. But of course, you could always just look at the posterior intervals. posterior_interval(model3.1)[&quot;b_reaction_cond&quot;, ] ## 2.5% 97.5% ## -0.2591588 0.7686859 3.4.3 Inference about the indirect of \\(X\\) on \\(Y\\) through \\(M\\). The indirect effect quantifies how much two cases that differ by a unit on \\(X\\) are estimated to differ on \\(Y\\) as a result of \\(X\\)’s influence on \\(M\\), which in turn influences \\(Y\\). The indirect effect is relevant as to [what extent] \\(X\\)’s effect on \\(Y\\) can be said to be transmitted through the mechanism represented by the \\(X \\rightarrow M \\rightarrow Y\\) causal chain of events. (p. 95) 3.4.3.1 The normal theory approach. This is not our approach. 3.4.3.2 Bootstrap confidence interval. This is not our approach. However, Markov chain Monte Carlo (MCMC) methods are iterative and share some characteristics with boostrapping. On page 98, Hayes outlined 6 steps for constructing the \\(ab\\) bootstrap confidence interval. Here are our responses to those steps w/r/t Bayes with MCMC–or in our case HMC (i.e., Hamiltonian Monte Carlo). If HMC or MCMC, in general, are new to you, you might check out this lecture or the Stan Reference Manual if you’re more technically oriented. Anyway, Hayes’s 6 steps: 3.4.3.2.1 Step 1. With HMC we do not take random samples of the data themselves. Rather, we take random draws from the posterior distribution. The posterior distribution is the joint probability distribution of our model. 3.4.3.2.2 Step 2. After we fit our model with the brm() function and save our posterior draws in a data frame (i.e., post &lt;- posterior_samples(my_model_fit)), we then make a new column (a.k.a. vector, variable) that is the product of our coefficients for the \\(a\\) and \\(b\\) pathways. In the example above, this looked like post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi). Let’s take a look at those columns. post %&gt;% select(b_pmi_cond, b_reaction_pmi, ab) %&gt;% slice(1:10) ## b_pmi_cond b_reaction_pmi ab ## 1 0.4317949 0.4454816 0.1923567 ## 2 0.3282448 0.5781861 0.1897866 ## 3 0.6163566 0.4289168 0.2643657 ## 4 0.3163480 0.5859403 0.1853611 ## 5 0.5319986 0.4387670 0.2334234 ## 6 0.2861751 0.4857291 0.1390035 ## 7 0.8062659 0.4548907 0.3667628 ## 8 0.2674144 0.5624687 0.1504122 ## 9 0.6673819 0.5266402 0.3514701 ## 10 0.2771463 0.5150936 0.1427563 Our data frame, post, has 4000 rows. Why 4000? By default, brms runs 4 HMC chains. Each chain has 2000 iterations, 1000 of which are warmups, which we always discard. As such, there are 1000 good iterations left in each chain and \\(1000 \\times 4 = 4000\\). We can change these defaults as needed. Each row in post contains the parameter values based on one of those draws. And again, these are draws from the posterior distribution. They are not draws from the data. 3.4.3.2.3 Step 3. We don’t refit the model \\(k\\) times based on the samples from the data. We take a number of draws from the posterior distribution. Hayes likes to take 5000 samples when he bootstraps. Happily, that number is quite similar to our default 4000 HMC draws. Whether 5000, 4000 or 10,000, these are all large enough numbers that the distributions become fairly stable. With HMC, however, you might want to increase the number of iterations if the effective sample size, ‘Eff.Sample’ in the print() output, is substantially smaller than the number of iterations. 3.4.3.2.4 Step 4. When we use the quantile() function to compute our Bayesian credible intervals, we’ve sorted. Conceptually, we’ve done this. post %&gt;% select(ab) %&gt;% arrange(ab) %&gt;% slice(1:10) ## ab ## 1 -0.2056336 ## 2 -0.1745748 ## 3 -0.1627155 ## 4 -0.1527381 ## 5 -0.1507441 ## 6 -0.1337197 ## 7 -0.1271329 ## 8 -0.1261394 ## 9 -0.1197648 ## 10 -0.1194200 3.4.3.2.5 Step 5. Yes, this is what we do, too. ci &lt;- 95 0.5 * (100 - ci) ## [1] 2.5 3.4.3.2.6 Step 6. This is also what we do. ci &lt;- 95 (100 - 0.5 * (100 - ci)) ## [1] 97.5 Also, notice the headers in the rightmost two columns in our posterior_summary() output: posterior_summary(model3.1) ## Estimate Est.Error Q2.5 Q97.5 ## b_reaction_Intercept 0.5220588 0.56038627 -0.56894728 1.6542507 ## b_pmi_Intercept 5.3778721 0.16325372 5.05879679 5.6963180 ## b_reaction_pmi 0.5069915 0.09885669 0.30960267 0.7022103 ## b_reaction_cond 0.2594951 0.26076802 -0.25915879 0.7686859 ## b_pmi_cond 0.4721362 0.24020629 -0.01439811 0.9538066 ## sigma_reaction 1.4079448 0.09152163 1.24656446 1.5949728 ## sigma_pmi 1.3177959 0.08377812 1.16592170 1.4979835 ## lp__ -434.8522548 1.94452334 -439.65536983 -432.2107403 Those .025 and .975 quantiles from above are just what brms is giving us in our 95% Bayesian credible intervals. Here’s our version of Figure 3.5. # these will come in handy in the subtitle ll &lt;- quantile(post$ab, probs = .025) %&gt;% round(digits = 3) ul &lt;- quantile(post$ab, probs = .975) %&gt;% round(digits = 3) post %&gt;% ggplot(aes(x = ab)) + geom_histogram(color = &quot;white&quot;, size = .25, fill = colorblind_pal()(5)[5], binwidth = .025, boundary = 0) + geom_vline(xintercept = quantile(post$ab, probs = c(.025, .975)), linetype = 3, color = colorblind_pal()(6)[6]) + labs(x = expression(paste(&quot;Indirect effect (&quot;, italic(&quot;ab&quot;), &quot;)&quot;)), y = &quot;Frequency in 4,000 HMC posterior draws&quot;, subtitle = paste(&quot;95% of the posterior draws are between&quot;, ll, &quot;and&quot;, ul)) + theme_classic() Again, as Hayes discussed how to specify different types of intervals in PROCESS on page 102, you can ask for different kinds of intervals in your print() or summary() output with the probs argument, just as you can with quantile() when working directly with the posterior draws. Hayes discussed setting the seed in PROCESS on page 104. You can do this with the seed argument in the brm() function, too. 3.4.3.3 Alternative “asymmetric” confidence interval approaches. This section does not quite refer to us. I’m a little surprised Hayes didn’t at least dedicate a paragraph or two on Bayesian estimation. Sure, he mentioned Monte Carlo, but not within the context of Bayes. So it goes. But if you’re interested, you can read about Bayesian intervals for mediation models in Yuan and MacKinnon’s Bayesian mediation analysis. And yes, Hayes is aware of this. He has cited it in his work. 3.5 An example with continuous \\(X\\): Economic stress among small-business owners Here’s the estress data. estress &lt;- read_csv(&quot;data/estress/estress.csv&quot;) glimpse(estress) ## Observations: 262 ## Variables: 7 ## $ tenure &lt;dbl&gt; 1.67, 0.58, 0.58, 2.00, 5.00, 9.00, 0.00, 2.50, 0.50, 0.58, 9.00, 1.92, 2.00, 1.42, 0.92, … ## $ estress &lt;dbl&gt; 6.0, 5.0, 5.5, 3.0, 4.5, 6.0, 5.5, 3.0, 5.5, 6.0, 5.5, 4.0, 3.0, 2.5, 3.5, 6.0, 4.0, 6.0, … ## $ affect &lt;dbl&gt; 2.60, 1.00, 2.40, 1.16, 1.00, 1.50, 1.00, 1.16, 1.33, 3.00, 3.00, 2.00, 1.83, 1.16, 1.16, … ## $ withdraw &lt;dbl&gt; 3.00, 1.00, 3.66, 4.66, 4.33, 3.00, 1.00, 1.00, 2.00, 4.00, 4.33, 1.00, 5.00, 1.66, 4.00, … ## $ sex &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, … ## $ age &lt;dbl&gt; 51, 45, 42, 50, 48, 48, 51, 47, 40, 43, 57, 36, 33, 29, 33, 48, 40, 45, 37, 42, 54, 57, 37… ## $ ese &lt;dbl&gt; 5.33, 6.05, 5.26, 4.35, 4.86, 5.05, 3.66, 6.13, 5.26, 4.00, 2.53, 6.60, 5.20, 5.66, 5.66, … The model set up is just like before. There are no complications switching from a binary \\(X\\) variable to a continuous one. y_model &lt;- bf(withdraw ~ 1 + estress + affect) m_model &lt;- bf(affect ~ 1 + estress) With our y_model and m_model defined, we’re ready to fit. model3.2 &lt;- brm(data = estress, family = gaussian, y_model + m_model + set_rescor(FALSE), cores = 4) Let’s take a look at the results. print(model3.2, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: withdraw ~ 1 + estress + affect ## affect ~ 1 + estress ## Data: estress (Number of observations: 262) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## withdraw_Intercept 1.448 0.256 0.945 1.963 1.002 5808 3165 ## affect_Intercept 0.800 0.143 0.522 1.081 1.001 6502 3321 ## withdraw_estress -0.078 0.053 -0.182 0.026 1.000 5461 3448 ## withdraw_affect 0.771 0.106 0.564 0.972 1.001 5187 3009 ## affect_estress 0.173 0.029 0.116 0.229 1.001 6388 3134 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_withdraw 1.139 0.051 1.045 1.245 1.001 6170 3185 ## sigma_affect 0.686 0.031 0.630 0.750 1.003 6978 2902 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The ‘Eff.Sample’ and ‘Rhat’ values look great. Happily, the values in our summary cohere well with those Hayes reported in Table 3.5. Here are our \\(R^2\\) values. bayes_R2(model3.2) ## Estimate Est.Error Q2.5 Q97.5 ## R2withdraw 0.1833827 0.03932012 0.10720426 0.2577434 ## R2affect 0.1167220 0.03407392 0.05450603 0.1848251 These are also quite similar to those in the text. Here’s our indirect effect. # putting the posterior draws into a data frame post &lt;- posterior_samples(model3.2) # computing the ab coefficient with multiplication post &lt;- post %&gt;% mutate(ab = b_affect_estress*b_withdraw_affect) # getting the posterior median and 95% intervals with `quantile()` quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.131 0.081 0.193 We can visualize its shape, median, and 95% intervals in a density plot. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(7)[7]) + geom_vline(xintercept = quantile(post$ab, probs = c(.025, .5, .975)), color = &quot;white&quot;, linetype = c(2, 1, 2), size = c(.5, .8, .5)) + scale_x_continuous(breaks = quantile(post$ab, probs = c(.025, .5, .975)), labels = quantile(post$ab, probs = c(.025, .5, .975)) %&gt;% round(2) %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Behold our &quot;, italic(&quot;ab&quot;), &quot;!&quot;)), x = NULL) + theme_classic() Here’s \\(c&#39;\\), the direct effect of esterss predicting withdraw. posterior_summary(model3.2)[&quot;b_withdraw_estress&quot;, ] ## Estimate Est.Error Q2.5 Q97.5 ## -0.07781526 0.05300991 -0.18218003 0.02647619 It has wide flapping intervals which do straddle zero. A little addition will give us the direct effect, \\(c\\). post &lt;- post %&gt;% mutate(c = b_withdraw_estress + ab) quantile(post$c, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.055 -0.052 0.163 Reference Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggthemes_4.2.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-139 matrixStats_0.55.0 xts_0.11-2 lubridate_1.7.4 threejs_0.3.1 ## [6] httr_1.4.0 rstan_2.19.2 tools_3.6.0 backports_1.1.5 utf8_1.1.4 ## [11] R6_2.4.0 DT_0.9 lazyeval_0.2.2 colorspace_1.4-1 withr_2.1.2 ## [16] prettyunits_1.0.2 processx_3.4.1 tidyselect_0.2.5 gridExtra_2.3 Brobdingnag_1.2-6 ## [21] compiler_3.6.0 cli_1.1.0 rvest_0.3.4 xml2_1.2.0 shinyjs_1.0 ## [26] labeling_0.3 colourpicker_1.0 scales_1.0.0 dygraphs_1.1.1.6 callr_3.3.2 ## [31] ggridges_0.5.1 StanHeaders_2.19.0 digest_0.6.21 rmarkdown_1.13 base64enc_0.1-3 ## [36] pkgconfig_2.0.3 htmltools_0.4.0 htmlwidgets_1.5 rlang_0.4.1 readxl_1.3.1 ## [41] rstudioapi_0.10 shiny_1.3.2 generics_0.0.2 zoo_1.8-6 jsonlite_1.6 ## [46] crosstalk_1.0.0 gtools_3.8.1 inline_0.3.15 magrittr_1.5 loo_2.1.0 ## [51] bayesplot_1.7.0 Matrix_1.2-17 munsell_0.5.0 fansi_0.4.0 abind_1.4-5 ## [56] lifecycle_0.1.0 stringi_1.4.3 pkgbuild_1.0.5 plyr_1.8.4 grid_3.6.0 ## [61] parallel_3.6.0 promises_1.1.0 crayon_1.3.4 miniUI_0.1.1.1 lattice_0.20-38 ## [66] haven_2.1.0 hms_0.4.2 ps_1.3.0 zeallot_0.1.0 knitr_1.23 ## [71] pillar_1.4.2 igraph_1.2.4.1 markdown_1.1 shinystan_2.5.0 stats4_3.6.0 ## [76] reshape2_1.4.3 rstantools_2.0.0 glue_1.3.1.9000 evaluate_0.14 modelr_0.1.4 ## [81] vctrs_0.2.0 httpuv_1.5.2 cellranger_1.1.0 gtable_0.3.0 assertthat_0.2.1 ## [86] xfun_0.10 mime_0.7 xtable_1.8-4 broom_0.5.2 coda_0.19-3 ## [91] later_1.0.0 rsconnect_0.8.15 shinythemes_1.1.2 ellipsis_0.3.0 bridgesampling_0.7-2 "],
["causal-steps-confounding-and-causal-order.html", "4 Causal Steps, Confounding, and Causal Order 4.1 What about Barron and Kenny? 4.2 Confounding and causal order 4.3 Effect size 4.4 Statistical power 4.5 Multiple \\(X\\)s or \\(Y\\)s: Analyze separately or simultaneously? 4.6 Chapter summary References Session info", " 4 Causal Steps, Confounding, and Causal Order Comfort with [the principles of the basic mediation model] allows you to conduct mediation analysis and use it to shed light on your research questions and hypotheses about causal processes. In this chapter, [we] take up a variety of complications, including testing and ruling out various alternative explanations for associations observed in a mediation analysis, effect size, and models with multiple causal agents and outcomes. (p. 113) 4.1 What about Barron and Kenny? Complete and partial mediation are concepts that are deeply ingrained in the thinking of social and behavioral scientists. But I just don’t see what they offer our understanding of a phenomenon. They are too sample-size-dependent and the distinction between them has no substantive or theoretical meaning or value of any consequence. I recommend avoiding expressing hypotheses about mediation or results of a mediation analysis using these terms. (p. 121) Agreed. 4.2 Confounding and causal order One of the beautiful features of experiments is the causal interpretations they afford about differences between groups. Good experimentation is tough and requires lots of careful planning and strict control over experimental procedures, construction of stimuli, treatment of participants, and so forth. But when done well, no research design gives a researcher more confidence in the claim that differences between groups defined by \\(X\\) on some variable of interest is due to \\(X\\) rather than something else. Given that a mediation model is a causal model, the ability to make unequivocal causal claims about the effect of \\(X\\) on \\(M\\) and the direct and total effects of \\(X\\) on \\(Y\\) gives experiments tremendous appeal. Absent random assignment to values of \\(X\\), all of the associations in a mediation model are susceptible to confounding and epiphenomenal association, not just the association between \\(M\\) and \\(Y\\). Whether one’s design includes manipulation and random assignment of \\(X\\) or not, it behooves the researcher to seriously ponder these potential threats to causal inference and, if possible, do something to reduce their plausibility as alternative explanations for associations observed. (pp 121–122, emphasis in the original) 4.2.1 Accounting for confounding and epiphenomenal association. Here we load a couple necessary packages, load the data, and take a peek at them. library(tidyverse) estress &lt;- read_csv(&quot;data/estress/estress.csv&quot;) glimpse(estress) ## Observations: 262 ## Variables: 7 ## $ tenure &lt;dbl&gt; 1.67, 0.58, 0.58, 2.00, 5.00, 9.00, 0.00, 2.50, 0.50, 0.58, 9.00, 1.92, 2.00, 1.42, 0.92, … ## $ estress &lt;dbl&gt; 6.0, 5.0, 5.5, 3.0, 4.5, 6.0, 5.5, 3.0, 5.5, 6.0, 5.5, 4.0, 3.0, 2.5, 3.5, 6.0, 4.0, 6.0, … ## $ affect &lt;dbl&gt; 2.60, 1.00, 2.40, 1.16, 1.00, 1.50, 1.00, 1.16, 1.33, 3.00, 3.00, 2.00, 1.83, 1.16, 1.16, … ## $ withdraw &lt;dbl&gt; 3.00, 1.00, 3.66, 4.66, 4.33, 3.00, 1.00, 1.00, 2.00, 4.00, 4.33, 1.00, 5.00, 1.66, 4.00, … ## $ sex &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, … ## $ age &lt;dbl&gt; 51, 45, 42, 50, 48, 48, 51, 47, 40, 43, 57, 36, 33, 29, 33, 48, 40, 45, 37, 42, 54, 57, 37… ## $ ese &lt;dbl&gt; 5.33, 6.05, 5.26, 4.35, 4.86, 5.05, 3.66, 6.13, 5.26, 4.00, 2.53, 6.60, 5.20, 5.66, 5.66, … The lowerCor() function from the psych package makes it easy to estimate the lower triangle of a correlation matrix. psych::lowerCor(estress, digits = 3) ## tenure estrss affect wthdrw sex age ese ## tenure 1.000 ## estress 0.068 1.000 ## affect -0.065 0.340 1.000 ## withdraw -0.035 0.064 0.417 1.000 ## sex -0.003 0.133 0.046 0.050 1.000 ## age 0.266 0.066 -0.018 -0.035 0.083 1.000 ## ese -0.060 -0.158 -0.246 -0.243 0.028 -0.083 1.000 Let’s open brms. library(brms) Recall that if you want the correlations with Bayesian estimation and those sweet Bayesian credible intervals, you set up an intercept-only multivariate model. model4.1 &lt;- brm(data = estress, family = gaussian, mvbind(ese, estress, affect, withdraw) ~ 1, cores = 4) Behold the summary. print(model4.1, digits = 3) ## Family: MV(gaussian, gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: ese ~ 1 ## estress ~ 1 ## affect ~ 1 ## withdraw ~ 1 ## Data: estress (Number of observations: 262) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## ese_Intercept 5.607 0.062 5.487 5.731 1.002 6703 2700 ## estress_Intercept 4.621 0.090 4.451 4.798 1.000 7513 3385 ## affect_Intercept 1.598 0.045 1.508 1.685 1.000 4887 3304 ## withdraw_Intercept 2.321 0.078 2.166 2.471 1.000 4763 3198 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_ese 0.954 0.041 0.875 1.039 1.000 6984 3141 ## sigma_estress 1.437 0.062 1.320 1.563 1.002 6673 3338 ## sigma_affect 0.729 0.032 0.673 0.795 1.000 5250 3334 ## sigma_withdraw 1.257 0.055 1.157 1.368 1.001 6613 3392 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(ese,estress) -0.155 0.060 -0.270 -0.034 1.001 7076 2855 ## rescor(ese,affect) -0.240 0.059 -0.352 -0.121 1.002 5117 3290 ## rescor(estress,affect) 0.334 0.056 0.222 0.441 1.001 4837 2871 ## rescor(ese,withdraw) -0.237 0.059 -0.350 -0.116 1.000 6195 3246 ## rescor(estress,withdraw) 0.059 0.062 -0.064 0.177 1.000 4775 3077 ## rescor(affect,withdraw) 0.410 0.051 0.307 0.505 1.000 5701 3463 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Since we have posteriors for the correlations, why not plot them? Here we use the theme_black() from brms and a color scheme from the viridis package. posterior_samples(model4.1) %&gt;% pivot_longer(c(rescor__ese__estress, rescor__ese__affect, rescor__estress__withdraw)) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(alpha = .85, color = &quot;transparent&quot;) + scale_fill_viridis_d(option = &quot;D&quot;, direction = -1, labels = c(expression(paste(rho[&quot;ese, affect&quot;])), expression(paste(rho[&quot;ese, estress&quot;])), expression(paste(rho[&quot;estress, withdraw&quot;]))), guide = guide_legend(label.hjust = 0, label.theme = element_text(size = 15, angle = 0, color = &quot;white&quot;), title.theme = element_blank())) + xlim(-1, 1) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Our correlation density plot&quot;, x = NULL) + theme_black() + theme(panel.grid = element_blank(), axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank()) In the last chapter, we said there were multiple ways to set up a multivariate model in brms. Our first approach was to externally define the submodels using the bf() function, save them as objects, and then include those objects within the brm() function. Another approach is to just define the separate bf() submodels directly in the brm() function, combining them with the + operator. That’s the approach we will practice in this chapter. Here’s what it looks like for our first mediation model. model4.2 &lt;- brm(data = estress, family = gaussian, bf(withdraw ~ 1 + estress + affect + ese + sex + tenure) + bf(affect ~ 1 + estress + ese + sex + tenure) + set_rescor(FALSE), cores = 4) Worked like a charm. Here’s the summary. print(model4.2, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: withdraw ~ 1 + estress + affect + ese + sex + tenure ## affect ~ 1 + estress + ese + sex + tenure ## Data: estress (Number of observations: 262) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## withdraw_Intercept 2.735 0.536 1.689 3.788 1.002 8475 2689 ## affect_Intercept 1.783 0.308 1.184 2.388 1.000 8891 3210 ## withdraw_estress -0.093 0.053 -0.195 0.013 1.002 7910 2629 ## withdraw_affect 0.708 0.104 0.506 0.913 1.000 6871 3244 ## withdraw_ese -0.211 0.075 -0.363 -0.062 1.002 8788 3017 ## withdraw_sex 0.125 0.142 -0.154 0.402 1.001 7881 3132 ## withdraw_tenure -0.002 0.011 -0.022 0.019 1.000 8692 3171 ## affect_estress 0.159 0.030 0.099 0.219 1.001 8703 3026 ## affect_ese -0.154 0.044 -0.240 -0.071 1.000 8025 3123 ## affect_sex 0.014 0.086 -0.153 0.183 1.000 9290 2854 ## affect_tenure -0.011 0.006 -0.023 0.001 1.000 10720 3474 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_withdraw 1.127 0.051 1.032 1.231 1.001 8047 2943 ## sigma_affect 0.671 0.029 0.617 0.732 1.000 7653 3026 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In the printout, notice how first within intercepts and then with covariates and sigma, the coefficients are presented as for withdraw first and then affect. Also notice how the coefficients for the covariates are presented in the same order for each criterions. Hopefully that’ll make it easier to sift through the printout. Happily, our coefficients are quite similar to those in Table 4.1. Here are the \\(R^2\\) summaries. bayes_R2(model4.2) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2withdraw 0.213 0.038 0.139 0.287 ## R2affect 0.170 0.037 0.099 0.242 These are also in the same ballpark, but a little higher. Why not glance at their densities? bayes_R2(model4.2, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = .85) + scale_fill_viridis_d(option = &quot;A&quot;, begin = .33, direction = -1, labels = c(&quot;affect&quot;, &quot;withdaw&quot;), guide = guide_legend(title.theme = element_blank())) + scale_y_continuous(NULL, breaks = NULL) + xlim(0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for model 4.2&quot;)), x = NULL) + theme_black() + theme(panel.grid = element_blank()) Here we retrieve the posterior samples, compute the indirect effect, and summarize the indirect effect with quantile(). post &lt;- posterior_samples(model4.2) %&gt;% mutate(ab = b_affect_estress * b_withdraw_affect) quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.112 0.063 0.169 The results are similar to those in the text (p. 127). Here’s what it looks like. post %&gt;% ggplot(aes(x = ab)) + geom_density(aes(fill = factor(0)), color = &quot;transparent&quot;, show.legend = F) + geom_vline(xintercept = quantile(post$ab, probs = c(.5, .025, .975)), color = &quot;black&quot;, linetype = c(1, 3, 3)) + scale_fill_viridis_d(option = &quot;A&quot;, begin = .6) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(italic(&quot;ab&quot;))) + theme_black() + theme(panel.grid = element_blank()) Once again, those sweet Bayesian credible intervals get the job done. Here’s a way to get both the direct effect, \\(c&#39;\\) (i.e., b_withdraw_estress), and the total effect, \\(c\\) (i.e., \\(c&#39;\\) + \\(ab\\)) of estress on withdraw. post %&gt;% mutate(c = b_withdraw_estress + ab, c_prime = b_withdraw_estress) %&gt;% pivot_longer(c(c_prime, c)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 2 x 4 ## name mean ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c 0.02 -0.089 0.129 ## 2 c_prime -0.093 -0.195 0.013 Both appear pretty small. Which leads us to the next section… 4.3 Effect size The quantification of effect size in mediation analysis is an evolving area of thought and research. [Hayes described] two measures of effect size that apply to the direct, indirect, and total effects in a mediation model…. For an excellent discussion of measures of effect size in mediation analysis, see Preacher and Kelley (2011). [We will] use their notation below. (p. 133) 4.3.1 The partially standardized effect. We get \\(SD\\)s using the sd() function. Here’s the \\(SD\\) for our \\(Y\\) variable, withdraw. sd(estress$withdraw) ## [1] 1.24687 Here we compute the partially standardized effect sizes for \\(c&#39;\\) and \\(ab\\) by dividing those vectors in our post object by sd(estress$withdraw), which we saved as sd_y. sd_y &lt;- sd(estress$withdraw) post %&gt;% mutate(c_prime_ps = b_withdraw_estress / sd_y, ab_ps = ab / sd_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% pivot_longer(c(c_prime_ps, ab_ps, c_ps)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_ps 0.09 0.09 0.051 0.136 ## 2 c_prime_ps -0.074 -0.074 -0.156 0.01 ## 3 c_ps 0.016 0.016 -0.072 0.104 The results are similar, though not identical, to those in the text. Here we have both rounding error and estimation differences at play. The plots: post %&gt;% mutate(c_prime_ps = b_withdraw_estress / sd_y, ab_ps = ab / sd_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% pivot_longer(c(c_prime_ps, ab_ps, c_ps)) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(alpha = .85, color = &quot;transparent&quot;) + scale_fill_viridis_d(option = &quot;D&quot;) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Partially-standardized coefficients&quot;, x = NULL) + theme_black() + theme(panel.grid = element_blank(), legend.position = &quot;none&quot;) + facet_wrap(~name, ncol = 3) On page 135, Hayes revisited the model from section 3.3. We’ll have to reload the data and refit that model to follow along. First, load the data. pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) Refit the model, this time with the bf() statements defined right within brm(). model4.3 &lt;- brm(data = pmi, family = gaussian, bf(reaction ~ 1 + pmi + cond) + bf(pmi ~ 1 + cond) + set_rescor(FALSE), cores = 4) The partially-standardized parameters require some posterior_samples() wrangling. post &lt;- posterior_samples(model4.3) sd_y &lt;- sd(pmi$reaction) post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi, c_prime = b_reaction_cond) %&gt;% mutate(ab_ps = ab / sd_y, c_prime_ps = c_prime / sd_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% pivot_longer(c(c_prime_ps, ab_ps, c_ps)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_ps 0.157 0.151 0.006 0.339 ## 2 c_prime_ps 0.163 0.166 -0.167 0.489 ## 3 c_ps 0.32 0.322 -0.045 0.677 Happily, these results are closer to those in the text than with the previous example. 4.3.2 The completely standardized effect. Note. Hayes could have made this clearer in the text, but the estress model he referred to in this section was the one from way back in section 3.5, not the one from earlier in this chapter. One way to get a standardized solution is to standardize the variables in the data and then fit the model with those standardized variables. To do so, we’ll revisit our custom standardize(), put it to work, and fit the standardized version of the model from section 3.5, which we’ll call model4.4. # make the function sandardize &lt;- function(x) { (x - mean(x)) / sd(x) } # use the function estress &lt;- estress %&gt;% mutate(withdraw_z = sandardize(withdraw), estress_z = sandardize(estress), affect_z = sandardize(affect)) Fit the model. model4.4 &lt;- brm(data = estress, family = gaussian, bf(withdraw_z ~ 1 + estress_z + affect_z) + bf(affect_z ~ 1 + estress_z) + set_rescor(FALSE), cores = 4) Here they are, our newly standardized coefficients. fixef(model4.4) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## withdrawz_Intercept 0.000 0.056 -0.114 0.109 ## affectz_Intercept -0.001 0.060 -0.117 0.118 ## withdrawz_estress_z -0.089 0.060 -0.206 0.031 ## withdrawz_affect_z 0.446 0.062 0.324 0.568 ## affectz_estress_z 0.341 0.059 0.225 0.458 Here we do the wrangling necessary to spell out the standardized effects for \\(ab\\), \\(c&#39;\\), and \\(c\\). posterior_samples(model4.4) %&gt;% mutate(ab_s = b_affectz_estress_z * b_withdrawz_affect_z, c_prime_s = b_withdrawz_estress_z) %&gt;% mutate(c_s = ab_s + c_prime_s) %&gt;% pivot_longer(c(c_prime_s, ab_s, c_s)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_s 0.152 0.15 0.093 0.223 ## 2 c_prime_s -0.089 -0.09 -0.206 0.031 ## 3 c_s 0.063 0.063 -0.06 0.185 Let’s confirm that we can recover these values by applying the formulas on page 135 to the unstandardized model, which we’ll call model5. First, we’ll have to fit that model since we haven’t fit that one since Chapter 3. model4.5 &lt;- brm(data = estress, family = gaussian, bf(withdraw ~ 1 + estress + affect) + bf(affect ~ 1 + estress) + set_rescor(FALSE), cores = 4) Check the unstandardized coefficient summaries. fixef(model4.5) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## withdraw_Intercept 1.448 0.253 0.960 1.936 ## affect_Intercept 0.801 0.146 0.515 1.096 ## withdraw_estress -0.077 0.053 -0.181 0.026 ## withdraw_affect 0.771 0.102 0.573 0.971 ## affect_estress 0.172 0.030 0.113 0.231 On pages 135–136, Hayes provided the formulas to compute the standardized effects, which are \\[\\begin{align*} c&#39;_{cs} &amp; = \\frac{SD_X(c&#39;)}{SD_{Y}} = SD_{X}(c&#39;_{ps}), \\\\ ab_{cs} &amp; = \\frac{SD_X(ab)}{SD_{Y}} = SD_{X}(ab_{ps}), \\text{and} \\\\ c_{cs} &amp; = \\frac{SD_X(c)}{SD_{Y}} = c&#39;_{cs} + ab_{ps}, \\end{align*}\\] where the \\(ps\\) subscript indicates partially standardized. Here we put them in action to standardize the unstandardized results. sd_x &lt;- sd(estress$estress) sd_y &lt;- sd(estress$withdraw) posterior_samples(model4.5) %&gt;% mutate(ab = b_affect_estress * b_withdraw_affect, c_prime = b_withdraw_estress) %&gt;% mutate(ab_s = (sd_x * ab) / sd_y, c_prime_s = (sd_x * c_prime) / sd_y) %&gt;% mutate(c_s = ab_s + c_prime_s) %&gt;% pivot_longer(c(c_prime_s, ab_s, c_s)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_s 0.152 0.151 0.091 0.221 ## 2 c_prime_s -0.088 -0.088 -0.207 0.029 ## 3 c_s 0.064 0.064 -0.059 0.188 Success! 4.3.3 Some (problematic) measures only for indirect effects. Hayes recommended against these, so I’m not going to bother working any examples. 4.4 Statistical power As Hayes discussed, power is an important but thorny issue within the frequentist paradigm. Given that we’re not particularly interested in rejecting the point-null hypothesis as Bayesians and that we bring in priors (which we’ve largely avoided explicitly mentioning in his project but have been quietly using all along), the issue is even more difficult for Bayesians. To learn more on the topic, check out Chapter 13 in Kruschke’s text, Miočević, MacKinnon, and Levy’s paper on power in small-sample Bayesian analyses or Gelman and Carlin’s paper offering an alternative to the power paradigm. You might look at Matti Vuorre’s Sample size planning with brms project. And finally, I have a series of blog posts on Bayesian power analyses. You can find the first post here. 4.5 Multiple \\(X\\)s or \\(Y\\)s: Analyze separately or simultaneously? “Researchers sometimes propose that several causal agents (\\(X\\) variables simultaneously transmit their effects on the same outcome through the same mediator(s)” (p. 141). 4.5.1 Multiple \\(X\\) variables. The danger in including multiple \\(X\\)’s in a mediation model, as when including statistical controls, is the possibility that highly correlated \\(X\\)s will cancel out each other’s effects. This is a standard concern in linear models involving correlated predictors. Two \\(X\\) variables (or an \\(X\\) variable and a control variable) highly correlated with each other may also both be correlated with \\(M\\) or \\(Y\\), so when they are both included as predictors of \\(M\\) or \\(Y\\) in a mediation model, they compete against each other in their attempt to explain variation in \\(M\\) and \\(Y\\). Their regression coefficients quantify their unique association with the model’s mediator and outcome variable(s). at the extreme, the two variables end up performing like two boxers in the ring simultaneously throwing a winning blow at the other at precisely the same time. Both get knocked out and neither goes away appearing worthy of a prize. The stronger the associations between the variables in the model, the greater the potential of such a problem. (pp. 143–144) The same basic problems with multicollinearity applies to the Bayesian paradigm, too. 4.5.2 Estimation of a model with multiple \\(X\\) variables in PROCESS brms. Hayes discussed the limitation that his PROCESS program may only handle a single \\(X\\) variable in the x= part of the command line, for which he displayed a workaround. We don’t have such a limitation in brms. Using Hayes’s hypothetical data syntax for a model with three \\(X\\)s, the brms code would be like this. model4.6 &lt;- brm(data = data, family = gaussian, bf(dv ~ 1 + iv1 + iv2 + iv3 + med) + bf(med ~ 1 + iv1 + iv2 + iv3) + set_rescor(FALSE), cores = 4) To show it in action, let’s simulate some data. n &lt;- 1e3 set.seed(4.5) d &lt;- tibble(iv1 = rnorm(n, mean = 0, sd = 1), iv2 = rnorm(n, mean = 0, sd = 1), iv3 = rnorm(n, mean = 0, sd = 1)) %&gt;% mutate(med = rnorm(n, mean = 0 + iv1 * -1 + iv2 * 0 + iv3 * 1, sd = 1), dv = rnorm(n, mean = 0 + iv1 * 0 + iv2 * .5 + iv3 * 1 + med * .5, sd = 1)) head(d) ## # A tibble: 6 x 5 ## iv1 iv2 iv3 med dv ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.217 0.177 -1.39 -0.755 -1.77 ## 2 -0.542 1.69 0.0513 0.721 0.402 ## 3 0.891 -1.35 1.10 0.777 -0.132 ## 4 0.596 1.08 -0.203 -0.955 1.02 ## 5 1.64 -0.456 -0.428 -2.89 -3.26 ## 6 0.689 -0.681 -0.429 -0.462 -2.38 Before we proceed, if data simulation is new to you, you might check out Roger Peng’s helpful tutorial or this great post by Ariel Muldoon. Here we fit the model. model4.6 &lt;- brm(data = d, family = gaussian, bf(dv ~ 1 + iv1 + iv2 + iv3 + med) + bf(med ~ 1 + iv1 + iv2 + iv3) + set_rescor(FALSE), cores = 4) Behold the results. print(model4.6) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: dv ~ 1 + iv1 + iv2 + iv3 + med ## med ~ 1 + iv1 + iv2 + iv3 ## Data: d (Number of observations: 1000) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## dv_Intercept -0.01 0.03 -0.07 0.05 1.00 6381 2620 ## med_Intercept 0.00 0.03 -0.06 0.06 1.00 8328 3209 ## dv_iv1 0.02 0.05 -0.06 0.11 1.00 3143 2958 ## dv_iv2 0.56 0.03 0.50 0.62 1.00 6816 3053 ## dv_iv3 1.01 0.05 0.92 1.10 1.00 3072 2835 ## dv_med 0.46 0.03 0.40 0.53 1.00 2598 3270 ## med_iv1 -0.93 0.03 -0.99 -0.87 1.00 6508 2690 ## med_iv2 0.03 0.03 -0.03 0.09 1.00 7471 2999 ## med_iv3 0.98 0.03 0.92 1.04 1.00 6776 3352 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_dv 1.00 0.02 0.96 1.05 1.00 6757 3151 ## sigma_med 0.97 0.02 0.93 1.02 1.00 7183 3073 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Good old brms::brm() came through just fine. If you wanted to simulate data with a particular correlation structure for the iv variables, you might use the mvnorm() function from the MASS package, which you can learn more about here. 4.5.3 Multiple \\(Y\\) variables. We’ve already been using the multivariate syntax in brms for our simple mediation models. Fitting a mediation model with multiple \\(Y\\) variables is a minor extension. To see, let’s simulate more data. n &lt;- 1e3 set.seed(4.5) d &lt;- tibble(iv = rnorm(n, mean = 0, sd = 1)) %&gt;% mutate(med = rnorm(n, mean = 0 + iv * .5, sd = 1)) %&gt;% mutate(dv1 = rnorm(n, mean = 0 + iv * -1 + med * 0, sd = 1), dv2 = rnorm(n, mean = 0 + iv * 0 + med * .5, sd = 1), dv3 = rnorm(n, mean = 0 + iv * 1 + med * 1, sd = 1)) head(d) ## # A tibble: 6 x 5 ## iv med dv1 dv2 dv3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.217 0.285 -1.61 0.999 0.420 ## 2 -0.542 1.42 0.594 0.836 0.0208 ## 3 0.891 -0.902 0.206 0.120 -0.954 ## 4 0.596 1.37 -0.799 0.530 3.13 ## 5 1.64 0.362 -2.06 -0.643 0.840 ## 6 0.689 -0.337 -1.12 0.487 -1.03 Fitting this requires a slew of bf() statements. model4.7 &lt;- brm(data = d, family = gaussian, bf(dv1 ~ 1 + iv + med) + bf(dv2 ~ 1 + iv + med) + bf(dv3 ~ 1 + iv + med) + bf(med ~ 1 + iv) + set_rescor(FALSE), cores = 4) print(model4.7) ## Family: MV(gaussian, gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: dv1 ~ 1 + iv + med ## dv2 ~ 1 + iv + med ## dv3 ~ 1 + iv + med ## med ~ 1 + iv ## Data: d (Number of observations: 1000) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## dv1_Intercept 0.01 0.03 -0.05 0.07 1.00 8052 3408 ## dv2_Intercept 0.00 0.03 -0.06 0.06 1.00 9291 2822 ## dv3_Intercept -0.01 0.03 -0.07 0.05 1.00 11394 3264 ## med_Intercept 0.03 0.03 -0.04 0.09 1.00 9076 3159 ## dv1_iv -1.05 0.04 -1.12 -0.98 1.00 7625 3621 ## dv1_med 0.05 0.03 -0.01 0.11 1.00 6884 3490 ## dv2_iv 0.05 0.04 -0.02 0.13 1.00 6359 3277 ## dv2_med 0.53 0.03 0.47 0.59 1.00 7057 3574 ## dv3_iv 1.03 0.04 0.96 1.10 1.00 6603 3204 ## dv3_med 1.06 0.03 1.00 1.12 1.00 6709 3134 ## med_iv 0.53 0.03 0.46 0.59 1.00 8371 2780 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_dv1 0.98 0.02 0.93 1.02 1.00 9101 3235 ## sigma_dv2 0.97 0.02 0.93 1.02 1.00 8124 2685 ## sigma_dv3 1.00 0.02 0.96 1.05 1.00 7786 2917 ## sigma_med 1.00 0.02 0.96 1.04 1.00 9576 2698 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Once again, brms to the rescue! 4.6 Chapter summary Statistical mediation analysis has changed since the publication of Baron and Kenny (1986). The heyday of the causal steps “criteria to establish mediation” approach is over. Also disappearing in the 21 century is a concern about whether a process can be labeled as complete or partial mediation. Modern mediation analysis emphasizes an explicit estimation of the indirect effect, inferential tests of the indirect effect that don’t make unnecessary assumptions, and an acknowledgement that evidence of a statistically significant association between \\(X\\) and \\(Y\\) is not necessary to talk about a model intervening variable process (in which case the concepts of complete and partial mediation simply don’t make sense). (p. 146) To this, I’ll just point out Hayes is speaking from a frequentist hypothesis-testing orientation. If you would like to dwell on significance tests, you certainty can. But particularly from within the Bayesian paradigm, you just don’t need to. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 purrr_0.3.3 ## [7] readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] nlme_3.1-139 matrixStats_0.55.0 xts_0.11-2 lubridate_1.7.4 threejs_0.3.1 ## [6] httr_1.4.0 rstan_2.19.2 tools_3.6.0 backports_1.1.5 utf8_1.1.4 ## [11] R6_2.4.0 DT_0.9 lazyeval_0.2.2 colorspace_1.4-1 withr_2.1.2 ## [16] prettyunits_1.0.2 processx_3.4.1 tidyselect_0.2.5 gridExtra_2.3 mnormt_1.5-5 ## [21] Brobdingnag_1.2-6 compiler_3.6.0 cli_1.1.0 rvest_0.3.4 shinyjs_1.0 ## [26] xml2_1.2.0 labeling_0.3 colourpicker_1.0 scales_1.0.0 dygraphs_1.1.1.6 ## [31] psych_1.8.12 callr_3.3.2 ggridges_0.5.1 StanHeaders_2.19.0 digest_0.6.21 ## [36] foreign_0.8-71 rmarkdown_1.13 base64enc_0.1-3 pkgconfig_2.0.3 htmltools_0.4.0 ## [41] htmlwidgets_1.5 rlang_0.4.1 readxl_1.3.1 rstudioapi_0.10 shiny_1.3.2 ## [46] generics_0.0.2 zoo_1.8-6 jsonlite_1.6 crosstalk_1.0.0 gtools_3.8.1 ## [51] inline_0.3.15 magrittr_1.5 loo_2.1.0 bayesplot_1.7.0 Matrix_1.2-17 ## [56] munsell_0.5.0 fansi_0.4.0 abind_1.4-5 lifecycle_0.1.0 stringi_1.4.3 ## [61] pkgbuild_1.0.5 plyr_1.8.4 grid_3.6.0 parallel_3.6.0 promises_1.1.0 ## [66] crayon_1.3.4 miniUI_0.1.1.1 lattice_0.20-38 haven_2.1.0 hms_0.4.2 ## [71] ps_1.3.0 zeallot_0.1.0 knitr_1.23 pillar_1.4.2 igraph_1.2.4.1 ## [76] markdown_1.1 shinystan_2.5.0 stats4_3.6.0 reshape2_1.4.3 rstantools_2.0.0 ## [81] glue_1.3.1.9000 evaluate_0.14 modelr_0.1.4 vctrs_0.2.0 httpuv_1.5.2 ## [86] cellranger_1.1.0 gtable_0.3.0 assertthat_0.2.1 xfun_0.10 mime_0.7 ## [91] xtable_1.8-4 broom_0.5.2 coda_0.19-3 later_1.0.0 viridisLite_0.3.0 ## [96] rsconnect_0.8.15 shinythemes_1.1.2 bridgesampling_0.7-2 "],
["more-than-one-mediator.html", "5 More Than One Mediator 5.1 The parallel multiple mediator model 5.2 Example using the presumed media influence study 5.3 Statistical inference 5.4 The serial multiple mediator model 5.5 Models with parallel and serial mediation properties 5.6 Complementarity and competition among mediators References Session info", " 5 More Than One Mediator In this chapter we’ll explore models with more than one mediator. [We will] focus on two forms of the multiple mediator model defined by whether the mediators are linked together in a causal chain (the serial multiple mediator model) or are merely allowed to correlate bot not causally influence another mediator in the model (the parallel multiple mediator model). [We’ll] also discuss models that blend parallel and serial processes. (p. 149, emphasis in the original) 5.1 The parallel multiple mediator model Going from one to multiple mediators can be a big step up, conceptually. But from a model fitting perspective, it often isn’t that big of a deal. We just have more parameters. 5.1.1 Direct and indirect effects in a parallel multiple mediator model. With multiple mediators, we use the language of specific indirect effects. We also add the notion of a total indirect effect, following the form \\[\\text{Total indirect effect of } X \\text{ on } Y = \\sum_{i = 1}^k a_i b_i,\\] where \\(k\\) is the number of mediator variables. Thus, the total effect of \\(X\\) on \\(Y\\) is \\[c = c&#39; + \\sum_{i = 1}^k a_i b_i.\\] 5.2 Example using the presumed media influence study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) glimpse(pmi) ## Observations: 123 ## Variables: 6 ## $ cond &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, … ## $ pmi &lt;dbl&gt; 7.0, 6.0, 5.5, 6.5, 6.0, 5.5, 3.5, 6.0, 4.5, 7.0, 1.0, 6.0, 5.0, 7.0, 7.0, 7.0, 4.5, 3.5, … ## $ import &lt;dbl&gt; 6, 1, 6, 6, 5, 1, 1, 6, 6, 6, 3, 3, 4, 7, 1, 6, 3, 3, 2, 4, 4, 6, 7, 4, 5, 4, 6, 5, 5, 7, … ## $ reaction &lt;dbl&gt; 5.25, 1.25, 5.00, 2.75, 2.50, 1.25, 1.50, 4.75, 4.25, 6.25, 1.25, 2.75, 3.75, 5.00, 4.00, … ## $ gender &lt;dbl&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, … ## $ age &lt;dbl&gt; 51.0, 40.0, 26.0, 21.0, 27.0, 25.0, 23.0, 25.0, 22.0, 24.0, 22.0, 21.0, 23.0, 21.0, 22.0, … Now load brms. library(brms) Bayesian correlations, recall, just take an intercepts-only multivariate model. model5.1 &lt;- brm(data = pmi, family = gaussian, mvbind(pmi, import) ~ 1, cores = 4) A little indexing with the posterior_summary() function will get us the Bayesian correlation with its posterior \\(SD\\) and intervals. posterior_summary(model5.1)[&quot;rescor__pmi__import&quot;, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.274 0.084 0.102 0.431 As with single mediation models, the multiple mediation model requires we carefully construct the formula for each criterion. Here we’ll use the multiple bf() approach from Chapter 3. m1_model &lt;- bf(import ~ 1 + cond) m2_model &lt;- bf(pmi ~ 1 + cond) y_model &lt;- bf(reaction ~ 1 + import + pmi + cond) And now we fit the model. model5.2 &lt;- brm(data = pmi, family = gaussian, y_model + m1_model + m2_model + set_rescor(FALSE), cores = 4) print(model5.2, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: reaction ~ 1 + import + pmi + cond ## import ~ 1 + cond ## pmi ~ 1 + cond ## Data: pmi (Number of observations: 123) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## reaction_Intercept -0.155 0.529 -1.220 0.897 1.001 7000 3193 ## import_Intercept 3.907 0.217 3.478 4.334 1.001 8850 3188 ## pmi_Intercept 5.378 0.161 5.062 5.697 1.001 9396 2705 ## reaction_import 0.325 0.071 0.183 0.461 1.000 6348 2918 ## reaction_pmi 0.398 0.094 0.216 0.582 1.002 6464 3227 ## reaction_cond 0.099 0.238 -0.369 0.566 1.002 7431 3107 ## import_cond 0.630 0.312 0.014 1.256 1.001 8770 2883 ## pmi_cond 0.474 0.231 0.021 0.928 1.000 7921 2470 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_reaction 1.303 0.087 1.147 1.482 1.003 6724 2801 ## sigma_import 1.734 0.112 1.535 1.958 1.003 8273 3088 ## sigma_pmi 1.318 0.087 1.159 1.502 1.002 8969 3099 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Because we have three criterion variables, we’ll have three Bayesian \\(R^2\\) posteriors. library(ggthemes) bayes_R2(model5.2, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% mutate(name = str_remove(name, &quot;R2&quot;)) %&gt;% ggplot(aes(x = value, color = name, fill = name)) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;Our &quot;, italic(R)^{2}, &quot; distributions&quot;)), subtitle = &quot;The densities for import and pmi are asymmetric, small, and largely overlapping.\\nThe density for reaction is approximately Gaussian and more impressive in magnitude.&quot;, x = NULL) + theme_minimal() + theme(legend.title = element_blank()) It’ll take a bit of data wrangling to rename our model parameters to the \\(a\\), \\(b\\)… configuration. We’ll compute the indirect effects and \\(c\\), too. post &lt;- posterior_samples(model5.2) post &lt;- post %&gt;% mutate(a1 = b_import_cond, a2 = b_pmi_cond, b1 = b_reaction_import, b2 = b_reaction_pmi, c_prime = b_reaction_cond) %&gt;% mutate(a1b1 = a1 * b1, a2b2 = a2 * b2) %&gt;% mutate(c = c_prime + a1b1 + a2b2) Next we compute their summaries. Since Bayesians use means, medians, and sometimes the mode to describe the central tendencies of a parameter, this time we’ll mix it up and just use the median. We’ve been summarising our posteriors within the summarize() function. This approach gives us a lot of control. It’s also on the verbose side. Another approach is to use a family of functions from the tidybayes package. Here we’ll use median_qi() to give us the posterior medians and quantile-based 95% intervals for our parameters of interest. library(tidybayes) post %&gt;% pivot_longer(a1:c) %&gt;% group_by(name) %&gt;% median_qi(value) ## # A tibble: 8 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 0.628 0.0143 1.26 0.95 median qi ## 2 a1b1 0.197 0.00490 0.456 0.95 median qi ## 3 a2 0.477 0.0206 0.928 0.95 median qi ## 4 a2b2 0.180 0.00726 0.415 0.95 median qi ## 5 b1 0.325 0.183 0.461 0.95 median qi ## 6 b2 0.396 0.216 0.582 0.95 median qi ## 7 c 0.495 -0.0329 1.01 0.95 median qi ## 8 c_prime 0.101 -0.369 0.566 0.95 median qi In the value column, we have our measure of central tendency (i.e., median). The 95% intervals are in the next two columns. With tidybayes, we can ask for different kinds of intervals and different kinds of measures of central tendency, as indicated by the .width and .point columns, respectively. For example, here’s the output for the same variables when we ask for posterior means and 80% intervals. post %&gt;% pivot_longer(a1:c) %&gt;% group_by(name) %&gt;% mean_qi(value, .width = .8) %&gt;% # for good measure mutate_if(is_double, round, digits = 3) ## # A tibble: 8 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 0.63 0.229 1.03 0.8 mean qi ## 2 a1b1 0.205 0.07 0.35 0.8 mean qi ## 3 a2 0.474 0.174 0.765 0.8 mean qi ## 4 a2b2 0.188 0.062 0.323 0.8 mean qi ## 5 b1 0.325 0.235 0.413 0.8 mean qi ## 6 b2 0.398 0.279 0.52 0.8 mean qi ## 7 c 0.492 0.149 0.844 0.8 mean qi ## 8 c_prime 0.099 -0.207 0.396 0.8 mean qi For more in this family of tidybayes functions, check out the Point summaries and intervals subsection of Kay’s helpful document, Extracting and visualizing tidy draws from brms models. In the middle paragraph of page 158, Hayes showed how the mean difference in imprt between the two cond groups multiplied by b1, the coefficient of import predicting reaction, is equal to the a1b1 indirect effect. He did that with simple algebra using the group means and the point estimates, following the formula \\[a_1 b_1 = \\{[\\overline M_1 | (X = 1)] - [\\overline M_1 | (X = 0)]\\} b_1.\\] Let’s follow along. First, we’ll get those two group means and save them as numbers to arbitrary precision. ( import_means &lt;- pmi %&gt;% group_by(cond) %&gt;% summarize(mean = mean(import)) ) ## # A tibble: 2 x 2 ## cond mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 3.91 ## 2 1 4.53 (cond_0_import_mean &lt;- import_means[1, 2] %&gt;% pull()) ## [1] 3.907692 (cond_1_import_mean &lt;- import_means[2, 2] %&gt;% pull()) ## [1] 4.534483 Here we follow the formula in the last sentence of the paragraph and then compare the results to the posterior for a1b1. post %&gt;% # use Hayes&#39;s formula to make a new vector, `handmade a1b1` mutate(`handmade a1b1` = (cond_1_import_mean - cond_0_import_mean) * b1) %&gt;% # wragle as usual pivot_longer(c(a1b1, `handmade a1b1`)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b1 0.205 0.005 0.456 0.95 mean qi ## 2 handmade a1b1 0.203 0.115 0.289 0.95 mean qi Yep, Hayes’s formula is good at the mean. But the distributions are distinct with vastly different posterior intervals. I’m no mathematician, so take this with a grain of salt, but I suspect this has to do with how we used fixed values (i.e., the difference of the subsample means) to compute handmade a1b1, but all the components in a1b1 were estimated. Here we’ll follow the same protocol for a2b2. ( pmi_means &lt;- pmi %&gt;% group_by(cond) %&gt;% summarize(mean = mean(pmi)) ) ## # A tibble: 2 x 2 ## cond mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 5.38 ## 2 1 5.85 cond_0_pmi_mean &lt;- pmi_means[1, 2] %&gt;% pull() cond_1_pmi_mean &lt;- pmi_means[2, 2] %&gt;% pull() post %&gt;% mutate(`handmade a2b2` = (cond_1_pmi_mean - cond_0_pmi_mean) * b2) %&gt;% pivot_longer(c(a2b2, `handmade a2b2`)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a2b2 0.188 0.007 0.415 0.95 mean qi ## 2 handmade a2b2 0.189 0.103 0.277 0.95 mean qi To get the total indirect effect as discussed on page 160, we simply add the a1b1 and a2b2 columns. post &lt;- post %&gt;% mutate(total_indirect_effect = a1b1 + a2b2) post %&gt;% mean_qi(total_indirect_effect) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 1 x 6 ## total_indirect_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.393 0.119 0.708 0.95 mean qi To use the equations on the top of page 161, we’ll just work directly with the original vectors in post. post %&gt;% mutate(Y_bar_given_X_1 = b_import_Intercept + b_reaction_cond * 1 + b_reaction_import * b_import_Intercept + b_reaction_pmi * b_pmi_Intercept, Y_bar_given_X_0 = b_import_Intercept + b_reaction_cond * 0 + b_reaction_import * b_import_Intercept + b_reaction_pmi * b_pmi_Intercept) %&gt;% mutate(`c_prime by hand` = Y_bar_given_X_1 - Y_bar_given_X_0) %&gt;% pivot_longer(c(c_prime, `c_prime by hand`)) %&gt;% group_by(name) %&gt;% mean_qi(value) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 c_prime 0.0991 -0.369 0.566 0.95 mean qi ## 2 c_prime by hand 0.0991 -0.369 0.566 0.95 mean qi We computed c a while ago. post %&gt;% mean_qi(c) ## # A tibble: 1 x 6 ## c .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.492 -0.0329 1.01 0.95 mean qi And c minus c_prime is straight subtraction. post %&gt;% mutate(`c minus c_prime` = c - c_prime) %&gt;% mean_qi(`c minus c_prime`) ## # A tibble: 1 x 6 ## `c minus c_prime` .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.393 0.119 0.708 0.95 mean qi 5.3 Statistical inference We’ve been focusing on this all along with our posterior intervals. 5.3.1 Inference about the direct and total effects. We’re not going to bother with \\(p\\)-values and we’ve already computed the 95% Bayesian credible intervals, above. But we can examine our parameters with a density plot. post %&gt;% pivot_longer(c(c, c_prime)) %&gt;% ggplot(aes(x = value, fill = name, color = name)) + geom_vline(xintercept = 0, color = &quot;black&quot;) + geom_density(alpha = .5) + scale_color_ptol(NULL) + scale_fill_ptol(NULL) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;It appears zero is more credible for the direct effect, &quot;, italic(c), &quot;&#39;, than it is the total effect, &quot;, italic(c), &quot;.&quot;)), x = NULL) + coord_cartesian(xlim = -c(-1.5, 1.5)) + theme_minimal() 5.3.2 Inference about specific indirect effects. Again, no need to worry about bootstrapping within the Bayesian paradigm. We can compute high-quality percentile-based intervals with our HMC-based posterior samples. post %&gt;% pivot_longer(c(a1b1, a2b2)) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b1 0.197 0.005 0.456 0.95 median qi ## 2 a2b2 0.18 0.007 0.415 0.95 median qi 5.3.3 Pairwise comparisons between specific indirect effects. Within the Bayesian paradigm, it’s straightforward to compare indirect effects. All one has to do is compute a difference score and summarize it somehow. Here it is, a1b1 minus a2b2. post &lt;- post %&gt;% mutate(difference = a1b1 - a2b2) post %&gt;% mean_qi(difference) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## difference .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.016 -0.289 0.337 0.95 mean qi Why not plot? post %&gt;% ggplot(aes(x = difference)) + geom_vline(xintercept = 0, color = &quot;black&quot;, linetype = 2) + geom_density(color = &quot;black&quot;, fill = &quot;black&quot;, alpha = .5) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The difference score between the indirect effects&quot;, subtitle = expression(paste(&quot;No &quot;, italic(p), &quot;-value or 95% intervals needed for this one.&quot;)), x = NULL) + coord_cartesian(xlim = -1:1) + theme_minimal() Although note well this does not mean their difference is exactly zero. The shape of the posterior distribution testifies our uncertainty in their difference. Our best bet is that the difference is approximately zero, but it could easily be plus or minus a quarter of a point or more. 5.3.4 Inference about the total indirect effect. Here’s the plot. post %&gt;% ggplot(aes(x = total_indirect_effect, fill = factor(0), color = factor(0))) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The total indirect effect of condition on reaction&quot;, subtitle = expression(paste(&quot;This is the sum of &quot;, italic(a)[1], italic(b)[1], &quot; and &quot;, italic(a)[2], italic(b)[2], &quot;. It&#39;s wide and uncertain.&quot;)), x = NULL) + theme_minimal() + theme(legend.position = &quot;none&quot;) 5.4 The serial multiple mediator model Examples of the parallel multiple mediator model like that described in the prior section are in abundance in the literature. A distinguishing feature of this model is the assumption that no mediator causally influences another. In practice, mediators will be correlated, but this model specified that they are not causally so. In the serial multiple mediator model, the assumption of no causal association between two or more mediators is not only relaxed, it is rejected outright a priori. The goal when an investigator estimates a serial multiple mediator model is to investigate the direct and indirect effects of \\(X\\) on \\(Y\\) while modeling a process in which \\(X\\) causes \\(M_1\\), which in turn causes \\(M_2\\), and so forth, concluding with \\(Y\\) as the final consequent. (p. 167, emphasis in the original) 5.4.1 Direct and indirect effects in a serial multiple mediator model. In a serial multiple mediator model, the total effect of \\(X\\) on \\(Y\\) partitions into direct and indirect components, just as it does in the simple and parallel multiple mediator models. Regardless of the number of mediators in the model, the direct effect is \\(c&#39;\\) and interpreted as always–the estimated difference in \\(Y\\) between two cases that differ by one unit on \\(X\\) but that are equal on all mediators in the model. The indirect effects, of which there may be many depending on the number of mediators in the model, are all constructed by multiplying the regression weights corresponding to each step in an indirect pathway. And they are all interpreted as the estimated difference in \\(Y\\) between two cases that differ by one unit on \\(X\\) through the causal sequence from \\(X\\) to mediator(s) to \\(Y\\). Regardless of the number of mediators, the sum of all the specific indirect effects is the total indirect effect of \\(X\\), and the direct and indirect effects sum to the total effect of \\(X\\). (p. 170) 5.4.2 Statistical inference. “In principle, Monte Carlo confidence intervals can be constructed for all indirect effects in a serial multiple mediator model” (p. 172). I’m pretty sure Hayes didn’t intend this to refer to Bayesian estimation, but I couldn’t resist the quote. 5.4.3 Example from the presumed media influence study. The model syntax is similar to the earlier multiple mediator model. All we change is adding import to the list of predictors in the submodel for m2_model. But this time, let’s take the approach from last chapter where we define our bf() formulas all within brm(). model5.3 &lt;- brm(data = pmi, family = gaussian, bf(import ~ 1 + cond) + bf(pmi ~ 1 + import + cond) + bf(reaction ~ 1 + import + pmi + cond) + set_rescor(FALSE), cores = 4) print(model5.3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: import ~ 1 + cond ## pmi ~ 1 + import + cond ## reaction ~ 1 + import + pmi + cond ## Data: pmi (Number of observations: 123) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## import_Intercept 3.91 0.22 3.46 4.33 1.00 8200 3008 ## pmi_Intercept 4.62 0.30 4.01 5.20 1.00 7898 3279 ## reaction_Intercept -0.15 0.54 -1.19 0.88 1.00 7148 2965 ## import_cond 0.63 0.32 0.01 1.25 1.00 8085 3363 ## pmi_import 0.20 0.07 0.06 0.33 1.00 7493 3110 ## pmi_cond 0.35 0.23 -0.09 0.80 1.00 7073 3145 ## reaction_import 0.32 0.07 0.18 0.47 1.00 8088 3161 ## reaction_pmi 0.40 0.09 0.21 0.58 1.00 6706 3482 ## reaction_cond 0.10 0.25 -0.38 0.58 1.01 9372 2636 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_import 1.73 0.11 1.52 1.98 1.00 8014 2541 ## sigma_pmi 1.28 0.08 1.12 1.45 1.00 8945 3206 ## sigma_reaction 1.30 0.08 1.15 1.48 1.00 8368 2379 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Behold the \\(R^2\\) posterior densities. bayes_R2(model5.3, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% mutate(name = str_remove(name, &quot;R2&quot;)) %&gt;% ggplot(aes(x = value, color = name, fill = name)) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for model3, the serial multiple mediator model&quot;)), subtitle = &quot;The density for reaction hasn&#39;t changed from model5.2. However, look how the pmi density separated from import.&quot;, x = NULL) + theme_minimal() + theme(legend.title = element_blank()) As before, here we’ll save the posterior samples into a data frame and rename the parameters a bit to match Hayes’s nomenclature. post &lt;- posterior_samples(model5.3) %&gt;% mutate(a1 = b_import_cond, a2 = b_pmi_cond, b1 = b_reaction_import, b2 = b_reaction_pmi, c_prime = b_reaction_cond, d21 = b_pmi_import) Here are the parameter summaries for the pathways depicted in Figure 5.6. post %&gt;% pivot_longer(a1:d21) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 6 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 0.628 0.009 1.25 0.95 mean qi ## 2 a2 0.355 -0.089 0.8 0.95 mean qi ## 3 b1 0.325 0.184 0.466 0.95 mean qi ## 4 b2 0.396 0.211 0.576 0.95 mean qi ## 5 c_prime 0.103 -0.38 0.580 0.95 mean qi ## 6 d21 0.195 0.061 0.327 0.95 mean qi To get our version of the parameter summaries in Table 5.2, all you have to do is add the summaries for the intercepts to what we did above. post %&gt;% rename(im1 = b_import_Intercept, im2 = b_pmi_Intercept, iy = b_reaction_Intercept) %&gt;% pivot_longer(c(a1:d21, starts_with(&quot;i&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% # simplify the output select(name:.upper) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 9 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a1 0.628 0.009 1.25 ## 2 a2 0.355 -0.089 0.8 ## 3 b1 0.325 0.184 0.466 ## 4 b2 0.396 0.211 0.576 ## 5 c_prime 0.103 -0.38 0.580 ## 6 d21 0.195 0.061 0.327 ## 7 im1 3.91 3.46 4.33 ## 8 im2 4.62 4.01 5.20 ## 9 iy -0.147 -1.19 0.884 Here we compute the four indirect effects. post &lt;- post %&gt;% mutate(a1b1 = a1 * b1, a2b2 = a2 * b2, a1d21b2 = a1 * d21 * b2) %&gt;% mutate(total_indirect_effect = a1b1 + a2b2 + a1d21b2) Anticipating the skew typical of indirect effects, we’ll summarize these posteriors with medians rather than means. post %&gt;% pivot_longer(a1b1:total_indirect_effect) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 4 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a1b1 0.195 0.003 0.46 ## 2 a1d21b2 0.042 0 0.128 ## 3 a2b2 0.136 -0.035 0.353 ## 4 total_indirect_effect 0.385 0.089 0.737 To get the contrasts Hayes presented in page 179, we just do a little subtraction. post %&gt;% mutate(c1 = a1b1 - a2b2, c2 = a1b1 - a1d21b2, c3 = a2b2 - a1d21b2) %&gt;% pivot_longer(c1:c3) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c1 0.06 -0.243 0.38 ## 2 c2 0.143 -0.001 0.379 ## 3 c3 0.088 -0.103 0.31 And just because it’s fun, we may as well plot our indirect effects. # this will help us save a little space with the plot code my_labels &lt;- c(expression(paste(italic(a)[1], italic(b)[1])), expression(paste(italic(a)[1], italic(d)[21], italic(b)[1])), expression(paste(italic(a)[2], italic(b)[2])), &quot;total indirect effect&quot;) # wrangle post %&gt;% pivot_longer(a1b1:total_indirect_effect) %&gt;% # plot! ggplot(aes(x = value, fill = name, color = name)) + geom_density(alpha = .5) + scale_color_ptol(NULL, labels = my_labels, guide = guide_legend(label.hjust = 0)) + scale_fill_ptol(NULL, labels = my_labels, guide = guide_legend(label.hjust = 0)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The four indirect effects of the serial multiple mediator model&quot;, x = NULL) + theme_minimal() 5.5 Models with parallel and serial mediation properties In a model with two mediators, the only difference between a serial and a parallel multiple mediator model is the inclusion of a causal path from \\(M_1\\) to \\(M_2\\). The serial model estimates this effect, whereas the parallel model assumes it is zero, which is equivalent to leaving it out of the model entirely. With more than three mediators, a model can be a blend of parallel and serial mediation processes, depending on which paths between mediators are estimated and which are fixed to zero through their exclusion from the model. (p. 180) 5.6 Complementarity and competition among mediators This chapter has been dedicated to mediation models containing more than one mediator. At this point, the benefits of estimating multiple mechanisms of influence in a single model are no doubt apparent. But the inclusion of more than one mediator in a model does entail certain risks as well, and at times the results of multiple mediator model may appear to contradict the results obtained when estimating a simpler model with a single mediator. Some of the risks, paradoxes, and contradictions that sometimes can occur are worth some acknowledgement and discussion. (p. 183) Tread carefully, friends. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 ggthemes_4.2.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 ## [7] dplyr_0.8.3 purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 ## [13] tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ggridges_0.5.1 rsconnect_0.8.15 ggstance_0.3.2 ## [5] markdown_1.1 base64enc_0.1-3 rstudioapi_0.10 rstan_2.19.2 ## [9] svUnit_0.7-12 DT_0.9 fansi_0.4.0 lubridate_1.7.4 ## [13] xml2_1.2.0 bridgesampling_0.7-2 knitr_1.23 shinythemes_1.1.2 ## [17] zeallot_0.1.0 bayesplot_1.7.0 jsonlite_1.6 broom_0.5.2 ## [21] shiny_1.3.2 compiler_3.6.0 httr_1.4.0 backports_1.1.5 ## [25] assertthat_0.2.1 Matrix_1.2-17 lazyeval_0.2.2 cli_1.1.0 ## [29] later_1.0.0 htmltools_0.4.0 prettyunits_1.0.2 tools_3.6.0 ## [33] igraph_1.2.4.1 coda_0.19-3 gtable_0.3.0 glue_1.3.1.9000 ## [37] reshape2_1.4.3 cellranger_1.1.0 vctrs_0.2.0 nlme_3.1-139 ## [41] crosstalk_1.0.0 xfun_0.10 ps_1.3.0 rvest_0.3.4 ## [45] mime_0.7 miniUI_0.1.1.1 lifecycle_0.1.0 gtools_3.8.1 ## [49] zoo_1.8-6 scales_1.0.0 colourpicker_1.0 hms_0.4.2 ## [53] promises_1.1.0 Brobdingnag_1.2-6 parallel_3.6.0 inline_0.3.15 ## [57] shinystan_2.5.0 gridExtra_2.3 loo_2.1.0 StanHeaders_2.19.0 ## [61] stringi_1.4.3 dygraphs_1.1.1.6 pkgbuild_1.0.5 rlang_0.4.1 ## [65] pkgconfig_2.0.3 matrixStats_0.55.0 evaluate_0.14 lattice_0.20-38 ## [69] rstantools_2.0.0 htmlwidgets_1.5 labeling_0.3 tidyselect_0.2.5 ## [73] processx_3.4.1 plyr_1.8.4 magrittr_1.5 R6_2.4.0 ## [77] generics_0.0.2 pillar_1.4.2 haven_2.1.0 withr_2.1.2 ## [81] xts_0.11-2 abind_1.4-5 modelr_0.1.4 crayon_1.3.4 ## [85] arrayhelpers_1.0-20160527 utf8_1.1.4 rmarkdown_1.13 grid_3.6.0 ## [89] readxl_1.3.1 callr_3.3.2 threejs_0.3.1 digest_0.6.21 ## [93] xtable_1.8-4 httpuv_1.5.2 stats4_3.6.0 munsell_0.5.0 ## [97] shinyjs_1.0 "],
["mediation-analysis-with-a-multicategorical-antecedent.html", "6 Mediation Analysis with a Multicategorical Antecedent 6.1 Relative total, direct, and indirect effects 6.2 An example: Sex discrimination in the workplace 6.3 Using a different group coding system 6.4 Some miscellaneous issues [unrelated to those Hayes covered in the text] References Session info", " 6 Mediation Analysis with a Multicategorical Antecedent “Historically, investigators interested in doing a mediation analysis with a multicategorical antecedents \\(X\\) have resorted to some less optimal strategies than the one [Hayes] discuss[ed] in this chapter (p. 188).” Happily, the approach outlined in this chapter avoids such gaffs. Hayes’s procedure “does not require discarding any data; the entire sample is analyzed simultaneously. Furthermore, the multicategorical nature of \\(X\\) is respected and retained (p. 189).” 6.1 Relative total, direct, and indirect effects In review of regression analysis in Chapter 2, we saw that a multicategorical antecedent variable with \\(g\\) categories can be used as an antecedent variable in a regression model if it is represented by \\(g - 1\\) variables using some kind of group coding system (see section 2.7). [Hayes] described indicator or dummy coding as one such system, where groups are represented with \\(g - 1\\) variables set to either zero or one (see Table 2.1). With indicator coding, one of the \\(g\\) groups is chosen as the reference group. Cases in the reference group receive a zero on all \\(g - 1\\) variables coding \\(X\\). Each of the remaining \\(g - 1\\) groups gets its own indicator variable that is set to 1 for cases in that group, with all other cases set to zero. Using such a system, which of the \\(g\\) groups a case is in is represented by its pattern of zeros and ones on the \\(g - 1\\) indicator variables. These \\(g - 1\\) indicator variables are then used as antecedent variables in a regression model as a stand-in for \\(X\\). (pp. 189–190, emphasis in the original) 6.1.1 Relative indirect effects. When our \\(X\\) is multicategorical, we end up with \\(g - 1\\) \\(a\\) coefficients. Presuming the \\(M\\) variable is continuous or binary, this will yield \\(g - 1\\) relative indirect effects, \\(a_j b\\). 6.1.2 Relative direct effects. Similar to above, when our \\(X\\) is multicategorical, we end up with \\(g - 1\\) \\(c&#39;\\) coefficients, each of which is a relative direct effects. 6.1.3 Relative total effects. With the two prior subsections in mind, when our \\(X\\) is multicategorical, we end up with \\(g - 1\\) \\(c\\) coefficients, each of which is a relative total effect. These follow the form \\[c_j = c_j&#39; + a_j b,\\] where \\(j\\) indexes a given group. 6.2 An example: Sex discrimination in the workplace Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) ## Observations: 129 ## Variables: 6 ## $ subnum &lt;dbl&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, 168, 97, 7… ## $ protest &lt;dbl&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, … ## $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.87, 4.87, … ## $ angry &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1, 1, 2, 1, … ## $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.50, 4.50, … ## $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.25, 5.00, … Here are the ungrouped means and \\(SD\\)s for respappr and liking shown at the bottom of Table 6.1. protest %&gt;% pivot_longer(liking:respappr) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 liking 5.64 1.05 ## 2 respappr 4.87 1.35 We compute the summaries for respappr and liking, grouped by protest, like so. protest %&gt;% pivot_longer(liking:respappr) %&gt;% group_by(protest, name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 6 x 4 ## # Groups: protest [3] ## protest name mean sd ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 liking 5.31 1.30 ## 2 0 respappr 3.88 1.46 ## 3 1 liking 5.83 0.819 ## 4 1 respappr 5.14 1.08 ## 5 2 liking 5.75 0.936 ## 6 2 respappr 5.49 0.936 It looks like Hayes has a typo in the \\(SD\\) for liking when protest == 0. It seems he accidentally entered the value for when protest == 1 in that slot. You’ll have to wait a minute to see where the adjusted \\(Y\\) values came from. With a little if_else(), computing the dummies d1 and d2 is easy enough. protest &lt;- protest %&gt;% mutate(d1 = if_else(protest == 1, 1, 0), d2 = if_else(protest == 2, 1, 0)) We’re almost ready to fit the model. Let’s load brms. library(brms) This is the first time we’ve had a simple univariate regression model in a while–no special mvbind() syntax or multiple bf() formulas, just straight up brms::brm(). model6.1 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + d1 + d2, cores = 4) Check the coefficient summaries. fixef(model6.1) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.3065586 0.1644651 4.987521552 5.6321918 ## d1 0.5187973 0.2313537 0.066754379 0.9659453 ## d2 0.4483320 0.2250177 -0.004960553 0.8860026 Our \\(R^2\\) differences a bit from the OLS version in the text. This shouldn’t be surprising when it’s near the boundary. bayes_R2(model6.1) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.05882954 0.03580924 0.005361728 0.1404927 Here’s its shape. For the plots in this chapter, we’ll take a few formatting cues from Edward Tufte, curtesy of the ggthemes package. The theme_tufte() function will change the default font and remove some chart junk. We will take our color palette from Pokemon via the palettetown package. library(ggthemes) library(palettetown) bayes_R2(model6.1, summary = F) %&gt;% data.frame() %&gt;% ggplot(aes(x = R2)) + geom_density(size = 0, fill = pokepal(pokemon = &quot;plusle&quot;)[2]) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + xlab(expression(italic(R)^{2})) + theme_tufte() + theme(legend.title = element_blank(), plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) To use the model-implied equations to compute the means for each group on the criterion, we’ll extract the posterior samples. post &lt;- posterior_samples(model6.1) post %&gt;% mutate(Y_np = b_Intercept + b_d1 * 0 + b_d2 * 0, Y_ip = b_Intercept + b_d1 * 1 + b_d2 * 0, Y_cp = b_Intercept + b_d1 * 0 + b_d2 * 1) %&gt;% pivot_longer(contains(&quot;Y_&quot;)) %&gt;% # this line will order our output the same way Hayes did in the text (p. 197) mutate(name = factor(name, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Y_np 5.31 0.164 ## 2 Y_ip 5.83 0.157 ## 3 Y_cp 5.75 0.152 What Hayes called the “relative total effects” \\(c_1\\) and \\(c_2\\) are the d1 and d2 lines in our fixef() output, above. Here are the sub-models for the mediation model. m_model &lt;- bf(respappr ~ 1 + d1 + d2) y_model &lt;- bf(liking ~ 1 + d1 + d2 + respappr) There’s a third way to fit multivariate models in brms. It uses either the mvbrmsformula() function, or its abbreviated version, mvbf(). With these, we first define our submodels in br() statements like before. We then combine them within mvbf(), separated with a comma. If we’d like to avoid estimating a residual correlation, which we do in this project–, we then set rescore = FALSE. Here’s how it looks like for our second model. model6.2 &lt;- brm(data = protest, family = gaussian, mvbf(m_model, y_model, rescor = FALSE), cores = 4) print(model6.2) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: respappr ~ 1 + d1 + d2 ## liking ~ 1 + d1 + d2 + respappr ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## respappr_Intercept 3.89 0.19 3.53 4.25 1.00 5389 2814 ## liking_Intercept 3.72 0.31 3.09 4.33 1.00 7012 3330 ## respappr_d1 1.26 0.25 0.76 1.75 1.00 4860 3084 ## respappr_d2 1.60 0.25 1.10 2.11 1.00 4966 3327 ## liking_d1 0.00 0.23 -0.44 0.45 1.00 3736 3297 ## liking_d2 -0.22 0.23 -0.66 0.23 1.00 3326 2936 ## liking_respappr 0.41 0.07 0.27 0.55 1.00 4364 3188 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_respappr 1.18 0.08 1.04 1.34 1.00 6479 2945 ## sigma_liking 0.93 0.06 0.82 1.06 1.01 5449 2523 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Behold the Bayesian \\(R^2\\) posteriors. bayes_R2(model6.2, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(size = 0, alpha = 2/3) + annotate(&quot;text&quot;, x = .18, y = 6.75, label = &quot;liking&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[2], family = &quot;Times&quot;) + annotate(&quot;text&quot;, x = .355, y = 6.75, label = &quot;respappr&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[6], family = &quot;Times&quot;) + scale_y_continuous(NULL, breaks = NULL) + scale_fill_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(2, 6)]) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(R)^{2}, &quot; densities overlap near perfectly, both hovering around .25.&quot;)), x = NULL) + theme_tufte() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) To get the model summaries as presented in the second two columns in Table 6.2, we use posterior_samples(), rename a bit, and summarize. Like in the last chapter, here we’ll do so with a little help from tidybayes. library(tidybayes) post &lt;- posterior_samples(model6.2) %&gt;% mutate(a1 = b_respappr_d1, a2 = b_respappr_d2, b = b_liking_respappr, c1_prime = b_liking_d1, c2_prime = b_liking_d2, i_m = b_respappr_Intercept, i_y = b_liking_Intercept) post %&gt;% pivot_longer(a1:i_y) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 7 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 1.26 0.762 1.76 0.95 mean qi ## 2 a2 1.60 1.10 2.11 0.95 mean qi ## 3 b 0.41 0.27 0.547 0.95 mean qi ## 4 c1_prime 0.003 -0.44 0.449 0.95 mean qi ## 5 c2_prime -0.215 -0.657 0.23 0.95 mean qi ## 6 i_m 3.88 3.53 4.25 0.95 mean qi ## 7 i_y 3.72 3.09 4.33 0.95 mean qi Working with the \\(\\overline M_{ij}\\) formulas in page 199 is quite similar to what we did above. post %&gt;% mutate(M_np = b_respappr_Intercept + b_respappr_d1 * 0 + b_respappr_d2 * 0, M_ip = b_respappr_Intercept + b_respappr_d1 * 1 + b_respappr_d2 * 0, M_cp = b_respappr_Intercept + b_respappr_d1 * 0 + b_respappr_d2 * 1) %&gt;% pivot_longer(starts_with(&quot;M_&quot;)) %&gt;% # this line will order our output the same way Hayes did in the text (p. 199) mutate(name = factor(name, levels = c(&quot;M_np&quot;, &quot;M_ip&quot;, &quot;M_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_np 3.89 0.188 ## 2 M_ip 5.14 0.177 ## 3 M_cp 5.49 0.175 The \\(\\overline Y^*_{ij}\\) formulas are more of the same. post &lt;- post %&gt;% mutate(Y_np = b_liking_Intercept + b_liking_d1 * 0 + b_liking_d2 * 0 + b_liking_respappr * mean(protest$respappr), Y_ip = b_liking_Intercept + b_liking_d1 * 1 + b_liking_d2 * 0 + b_liking_respappr * mean(protest$respappr), Y_cp = b_liking_Intercept + b_liking_d1 * 0 + b_liking_d2 * 1 + b_liking_respappr * mean(protest$respappr)) post %&gt;% pivot_longer(starts_with(&quot;Y_&quot;)) %&gt;% mutate(name = factor(name, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Y_np 5.71 0.163 ## 2 Y_ip 5.72 0.143 ## 3 Y_cp 5.50 0.142 Note, these are where the adjusted \\(Y\\) values came from in Table 6.1. This is as fine a spot as any to introduce coefficient plots. brms, tidybayes, and the bayesplot package all offer convenience functions for coefficient plots. Before we get all lazy using convenience functions, it’s good to know how to make coefficient plots by hand. Here’s ours for those last three \\(\\overline Y^*_{ij}\\)-values. post %&gt;% pivot_longer(starts_with(&quot;Y_&quot;)) %&gt;% ggplot(aes(x = name, y = value, color = name)) + stat_summary(geom = &quot;pointrange&quot;, fun.y = median, fun.ymin = function(x){quantile(x, probs = .025)}, fun.ymax = function(x){quantile(x, probs = .975)}, size = .75) + stat_summary(geom = &quot;linerange&quot;, fun.ymin = function(x){quantile(x, probs = .25)}, fun.ymax = function(x){quantile(x, probs = .75)}, size = 1.5) + scale_color_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(3, 7, 9)]) + coord_flip() + theme_tufte() + labs(x = NULL, y = NULL) + theme(axis.ticks.y = element_blank(), legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) The points are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. For kicks, we distinguished the three values by color. If we want to examine \\(R^2\\) change for dropping the dummy variables, we’ll first fit a model that omits them. model6.3 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + respappr, cores = 4) Here are the competing \\(R^2\\) distributions. # get the R2 draws and wrangle r2 &lt;- bayes_R2(model6.2, resp = &quot;liking&quot;, summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;R2&quot;) %&gt;% bind_rows( bayes_R2(model6.3, summary = F) %&gt;% data.frame() ) %&gt;% mutate(fit = rep(c(&quot;model6.2&quot;, &quot;model6.3&quot;), each = 4000)) # plot! r2 %&gt;% ggplot(aes(x = R2, fill = fit)) + geom_density(size = 0, alpha = 2/3) + scale_fill_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(6, 7)]) + annotate(&quot;text&quot;, x = .15, y = 6.75, label = &quot;model3&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[7], family = &quot;Times&quot;) + annotate(&quot;text&quot;, x = .35, y = 6.75, label = &quot;model2&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[6], family = &quot;Times&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(R)^{2}, &quot; densities for LIKING overlap a lot.&quot;)), x = NULL) + theme_tufte() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) If you want to compare then with a change score, do something like this. r2 %&gt;% mutate(iter = rep(1:4000, times = 2)) %&gt;% pivot_wider(names_from = fit, values_from = R2) %&gt;% mutate(difference = model6.2 - model6.3) %&gt;% ggplot(aes(x = difference)) + geom_density(size = 0, fill = pokepal(pokemon = &quot;plusle&quot;)[4]) + geom_vline(xintercept = 0, color = pokepal(pokemon = &quot;plusle&quot;)[8]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The &quot;, Delta, italic(R)^{2}, &quot; distribution&quot;)), subtitle = &quot;Doesn&#39;t appear we have a lot of change.&quot;, x = NULL) + theme_tufte() + theme(legend.title = element_blank(), plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) Now compute the posterior means and 95% intervals for \\(a_1 b\\) and \\(a_2 b\\), the conditional indirect effects. post %&gt;% mutate(a1b = a1 * b, a2b = a2 * b) %&gt;% pivot_longer(a1b:a2b) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b 0.516 0.268 0.812 0.95 mean qi ## 2 a2b 0.658 0.38 0.984 0.95 mean qi 6.3 Using a different group coding system Here we’ll make our alternative dummies, what we’ll call d_1 and d_2, with orthogonal contrast coding. protest &lt;- protest %&gt;% mutate(d_1 = if_else(protest == 0, -2/3, 1/3), d_2 = if_else(protest == 0, 0, if_else(protest == 1, -1/2, 1/2))) Here are the sub-models. m_model &lt;- bf(respappr ~ 1 + d_1 + d_2) y_model &lt;- bf(liking ~ 1 + d_1 + d_2 + respappr) Now we fit using the mvbf() approach. model6.4 &lt;- brm(data = protest, family = gaussian, mvbf(m_model, y_model, rescor = FALSE), cores = 4) Here are our intercepts and regression coefficient summaries. fixef(model6.4) ## Estimate Est.Error Q2.5 Q97.5 ## respappr_Intercept 4.8421202 0.10233999 4.6374197 5.0488520 ## liking_Intercept 3.6295030 0.35531407 2.9201509 4.3177206 ## respappr_d_1 1.4362663 0.21736835 1.0058359 1.8627144 ## respappr_d_2 0.3516122 0.25351866 -0.1578317 0.8447912 ## liking_d_1 -0.1150324 0.20358287 -0.5087575 0.2845606 ## liking_d_2 -0.2177093 0.20456106 -0.6275818 0.1862900 ## liking_respappr 0.4132765 0.07107282 0.2747422 0.5561193 It’s important to note that these will not correspond to the “TOTAL EFFECT MODEL” section of the PROCESS output of Figure 6.3. Hayes’s PROCESS has the mcx=3 command which tells the program to reparametrize the orthogonal contrasts. brms doesn’t have such a command. For now, we’ll have to jump to Equation 6.8 towards the bottom of page 207. Those parameters are evident in our output. For good measure, here we’ll practice with posterior_summary(). posterior_summary(model6.4) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) %&gt;% filter(str_detect(parameter, &quot;b_respappr&quot;)) ## parameter Estimate Est.Error Q2.5 Q97.5 ## 1 b_respappr_Intercept 4.8421202 0.1023400 4.6374197 5.0488520 ## 2 b_respappr_d_1 1.4362663 0.2173683 1.0058359 1.8627144 ## 3 b_respappr_d_2 0.3516122 0.2535187 -0.1578317 0.8447912 Thus it’s easy to get the \\(\\overline M_{ij}\\) means with a little posterior manipulation. post &lt;- posterior_samples(model6.4) %&gt;% mutate(M_np = b_respappr_Intercept + b_respappr_d_1 * -2/3 + b_respappr_d_2 * 0, M_ip = b_respappr_Intercept + b_respappr_d_1 * 1/3 + b_respappr_d_2 * -1/2, M_cp = b_respappr_Intercept + b_respappr_d_1 * 1/3 + b_respappr_d_2 * 1/2) post %&gt;% pivot_longer(starts_with(&quot;M_&quot;)) %&gt;% mutate(name = factor(name, levels = c(&quot;M_np&quot;, &quot;M_ip&quot;, &quot;M_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_np 3.88 0.181 ## 2 M_ip 5.15 0.176 ## 3 M_cp 5.50 0.177 With these in hand, we can compute \\(a_1\\) and \\(a_2\\). post &lt;- post %&gt;% mutate(a1 = (M_ip + M_cp)/2 - M_np, a2 = M_cp - M_ip) post %&gt;% pivot_longer(a1:a2) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a1 1.44 0.217 ## 2 a2 0.352 0.254 Happily, our model output will allow us to work with Hayes’s \\(\\overline Y^*_{ij}\\) equations in the middle of page 210. post &lt;- post %&gt;% mutate(Y_np = b_liking_Intercept + b_liking_d_1 * -2/3 + b_liking_d_2 * 0 + b_liking_respappr * mean(protest$respappr), Y_ip = b_liking_Intercept + b_liking_d_1 * 1/3 + b_liking_d_2 * -1/2 + b_liking_respappr * mean(protest$respappr), Y_cp = b_liking_Intercept + b_liking_d_1 * 1/3 + b_liking_d_2 * 1/2 + b_liking_respappr * mean(protest$respappr)) post %&gt;% pivot_longer(starts_with(&quot;Y_&quot;)) %&gt;% mutate(name = factor(name, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Y_np 5.72 0.161 ## 2 Y_ip 5.71 0.145 ## 3 Y_cp 5.49 0.147 And with these in hand, we can compute \\(c&#39;_1\\) and \\(c&#39;_2\\). post &lt;- post %&gt;% mutate(c1_prime = (Y_ip + Y_cp) / 2 - Y_np, c2_prime = Y_cp - Y_ip) post %&gt;% pivot_longer(c1_prime:c2_prime) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c1_prime -0.115 0.204 ## 2 c2_prime -0.218 0.205 It appears Hayes has a typo in the formula for \\(c&#39;_2\\) on page 211. The value he has down for \\(\\overline Y^*_{IP}\\), 5.145, is incorrect. It’s not the one he displayed at the bottom of the previous page and it also contradicts the analyses herein. So it goes… These things happen. We haven’t spelled it out, but the \\(b\\) parameter is currently labeled b_liking_respappr in our post object. Here we’ll make a b column to make things easier. While we’re at it, we’ll compute the indirect effects, too. post &lt;- post %&gt;% mutate(b = b_liking_respappr) %&gt;% mutate(a1b = a1 * b, a2b = a2 * b) post %&gt;% pivot_longer(a1b:a2b) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b 0.593 0.35 0.882 0.95 mean qi ## 2 a2b 0.145 -0.065 0.368 0.95 mean qi Now we can compute and summarize() our \\(c_1\\) and \\(c_2\\). post &lt;- post %&gt;% mutate(c1 = c1_prime + a1b, c2 = c2_prime + a2b) post %&gt;% pivot_longer(c1:c2) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c1 0.478 0.197 ## 2 c2 -0.0724 0.235 6.4 Some miscellaneous issues [unrelated to those Hayes covered in the text] Do you recall how way back in Chapter 2 we covered an alternative way to fit models with multicategorical grouping variables? Well, we did. The basic strategy is to save our grouping variable as a factor and then enter it into the model with the special 0 + syntax, which removes the typical intercept. Since this chapter is all about multicategorical variables, it might make sense to explore what happens when we use this approach. For our first step, well prepare the data. protest &lt;- protest %&gt;% mutate(group = factor(protest, levels = 0:2, labels = c(&quot;none&quot;, &quot;individual&quot;, &quot;collective&quot;))) protest %&gt;% select(protest, group) ## # A tibble: 129 x 2 ## protest group ## &lt;dbl&gt; &lt;fct&gt; ## 1 2 collective ## 2 0 none ## 3 2 collective ## 4 2 collective ## 5 2 collective ## 6 1 individual ## 7 2 collective ## 8 0 none ## 9 0 none ## 10 0 none ## # … with 119 more rows Before we fit a full mediation model, we should warm up. Here we fit a univariable model for liking. This is an alternative to what we did way back with model6.1. model6.5 &lt;- brm(data = protest, family = gaussian, liking ~ 0 + group, cores = 4) Check the summary. print(model6.5) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ 0 + group ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## groupnone 5.31 0.17 4.99 5.63 1.00 4481 2742 ## groupindividual 5.82 0.16 5.51 6.14 1.00 4041 2890 ## groupcollective 5.75 0.15 5.46 6.05 1.00 4286 3122 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.04 0.07 0.92 1.18 1.00 3820 3058 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). There’s no conventional intercept parameter. Rather, each of the each of the levels of group get its own conditional intercept. To get a sense of what this model is, let’s practice our coefficient plotting skills. This time we’ll compute the necessary values before plugging them into ggplot2. # compute the means for `liking` by `group` group_means &lt;- protest %&gt;% group_by(group) %&gt;% summarize(mu_liking = mean(liking)) # pull the posterior summaries and wrangle fixef(model6.5) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) %&gt;% mutate(group = str_remove(parameter, &quot;group&quot;)) %&gt;% # plot! ggplot(aes(x = group)) + # this is the main function for our coefficient plots geom_pointrange(aes(y = Estimate, ymin = Q2.5, ymax = Q97.5, color = group), size = 3/4) + geom_point(data = group_means, aes(y = mu_liking)) + scale_color_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(3, 7, 9)]) + coord_flip() + labs(x = NULL, y = NULL) + theme_tufte() + theme(axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank(), legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) The results from the model are in colored point ranges. The black dots in the foreground are the empirical means. It looks like our model did a good job estimating the group means for liking. Let’s see how this coding approach works when you fit a full mediation model. First, define the sub-models with two bf() lines. m_model &lt;- bf(respappr ~ 0 + group) y_model &lt;- bf(liking ~ 0 + group + respappr) Now fit model6 using the mvbf() approach. model6.6 &lt;- brm(data = protest, family = gaussian, mvbf(m_model, y_model, rescor = FALSE), cores = 4) What will the summary hold? print(model6.6) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: respappr ~ 0 + group ## liking ~ 0 + group + respappr ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## respappr_groupnone 3.88 0.18 3.53 4.25 1.00 4047 2935 ## respappr_groupindividual 5.14 0.18 4.80 5.50 1.00 4292 2872 ## respappr_groupcollective 5.49 0.18 5.14 5.84 1.00 4163 3112 ## liking_groupnone 3.69 0.31 3.07 4.31 1.00 1809 2305 ## liking_groupindividual 3.69 0.39 2.91 4.44 1.00 1791 2306 ## liking_groupcollective 3.47 0.41 2.65 4.29 1.00 1722 1948 ## liking_respappr 0.42 0.07 0.28 0.56 1.00 1667 2197 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_respappr 1.18 0.07 1.05 1.34 1.00 4186 2680 ## sigma_liking 0.93 0.06 0.82 1.05 1.00 3887 2790 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). If you flip back to page 199, you’ll notice the posterior mean in the first three rows (i.e., respappr_groupnone through respappr_groupcollective) correspond to the estimates for \\(\\overline M_{NP}\\), \\(\\overline M_{IP}\\), and \\(\\overline M_{CP}\\), respectively. Let’s get to the \\(a_j b\\) estimates. post &lt;- posterior_samples(model6.6) %&gt;% mutate(a1 = b_respappr_groupnone, a2 = b_respappr_groupindividual, a3 = b_respappr_groupcollective, b = b_liking_respappr) %&gt;% mutate(a1b = a1 * b, a2b = a2 * b, a3b = a3 * b) post %&gt;% pivot_longer(a1b:a3b) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b 1.61 1.06 2.19 0.95 mean qi ## 2 a2b 2.14 1.42 2.87 0.95 mean qi ## 3 a3b 2.28 1.52 3.07 0.95 mean qi With this parameterization, it’s a little difficult to the \\(a_j b\\) estimates. None of them are in comparison to anything. However, this approach is quite useful once you compute their various difference scores. # compute the difference scores post &lt;- post %&gt;% mutate(diff_individual_minus_none = a2b - a1b, diff_collective_minus_none = a3b - a1b, diff_collective_minus_individual = a3b - a2b) # summarize post %&gt;% pivot_longer(contains(&quot;diff&quot;)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 diff_collective_minus_individual 0.144 -0.055 0.364 0.95 mean qi ## 2 diff_collective_minus_none 0.669 0.381 0.992 0.95 mean qi ## 3 diff_individual_minus_none 0.524 0.274 0.826 0.95 mean qi If you look back to our results from model6.2, you’ll see that diff_individual_minus_none and diff_collective_minus_none correspond to a1b and a2b, respectively. But with our model6.6 approach, we get the additional information of what kind of indirect effect we might have yielded had we used a different coding scheme for our original set of dummy variables. That is, we get diff_collective_minus_individual. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 palettetown_0.1.1 ggthemes_4.2.0 brms_2.10.3 Rcpp_1.0.2 ## [6] forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 purrr_0.3.3 readr_1.3.1 ## [11] tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ggridges_0.5.1 rsconnect_0.8.15 ggstance_0.3.2 ## [5] markdown_1.1 base64enc_0.1-3 rstudioapi_0.10 rstan_2.19.2 ## [9] svUnit_0.7-12 DT_0.9 fansi_0.4.0 lubridate_1.7.4 ## [13] xml2_1.2.0 bridgesampling_0.7-2 knitr_1.23 shinythemes_1.1.2 ## [17] zeallot_0.1.0 bayesplot_1.7.0 jsonlite_1.6 broom_0.5.2 ## [21] shiny_1.3.2 compiler_3.6.0 httr_1.4.0 backports_1.1.5 ## [25] assertthat_0.2.1 Matrix_1.2-17 lazyeval_0.2.2 cli_1.1.0 ## [29] later_1.0.0 htmltools_0.4.0 prettyunits_1.0.2 tools_3.6.0 ## [33] igraph_1.2.4.1 coda_0.19-3 gtable_0.3.0 glue_1.3.1.9000 ## [37] reshape2_1.4.3 cellranger_1.1.0 vctrs_0.2.0 nlme_3.1-139 ## [41] crosstalk_1.0.0 xfun_0.10 ps_1.3.0 rvest_0.3.4 ## [45] mime_0.7 miniUI_0.1.1.1 lifecycle_0.1.0 gtools_3.8.1 ## [49] zoo_1.8-6 scales_1.0.0 colourpicker_1.0 hms_0.4.2 ## [53] promises_1.1.0 Brobdingnag_1.2-6 parallel_3.6.0 inline_0.3.15 ## [57] shinystan_2.5.0 gridExtra_2.3 loo_2.1.0 StanHeaders_2.19.0 ## [61] stringi_1.4.3 dygraphs_1.1.1.6 pkgbuild_1.0.5 rlang_0.4.1 ## [65] pkgconfig_2.0.3 matrixStats_0.55.0 evaluate_0.14 lattice_0.20-38 ## [69] rstantools_2.0.0 htmlwidgets_1.5 labeling_0.3 tidyselect_0.2.5 ## [73] processx_3.4.1 plyr_1.8.4 magrittr_1.5 R6_2.4.0 ## [77] generics_0.0.2 pillar_1.4.2 haven_2.1.0 withr_2.1.2 ## [81] xts_0.11-2 abind_1.4-5 modelr_0.1.4 crayon_1.3.4 ## [85] arrayhelpers_1.0-20160527 utf8_1.1.4 rmarkdown_1.13 grid_3.6.0 ## [89] readxl_1.3.1 callr_3.3.2 threejs_0.3.1 digest_0.6.21 ## [93] xtable_1.8-4 httpuv_1.5.2 stats4_3.6.0 munsell_0.5.0 ## [97] shinyjs_1.0 "],
["fundamentals-of-moderation-analysis.html", "7 Fundamentals of Moderation Analysis 7.1 Conditional and unconditional effects 7.2 An example: Climate change disasters and humanitarianism 7.3 Visualizing moderation 7.4 Probing an interaction 7.5 The difference between testing for moderation and probing it 7.6 Artificial categorization and subgroups References Session info Footnote", " 7 Fundamentals of Moderation Analysis The effect of \\(X\\) on some variable \\(Y\\) is moderated by \\(W\\) if its size, sign, or strength depends on or can be predicted by \\(W\\). In that case, \\(W\\) is said to be a moderator of \\(X\\)’s effect on \\(Y\\), or that \\(W\\) and \\(X\\) interact in their influence on \\(Y\\). Identifying a moderator of an effect helps to establish the boundary conditions of that effect or the circumstances, stimuli, or type of people for which the effect is large versus small, present versus absent, positive versus negative, and so forth. (p. 220, emphasis in the original) 7.1 Conditional and unconditional effects If \\(X\\)’s effect on \\(Y\\) is moderated by another variable in the model, that means \\(X\\)’s effect depends on that other variable. But this model constrains \\(X\\)’s effect to be unconditional on \\(W\\), meaning that it is invariant across all values of \\(W\\). (p. 224) Hayes’s Table 7.1 and the related Figure 7.2 showcase this well. You might reproduce the data for both like this. library(tidyverse) d &lt;- crossing(x = -1:2, w = 0:2) %&gt;% mutate(A = 4 + 1 * x + 2 * w, B = 4 + 1 * x + 2 * w + 1.5 * x * w) d ## # A tibble: 12 x 4 ## x w A B ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -1 0 3 3 ## 2 -1 1 5 3.5 ## 3 -1 2 7 4 ## 4 0 0 4 4 ## 5 0 1 6 6 ## 6 0 2 8 8 ## 7 1 0 5 5 ## 8 1 1 7 8.5 ## 9 1 2 9 12 ## 10 2 0 6 6 ## 11 2 1 8 11 ## 12 2 2 10 16 In previous chapters, we alteried our plot themes using either built-in settings from ggplot2 or extra themes from the ggthemes package. When we wanted to change them further, we did so with extra theme() arguments. One, it’s nice to be know how to make one’s own custom theme and, two, it’d be handy to condense our code a bit. Here we’ll take a few cues from the Building a New Theme section from Peng, Kross, and Anderson’s Mastering Software Development in R. We’ll make our own theme, theme_07, by saving a handful of augmentations from the default theme_gray() theme. library(dutchmasters) theme_07 &lt;- theme_gray() + theme(plot.background = element_rect(fill = dutchmasters$little_street[7]), panel.background = element_rect(fill = dutchmasters$little_street[2]), strip.background = element_rect(fill = alpha(dutchmasters$little_street[5], 2/3), color = &quot;transparent&quot;), legend.background = element_rect(fill = &quot;transparent&quot;), legend.key = element_rect(fill = &quot;transparent&quot;, color = &quot;transparent&quot;), panel.grid = element_blank(), text = element_text(family = &quot;Courier&quot;, color = dutchmasters$little_street[6], size = 14), axis.text = element_text(color = dutchmasters$little_street[6])) This chapter’s color palette comes from the dutchmasters package, which was itself based of Vermeer’s The Little Street. To get a quick glance at the full palette, we’ll also use viz_palette(), a convenience function from the ochRe package. # devtools::install_github(&quot;ropenscilabs/ochRe&quot;) library(ochRe) viz_palette(dutchmasters$little_street) With our new theme_07 in hand, we’re ready to make our version of Figure 7.2. library(directlabels) d %&gt;% pivot_longer(A:B, values_to = &quot;y&quot;) %&gt;% mutate(label = str_c(&quot;W = &quot;, w), w = factor(w), strip = if_else(name == &quot;A&quot;, &quot;A: where W is a covariate&quot;, &quot;B: where W is a moderator&quot;)) %&gt;% ggplot(aes(x = x, y = y, group = w, size = w, label = label)) + geom_line(color = dutchmasters$little_street[9]) + geom_dl(method = list(dl.trans(x = x + 0.2), &quot;last.points&quot;, cex = 1, color = dutchmasters$little_street[9], fontfamily = &quot;Courier&quot;)) + scale_size_manual(values = c(.5, .75, 1)) + coord_cartesian(xlim = c(-1, 2.6), ylim = 0:16) + labs(x = expression(italic(X)), y = expression(hat(italic(Y)))) + facet_wrap(~strip) + theme_07 + # because we didn&#39;t alter the `legend.position` argument in our `theme_07`, # we need to use `theme()` to remove it theme(legend.position = &quot;none&quot;) We borrowed geom_dl() form the directlabels package, which made it easy to insert the “W = \\(i\\)” labels to the right of the lines. I played around with the annotation in Figure 7.4 for a while and it was just way more trouble than it was worth. If you’re ever inspired to work it out, please share your code. I’m moving on. 7.1.1 Eliminating the constraint of unconditionality. We can write the generic moderation model as \\[Y = i_Y + f(W) X + b_2 W + e_Y,\\] where \\(f(W)\\) is a function of \\(W\\). Consider a simple function of the form \\(f(W) = b_1 + b_3 W\\). This function of \\(W\\) looks like a simple linear regression model where \\(b_1\\) is the constant and \\(b_3\\) is the regression coefficient for \\(W\\), except that rather than estimating some consequent variable from \\(W\\), it is a model of the effect of \\(X\\) on \\(Y\\). (p. 226) If we use that definition of \\(f(W)\\), we can update our equation to \\[\\begin{align*} Y &amp; = i_Y + (b_1 + b_3 W) X + b_2 W + e_Y, \\text{or} \\\\ Y &amp; = i_Y + b_1 X + b_2 W + b_3 XW + e_Y. \\end{align*}\\] Hayes called this the simple linear moderation model. Out of this equation we can extract \\(\\theta_{X \\rightarrow Y}\\), the conditional effect of \\(X\\) on \\(Y\\), which takes the form \\[\\theta_{X \\rightarrow Y} = b_1 + b_3 W.\\] This is what Figure 7.2 was all about. 7.1.2 Symmetry in moderation. It turns out that, mathematically, there’s no difference in speaking about \\(X\\) moderating \\(W\\) than speaking about \\(W\\) moderating \\(X\\). These are all just capital letters standing in for variables and perhaps you’ll recall from grade school that \\(a + b + ab\\) is just the same as \\(b + a + ba\\). Thus we can rearrange the simple moderation equations above to \\[Y = i_Y + b_1 X + (b_2 + b_3 X) W + e_Y\\] and speak instead about the conditional effect of \\(W\\) on \\(Y\\), \\[\\theta_{w \\rightarrow Y} = b_2 + b_3 X.\\] 7.1.3 Interpretation of the regression coefficients. With all this wacky stuff going on, we should clarify some of our terms. \\(i_Y\\) is still the expected value for \\(Y\\) with both \\(X = 0\\) and \\(W = 0\\). \\(b_1\\) is the conditional effect of \\(X\\) on \\(Y\\) when \\(W = 0\\). \\(b_2\\) is the conditional effect of \\(W\\) on \\(Y\\) when \\(X = 0\\). It turns out \\(b_3\\) requires more words, which we’ll provide in the next subsection. 7.1.4 The importance of \\(b_3\\) wen asking about mediation. The simple moderation model allows \\(X\\)’s effect on \\(Y\\) to be a linear function of \\(W\\). Of course, allowing that effect to depend on \\(W\\) doesn’t mean that it actually does in reality. In most any sample of data, [the point estimate (i.e., posterior mean or median) for] \\(b_3\\) will be different from zero even when \\(X\\)’s effect on \\(Y\\) is independent of \\(W\\). Of interest when [modeling] a moderation hypothesis is not just allowing \\(X\\)’s effect to be contingent on \\(W\\), but also determining whether \\(b_3\\) deviates too far from zero than would be expected given that \\(b_3\\), like any statistic, is subject to sampling variance. (p. 231) 7.2 An example: Climate change disasters and humanitarianism Here we load a couple necessary packages, load Chapman and Lickel (2016) data, and take a glimpse(). disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) ## Observations: 211 ## Variables: 5 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, … ## $ frame &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0… ## $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5.4, 3.4, 7… ## $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.65, 3.15, 2… ## $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1.0, 6.4, 3… Here is how to get the ungrouped mean and \\(SD\\) values for justify and skeptic, as presented in Table 7.3. disaster %&gt;% pivot_longer(justify:skeptic) %&gt;% group_by(name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 justify 2.87 0.93 ## 2 skeptic 3.38 2.03 And here we get the same summary values, this time grouped by frame. disaster %&gt;% pivot_longer(justify:skeptic) %&gt;% group_by(frame, name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 4 ## # Groups: frame [2] ## frame name mean sd ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 justify 2.80 0.849 ## 2 0 skeptic 3.34 2.04 ## 3 1 justify 2.94 1.01 ## 4 1 skeptic 3.42 2.03 Let’s open brms. library(brms) Now fit the simple univariable model. model7.1 &lt;- brm(data = disaster, family = gaussian, justify ~ 1 + frame, cores = 4) print(model7.1) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: justify ~ 1 + frame ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 2.80 0.09 2.62 2.97 1.00 3844 2857 ## frame 0.14 0.13 -0.11 0.38 1.00 3709 2972 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.94 0.05 0.85 1.03 1.00 3908 2827 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The ‘Estimate’ (i.e., posterior mean) of the model intercept is the expected justify value for when frame is 0. The ‘Estimate’ for frame is the expected difference when frame is a 1. If all you care about is the posterior mean, you could execute fixef(model7.1)[&quot;Intercept&quot;, 1] + fixef(model7.1)[&quot;frame&quot;, 1] ## [1] 2.937405 which matches up nicely with the equation on page 233. But this wouldn’t be very Bayesian of us. It’d be more satisfying if we had an expression of the uncertainty in the value. For that, we’ll follow our usual practice of extracting the posterior samples, making nicely-named vectors, and summarizing a bit. post &lt;- posterior_samples(model7.1) %&gt;% mutate(when_x_is_0 = b_Intercept, when_x_is_1 = b_Intercept + b_frame) post %&gt;% pivot_longer(when_x_is_0:when_x_is_1) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 when_x_is_0 2.8 0.089 ## 2 when_x_is_1 2.94 0.094 Hayes referenced a \\(t\\)-test and accompanying \\(p\\)-value in the lower part of page 233. We, of course, aren’t going to do that. But we do have the 95% intervals in our print() output, above, which we can also look at with the brms::posterior_interval() function. posterior_interval(model7.1)[&quot;b_frame&quot;, ] ## 2.5% 97.5% ## -0.1104055 0.3802928 And we can always plot. post %&gt;% ggplot(aes(x = b_frame)) + geom_density(size = 0, fill = dutchmasters$little_street[1]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[11]) + scale_x_continuous(breaks = c(-.3, 0, .6)) + scale_y_continuous(NULL, breaks = NULL) + theme_07 + theme(legend.position = &quot;none&quot;) We’ll use the update() function to hastily fit model7.2 and model7.3. model7.2 &lt;- update(model7.1, newdata = disaster, formula = justify ~ 1 + frame + skeptic, cores = 4) model7.3 &lt;- update(model7.1, newdata = disaster, formula = justify ~ 1 + frame + skeptic + frame:skeptic, cores = 4) Note our use of the frame:skeptic syntax in model7.3. With that syntax we didn’t need to make an interaction variable in the data by hand. The brms package just handled it for us. An alternative syntax would have been frame*skeptic. But if you really wanted to make the interaction variable by hand, you’d do this. disaster &lt;- disaster %&gt;% mutate(interaction_variable = frame * skeptic) Once you have interaction_variable in the data, you’d specify a model formula within the brm() function like formula = justify ~ 1 + frame + skeptic + interaction_variable. I’m not going to do that, here, but you can play around yourself if so inclined. Here are the quick and dirty coefficient summaries for our two new models. posterior_summary(model7.2) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 2.1329427 0.12666520 1.8795620 2.3857316 ## b_frame 0.1178844 0.11820458 -0.1143265 0.3487719 ## b_skeptic 0.2001487 0.02888595 0.1435666 0.2564288 ## sigma 0.8409529 0.04104724 0.7653761 0.9274223 ## lp__ -268.3636435 1.46962043 -272.1776486 -266.5660614 posterior_summary(model7.3) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 2.4554199 0.14742452 2.16468057 2.7530935 ## b_frame -0.5698758 0.21855069 -1.00621926 -0.1555456 ## b_skeptic 0.1037442 0.03795116 0.02815453 0.1750698 ## b_frame:skeptic 0.2033168 0.05493597 0.09793366 0.3130835 ## sigma 0.8165278 0.04032698 0.73925992 0.9000036 ## lp__ -262.3327179 1.55614763 -266.24420581 -260.2590010 Just focusing on our primary model, model7.3, here’s another way to look at the coefficients. stanplot(model7.3) + theme_07 By default, the brms::stanplot() function returns coefficient plots which depict the parameters of a model by their posterior means (i.e., dots), 50% intervals (i.e., thick horizontal lines), and 95% intervals (i.e., thin horizontal lines). As stanplot() returns a ggplot2 object, one can customize the theme and so on. We’ll extract the \\(R^2\\) iterations in the usual way once for each model, and then combine them for a plot. # for each of the three models, we create a separare R2 tibble r2_1 &lt;- bayes_R2(model7.1, summary = F) %&gt;% data.frame() r2_2 &lt;- bayes_R2(model7.2, summary = F) %&gt;% data.frame() r2_3 &lt;- bayes_R2(model7.3, summary = F) %&gt;% data.frame() # here we combine them into one tibble, indexed by `model` r2 &lt;- r2_1 %&gt;% bind_rows(r2_2) %&gt;% bind_rows(r2_3) %&gt;% mutate(model = rep(str_c(&quot;7.&quot;, 1:3), each = 4000)) # now we plot r2 %&gt;% ggplot(aes(x = R2)) + geom_density(aes(fill = model), size = 0, alpha = 2/3) + scale_fill_manual(values = dutchmasters$little_street[c(3, 4, 8)] %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(italic(R)^2, &quot; distribution&quot;))) + coord_cartesian(xlim = 0:1) + theme_07 Here’s the \\(\\Delta R^2\\) distribution for model7.3 minus model7.2. r2_2 %&gt;% bind_cols(r2_3) %&gt;% set_names(str_c(&quot;model7.&quot;, 2:3)) %&gt;% mutate(dif = model7.3 - model7.2) %&gt;% ggplot(aes(x = dif)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The &quot;, Delta, italic(R)^2)), subtitle = &quot;Like in the text, the posterior\\nmean is about 0.05.&quot;, x = NULL) + theme_07 In addition to the \\(R^2\\), one can use information criteria to compare the models. Here we’ll use the LOO to compare all three. model7.1 &lt;- add_criterion(model7.1, &quot;loo&quot;) model7.2 &lt;- add_criterion(model7.2, &quot;loo&quot;) model7.3 &lt;- add_criterion(model7.3, &quot;loo&quot;) loo_compare(model7.1, model7.2, model7.3) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model7.3 0.0 0.0 -259.1 10.9 5.5 0.9 518.1 21.7 ## model7.2 -5.7 4.2 -264.7 11.2 4.7 0.9 529.4 22.4 ## model7.1 -27.1 9.5 -286.2 12.0 3.3 0.8 572.4 24.0 The LOO point estimate for both multivariable models were clearly lower than that for model7.1. The point estimate for the moderation model, model7.3, was within the double-digit range lower than that for model7.2, which typically suggests better fit. But notice how wide the standard error was. There’s a lot of uncertainty, there. Hopefully this isn’t surprising. Our \\(R^2\\) difference was small and uncertain, too. We can also compare them with AIC-type model weighting, which you can learn more about starting at this point in this lecture or this related vignette for the loo package. Here we’ll keep things simple and weight with the LOO. model_weights(model7.1, model7.2, model7.3, weights = &quot;loo&quot;) %&gt;% round(digits = 3) ## model7.1 model7.2 model7.3 ## 0.000 0.003 0.997 The model_weights() results put almost all the relative weight on model7.3. This doesn’t mean model7.3 is the “true model” or anything like that. It just suggests that it’s the better of the three with respect to the data. Here are the results of the equations in the second half of page 237. post &lt;- posterior_samples(model7.3) post %&gt;% mutate(if_2 = b_frame + `b_frame:skeptic` * 2, if_3.5 = b_frame + `b_frame:skeptic` * 3.5, if_5 = b_frame + `b_frame:skeptic` * 5) %&gt;% pivot_longer(starts_with(&quot;if_&quot;)) %&gt;% group_by(name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% mutate(name = str_remove(name, &quot;if_&quot;)) %&gt;% rename(`conditional effect of X on Y when W =` = name) ## # A tibble: 3 x 3 ## `conditional effect of X on Y when W =` mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 -0.163 0.137 ## 2 3.5 0.142 0.113 ## 3 5 0.447 0.143 7.2.1 Estimation using PROCESS brms. Similar to what Hayes advertised with PROCESS, with our formula = justify ~ 1 + frame + skeptic + frame:skeptic code in model7.3, we didn’t need to hard code an interaction variable into the data. brms handled that for us. 7.2.2 Interpreting the regression coefficients. When you add an interaction term into a model, such as \\(x_1 \\cdot x_2\\), this is sometimes called a higher order term. The terms that made up the higher order term–\\(x_1\\) and \\(x_2\\), in this case–are correspondingly called the lower order terms. As Hayes pointed out, these lower order terms are conditional effects. Interpret them with care. 7.2.3 Variable scaling and the interpretation of \\(b_1\\) and \\(b_3\\). Making the mean-centered version of our \\(W\\) variable, skeptic, is a simple mutate() operation. We’ll just call it skeptic_c. disaster &lt;- disaster %&gt;% mutate(skeptic_c = skeptic - mean(skeptic)) And here’s how we might fit the model. model7.4 &lt;- update(model7.3, newdata = disaster, formula = justify ~ 1 + frame + skeptic_c + frame:skeptic_c, cores = 4) Here are the summaries of our fixed effects. fixef(model7.4) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.8074617 0.07751648 2.65887008 2.9642447 ## frame 0.1161191 0.11043112 -0.11107219 0.3235638 ## skeptic_c 0.1056709 0.03772872 0.03261492 0.1803278 ## frame:skeptic_c 0.1995691 0.05509437 0.09086664 0.3101503 To practice, frame and skeptic_c are lower order terms and, as such, they are conditional effects. The higher order term is frame:skeptic_c. Anyway, here are the \\(R^2\\) distributions for model7.3 and model7.4. They’re the same within simulation variance. bayes_R2(model7.3) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.249 0.045 0.159 0.332 bayes_R2(model7.4) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.248 0.045 0.159 0.336 If you’re bothered by the differences resulting from sampling variation, you might increase the number of HMC iterations from the 2000-per-chain default. Doing so might look something like this. model7.3 &lt;- update(model7.3, chains = 4, cores = 4, warmup = 1000, iter = 10000) model7.4 &lt;- update(model7.4, chains = 4, cores = 4, warmup = 1000, iter = 10000) Before we fit model7.5, we’ll recode frame to a -.5/.5 metric and name it frame_.5. disaster &lt;- disaster %&gt;% mutate(frame_.5 = ifelse(frame == 0, -.5, .5)) Time to fit model5. model7.5 &lt;- update(model7.4, newdata = disaster, formula = justify ~ 1 + frame_.5 + skeptic_c + frame_.5:skeptic_c, cores = 4) Our posterior summaries match up nicely with the output in Hayes’s Table 7.4. fixef(model7.5) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.8652210 0.05594018 2.75503579 2.9742392 ## frame_.5 0.1197490 0.11139462 -0.09630588 0.3354997 ## skeptic_c 0.2049131 0.02754867 0.15055341 0.2584152 ## frame_.5:skeptic_c 0.2009519 0.05572345 0.08998898 0.3118033 Here’s a summary of the Bayesian \\(R^2\\). bayes_R2(model7.5) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.248159 0.04337085 0.159787 0.3294168 7.3 Visualizing moderation A regression model with the product to two antecedent variables in an abstract mathematical representation of one’s data that can be harder to interpret than a model without such a produce. As described earlier, the coefficients for \\(X\\) and \\(W\\) are conditional effects that may not have any substantive interpretation, and the coefficient for \\(XW\\) is interpreted as a difference between differences that can be hard to make sense of without more information. (pp. 223–224) This is why we plot. To get quick plots for the interaction effect in brms, you might use the conditional_effects() function. conditional_effects(model7.3) By default, conditional_effects() will show three levels of the variable on the right side of the interaction term. The formula in model7.3 was justify ~ frame + skeptic + frame:skeptic, with frame:skeptic as the interaction term and skeptic making up the right hand side of the term. The three levels of skeptic in the plot, above, are the mean \\(\\pm 1\\) standard deviation. See the brms reference manual for details on the conditional_effects() function. On page 244, Hayes discussed using the 16th, 50th, and 84th percentiles for the moderator variable. We can compute those with quantile(). quantile(disaster$skeptic, probs = c(.16, .5, .84)) ## 16% 50% 84% ## 1.6 2.8 5.2 The first two columns in Hayes’s Table 7.5 contain the values he combined with the point estimates of his model to get the \\(\\hat Y\\) column. The way we’ll push those values through model7.3’s posterior is with brms::fitted(). As a preparatory step, we’ll put the predictor values in a data object, nd. ( nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .84))) ) ## # A tibble: 6 x 2 ## frame skeptic ## &lt;int&gt; &lt;dbl&gt; ## 1 0 1.6 ## 2 0 2.8 ## 3 0 5.2 ## 4 1 1.6 ## 5 1 2.8 ## 6 1 5.2 Now we’ve go our nd, we’ll get our posterior estimates for \\(Y\\) with fitted(). fitted(model7.3, newdata = nd) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 2.621411 0.10111061 2.421408 2.825915 ## [2,] 2.745904 0.08018575 2.587693 2.903098 ## [3,] 2.994890 0.10623870 2.785234 3.202648 ## [4,] 2.376842 0.11046776 2.156588 2.590565 ## [5,] 2.745315 0.08474800 2.573896 2.912143 ## [6,] 3.482262 0.10738886 3.266337 3.690769 When using the default summary = TRUE settings in fitted(), the function returns posterior means, \\(SD\\)s and 95% intervals for \\(Y\\) based on each row in the nd data we specified in the newdata = nd argument. You don’t have to name your newdata nd or anything like that; it’s just my convention. Here’ a quick plot of what those values imply. fitted(model7.3, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame %&gt;% as.character())) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + theme_07 That plot is okay, but we can do better. In order to plot the model-implied effects across the full range of skeptic values presented in Figure 7.7, you need to change the range of those values in the nd data. Also, although the effect is subtle in the above example, 95% intervals often follow a bowtie shape. In order to insure the contours of that shape are smooth, it’s often helpful to specify 30 or so evenly-spaced values in the variable on the x-axis, skeptic in this case. We’ll employ the seq() function for that and specify length.out = 30. In addition, we add a few other flourishes to make our plot more closely resemble the one in the text. Here’s our Figure 7.7. nd &lt;- crossing(frame = 0:1, skeptic = seq(from = 0, to = 7, length.out = 30)) fitted(model7.3, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame %&gt;% as.character())) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 2:4) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) Do you see that subtle bowtie shape? 7.4 Probing an interaction As with other modeling contexts, there the results from our moderation models, like depicted in the last plot, carry uncertainty with them. To deal with the uncertainty, it is common to follow up a test of interaction with a set of additional inferential tests to establish where in the distribution of the moderator \\(X\\) has an effect on \\(Y\\) that is different from zero and where it does not. This exercise is commonly known as “probing” an interaction, like you might squeeze an avocado or a mango in the produce section of the grocery store to assess its ripeness. The goal is to ascertain where in the distribution of the moderator \\(X\\) is related to \\(Y\\) and where it is not in an attempt to better discern the substantive interpretation of the interaction. In this section [we will cover] two approaches to probing an interaction. (p. 249) As in earlier sections and chapters, our approach will largely follow Hayes’s, but we will not be emphasizing statistical tests, \\(p\\)-values, and so on. You’ll see. 7.4.1 The pick-a-point approach. The pick-a-point approach (Rogosa, 1980; Bauer &amp; Curran, 2005), sometimes called an analysis of simple slopes or a spotlight analysis, is perhaps the most popular approach to probing an interaction and is described in most discussions of multiple regression with interactions (e.g., Aiken &amp; West, 1991; Cohen et al., 2003; Darlington &amp; Hayes, 2017; Hayes, 2005; Jaccard &amp; Turrisi, 2003; Spiller, Fitzsimons, Lynch, &amp; McClelland, 2013). This procedure involves selecting a value or values of the moderator \\(W\\), calculating the conditional effect of \\(X\\) on \\(Y (\\theta_{X \\rightarrow Y})\\) at that value or values, and then conducting an inferential test or generating a confidence interval. (p. 249, emphasis in the original) Though we will not be using inferential tests, we will use various ways of expressing the uncertainty in our Bayesian models, such as with 95% credible intervals and other ways of summarizing the posterior. 7.4.1.1 The pick-a-point approach implimented by regression centering working directly with the posterior. Yes, if you wanted to use the regression centering approach, you could do that in brms. Just center the necessary variables in the way Hayes described in the text, refit the model, and summarize(). I suspect this would be particularly approachable for someone new to R and to the ins and outs of data wrangling. But I’m going leave that as an exercise for the interested reader. Now that we’ve already got a posterior for our model, we can just either algebraically manipulate the vectors yielded by posterior_samples() or push predictions through fitted(). To give a sense, we’ll start off with the 16th percentile for skeptic. Recall we can get that with the quantile() function. quantile(disaster$skeptic, probs = .16) ## 16% ## 1.6 Now we just need to feed that value and different values of frame into the posterior samples of the model coefficients. We then create a difference score for the model-implied estimates given frame is either 0 or 1 and then plot that difference. post %&gt;% # use the model formula mutate(y_given_frame_0_skeptic_1.6 = b_Intercept + b_frame * 0 + b_skeptic * 1.6 + `b_frame:skeptic` * 0 * 1.6, y_given_frame_1_skeptic_1.6 = b_Intercept + b_frame * 1 + b_skeptic * 1.6 + `b_frame:skeptic` * 1 * 1.6) %&gt;% # compute the difference mutate(difference = y_given_frame_1_skeptic_1.6 - y_given_frame_0_skeptic_1.6) %&gt;% # plot! ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[7], linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify\\ngiven skeptic = 1.6&quot;, x = NULL) + theme_07 Note how nicely that distribution corresponds to the output in the lower left corner of Hayes’s Figure 7.8. If we wanted the values for other values of skeptic (e.g., 2.8 and 5.2 as in the text), we’d just rinse, wash, and repeat. A nice quality of this method is it requires you to work explicitly with the model formula. But it’s also clunky if you want to do this over many values. The fitted() function offers an alternative approach. Recall how the default fitted() settings are to return summaries of a model’s \\(Y\\)-variable given values of the predictor variables. In the previous section we put our preferred frame and skeptic values into a data object named nd and used the newdata argument to push those values through fitted(). Buy default, this yielded the typical posterior means, \\(SD\\)s, and 95% intervals for the predictions. However, if one sets summary = F, the output will differ. First. Let’s revisit what nd looks like. ( nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .84))) ) ## # A tibble: 6 x 2 ## frame skeptic ## &lt;int&gt; &lt;dbl&gt; ## 1 0 1.6 ## 2 0 2.8 ## 3 0 5.2 ## 4 1 1.6 ## 5 1 2.8 ## 6 1 5.2 Here’s what happens when we use summary = F. f &lt;- fitted(model7.3, newdata = nd, summary = F) f %&gt;% str() ## num [1:4000, 1:6] 2.79 2.67 2.67 2.72 2.62 ... f %&gt;% head() ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 2.786198 2.844305 2.960519 2.248915 2.664708 3.496295 ## [2,] 2.673565 2.773401 2.973074 2.307611 2.749349 3.632825 ## [3,] 2.666410 2.816476 3.116607 2.328586 2.719344 3.500860 ## [4,] 2.719128 2.866154 3.160204 2.309730 2.658833 3.357040 ## [5,] 2.617568 2.781539 3.109481 2.379756 2.731071 3.433701 ## [6,] 2.707056 2.792687 2.963949 2.410383 2.784270 3.532045 With summary = F, fitted() returned a matrix of 4000 rows (i.e., one for each posterior draw) and 6 vectors (i.e., one for each row in our nd data). So now instead of summary information, we have a full expression of the uncertainty in terms of 4000 draws. If you prefer working within the tidyverse and plotting with ggplot2, matrices aren’t the most useful data type. Let’s wrangle a bit. f &lt;- f %&gt;% data.frame() %&gt;% gather() %&gt;% select(-key) %&gt;% bind_cols( nd %&gt;% expand(nesting(frame, skeptic), iter = 1:4000) ) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`, # this isn&#39;t necessary, but will help with the facet labels skeptic = str_c(&quot;skeptic = &quot;, skeptic)) f %&gt;% head() ## # A tibble: 6 x 5 ## skeptic iter `0` `1` difference ## &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 skeptic = 1.6 1 2.79 2.25 -0.537 ## 2 skeptic = 1.6 2 2.67 2.31 -0.366 ## 3 skeptic = 1.6 3 2.67 2.33 -0.338 ## 4 skeptic = 1.6 4 2.72 2.31 -0.409 ## 5 skeptic = 1.6 5 2.62 2.38 -0.238 ## 6 skeptic = 1.6 6 2.71 2.41 -0.297 Now we have our draws in a nice structure, we’re ready to plot. f %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[7], linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify given three different values of skeptic&quot;, x = NULL) + theme_07 + facet_wrap(~skeptic) And if you prefered summary information instead of plots, you might just use tidybayes::median_qi(). library(tidybayes) f %&gt;% group_by(skeptic) %&gt;% median_qi(difference) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## skeptic difference .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 skeptic = 1.6 -0.246 -0.546 0.042 0.95 median qi ## 2 skeptic = 2.8 0 -0.23 0.224 0.95 median qi ## 3 skeptic = 5.2 0.483 0.199 0.78 0.95 median qi 7.4.2 The Johnson-Neyman technique. The JN technique generalizes this approach over many values of \\(W\\) (i.e., skeptic in this example) in order to get a sense of the trend and summarize regions of the trend in terms of \\(p\\)-value thresholds. Since we’re emphasizing modeling and deemphasizing null-hypothesis testing in this project, I’ll show a Bayesian version of the approach without the \\(p\\)-values. 7.4.2.1 Implementation in PROCESS brms. Since Figure 7.9 had skeptic values ranging from 1 to 6 with ticks on the 0.5s, we’ll use a similar approach for our version. We will display posterior samples with fitted() for skeptic values ranging from .5 to 6.5, one for each 0.5—13 in total. But since we have two levels of frame (i.e., 0 and 1), that really gives us 26. And we don’t just want 26 summaries; we want full posterior distributions for each of those 26. We’ve got a lot of moving parts in the code, below. To help make sure everything adds up, we’ll save several important values as R objects. iter &lt;- 4000 # this number comes from the total number of post-warmup posterior iterations from `brm()` n_skeptic_values &lt;- 13 # we&#39;re choosing 13 in this example to follow some of the sensibilities in Figure 7.9. You&#39;ll see. # as before, we&#39;ll make `nd` to feed in to `fitted()` nd &lt;- crossing(frame = 0:1, skeptic = seq(from = .5, to = 6.5, length.out = n_skeptic_values)) # after the initial `fitted()` action, we need a few steps to wrangle the data into a useful format f &lt;- fitted(model7.3, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(frame, skeptic), iter = 1:iter) ) %&gt;% select(-key) %&gt;% rename(estimate = value) %&gt;% pivot_wider(names_from = frame, values_from = estimate) %&gt;% mutate(difference = `1` - `0`) # finally, here&#39;s the plot f %&gt;% ggplot(aes(x = skeptic %&gt;% as.character, y = difference)) + geom_hline(yintercept = 0, color = dutchmasters$little_street[7]) + geom_violin(size = 0, fill = dutchmasters$little_street[6]) + stat_summary(fun.y = median, fun.ymin = function(x){quantile(x, probs = .025)}, fun.ymax = function(x){quantile(x, probs = .975)}, color = dutchmasters$little_street[5]) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 [Note. I got the atop() trick for the label for the y-axis from Drew Steen’s answer to this stackoverflow question.] This isn’t quite our version of Figure 7.9, but I’m hoping it’ll add some pedagogical value for what we’re doing. Since we specified summary = F within fitted(), we got full posterior distributions for each of our 26 conditions. Because Figure 7.9 is all about differences between each frame pair across the various values of skeptic, we needed to make a difference score for each pair; this is what we did with the last mutate() line before the plot code. This initial version of the plot shows the full posterior distribution for each difference score. The posteriors are depicted with violin plots, which are density plots set on their side and symmetrically reflected as if by a mirror to give a pleasing leaf- or violin-like shape (though beware). The light dots and vertical lines are the posterior medians and 95% intervals for each. Going from left to right, it appears we have a clearly emerging trend. We can more simply express the trend by summarizing each posterior with medians and 95% intervals. f %&gt;% group_by(skeptic) %&gt;% median_qi(difference) %&gt;% ggplot(aes(x = skeptic)) + geom_hline(yintercept = 0, color = dutchmasters$little_street[7]) + geom_vline(xintercept = c(1.171, 3.934), color = dutchmasters$little_street[7]) + geom_ribbon(aes(ymin = .lower, ymax = .upper), fill = dutchmasters$little_street[5], alpha = 1/2) + geom_line(aes(y = difference), color = dutchmasters$little_street[5], size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(-1, 1.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 Notice how the contour boundaries of the 95% intervals are a little clunky. That’s because our bowtie-shape is based on only 13 x-axis values. If you wanted a smoother shape, you’d specify more skeptic values in the data object you feed into fitted()’s newdata argument. For linear effects, 30 or so usually does it. Anyway, I got the values for the two vertical lines directly out of the text. It’s not clear to me how one might elegantly determine those values within the paradigm we’ve been using. But that leads to an important digression. The two vertical lines are quite \\(p\\)-value centric. They are an attempt to separate the x-axis into areas where the difference trend either is or is not statistically-significantly different from zero. That is, we’re dichotomizing–or “trichotomizing”, depending on how you look at it–a continuous phenomenon. This is somewhat at odds with the sensibilities of the Bayesians associated with Stan and brms (e.g., here). On page 259, Hayes wrote: Although the JN technique eliminates the need to select arbitrary values of \\(W\\) when probing an interaction, it does not eliminate your need to keep your brain turned into the task and thinking critically about the answer the method gives you. I think this is valuable advice, particularly when working within the Bayesian paradigm. Our version of Figure 7.9 gives some interesting insights into the moderation model, model7.3. I’m just not so sure I’d want to encourage people to interpret a continuous phenomenon by heuristically dividing it into discrete regions. 7.5 The difference between testing for moderation and probing it This is another section where the NHST-type paradigm contrasts with many within the contemporary Bayesian paradigm. E.g., Hayes opened the section with: “We test for evidence of moderation when we want to know whether the relationship between \\(X\\) and \\(Y\\) varies systematically as a function of a proposed moderator \\(W\\)”. His use of “whether” suggests we are talking about a binary answer–either there is an effect or there isn’t. But, as Gelman argued, the default presumption in social science [and warning, I’m a psychologist and thus biased towards thinking in terms of social science] is that treatment effects–and more generally, causal effects–vary across contexts 3 . As such, asking “whether” there’s a difference or an interaction effect isn’t really the right question. Rather, we should presume variation at the outset and ask instead what the magnitude of that variation is and how much accounting for it matters for our given purposes. If the variation–read interaction effect–is tiny and of little theoretical interest, perhaps we might just ignore it and not include it in the model. Alternatively, if the variation is large or of theoretical interest, we might should include it in the model regardless of statistical significance. Another way into this topic is posterior predictive checking. We’ve already done a bit of this in previous chapters. The basic idea, recall, is that better models should give us a better sense of the patterns in the data. In the plot below, we continue to show the interaction effect with two regression lines, but this time we separate them into their own panels by frame. In addition, we add the original data which we also separate and color code by frame. nd &lt;- crossing(frame = 0:1, skeptic = seq(from = 0, to = 10, length.out = 30)) fitted(model7.3, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% mutate(frame = frame %&gt;% as.character()) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame)) + geom_point(data = disaster %&gt;% mutate(frame = frame %&gt;% as.character()), aes(y = justify, color = frame), alpha = 3/4) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:9) + coord_cartesian(xlim = 1:9) + labs(title = &quot;model 7.3, the interaction model&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) + facet_wrap(~frame) When we separate out the data this way, it really does appear that when frame == 1, the justify values do increase as the skeptic values increase, but not so much when frame == 0. We can use the same plotting approach, but this time with the results from the non-interaction multivariable model, model7.2. fitted(model7.2, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% mutate(frame = frame %&gt;% as.character()) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame %&gt;% as.character())) + geom_point(data = disaster %&gt;% mutate(frame = frame %&gt;% as.character()), aes(y = justify, color = frame), alpha = 3/4) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:9) + coord_cartesian(xlim = 1:9) + labs(title = &quot;model 7.2, the multivariable model&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) + facet_wrap(~frame) This time when we allowed the intercept but not the slope to vary by frame, it appears the regression lines are missing part of the story. They look okay, but it appears that the red line on the left is sloping up to quickly and that the cream line on the right isn’t sloping steeply enough. We have missed an insight. Now imagine scenarios in which the differences by frame are more or less pronounced. Imagine those scenarios fall along a continuum. It’s not so much that you can say with certainty where on such a continuous an interaction effect would exist or not, but rather, such a continuum suggests it would appear more or less important, of greater or smaller magnitude. It’s not that the effect exists or is non-zero. It’s that it is orderly enough and of a large enough magnitude, and perhaps of theoretical interest, that it appears to matter in terms of explaining the data. And none of this is to serve as a harsh criticism of Andrew Hayes. His text is a fine effort to teach mediation and moderation from a frequentist OLS perspective. I have benefited tremendously from his work. Yet I’d also like to connect his work to some other sensibilities. Building further, consider this sentence from the text: Rather, probing moderation involves ascertaining whether the conditional effect of \\(X\\) on \\(Y\\) is different from zero at certain specified values of \\(W\\) (if using the pick-a-point approach) or exploring where in the distribution of \\(W\\) the conditional effect of \\(X\\) on \\(Y\\) transitions between statistically significant and non-significant (if using the Johnson-Neyman technique). (pp. 259–260) From an NHST/frequentist perspective, this makes clear sense. But we’re dealing with an entire posterior distribution. Consider again a figure from above. nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .84))) fitted(model7.3, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% select(-key) %&gt;% bind_cols( nd %&gt;% expand(nesting(frame, skeptic), iter = 1:4000) ) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`, skeptic = str_c(&quot;skeptic = &quot;, skeptic)) %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify given three different values of skeptic&quot;, x = NULL) + theme_07 + facet_wrap(~skeptic) With the pick pick-a-point approach one could fixate on whether zero was a credible value within the posterior, given a particular skeptic value. And yet zero is just one point in the parameter space. One might also focus on the whole shapes of the posteriors of these three skeptic values. You could focus on where the most credible values (i.e., those at and around their peaks) are on the number line (i.e., the effect sizes) and you could also focus on the relative widths of the distributions (i.e., the precision with which the effect sizes are estimated). These sensibilities can apply to the JN technique, as well. Sure, we might be interested in how credible zero is. But there’s a lot more to notice, too. Now consider a modified version of our JN technique plot, from above. f %&gt;% ggplot(aes(x = skeptic, y = difference)) + # the main action is in `tidybayes::stat_lineribbon()` stat_lineribbon(.width = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, .99), fill = dutchmasters$little_street[5], alpha = 1/5, size = 0) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(-1, 1.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 This time we emphasized the shape of the posterior with stacked semitransparent 10, 20, 30, 40, 50, 60, 70, 80, 90, and 99% intervals. We also deemphasized the central tendency–our analogue to the OLS point estimate–by removing the median line. Yes, one could focus on where the 95% intervals cross zero. And yes one could request we emphasize central tendency. But such focuses miss a lot of information about the shape–the entire smooth, seamless distribution of credible values. I suppose you could consider this our version of Figure 7.10. 7.6 Artificial categorization and subgroups There are multiple ways to dichotomize the data by skeptic. A quick simple way is to use if_else() to make a skeptic_hi dummy. disaster &lt;- disaster %&gt;% mutate(skeptic_hi = if_else(skeptic &gt;= mean(skeptic), 1, 0)) With our dummy in hand, we’re ready to fit the two models. model7.6 &lt;- brm(data = disaster %&gt;% filter(skeptic_hi == 0), family = gaussian, justify ~ 1 + frame, cores = 4) model7.7 &lt;- update(model7.6, newdata = disaster %&gt;% filter(skeptic_hi == 1), cores = 4) Behold the coefficient summaries. fixef(model7.6) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.624 0.100 2.426 2.820 ## frame -0.106 0.141 -0.381 0.171 fixef(model7.7) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 3.071 0.140 2.793 3.351 ## frame 0.478 0.209 0.075 0.886 You can use fitted() to get the posterior means and other summaries for the two frame groups, by model. fitted(model7.6, newdata = tibble(frame = 0:1)) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 2.624 0.100 2.426 2.820 ## [2,] 2.518 0.101 2.325 2.719 fitted(model7.7, newdata = tibble(frame = 0:1)) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 3.071 0.140 2.793 3.351 ## [2,] 3.549 0.149 3.263 3.848 Do note that though brms ‘Est.Error’ is the posterior \\(SD\\) for the coefficient, it is not the same thing as descriptive statistic \\(SD\\) of a subset of the data. Thus, although our ‘Estimates’ correspond nicely to the mean values Hayes reported in the middle of page 264, his \\(SD\\)s will not match up with our ‘Est.Error’ values, and nor should they. Anyway, our results don’t yield \\(t\\)-tests. But you don’t need those anyway. We’re working within the Bayesian regression paradigm! But if you’re really interested in the sub-model-implied differences between the two levels of frame by skeptic_hi subgroup, all you need is the frame coefficient of model7.6 and model7.7. Here we’ll use bind_rows() to combine their posterior samples and then plot. posterior_samples(model7.6) %&gt;% select(b_frame) %&gt;% bind_rows( posterior_samples(model7.7) %&gt;% select(b_frame) ) %&gt;% mutate(model = rep(c(&quot;model7.6&quot;, &quot;model7.7&quot;), each = 4000)) %&gt;% ggplot(aes(x = b_frame, fill = model)) + geom_density(size = 0, alpha = .8) + scale_fill_manual(NULL, values = dutchmasters$little_street[c(1, 9)] %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The difference score distributions between frame\\nlevels, color coded by mean-split skeptic&quot;, x = NULL) + theme_07 As within the frequentist paradigm, please don’t mean split as a Bayesian. When possible, use all available data and use the regression formula to model theoretically-meaningful variables in your analyses. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 brms_2.10.3 Rcpp_1.0.2 directlabels_2018.05.22 ## [5] ochRe_1.0.0 dutchmasters_0.1.0 forcats_0.4.0 stringr_1.4.0 ## [9] dplyr_0.8.3 purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 ## [13] tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ggridges_0.5.1 rsconnect_0.8.15 ## [5] ggstance_0.3.2 markdown_1.1 base64enc_0.1-3 rstudioapi_0.10 ## [9] rstan_2.19.2 svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 bridgesampling_0.7-2 codetools_0.2-16 ## [17] knitr_1.23 shinythemes_1.1.2 zeallot_0.1.0 bayesplot_1.7.0 ## [21] jsonlite_1.6 broom_0.5.2 shiny_1.3.2 compiler_3.6.0 ## [25] httr_1.4.0 backports_1.1.5 assertthat_0.2.1 Matrix_1.2-17 ## [29] lazyeval_0.2.2 cli_1.1.0 later_1.0.0 htmltools_0.4.0 ## [33] prettyunits_1.0.2 tools_3.6.0 igraph_1.2.4.1 coda_0.19-3 ## [37] gtable_0.3.0 glue_1.3.1.9000 reshape2_1.4.3 cellranger_1.1.0 ## [41] raster_2.9-5 vctrs_0.2.0 nlme_3.1-139 crosstalk_1.0.0 ## [45] xfun_0.10 ps_1.3.0 rvest_0.3.4 mime_0.7 ## [49] miniUI_0.1.1.1 lifecycle_0.1.0 gtools_3.8.1 zoo_1.8-6 ## [53] scales_1.0.0 colourpicker_1.0 hms_0.4.2 promises_1.1.0 ## [57] Brobdingnag_1.2-6 parallel_3.6.0 inline_0.3.15 shinystan_2.5.0 ## [61] gridExtra_2.3 loo_2.1.0 StanHeaders_2.19.0 stringi_1.4.3 ## [65] dygraphs_1.1.1.6 pkgbuild_1.0.5 rlang_0.4.1 pkgconfig_2.0.3 ## [69] matrixStats_0.55.0 evaluate_0.14 lattice_0.20-38 rstantools_2.0.0 ## [73] htmlwidgets_1.5 labeling_0.3 tidyselect_0.2.5 processx_3.4.1 ## [77] plyr_1.8.4 magrittr_1.5 R6_2.4.0 generics_0.0.2 ## [81] pillar_1.4.2 haven_2.1.0 withr_2.1.2 xts_0.11-2 ## [85] abind_1.4-5 sp_1.3-1 modelr_0.1.4 crayon_1.3.4 ## [89] arrayhelpers_1.0-20160527 utf8_1.1.4 rmarkdown_1.13 grid_3.6.0 ## [93] readxl_1.3.1 callr_3.3.2 threejs_0.3.1 digest_0.6.21 ## [97] xtable_1.8-4 httpuv_1.5.2 stats4_3.6.0 munsell_0.5.0 ## [101] viridisLite_0.3.0 quadprog_1.5-7 shinyjs_1.0 Footnote If you’re an experimental psychologist, check out the great paper by Bolger, Zee, Rossignac-Milon, and Hassin, Causal processes in psychology are heterogeneous. The rest of you social scientists aren’t off the hook. Check out Ellen Hamaker’s excellent book chapter, Why researchers should think “within-person”: A paradigmatic rationale. Both works suggest researchers might do well to switch out their fixed-effects models for multilevel models. Does this mean the methods we’ve been covering are of no use? No. But don’t stop here, friends. Keep learning!↩ "],
["extending-the-fundamental-principles-of-moderation-analysis.html", "8 Extending the Fundamental Principles of Moderation Analysis 8.1 Moderation with a dichotomous moderator 8.2 Interaction between two quantitative variables 8.3 Hierarchical versus simultaneous entry 8.4 The equivalence between moderated regression analysis and a 2 X 2 factorial analysis of variance References Session info", " 8 Extending the Fundamental Principles of Moderation Analysis As Hayes opened, “in this chapter, [we’ll see] how [the] principles of moderation analysis are applied when the moderator is dichotomous (rather than a continuum, as in the previous chapter) as well as when both focal antecedent and moderator are continuous (p. 267).” 8.1 Moderation with a dichotomous moderator Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) library(brms) disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) ## Observations: 211 ## Variables: 5 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23… ## $ frame &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, … ## $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5… ## $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.6… ## $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1… Regardless of whether the antecedent variables are continuous or binary, the equation for the simple moderation is still \\[Y = i_Y + b_1 X + b_2 W + b_3 XW + e_Y.\\] We can use that equation to fit our first moderation model with a binary \\(W\\) (i.e., frame) like so. model8.1 &lt;- brm(data = disaster, family = gaussian, justify ~ 1 + skeptic + frame + frame:skeptic, cores = 4) Check the summary. print(model8.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: justify ~ 1 + skeptic + frame + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 2.455 0.148 2.157 2.740 1.000 2727 3010 ## skeptic 0.104 0.037 0.031 0.180 1.001 2631 2711 ## frame -0.567 0.216 -0.986 -0.151 1.001 2332 2631 ## skeptic:frame 0.202 0.054 0.096 0.310 1.001 2205 2528 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.819 0.041 0.744 0.906 1.001 3270 2730 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). We’ll compute our Bayeisan \\(R^2\\) in the typical way. bayes_R2(model8.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.249 0.044 0.164 0.333 This model should look familiar to you because it is exactly the same model estimated in the analysis presented in Chapter 7 (see Table 7.4, model 3). The only differences between these two analyses are how the corresponding question is framed, meaning which variable is deemed the focal antecedent and which is the moderator, and how these variables are symbolically labeled as \\(X\\) and \\(W\\). In the analysis in Chapter 7, the focal antecedent variable was a dichotomous variable coding the framing of the cause of the disaster (labeled \\(X\\) then, but \\(W\\) now), whereas in this analysis, the focal antecedent is a continuous variable placing each person on a continuum of climate change skepticism (labeled \\(W\\) then, but \\(X\\) now), with the moderator being a dichotomous variable coding experimental condition. So this example illustrates the symmetry property of interactions introduced in section 7.1. (p. 272) 8.1.1 Visualizing and probing the interaction. For the plots in this chapter, we’ll take our color palette from the ochRe package, which provides Australia-inspired colors. We’ll also use a few theme settings from good-old ggthemes. As in the last chapter, we’ll save our adjusted theme settings as an object, theme_08. library(ggthemes) library(ochRe) theme_08 &lt;- theme_minimal() + theme(panel.grid.minor = element_blank(), plot.background = element_rect(fill = ochre_palettes[[&quot;olsen_seq&quot;]][8], color = &quot;transparent&quot;)) Happily, the ochRe package has a handy convenience function, viz_palette(), that makes it easy to preview the colors available in a given palette. We’ll be using “olsen_qual” and “olsen_seq”. viz_palette(ochre_palettes[[&quot;olsen_qual&quot;]]) viz_palette(ochre_palettes[[&quot;olsen_seq&quot;]]) Behold our Figure 8.3. # these will come in handy with `geom_text()`, below green_slope &lt;- (fixef(model8.1)[&quot;skeptic&quot;, 1] + fixef(model8.1)[4, 1]) %&gt;% round(digits = 3) blue_slope &lt;- fixef(model8.1)[&quot;skeptic&quot;, 1] %&gt;% round(digits = 3) # define the new data nd &lt;- crossing(frame = 0:1, skeptic = c(0, 7)) # extract the `fitted()` draws fitted(model8.1, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% # bind the new data bind_cols( nd %&gt;% expand(nesting(frame, skeptic), iter = 1:4000) ) %&gt;% # plot! ggplot(aes(x = skeptic, y = value, group = interaction(frame, iter), color = frame %&gt;% as.character())) + geom_line(aes(color = frame %&gt;% as.character()), size = 1/6, alpha = 1/25) + geom_text(data = tibble(skeptic = c(4, 4.6), value = c(3.5, 2.6), frame = 1:0, iter = 0, label = c(paste(&quot;the slope when frame = 1 is about&quot;, green_slope), paste(&quot;the slope when frame = 0 is about&quot;, blue_slope)), angle = c(28, 5)), aes(label = label, angle = angle)) + scale_color_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][(5:6)]) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 2:4) + labs(title = &quot;The moderation effect in a spaghetti plot&quot;, subtitle = &quot;Using brms defaults, we have 4000 posterior draws. Much like we have\\n4000 draws for each model parameter, when we combine those draws\\nacross parameters, we end up with 4000 model equations. The\\nconsequence is we can also express the line plot as 4000\\nsemitransparent lines, one for each level of our moderator, frame.&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = &quot;Strength of Justification for Withholding Aid&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) In addition to our fancy Australia-inspired colors, we’ll also play around a bit with spaghetti plots in this chapter. To my knowledge, this use of spaghetti plots is uniquely Bayesian. If you’re trying to wrap your head around what on earth we just did, take a look at the first few rows from posterior_samples() object, post. post &lt;- posterior_samples(model8.1) head(post) ## b_Intercept b_skeptic b_frame b_skeptic:frame sigma lp__ ## 1 2.171268 0.18122884 -0.6213774 0.1814370 0.8144831 -264.4922 ## 2 2.112918 0.19286032 -0.5346854 0.1749145 0.8169612 -264.5730 ## 3 2.580092 0.04726581 -0.3385162 0.1657682 0.8691147 -264.6696 ## 4 2.609206 0.04635323 -0.3941262 0.1594145 0.8658938 -264.7612 ## 5 2.408386 0.12717550 -0.5910781 0.1956912 0.8121655 -260.1720 ## 6 2.383672 0.11459057 -0.5955617 0.2302462 0.8024598 -260.5167 The head() function returned six rows, each one corresponding to the credible parameter values from a given posterior draw. The lp__ is uniquely Bayesian and beyond the scope of this project. You might think of sigma as the Bayesian analogue to what the OLS folks often refer to as error or the residual variance. Hayes doesn’t tend to emphasize it in this text, but it’s something you’ll want to pay increasing attention to as you move along in your Bayesian career. All the columns starting with b_ are the regression parameters, the model coefficients or the fixed effects. But anyways, notice that those b_ columns correspond to the four parameter values in Formula 8.2 on page 270. Here they are, but reformatted to more closely mimic the text: \\(\\hat{Y}\\) = 2.171 + 0.181\\(X\\) + -0.621\\(W\\) + 0.181XW \\(\\hat{Y}\\) = 2.113 + 0.193\\(X\\) + -0.535\\(W\\) + 0.175XW \\(\\hat{Y}\\) = 2.58 + 0.047\\(X\\) + -0.339\\(W\\) + 0.166XW \\(\\hat{Y}\\) = 2.609 + 0.046\\(X\\) + -0.394\\(W\\) + 0.159XW \\(\\hat{Y}\\) = 2.408 + 0.127\\(X\\) + -0.591\\(W\\) + 0.196XW \\(\\hat{Y}\\) = 2.384 + 0.115\\(X\\) + -0.596\\(W\\) + 0.23XW Each row of post, each iteration or posterior draw, yields a full model equation that is a credible description of the data–or at least as credible as we can get within the limits of the model we have specified, our priors (which we typically cop out on and just use defaults in this project), and how well those fit when applied to the data at hand. So when we use brms convenience functions like fitted(), we pass specific predictor values through those 4000 unique model equations, which returns 4000 similar but distinct expected \\(Y\\)-values. So although a nice way to summarize those 4000 values is with summaries such as the posterior mean/median and 95% intervals, another way is to just plot an individual regression line for each of the iterations. That is what’s going on when we depict out models with a spaghetti plot. The thing I like about spaghetti plots is that they give a three-dimensional sense of the posterior. Note that each individual line is very skinny and semitransparent. When you pile a whole bunch of them atop each other, the peaked or most credible regions of the posterior are the most saturated in color. Less credible posterior regions almost seamlessly merge into the background. Also, note how the combination of many similar but distinct straight lines results in a bowtie shape. Hopefully this clarifies where that shape’s been coming from when we use geom_ribbon() to plot the 95% intervals. Back to the text, on the bottom of page 274, Hayes pointed out the conditional effect of skeptic when frame == 1 is \\(b_1 + b_3 = 0.306\\). We can show that with a little arithmetic followed up with tidybayes::mean_qi(). library(tidybayes) post &lt;- post %&gt;% mutate(`b1 + b3` = b_skeptic + `b_skeptic:frame`) post %&gt;% mean_qi(`b1 + b3`) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## `b1 + b3` .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.306 0.23 0.384 0.95 mean qi But anyways, you could recode frame in a number of ways, including if_else() or, in this case, by simple arithmetic. disaster &lt;- disaster %&gt;% mutate(frame_ep = 1 - frame) With frame_ep in hand, we’re ready to refit the model. model8.2 &lt;- update(model8.1, newdata = disaster, formula = justify ~ 1 + skeptic + frame_ep + frame_ep:skeptic, cores = 4) print(model8.2) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: justify ~ skeptic + frame_ep + skeptic:frame_ep ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.88 0.16 1.56 2.19 1.00 2193 2986 ## skeptic 0.31 0.04 0.23 0.39 1.00 2194 2480 ## frame_ep 0.57 0.21 0.14 0.98 1.00 1891 2273 ## skeptic:frame_ep -0.20 0.05 -0.31 -0.10 1.00 1907 2081 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.82 0.04 0.74 0.90 1.00 3017 2732 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our results match nicely with the formula on page 275. If you want to follow along with Hayes on page 276 and isolate the 95% credible intervals for the skeptic parameter, you can use the posterior_interval() function. posterior_interval(model8.2)[&quot;b_skeptic&quot;, ] %&gt;% round(digits = 3) ## 2.5% 97.5% ## 0.231 0.389 8.2 Interaction between two quantitative variables Here’s the glbwarm data. glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) ## Observations: 815 ## Variables: 7 ## $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, … ## $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.… ## $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.… ## $ ideology &lt;dbl&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4,… ## $ age &lt;dbl&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, … ## $ sex &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1,… ## $ partyid &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1,… In this section we add three covariates (i.e., \\(C\\) variables) to the basic moderation model. Although Hayes made a distinction between the \\(X\\), \\(M\\), and \\(C\\) variables in the text, that distinction is conceptual and doesn’t impact the way we enter them into brm(). Rather, the brm() formula clarifies they’re all just predictors. model8.3 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + age + negemot:age + posemot + ideology + sex, cores = 4) Our results cohere nicely with the Hayes’s formula in the middle of page 278 or with the results he displayed in Table 8.2. print(model8.3, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + age + negemot:age + posemot + ideology + sex ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.176 0.340 4.528 5.838 1.000 2494 2796 ## negemot 0.119 0.083 -0.042 0.282 1.002 2320 2502 ## age -0.024 0.006 -0.036 -0.012 1.001 2279 2394 ## posemot -0.021 0.028 -0.078 0.034 1.002 4074 2772 ## ideology -0.211 0.027 -0.264 -0.159 1.000 4268 2995 ## sex -0.012 0.075 -0.163 0.134 1.002 4037 2925 ## negemot:age 0.006 0.002 0.003 0.009 1.001 2364 2564 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.059 0.026 1.009 1.112 1.000 3783 2748 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Here’s the \\(R^2\\) summary. bayes_R2(model8.3) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.401 0.02 0.36 0.44 As the \\(R^2\\) is a good bit away from the boundaries, it’s nicely Gaussian. bayes_R2(model8.3, summary = F) %&gt;% as_tibble() %&gt;% ggplot(aes(x = R2)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_qual&quot;]][(1)]) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;Loot at how Gaussian our &quot;, italic(R)^2, &quot; is!&quot;)), subtitle = expression(paste(&quot;No need to put a &quot;, italic(p), &quot;-value on that sucker.&quot;)), x = NULL) + theme_08 8.2.1 Visualizing and probing the interaction. For our version of Figure 8.5, we’ll need to adjust our nd data for fitted(). ( nd &lt;- crossing(negemot = c(1, 6), age = c(30, 50, 70)) %&gt;% mutate(posemot = mean(glbwarm$posemot), ideology = mean(glbwarm$ideology), sex = mean(glbwarm$sex)) ) ## # A tibble: 6 x 5 ## negemot age posemot ideology sex ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 30 3.13 4.08 0.488 ## 2 1 50 3.13 4.08 0.488 ## 3 1 70 3.13 4.08 0.488 ## 4 6 30 3.13 4.08 0.488 ## 5 6 50 3.13 4.08 0.488 ## 6 6 70 3.13 4.08 0.488 Our fitted() and ggplot2 code will be quite similar to the last spaghetti plot. Only this time we’ll use filter() to reduce the number of posterior draws we show in the plot. # these will come in handy with `geom_text()`, below slope_30 &lt;- (fixef(model8.3)[&quot;negemot&quot;, 1] + fixef(model8.3)[&quot;negemot:age&quot;, 1] * 30) %&gt;% round(digits = 3) slope_50 &lt;- (fixef(model8.3)[&quot;negemot&quot;, 1] + fixef(model8.3)[&quot;negemot:age&quot;, 1] * 50) %&gt;% round(digits = 3) slope_70 &lt;- (fixef(model8.3)[&quot;negemot&quot;, 1] + fixef(model8.3)[&quot;negemot:age&quot;, 1] * 70) %&gt;% round(digits = 3) fitted(model8.3, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(negemot, age), iter = 1:4000) ) %&gt;% filter(iter &lt;= 100) %&gt;% ggplot(aes(x = negemot, y = value, group = interaction(age, iter), color = age %&gt;% as.character())) + geom_line(aes(color = age %&gt;% as.character()), size = 3/4, alpha = 1/8) + geom_text(data = tibble(negemot = 6.1, value = c(5.4, 5.7, 6), age = c(30, 50, 70), iter = 0, label = c(paste(&quot;the slope for 30 year olds is about&quot;, slope_30), paste(&quot;the slope for 50 year olds is about&quot;, slope_50), paste(&quot;the slope for 70 year olds is about&quot;, slope_70))), aes(label = label), hjust = 0) + scale_color_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][c(4, 1, 3)]) + scale_x_continuous(breaks = 1:6, limits = c(1, 9)) + scale_y_continuous(&quot;Support for Government Action&quot;, limits = c(2.9, 6.1)) + labs(title = &quot;The moderation effect of age on negemot&quot;, x = expression(paste(&quot;Negative Emotions about Climate Change (&quot;, italic(&quot;X&quot;), &quot;)&quot;))) + theme_08 + theme(legend.position = &quot;none&quot;) When we reduce the number of lines depicted in the plot, we lose some of the three-dimensional illusion. It’s nice, however, to get a closer look to each individual line. To each their own. We’ll continue with our spaghetti plot approach for Figure 8.7. Again, when we made the JN technique plot for Chapter 7, we computed values for the posterior mean and the 95% intervals. Because the intervals follow a bowtie shape, we had to compute the \\(Y\\)-values for many values across the x-axis in order to make the curve look smooth. But as long as we stick with the spaghetti plot approach, all we need are the values at the endpoints of each iteration. Although each line is straight, the combination of many lines is what produces the bowtie effect. # here is our primary data object post &lt;- posterior_samples(model8.3) %&gt;% transmute(at_15 = b_negemot + `b_negemot:age` * 15, at_90 = b_negemot + `b_negemot:age` * 90, iter = 1:n()) %&gt;% pivot_longer(-iter, names_to = &quot;age&quot;) %&gt;% mutate(age = str_remove(age, &quot;at_&quot;) %&gt;% as.double()) # here we compute the points for the posterior mean post_means &lt;- post %&gt;% group_by(age) %&gt;% summarize(value = mean(value)) %&gt;% mutate(iter = 0) # plot! post %&gt;% filter(iter &lt; 501) %&gt;% ggplot(aes(x = age, y = value, group = iter)) + geom_line(color = ochre_palettes[[&quot;olsen_qual&quot;]][1], alpha = 1/12) + geom_line(data = post_means, color = ochre_palettes[[&quot;olsen_qual&quot;]][3], size = 1.1) + scale_y_continuous(breaks = seq(from = -.25, to = 1, by = .25)) + coord_cartesian(xlim = c(20, 85), ylim = c(-.25, 1)) + labs(subtitle = &quot;Each orange line is the consequence of one of 1000 posterior draws. All are\\ncredible regression lines for the data, but because they are semitransparent,\\nthe most credible regions are the ones with the darkest color. The line\\ncorresponding to the posterior mean is in red-orange.&quot;, x = expression(paste(&quot;Age (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Conditional Effects of Negative Emotions on\\nSupport for Government Action&quot;) + theme_08 In other words, each of those orange lines is a credible expression of \\(\\theta_{X \\rightarrow Y}\\) (i.e., \\(b_1 + b_3 W\\)) across a continuous range of \\(W\\) values. 8.3 Hierarchical versus simultaneous entry Many investigators test a moderation hypothesis in regression analysis using a method that on the surface seems different than the procedure described thus far. This alternative approach is to build a regression model by adding the product of \\(X\\) and \\(W\\) to a model already containing \\(X\\) and \\(W\\). This procedure is sometimes called hierarchical regression or hierarchical variable entry (and easily confused by name with hierarchical linear modeling, which is an entirely different thing). The goal using this method is to determine whether allowing \\(X\\)’s effect to be contingent on \\(W\\) produces a better fitting model than one in which the effect of \\(X\\) is constrained to be unconditional on \\(W\\). According to the logic of hierarchical entry, if the contingent model accounts for more of the variation in Y than the model that forces \\(X\\)’s effect to be independent of \\(W\\), then the better model is one in which \\(W\\) is allowed to moderate \\(X\\)’s effect. Although this approach works, it is a widely believed myth that it is necessary to use this approach in order to test a moderation hypothesis. (p. 289, emphasis in the original) Although this method is not necessary, it can be handy to slowly build your model. This method can also serve nice rhetorical purposes in a paper. Anyway, here’s our multivariable but non-moderation model, model8.4. model8.4 &lt;- update(model8.1, formula = justify ~ 1 + skeptic + frame, cores = 4) Here we’ll compute the corresponding \\(R^2\\) and compare it with the one for the original interaction model with a difference score. # the moderation model&#39;s R2 r2 &lt;- bayes_R2(model8.1, summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;moderation_model&quot;) %&gt;% # here we add the multivaraible model&#39;s R2 bind_cols( bayes_R2(model8.4, summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;multivariable_model&quot;) ) %&gt;% # we&#39;ll need a difference score mutate(difference = moderation_model - multivariable_model) %&gt;% # putting the data in the long format and grouping will make summarizing easier pivot_longer(everything(), names_to = &quot;R2&quot;) r2 %&gt;% group_by(R2) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## R2 value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 difference 0.05 -0.073 0.169 0.95 median qi ## 2 moderation_model 0.25 0.164 0.333 0.95 median qi ## 3 multivariable_model 0.2 0.113 0.284 0.95 median qi Note that the Bayesian \\(R^2\\) performed differently than the \\(F\\)-test in the text. r2 %&gt;% filter(R2 == &quot;difference&quot;) %&gt;% ggplot(aes(x = value, fill = model)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_seq&quot;]][14]) + scale_x_continuous(NULL, limits = c(-.4, .4)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The Bayesian &quot;, Delta, italic(R)^2, &quot; distribution&quot;)), subtitle = &quot;Although most of the posterior mass is positive--suggesting the moderation model accounted for more variance than\\nthe simple multivariable model--, a substantial portion of the postrior is within the negative parameter space. Sure,\\nif we had to bet, the safer bet is on the moderation model. But that bet wouled be quite uncertain and we might well\\nloose our shirts. Also, note the width of the distribution; credible values range from -0.1 to nearly 0.2.&quot;) + theme_08 We can also compare these with the LOO, which, as is typical of information criteria, corrects for model complexity. First, we compute them and attach the results to the model fit objects. model8.1 &lt;- add_criterion(model8.1, &quot;loo&quot;) model8.4 &lt;- add_criterion(model8.4, &quot;loo&quot;) Now use the loo_compare() function to compare them directly. loo_compare(model8.1, model8.4) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model8.1 0.0 0.0 -259.1 10.8 5.5 0.9 518.2 21.6 ## model8.4 -5.8 4.1 -264.8 11.2 4.9 0.9 529.7 22.4 As a reminder, we generally prefer models with lower information criteria, which in this case is clearly the moderation model (i.e., model8.1). However, the standard error value (i.e., se_diff) for the difference (i.e., elpd_diff) is quite large, which suggests that the model with the lowest value isn’t the clear winner. Happily, these results match nicely with the Bayesian \\(R^2\\) difference score. The moderation model appears somewhat better than the multivariable model, but its superiority is hardly decisive. 8.4 The equivalence between moderated regression analysis and a 2 X 2 factorial analysis of variance I’m just not going to encourage ANOVA \\(F\\)-testing methodology. However, I will show the Bayesian regression model. First, here are the data. caskets &lt;- read_csv(&quot;data/caskets/caskets.csv&quot;) glimpse(caskets) ## Observations: 541 ## Variables: 7 ## $ policy &lt;dbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0,… ## $ interest &lt;dbl&gt; 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.5, 3.0, 1.0, 2.0, 3.5, 1.0, 1.0, 1.5, 3.0, … ## $ age &lt;dbl&gt; 39, 57, 63, 56, 50, 87, 33, 64, 82, 28, 18, 52, 42, 39, 64, 72, 54, 84, 55, 27, … ## $ educ &lt;dbl&gt; 3, 3, 2, 5, 3, 2, 7, 2, 3, 3, 1, 1, 5, 4, 3, 2, 3, 4, 7, 2, 3, 5, 4, 5, 5, 3, 3,… ## $ male &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1,… ## $ conserv &lt;dbl&gt; 4, 3, 6, 3, 3, 5, 6, 3, 6, 7, 4, 2, 7, 6, 5, 6, 6, 3, 7, 6, 5, 5, 3, 4, 6, 2, 7,… ## $ kerry &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0,… Fit the moderation model. model8.5 &lt;- brm(data = caskets, family = gaussian, interest ~ 1 + policy + kerry + policy:kerry, cores = 4) print(model8.5) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: interest ~ 1 + policy + kerry + policy:kerry ## Data: caskets (Number of observations: 541) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.78 0.09 1.61 1.96 1.00 2374 2968 ## policy -0.38 0.12 -0.63 -0.14 1.00 2096 2639 ## kerry 0.60 0.13 0.34 0.84 1.00 2176 2434 ## policy:kerry 0.36 0.17 0.03 0.71 1.00 1926 2375 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.04 0.03 0.98 1.10 1.00 3741 2853 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Those results don’t look anything like what Hayes reported in Tables 8.3 or 8.4. However, a little deft manipulation of the posterior samples can yield equivalent results to Hayes’s Table 8.3. post &lt;- posterior_samples(model8.5) %&gt;% mutate(Y_bar_1 = b_Intercept + b_policy * 0 + b_kerry * 0 + `b_policy:kerry` * 0 * 0, Y_bar_3 = b_Intercept + b_policy * 0 + b_kerry * 1 + `b_policy:kerry` * 0 * 1, Y_bar_2 = b_Intercept + b_policy * 1 + b_kerry * 0 + `b_policy:kerry` * 1 * 0, Y_bar_4 = b_Intercept + b_policy * 1 + b_kerry * 1 + `b_policy:kerry` * 1 * 1, Y_bar_12 = b_Intercept + b_policy * .5 + b_kerry * 0 + `b_policy:kerry` * .5 * 0, Y_bar_34 = b_Intercept + b_policy * .5 + b_kerry * 1 + `b_policy:kerry` * .5 * 1, Y_bar_13 = b_Intercept + b_policy * 0 + b_kerry * .5 + `b_policy:kerry` * 0 * .5, Y_bar_24 = b_Intercept + b_policy * 1 + b_kerry * .5 + `b_policy:kerry` * 1 * .5) Here are the cell-specific means in Table 8.3. post %&gt;% pivot_longer(Y_bar_1:Y_bar_4) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Y_bar_1 1.78 1.61 1.96 0.95 median qi ## 2 Y_bar_2 1.40 1.23 1.58 0.95 median qi ## 3 Y_bar_3 2.38 2.21 2.56 0.95 median qi ## 4 Y_bar_4 2.36 2.19 2.53 0.95 median qi And here are the marginal means from Table 8.3. post %&gt;% pivot_longer(Y_bar_12:Y_bar_24) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Y_bar_12 1.59 1.47 1.72 0.95 median qi ## 2 Y_bar_13 2.08 1.96 2.21 0.95 median qi ## 3 Y_bar_24 1.88 1.76 2.00 0.95 median qi ## 4 Y_bar_34 2.37 2.24 2.50 0.95 median qi For kicks and giggles, here are what the cell-specific means look like in box plots. post %&gt;% pivot_longer(Y_bar_1:Y_bar_4) %&gt;% ggplot(aes(x = name, y = value, fill = name)) + geom_boxplot(size = 1/3) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + labs(title = &quot;Cell-specific effects&quot;, x = NULL, y = &quot;interest&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) And here are the same for the marginal means. This time we’ll show the shapes of the posteriors with violin plots with horizontal lines depicting the median and interquartile ranges. post %&gt;% pivot_longer(Y_bar_12:Y_bar_24) %&gt;% ggplot(aes(x = name, y = value, fill = name)) + geom_violin(draw_quantiles = c(.25, .5, .75), color = ochre_palettes[[&quot;olsen_seq&quot;]][8]) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + labs(title = &quot;Marginal means&quot;, x = NULL, y = &quot;interest&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) On page 294, Hayes used point estimates to compute the simple effect of policy information among Kerry supporters and then the same thing among Bush supporters. Here’s how we’d do that when working with the full vector of posterior draws. post %&gt;% mutate(simple_effect_Kerry = Y_bar_4 - Y_bar_3, simple_effect_Bush = Y_bar_2 - Y_bar_1) %&gt;% pivot_longer(contains(&quot;simple&quot;)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 simple_effect_Bush -0.382 -0.631 -0.142 0.95 mean qi ## 2 simple_effect_Kerry -0.023 -0.265 0.221 0.95 mean qi So then computing the main effect for policy information using the simple effects is little more than an extension of those steps. post %&gt;% transmute(main_effect = ((Y_bar_4 - Y_bar_3) + (Y_bar_2 - Y_bar_1))/2) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.203 -0.381 -0.029 0.95 mean qi And we get the same results by strategically subtracting the marginal means. post %&gt;% transmute(main_effect = Y_bar_24 - Y_bar_13) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.203 -0.381 -0.029 0.95 mean qi The main effect of for candidate is similarly computed using either approach. post %&gt;% transmute(main_effect = ((Y_bar_4 - Y_bar_2) + (Y_bar_3 - Y_bar_1))/2) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.78 0.606 0.958 0.95 mean qi post %&gt;% transmute(main_effect = Y_bar_34 - Y_bar_12) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.78 0.606 0.958 0.95 mean qi We don’t have an \\(F\\)-test for our Bayesian moderation model. But we do have an interaction term. Here’s its distribution. post %&gt;% ggplot(aes(x = `b_policy:kerry`)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_qual&quot;]][2]) + geom_vline(xintercept = fixef(model8.5)[&quot;policy:kerry&quot;, c(1, 3, 4)], color = ochre_palettes[[&quot;olsen_seq&quot;]][8], linetype = c(1, 2, 2)) + scale_x_continuous(NULL, breaks = fixef(model8.5)[&quot;policy:kerry&quot;, c(1, 3, 4)], labels = fixef(model8.5)[&quot;policy:kerry&quot;, c(1, 3, 4)] %&gt;% round(digits = 2)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The interaction term, `policy:kerry`&quot;, subtitle = &quot;The solid vertical line is the posterior mean\\nand the dashed lines to either end denote the\\npercentile- based 95% intervals.&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) Following Hayes’s work on the bottom of page 295, here’s how you’d reproduce that by manipulating our \\(\\overline Y\\) vectors. post %&gt;% transmute(reproduced_interaction_term = (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)) %&gt;% mean_qi(reproduced_interaction_term) %&gt;% mutate_if(is.double, round, digits = 2) ## # A tibble: 1 x 6 ## reproduced_interaction_term .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.36 0.03 0.71 0.95 mean qi Extending that logic, we also get the answer this way. post %&gt;% transmute(reproduced_interaction_term = (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)) %&gt;% mean_qi(reproduced_interaction_term) %&gt;% mutate_if(is.double, round, digits = 2) ## # A tibble: 1 x 6 ## reproduced_interaction_term .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.36 0.03 0.71 0.95 mean qi 8.4.1 Simple effects parameterization. We might reacquaint ourselves with the formula from model8.5. model8.5$formula ## interest ~ 1 + policy + kerry + policy:kerry The results cohere nicely with the “Model 1” results at the top of Table 8.5. fixef(model8.5) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 1.781 0.089 1.611 1.961 ## policy -0.382 0.124 -0.631 -0.142 ## kerry 0.601 0.127 0.345 0.845 ## policy:kerry 0.359 0.174 0.026 0.712 The Bayesian \\(R^2\\) portion looks on point, too. bayes_R2(model8.5) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.14 0.025 0.092 0.19 Our various Y_bar transformations from before continue to cohere with the coefficients, above, just like in the text. E.g., the policy coefficient may be returned like so. post %&gt;% transmute(b1 = b_policy, `Y_bar_2 - Y_bar_1` = Y_bar_2 - Y_bar_1) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b1 -0.382 0.124 ## 2 Y_bar_2 - Y_bar_1 -0.382 0.124 We can continue to use Hayes’s Y_bar transformations to return the kerry coefficient, too. post %&gt;% transmute(b2 = b_kerry, `Y_bar_3 - Y_bar_1` = Y_bar_3 - Y_bar_1) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b2 0.601 0.127 ## 2 Y_bar_3 - Y_bar_1 0.601 0.127 Here we compute \\(b_3\\) with the difference between the simple effects of \\(X\\) at levels of \\(W\\). post %&gt;% transmute(b3 = `b_policy:kerry`, `(Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)` = (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1) 0.359 0.174 ## 2 b3 0.359 0.174 And now \\(b_{3}\\) with the difference between the simple effects of \\(W\\) at levels of \\(X\\). post %&gt;% transmute(b3 = `b_policy:kerry`, `(Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)` = (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1) 0.359 0.174 ## 2 b3 0.359 0.174 8.4.2 Main effects parameterization. A nice feature of brms is you can transform your data right within the brm() or update() functions. Here we’ll make our two new main-effects-coded variables, policy_me and kerry_me, with the mutate() function right within update(). model8.6 &lt;- update(model8.5, newdata = caskets %&gt;% mutate(policy_me = policy - .5, kerry_me = kerry - .5), family = gaussian, interest ~ 1 + policy_me + kerry_me + policy_me:kerry_me, cores = 4) Transforming your data within the brms functions won’t change the original data structure. However, brms will save the data used to fit the model within the brm() object. You can access that data like so. model8.6$data %&gt;% head() ## interest policy_me kerry_me ## 1 4 0.5 0.5 ## 2 2 -0.5 0.5 ## 3 3 0.5 0.5 ## 4 1 0.5 0.5 ## 5 1 0.5 0.5 ## 6 2 -0.5 -0.5 But we digress. Here’s our analogue to the “Model 2” portion of Table 8.5. rbind( fixef(model8.6) %&gt;% round(digits = 3), bayes_R2(model8.6) %&gt;% round(digits = 3) ) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 1.981 0.045 1.893 2.070 ## policy_me -0.208 0.090 -0.387 -0.032 ## kerry_me 0.780 0.090 0.607 0.955 ## policy_me:kerry_me 0.354 0.180 0.007 0.707 ## R2 0.140 0.025 0.093 0.191 Like with model8.6, above, we’ll need a bit of algebra to compute our \\(\\overline Y_i\\) vectors. post &lt;- posterior_samples(model8.6) %&gt;% mutate(Y_bar_1 = b_Intercept + b_policy_me * -.5 + b_kerry_me * -.5 + `b_policy_me:kerry_me` * -.5 * -.5, Y_bar_3 = b_Intercept + b_policy_me * -.5 + b_kerry_me * .5 + `b_policy_me:kerry_me` * -.5 * .5, Y_bar_2 = b_Intercept + b_policy_me * .5 + b_kerry_me * -.5 + `b_policy_me:kerry_me` * .5 * -.5, Y_bar_4 = b_Intercept + b_policy_me * .5 + b_kerry_me * .5 + `b_policy_me:kerry_me` * .5 * .5) With our post for fit5 in hand, we’ll follow the formulas at the top of page 298 to compute our \\(b_1\\) and \\(b_2\\) distributions. post %&gt;% transmute(b1 = ((Y_bar_4 - Y_bar_3) + (Y_bar_2 - Y_bar_1)) / 2, b2 = ((Y_bar_4 - Y_bar_2) + (Y_bar_3 - Y_bar_1)) / 2) %&gt;% pivot_longer(b1:b2) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b1 -0.208 0.09 ## 2 b2 0.78 0.09 Hayes pointed out that the interaction effect, \\(b_3\\), is the same across models his OLS Models 1 and 2. This is largely true for our Bayesian HMC model8.5 and model8.6 models. fixef(model8.5)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.359 0.174 0.026 0.712 fixef(model8.6)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.354 0.180 0.007 0.707 However, the results aren’t exactly the same because of simulation error. If you were working on a project requiring high precision, increase the number of posterior iterations. To demonstrate, here we’ll increase each chain’s post-warmup iteration count by an order of magnitude, resulting in 80,000 post-warmup iterations rather than the default 4,000. model8.7 &lt;- update(model8.5, chains = 4, cores = 4, warmup = 1000, iter = 21000) model8.8 &lt;- update(model8.6, chains = 4, cores = 4, warmup = 1000, iter = 21000) Now they’re quite a bit closer. fixef(model8.7)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.360 0.178 0.011 0.711 fixef(model8.8)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.360 0.178 0.011 0.709 And before you get fixate on how there are still differences after 80,000 iterations, each, consider comparing the two density plots. posterior_samples(model8.7) %&gt;% transmute(iteraction = `b_policy:kerry`) %&gt;% bind_rows( posterior_samples(model8.8) %&gt;% transmute(iteraction = `b_policy_me:kerry_me`) ) %&gt;% mutate(model = rep(str_c(&quot;8.&quot;, 7:8), times = n() / 2)) %&gt;% ggplot(aes(x = iteraction, fill = model)) + geom_density(size = 0, alpha = 1/2) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(3, 6)]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The interaction densities, by model&quot;, subtitle = &quot;Yes, they are indeed different. And yet that difference is so\\ntrivial that we&#39;d expect greater variability from measurement\\nerror than we still have from simulation error.&quot;, x = NULL) + theme_08 8.4.3 Conducting a \\(2 \\times 2\\) between-participants factorial ANOVA using PROCESS another regression model with brms. Since we’re square in single-level regression land with our brms approach, there’s no direct analogue for us, here. However, notice the post-ANOVA \\(t\\)-tests Hayes presented on page 300. If we just want to consider the \\(2 \\times 2\\) structure of our two dummy variables as indicative of four groups, we have one more coding system available for the job. With the handy str_c() function, we’ll concatenate the policy and kerry values into a nominal variable, policy_kerry. Here’s what that looks like: caskets &lt;- caskets %&gt;% mutate(policy_kerry = str_c(policy, kerry)) head(caskets) ## # A tibble: 6 x 8 ## policy interest age educ male conserv kerry policy_kerry ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 4 39 3 1 4 1 11 ## 2 0 2 57 3 1 3 1 01 ## 3 1 3 63 2 0 6 1 11 ## 4 1 1 56 5 1 3 1 11 ## 5 1 1 50 3 0 3 1 11 ## 6 0 2 87 2 1 5 0 00 Now check out what happens if we reformat our formula to interest ~ 0 + policy_kerry. model8.9 &lt;- brm(data = caskets, family = gaussian, interest ~ 0 + policy_kerry, cores = 4) The brm() function recnognized policy_kerry was a character vector and treated it as a nominal variable. The 0 + part of the function removed the model intercept. Here’s how that effects the output. print(model8.9) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: interest ~ 0 + policy_kerry ## Data: caskets (Number of observations: 541) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## policy_kerry00 1.78 0.09 1.61 1.96 1.00 4728 3033 ## policy_kerry01 2.38 0.09 2.21 2.56 1.00 4673 3337 ## policy_kerry10 1.40 0.09 1.22 1.57 1.00 5379 3114 ## policy_kerry11 2.36 0.09 2.19 2.52 1.00 4375 2931 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.04 0.03 0.98 1.10 1.00 4792 2939 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Without the typical intercept, brm() estimated the means for each of the four policy_kerry groups. It’s kinda like an intercept-only model, but with four intercepts. Here’s what their densities look like: post &lt;- posterior_samples(model8.9) post %&gt;% pivot_longer(b_policy_kerry00:b_policy_kerry11) %&gt;% mutate(name = str_remove(name, &quot;b_&quot;)) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = 2/3) + scale_fill_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Group means&quot;, x = NULL) + theme_08 Since each of the four primary vectors in our post object is of a group mean, it’s trivial to compute difference scores. To compute the difference score analogous to Hayes’s two \\(t\\)-tests, we’d do the following. post %&gt;% mutate(difference_1 = b_policy_kerry10 - b_policy_kerry00, difference_2 = b_policy_kerry11 - b_policy_kerry01) %&gt;% pivot_longer(starts_with(&quot;difference_&quot;)) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 difference_1 -0.386 -0.639 -0.137 0.95 median qi ## 2 difference_2 -0.026 -0.273 0.213 0.95 median qi References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 ochRe_1.0.0 ggthemes_4.2.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 ## [7] stringr_1.4.0 dplyr_0.8.3 purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ## [13] ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ggridges_0.5.1 ## [4] rsconnect_0.8.15 ggstance_0.3.2 markdown_1.1 ## [7] base64enc_0.1-3 rstudioapi_0.10 rstan_2.19.2 ## [10] svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 codetools_0.2-16 ## [16] bridgesampling_0.7-2 knitr_1.23 shinythemes_1.1.2 ## [19] zeallot_0.1.0 bayesplot_1.7.0 jsonlite_1.6 ## [22] broom_0.5.2 shiny_1.3.2 compiler_3.6.0 ## [25] httr_1.4.0 backports_1.1.5 assertthat_0.2.1 ## [28] Matrix_1.2-17 lazyeval_0.2.2 cli_1.1.0 ## [31] later_1.0.0 htmltools_0.4.0 prettyunits_1.0.2 ## [34] tools_3.6.0 igraph_1.2.4.1 coda_0.19-3 ## [37] gtable_0.3.0 glue_1.3.1.9000 reshape2_1.4.3 ## [40] raster_2.9-5 cellranger_1.1.0 vctrs_0.2.0 ## [43] nlme_3.1-139 crosstalk_1.0.0 xfun_0.10 ## [46] ps_1.3.0 rvest_0.3.4 mime_0.7 ## [49] miniUI_0.1.1.1 lifecycle_0.1.0 gtools_3.8.1 ## [52] zoo_1.8-6 scales_1.0.0 colourpicker_1.0 ## [55] hms_0.4.2 promises_1.1.0 Brobdingnag_1.2-6 ## [58] parallel_3.6.0 inline_0.3.15 shinystan_2.5.0 ## [61] gridExtra_2.3 loo_2.1.0 StanHeaders_2.19.0 ## [64] stringi_1.4.3 dygraphs_1.1.1.6 pkgbuild_1.0.5 ## [67] rlang_0.4.1 pkgconfig_2.0.3 matrixStats_0.55.0 ## [70] evaluate_0.14 lattice_0.20-38 rstantools_2.0.0 ## [73] htmlwidgets_1.5 labeling_0.3 tidyselect_0.2.5 ## [76] processx_3.4.1 plyr_1.8.4 magrittr_1.5 ## [79] R6_2.4.0 generics_0.0.2 pillar_1.4.2 ## [82] haven_2.1.0 withr_2.1.2 xts_0.11-2 ## [85] sp_1.3-1 abind_1.4-5 modelr_0.1.4 ## [88] crayon_1.3.4 arrayhelpers_1.0-20160527 utf8_1.1.4 ## [91] rmarkdown_1.13 grid_3.6.0 readxl_1.3.1 ## [94] callr_3.3.2 threejs_0.3.1 digest_0.6.21 ## [97] xtable_1.8-4 httpuv_1.5.2 stats4_3.6.0 ## [100] munsell_0.5.0 shinyjs_1.0 "],
["some-myths-and-additional-extensions-of-moderation-analysis.html", "9 Some Myths and Additional Extensions of Moderation Analysis 9.1 Truths and myths about mean-centering 9.2 The estimation and interpretation of standardized regression coefficients in a moderation analysis 9.3 A caution on manual centering and standardization [because of missing data] 9.4 More than one moderator 9.5 Comparing conditional effects References Session info", " 9 Some Myths and Additional Extensions of Moderation Analysis In this chapter, our Bayesian approach complicates some of Hayes’s flow. We’ll see how Bayesian HMC estimation can make us reconsider the value in mean centering and we’ll also slip in some missing data talk. 9.1 Truths and myths about mean-centering Mean-centering has been recommended in a few highly regarded books on regression analysis (e.g., Aiken &amp; West, 1991; Cohen et al., 2003), and several explanations have been offered for why mean-centering should be undertaken prior to computation of the product and model estimation. The explanation that seems to have resulted in the most misunderstanding is that \\(X\\) and \\(W\\) are likely to be highly correlated with \\(XW\\) and this will produce estimation problems caused by collinearity and result in poor or “strange” estimates of regression coefficients, large standard errors, and reduced power of the statistical test of the interaction. But this is, in large part, simply a myth. As I describe later, there are some reasons that mean- centering the focal antecedent or moderator variables can be a beneficial thing to do, which is why it has been recommended by some. However, it is incorrect to claim that it is necessary, that a failure to do so will lead one to incorrect inferences about moderation, or that the resulting regression coefficients are somehow strange or inherently uninterpretable. (pp. 304–305, emphasis in the original) Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) ## Observations: 815 ## Variables: 7 ## $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1.0, … ## $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.67, 3… ## $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.67, 2… ## $ ideology &lt;dbl&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, 5, 4… ## $ age &lt;dbl&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 38, 6… ## $ sex &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0… ## $ partyid &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1… Before we fit our models, we’ll go ahead and make our mean-centered predictors, negemot_c and age_c. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_c = negemot - mean(negemot), age_c = age - mean(age)) Now we’re ready to fit Models 1 and 2. But before we do, it’s worth repeating part of the text: Let’s load brms. library(brms) As we’ll see in just a bit, there are some important reasons for Bayesians using HMC to mean center that wouldn’t pop up within the OLS paradigm. First let’s fit model9.1 and model9.2. model9.1 follows the conventional moderation equation \\[Y = i_Y + b_1 X + b_2 W + b_3 XW + e_Y.\\] model9.2 is our mean-centered model, which we can express formally as \\[\\begin{align*} Y &amp; = i_Y + b_1 (X - \\overline X) + b_2 (W - \\overline W) + b_3 (X - \\overline X)(W - \\overline W) + e_Y, \\; \\text{or more simply} \\\\ &amp; = i_Y + b_1 X&#39; + b_2 W&#39; + b_3 X&#39;W&#39; + e_Y, \\end{align*}\\] where \\(X&#39; = (X - \\overline X)\\) and so on. model9.1 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + age + negemot:age, cores = 4) model9.2 &lt;- update(model9.1, newdata = glbwarm, govact ~ 1 + negemot_c + age_c + negemot_c:age_c, cores = 4) As with Hayes’s OLS models, our HMC models yield the same Bayesian \\(R^2\\) distributions, within simulation error. bayes_R2(model9.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.022 0.311 0.393 bayes_R2(model9.2) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.022 0.308 0.394 Our model summaries also correspond nicely with those at the top of Table 9.1. print(model9.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + age + negemot:age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.334 0.322 3.698 4.969 1.001 1579 2082 ## negemot 0.148 0.084 -0.016 0.311 1.001 1561 2132 ## age -0.031 0.006 -0.042 -0.019 1.001 1616 1948 ## negemot:age 0.007 0.002 0.004 0.010 1.001 1595 2195 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.098 0.027 1.046 1.154 1.001 2605 2416 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ negemot_c + age_c + negemot_c:age_c ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.598 0.038 4.523 4.672 1.001 3504 3131 ## negemot_c 0.501 0.025 0.449 0.548 1.001 3474 3003 ## age_c -0.005 0.002 -0.010 -0.001 1.000 5349 3012 ## negemot_c:age_c 0.007 0.002 0.004 0.010 1.001 4970 3218 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.098 0.027 1.048 1.152 1.001 3608 2751 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). However, notice the ‘Bulk_ESS’ and ‘Tail_ESS’ columns. The values for model9.2 were substantially larger than those for model9.1. These columns denote the number of effective samples (a.k.a. the effective sample size). Versions of brms before 2.10.0 returned a single effective sample size (ESS) value per parameter. We will cover where the change came from in a bit. But first, recall that we’ve been using brms defaults, which results in 4 HMC chains, each of which contains 2000 draws (iterations), the first 1000 of which are warmup values. After we discard the warmup values, that leaves 1000 draws from each chain–4000 total. As it turns out, Markov chains, and thus HMC chains, are typically autocorrelated, which means that each draw is partially dependent on the previous draw. Ideally, the autocorrelations are near zero. That’s often not the case. The bayesplot package offers a variety of diagnostic plots. Here we’ll use the mcmc_acf() function to make autocorrelation plots for all model parameters. Note that when we add add_chain = T to brms::posterior_samples(), we add an index to the data that allows us to keep track of which iteration comes from which chain. That index will come in handy for our mcmc_acf() plots. But before we get there, we’ll be using an xkcd-inspired theme with help from the xkcd package for our plots in this chapter. # install.packages(&quot;xkcd&quot;, dependencies = T) library(xkcd) If you haven’t used the xkcd package, before, you might also need to take a few extra steps outlined here, part of which requires help from the extrafont package, library(extrafont) download.file(&quot;http://simonsoftware.se/other/xkcd.ttf&quot;, dest = &quot;xkcd.ttf&quot;, mode = &quot;wb&quot;) system(&quot;mkdir ~/.fonts&quot;) system(&quot;cp xkcd.ttf ~/.fonts&quot;) # this line of code returned an error message # font_import(pattern = &quot;[X/x]kcd&quot;, prompt = FALSE) # this line from (https://stackoverflow.com/questions/49221040/error-in-font-import-while-installing-xkcd-font) fixed the problem font_import(path = &quot;~/.fonts&quot;, pattern = &quot;[X/x]kcd&quot;, prompt=FALSE) fonts() fonttable() if(.Platform$OS.type != &quot;unix&quot;) { ## Register fonts for Windows bitmap output loadfonts(device=&quot;win&quot;) } else { loadfonts() } After installing, I still experienced error messages, which were alleviated after I followed these steps outlined by Remi.b. You may or may not need them. But anyways, here are our mcmc_acf() plots. library(bayesplot) post1 &lt;- posterior_samples(model9.1, add_chain = T) mcmc_acf(post1, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot&quot;, &quot;b_age&quot;, &quot;b_negemot:age&quot;, &quot;sigma&quot;), lags = 4) + theme_xkcd() post2 &lt;- posterior_samples(model9.2, add_chain = T) mcmc_acf(post2, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot_c&quot;, &quot;b_age_c&quot;, &quot;b_negemot_c:age_c&quot;, &quot;sigma&quot;), lags = 4) + theme_xkcd() As it turns out, theme_xkcd() can’t handle special characters like &quot;_&quot;, so it returns rectangles instead. So it goes… But again, high autocorrelations in the HMC chains have consequences for the effective sample size. In the Visual MCMC diagnostics using the bayesplot package vignette, Gabry wrote: The effective sample size is an estimate of the number of independent draws from the posterior distribution of the estimand of interest. Because the draws within a Markov chain are not independent if there is autocorrelation, the effective sample size, \\(n_{eff}\\), will be smaller than the total sample size, \\(N\\). The larger the ratio of \\(n_{eff}\\) to \\(N\\) the better. In that quote, Gabry spoke as if there was only one measure of ESS. Though this has been the case for some time, times have changed. In a 2019 paper, Stan-team allstars Vehtari, Gelman, Simpson, Carpenter, and Bürkner proposed two measures of ESS: “bulk-ESS” and “tail-ESS.” From their paper, we read: if you plan to report quantile estimates or posterior intervals, we strongly suggest assessing the convergence of the chains for these quantiles. In Section 4.3 we show that convergence of Markov chains is not uniform across the parameter space and propose diagnostics and effective sample sizes specifically for extreme quantiles. This is different from the standard ESS estimate (which we refer to as the “bulk-ESS”), which mainly assesses how well the centre of the distribution is resolved. Instead, these “tail-ESS” measures allow the user to estimate the MCSE for interval estimates. (p. 5, emphasis in the original) You can read the paper for technical details. In short, the Bulk_ESS in the output of brms 2.10.0 and up is what was previously referred to as Eff.Sample, the effective sample size. This indexed the number of effective samples in “the centre of the” posterior distribution (i.e., the posterior mean or median). But since we also care about uncertainty in our models, we also care about how well we have characterized the tails of the posterior distribution in 95% intervals and such. The new Tail_ESS in brms output allows us to gauge the effective sample size for those intervals. The Bulk_ESS and Tail_ESS values were all well above 2,000 with model9.2 and the autocorrelations were very low, too. model9.1 had higher autocorrelations and lower ESS values. The upshot is that even though we have 4,000 samples for each parameter, those samples don’t necessarily give us the same quality of information fully independent samples would. Bulk_ESS and Tail_ESS values help you determine how concerned you should be. And, as it turns out, things like centering can help increase a models Bulk_ESS and Tail_ESS values. Wading in further, we can use the neff_ratio() function to collect the \\(n_{eff}\\) to \\(N\\) ratio for each model parameter and then use mcmc_neff() to make a visual diagnostic. Here we do so for model9.1 and model9.2. ratios_model9.1 &lt;- neff_ratio(model9.1, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot&quot;, &quot;b_age&quot;, &quot;b_negemot:age&quot;, &quot;sigma&quot;)) ratios_model9.2 &lt;- neff_ratio(model9.2, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot_c&quot;, &quot;b_age_c&quot;, &quot;b_negemot_c:age_c&quot;, &quot;sigma&quot;)) mcmc_neff(ratios_model9.1) + yaxis_text(hjust = 0) + theme_xkcd() mcmc_neff(ratios_model9.2) + yaxis_text(hjust = 0) + theme_xkcd() Although none of the \\(n_{eff}\\) to \\(N\\) ratios were in the shockingly-low range for either model, there were substantially higher for model9.2. In addition to autocorrelations and \\(n_{eff}\\) to \\(N\\) ratios, there is also the issue that the parameters in the model can themselves be correlated. If you like a visual approach, you can use brms::pairs() to retrieve histograms for each parameter along with scatter plots showing the shape of their correlations. Here we’ll use the off_diag_args argument to customize some of the plot settings. pairs(model9.1, off_diag_args = list(size = 1/10, alpha = 1/5)) pairs(model9.2, off_diag_args = list(size = 1/10, alpha = 1/5)) When fitting models with HMC, centering can make a difference for the parameter correlations. If you prefer a more numeric approach, vcov() will yield the variance/covariance matrix–or correlation matrix when using correlation = T–for the parameters in a model. vcov(model9.1, correlation = T) %&gt;% round(digits = 2) ## Intercept negemot age negemot:age ## Intercept 1.00 -0.93 -0.95 0.88 ## negemot -0.93 1.00 0.88 -0.95 ## age -0.95 0.88 1.00 -0.92 ## negemot:age 0.88 -0.95 -0.92 1.00 vcov(model9.2, correlation = T) %&gt;% round(digits = 2) ## Intercept negemot_c age_c negemot_c:age_c ## Intercept 1.00 -0.05 -0.03 0.07 ## negemot_c -0.05 1.00 0.02 -0.09 ## age_c -0.03 0.02 1.00 -0.02 ## negemot_c:age_c 0.07 -0.09 -0.02 1.00 And so wait, what does that even mean for a parameter to correlate with another parameter? you might ask. Fair enough. Let’s compute a parameter correlation step by step. The first step requires posterior_samples(). post &lt;- posterior_samples(model9.1) head(post) ## b_Intercept b_negemot b_age b_negemot:age sigma lp__ ## 1 4.784589 0.09051007 -0.03736229 0.007524971 1.043218 -1240.427 ## 2 4.535839 0.10386142 -0.03432908 0.008052277 1.140911 -1236.445 ## 3 4.624798 0.11578574 -0.03397618 0.007172857 1.116228 -1236.578 ## 4 4.604103 0.06094752 -0.03593282 0.008872074 1.097935 -1235.321 ## 5 4.496733 0.10233315 -0.03130703 0.007536339 1.072701 -1236.124 ## 6 4.773596 0.05192045 -0.03672549 0.008539841 1.082068 -1236.373 Now we’ve put our posterior iterations into a data object, post, we can make a scatter plot of two parameters. Here we’ll choose b_negemot and the interaction coefficient, b_negemot:age. post %&gt;% ggplot(aes(x = b_negemot, y = `b_negemot:age`)) + geom_point(size = 1/10, alpha = 1/5) + labs(subtitle = &quot;Each dot is the parameter pair\\nfrom a single iteration. Looking\\nacross the 4,000 total posterior\\niterations, it becomes clear the\\ntwo parameters are highly\\nnegatively correlated.&quot;) + theme_xkcd() And indeed, the Pearson’s correlation coefficient is strong. cor(post$b_negemot, post$`b_negemot:age`) ## [1] -0.9547416 And what was that part from the vcov() output, again? vcov(model9.1, correlation = T)[&quot;negemot&quot;, &quot;negemot:age&quot;] ## [1] -0.9547416 Boom! That’s where those correlations come from. This entire topic of HMC diagnostics can seem baffling, especially when compared to the simplicity of OLS. If this is your first introduction, you might want to watch lectures 10 and 11 from McElreath’s Statistical Rethinking Fall 2017 lecture series. Accordingly, you might check out Chapter 8 of his Statistical Rethinking text and my project explaining how to reproduce the analyses in that chapter in brms. 9.1.1 The effect of mean-centering on multicollinearity and the standard error of \\(b_3\\). This can be difficult to keep track of, but what we just looked at were the correlations among model parameters. These are not the same as correlations among variables. As such, those correlations are not the same as those in Table 9.2. But we can get those, too. First we’ll have to do a little more data processing to get all the necessary mean-centered variables and standardized variables. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_x_age = negemot * age, negemot_c_x_age_c = negemot_c * age_c, negemot_z = (negemot - mean(negemot)) / sd(negemot), age_z = (age - mean(age) ) / sd(age)) %&gt;% mutate(negemot_z_x_age_z = negemot_z * age_z) And recall that to get our sweet Bayesian correlations, we use the multivariate mvbind() syntax to fit an intercepts-only model. Here we do that for all three of the Table 9.2 sections. model9.3 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot, age, negemot_x_age) ~ 1, cores = 4) model9.4 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot_c, age_c, negemot_c_x_age_c) ~ 1, cores = 4) model9.5 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot_z, age_z, negemot_z_x_age_z) ~ 1, cores = 4) Here are their summaries. print(model9.3, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot ~ 1 ## age ~ 1 ## negemot_x_age ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemot_Intercept 3.557 0.054 3.450 3.664 1.000 3573 2647 ## age_Intercept 49.535 0.574 48.414 50.645 1.001 3746 2439 ## negemotxage_Intercept 174.768 3.466 167.909 181.452 1.001 3307 2656 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemot 1.529 0.038 1.454 1.604 1.002 3435 2714 ## sigma_age 16.361 0.409 15.581 17.191 1.000 3023 2544 ## sigma_negemotxage 97.421 2.380 92.865 102.158 1.002 2626 2300 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemot,age) -0.058 0.035 -0.127 0.009 1.000 2437 1846 ## rescor(negemot,negemotxage) 0.765 0.015 0.735 0.793 1.002 2363 2442 ## rescor(age,negemotxage) 0.548 0.025 0.498 0.594 1.001 3230 2750 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.4, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot_c ~ 1 ## age_c ~ 1 ## negemot_c_x_age_c ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemotc_Intercept -0.001 0.054 -0.106 0.106 1.002 6244 3061 ## agec_Intercept -0.004 0.568 -1.092 1.064 1.002 6529 2913 ## negemotcxagec_Intercept -1.411 0.862 -3.090 0.303 1.001 7503 3141 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemotc 1.533 0.036 1.461 1.607 1.002 6919 3187 ## sigma_agec 16.362 0.419 15.577 17.169 1.000 7966 3130 ## sigma_negemotcxagec 24.236 0.608 23.075 25.463 1.001 6427 3062 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemotc,agec) -0.057 0.034 -0.121 0.013 1.004 6669 2937 ## rescor(negemotc,negemotcxagec) 0.092 0.035 0.023 0.159 1.002 7534 2911 ## rescor(agec,negemotcxagec) -0.014 0.035 -0.083 0.054 1.001 7142 2690 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.5, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot_z ~ 1 ## age_z ~ 1 ## negemot_z_x_age_z ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemotz_Intercept 0.000 0.036 -0.071 0.069 1.003 7595 3150 ## agez_Intercept -0.001 0.035 -0.070 0.069 1.000 6965 2835 ## negemotzxagez_Intercept -0.057 0.034 -0.122 0.011 1.001 7735 2581 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemotz 1.003 0.025 0.956 1.053 1.003 7990 2943 ## sigma_agez 1.002 0.025 0.953 1.053 1.000 7529 2834 ## sigma_negemotzxagez 0.972 0.025 0.925 1.022 1.001 7272 2969 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemotz,agez) -0.057 0.035 -0.127 0.012 1.006 7927 2851 ## rescor(negemotz,negemotzxagez) 0.092 0.034 0.026 0.158 1.000 6929 2379 ## rescor(agez,negemotzxagez) -0.015 0.035 -0.086 0.053 1.000 7536 2978 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). A more condensed way to get that information might be with the brms::VarCorr() function. Just make sure to tack $residual__$cor onto the end. VarCorr(model9.3)$residual__$cor %&gt;% round(digits = 3) ## , , negemot ## ## Estimate Est.Error Q2.5 Q97.5 ## negemot 1.000 0.000 1.000 1.000 ## age -0.058 0.035 -0.127 0.009 ## negemotxage 0.765 0.015 0.735 0.793 ## ## , , age ## ## Estimate Est.Error Q2.5 Q97.5 ## negemot -0.058 0.035 -0.127 0.009 ## age 1.000 0.000 1.000 1.000 ## negemotxage 0.548 0.025 0.498 0.594 ## ## , , negemotxage ## ## Estimate Est.Error Q2.5 Q97.5 ## negemot 0.765 0.015 0.735 0.793 ## age 0.548 0.025 0.498 0.594 ## negemotxage 1.000 0.000 1.000 1.000 For the sake of space, I’ll let you check that out for model9.4 and model9.5. If you’re tricky with your VarCorr() indexing, you can also get the model-implied variances. VarCorr(model9.3)$residual__$cov[1, , &quot;negemot&quot;] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 2.340 0.118 2.115 2.574 VarCorr(model9.3)$residual__$cov[2, , &quot;age&quot;] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 267.848 13.402 242.758 295.519 VarCorr(model9.3)$residual__$cov[3, , &quot;negemotxage&quot;] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 9496.434 464.569 8623.939 10436.186 And if you’re like totally lost with all this indexing, you might execute VarCorr(correlations1) %&gt;% str() and spend a little time looking at what VarCorr() returns. On page 309, Hayes explained why the OLS variance for \\(b_3\\) is unaffected by mean centering. The story was similar for our HMC model, too. fixef(model9.1)[&quot;negemot:age&quot;, &quot;Est.Error&quot;] ## [1] 0.00157804 fixef(model9.2)[&quot;negemot_c:age_c&quot;, &quot;Est.Error&quot;] ## [1] 0.001577989 For more details, you might also see the 22.12. Standardizing Predictors and Outputs subsection of the Stan User’s Guide, Version 2.21–Stan, of course, being the computational engine underneath our brms hood. 9.1.2 The effect of mean-centering on \\(b_1\\), \\(b_2\\), and their standard errors posterior \\(SD\\)s. A second explanation given for why mean-centering is preferred is that it makes \\(b_1\\) and \\(b_2\\), the regression coefficients for \\(X\\) and \\(W\\), more meaningful. This is generally true and thus not a myth, although it is not necessarily true in all circumstances… Mean-centering \\(X\\) and \\(W\\) prior to computation of the product and estimation of the model will produce \\(b_1\\) and \\(b_2\\) that are always meaningful, rather than meaningful only when \\(X\\) and/or \\(W\\) are meaningful when equal to zero… [After mean centering,] \\(b_1\\) estimates the difference in \\(Y\\) between two cases that differ by one unit on \\(X\\) among cases that are average on \\(W\\). Similarly, \\(b_2\\) estimates the difference in \\(Y\\) between two cases that differ by one unit on \\(W\\) among cases that are average on \\(X\\). These will always estimate conditional effects of \\(X\\) on $Yv within the range of the data, and they can always be interpreted. (p. 310. emphasis in the original) If you only care about posterior means, you can use model9.1 to reproduce the results at the bottom of page 310 like this. fixef(model9.1)[&quot;negemot&quot;, 1] + fixef(model9.1)[&quot;negemot:age&quot;, 1] * mean(glbwarm$age) ## [1] 0.5003564 Here’s the same computation using model9.2. fixef(model9.2)[&quot;negemot_c&quot;, 1] + fixef(model9.2)[&quot;negemot_c:age_c&quot;, 1] * mean(glbwarm$age_c) ## [1] 0.5005431 But we’re proper Bayesians and like a summary of the spread in the posterior. So we’ll evoke posterior_samples() and the other usual steps, this time just focusing on model9.1. post &lt;- posterior_samples(model9.1) post %&gt;% transmute(our_contidional_effect_given_W_bar = b_negemot + `b_negemot:age` * mean(glbwarm$age)) %&gt;% summarize(mean = mean(our_contidional_effect_given_W_bar), sd = sd(our_contidional_effect_given_W_bar)) %&gt;% round(digits = 3) ## mean sd ## 1 0.5 0.025 And note how the standard error Hayes computed at the top of page 311 corresponds nicely with the posterior \\(SD\\) we just computed. Hayes employed a fancy formula; we just used sd(). At any rate, the main message is centering did not effect our estimate of the conditional effect of \\(X\\). It turns out \\((\\theta_{X \\rightarrow Y} | W) = (\\theta_{\\overline X \\rightarrow Y} | \\overline W)\\). 9.1.3 The centering option in PROCESS. I’m not aware of a similar function in brms. You’ll have to use your data wrangling skills. 9.2 The estimation and interpretation of standardized regression coefficients in a moderation analysis Mean-centering does nothing to change the scaling of regression coefficients. Whether or not mean-centering is used when estimating a model of the form \\(\\hat Y = i_Y + b_1 X + b_2 W + b_3 XW\\), \\(b_1\\), \\(b_2\\), and \\(b_3\\) are interpreted with respect to the measured metrics of \\(X\\), \\(W\\), and \\(Y\\) (i.e., in unstandardized form). Although [Hayes] generally prefer[s] to report and interpret regression analyses based on unstandardized coefficients, it is possible to generate regression coefficients that are analogous to standardized regression coefficients in regression models without a product term as a predictor. However, one must be careful when doing so. (p. 313, emphasis in the original) 9.2.1 Variant 1. We’ve already computed standardized predictors. Now we just need to standardize the criterion, govact. glbwarm &lt;- glbwarm %&gt;% mutate(govact_z = (govact - mean(govact)) / sd(govact)) Fit the model. model9.6 &lt;- update(model9.1, newdata = glbwarm, govact_z ~ 1 + negemot_z + age_z + negemot_z:age_z, cores = 4) Check the Bayesian \\(R^2\\). bayes_R2(model9.6) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.355 0.022 0.311 0.397 Check the parameter summaries. print(model9.6, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z + age_z + negemot_z:age_z ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.007 0.028 -0.048 0.064 1.000 4443 2985 ## negemot_z 0.563 0.028 0.507 0.619 1.001 4793 3216 ## age_z -0.063 0.029 -0.120 -0.004 1.002 4304 2918 ## negemot_z:age_z 0.131 0.029 0.073 0.189 1.003 4767 3267 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.807 0.020 0.769 0.845 1.001 4648 3263 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). If you go all the way up back to Table 9.1, you’ll see our results are pretty similar to those in the text. 9.2.2 Variant 2. This time we need to standardize our interaction term, negemot_x_age_z, by hand. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_x_age_z = (negemot_x_age - mean(negemot_x_age)) / sd(negemot_x_age)) Now we’re ready to update() model9.7 &lt;- update(model9.1, newdata = glbwarm, govact_z ~ 1 + negemot_z + age_z + negemot_x_age_z, cores = 4) bayes_R2(model9.7) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.022 0.309 0.395 print(model9.7, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z + age_z + negemot_x_age_z ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.000 0.029 -0.058 0.056 1.003 2832 2558 ## negemot_z 0.170 0.093 -0.013 0.349 1.001 1316 1784 ## age_z -0.365 0.071 -0.507 -0.228 1.001 1334 1559 ## negemot_x_age_z 0.506 0.111 0.291 0.728 1.002 1290 1772 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.806 0.021 0.767 0.848 1.000 2728 2048 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The results correspond nicely to those in Table 9.1, too. 9.3 A caution on manual centering and standardization [because of missing data] It’s worthwhile considering the issue of listwise deletion when data are partially missing. The brms default is to delete rows with missingness, NA in R, for the predictors. However, brms allows users to perform one-step Bayesian imputation for missing values using the mi() syntax. First we’ll fit see what happens when you fit a model in brms when some of the negemot_z values are missing, but without using the mi() syntax. And of course before we do that, we’ll make a negemot_z_missing variable, which is identical to negemot_z, but about 10% of the values are missing. set.seed(9) glbwarm &lt;- glbwarm %&gt;% mutate(missing = rbinom(n = n(), size = 1, prob = .1)) %&gt;% mutate(negemot_z_missing = ifelse(missing == 1, NA, negemot_z)) If you’ve never used rbinom() before, execute ?rbinom or look it up in your favorite web search engine. Here’s our listwise deletion model, which corresponds to what you’d get from a typical OLS-based program. model9.8 &lt;- update(model9.6, newdata = glbwarm, govact_z ~ 1 + negemot_z_missing + age_z + negemot_z_missing:age_z, cores = 4) Let’s compare the listwise deletion results with the model based on all the data. print(model9.6) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z + age_z + negemot_z:age_z ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.01 0.03 -0.05 0.06 1.00 4443 2985 ## negemot_z 0.56 0.03 0.51 0.62 1.00 4793 3216 ## age_z -0.06 0.03 -0.12 -0.00 1.00 4304 2918 ## negemot_z:age_z 0.13 0.03 0.07 0.19 1.00 4767 3267 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.81 0.02 0.77 0.85 1.00 4648 3263 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.8) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z_missing + age_z + negemot_z_missing:age_z ## Data: glbwarm (Number of observations: 731) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.00 0.03 -0.05 0.06 1.00 4803 2808 ## negemot_z_missing 0.57 0.03 0.51 0.63 1.00 4543 2599 ## age_z -0.05 0.03 -0.10 0.01 1.00 4839 2868 ## negemot_z_missing:age_z 0.12 0.03 0.06 0.18 1.00 4989 3234 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.81 0.02 0.77 0.85 1.00 5280 2741 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In this case, the model results were similar to those based on all the data because we used rbinom() to delete the predictor values completely at random. With real data and real-live missing data mechanisms, the situation isn’t often so rosy. But anyway, the real story, here, is the Data: glbwarm (Number of observations: n) line at the top of the print() outputs. The number, \\(n\\), was 815 in the model using all the data and 731 for the one based on listwise deletion. That’s a lot of missing information. The mi() syntax will allow us to use all the rows in a model, even if one or more of the predictors contain missing values. The syntax makes the model a multivariate model in that now we’ll be modeling both govact_z and negemot_z_missing. As we’ve covered in prior chapters, there are multiple ways to write a multivariate model in brms. One nice way is to write the model for each criterion separately in a bf() statement. You combine the bf() statements together with the + operator. And for models like the ones in Hayes’s text, you’ll also want to tack on set_rescor(FALSE). You can do this within the brm() function, as usual. But I find that this clutters the code up more than I like. So another approach is to save the combination of bf() statements as an object. my_model &lt;- bf(govact_z ~ 1 + mi(negemot_z_missing) + age_z + mi(negemot_z_missing):age_z) + bf(negemot_z_missing | mi() ~ 1) + set_rescor(FALSE) With our multivariate formula saved as my_model, we’re ready to plug it into brm() and fit. model9.9 &lt;- brm(data = glbwarm, family = gaussian, my_model, cores = 4) Let’s see what we’ve done. print(model9.9) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: govact_z ~ 1 + mi(negemot_z_missing) + age_z + mi(negemot_z_missing):age_z ## negemot_z_missing | mi() ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## govactz_Intercept 0.01 0.03 -0.05 0.06 1.00 4695 2818 ## negemotzmissing_Intercept -0.00 0.04 -0.07 0.07 1.00 4876 2901 ## govactz_age_z -0.06 0.03 -0.12 -0.00 1.00 5861 2603 ## govactz_minegemot_z_missing 0.57 0.03 0.51 0.63 1.00 4487 2647 ## govactz_minegemot_z_missing:age_z 0.13 0.03 0.07 0.19 1.00 4358 2582 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_govactz 0.80 0.02 0.77 0.85 1.00 5546 3135 ## sigma_negemotzmissing 1.00 0.03 0.95 1.05 1.00 4226 3234 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). When using the multivariate mi() syntax, your print() output becomes more complicated. We got regression sub-models for both govact_z and negemot_z_missing. But look at the line at the top of the output that reads “Data: glbwarm (Number of observations: 815)”. The multivariate mi() syntax used all the available data. No listwise deletion necessary. The print() output for our model obscured some of the results. To clarify what the mi() syntax did, let’s peek at the first columns returned by posterior_samples(). post &lt;- posterior_samples(model9.9) post[, 1:20] %&gt;% glimpse() ## Observations: 4,000 ## Variables: 20 ## $ b_govactz_Intercept &lt;dbl&gt; 0.0511836815, 0.0128788162, 0.0009209448, -0.047046148… ## $ b_negemotzmissing_Intercept &lt;dbl&gt; 0.0667552821, -0.0348313048, 0.0196244734, 0.072896235… ## $ b_govactz_age_z &lt;dbl&gt; -0.013879975, -0.116291294, -0.039856620, -0.098567649… ## $ bsp_govactz_minegemot_z_missing &lt;dbl&gt; 0.5746923, 0.5591172, 0.5578617, 0.5481572, 0.5918545,… ## $ `bsp_govactz_minegemot_z_missing:age_z` &lt;dbl&gt; 0.13033787, 0.15948055, 0.07389118, 0.13219047, 0.1316… ## $ sigma_govactz &lt;dbl&gt; 0.7762248, 0.8187004, 0.8044304, 0.8035145, 0.7992377,… ## $ sigma_negemotzmissing &lt;dbl&gt; 0.9884742, 1.0044714, 0.9758054, 0.9892599, 0.9898388,… ## $ `Ymi_negemotzmissing[10]` &lt;dbl&gt; -1.32620629, -1.48806393, -0.45006561, -0.45126959, -1… ## $ `Ymi_negemotzmissing[18]` &lt;dbl&gt; -1.11552232, -1.42524665, 0.33196970, -0.14569350, -1.… ## $ `Ymi_negemotzmissing[26]` &lt;dbl&gt; 0.985209590, 0.685942447, 0.731777668, 0.783938990, 0.… ## $ `Ymi_negemotzmissing[29]` &lt;dbl&gt; 0.641768757, 0.803036790, -0.081791642, -0.554251229, … ## $ `Ymi_negemotzmissing[32]` &lt;dbl&gt; -0.54750557, -0.68269765, -0.79909703, -0.04961853, -0… ## $ `Ymi_negemotzmissing[34]` &lt;dbl&gt; 0.765672301, 0.606357262, -0.434451999, 0.311854581, 0… ## $ `Ymi_negemotzmissing[38]` &lt;dbl&gt; -1.8536319, -1.8540774, -1.2281257, -2.2368816, -0.865… ## $ `Ymi_negemotzmissing[41]` &lt;dbl&gt; 2.20891904, -0.92963476, 1.71167671, -0.73501717, 2.01… ## $ `Ymi_negemotzmissing[50]` &lt;dbl&gt; -1.09947044, 1.46852537, -0.88236811, 0.34262669, -0.8… ## $ `Ymi_negemotzmissing[51]` &lt;dbl&gt; 0.18231797, -1.48490397, 0.59038786, -0.05293762, -0.9… ## $ `Ymi_negemotzmissing[56]` &lt;dbl&gt; -2.35724416, 1.23301199, -1.26320544, -0.63057085, 0.5… ## $ `Ymi_negemotzmissing[78]` &lt;dbl&gt; -0.554938052, 0.246140168, -0.909169616, -0.970796887,… ## $ `Ymi_negemotzmissing[89]` &lt;dbl&gt; -0.5441625, -1.6380123, 0.2389384, -0.8950995, -0.6292… Columns b_govactz_Intercept through sigma_negemotzmissing were business as usual. But notice all the Ymi_negemotzmissing[i] columns. In each of these we see 4,000 posterior draws for the missing negemot_z_missing values. The [i] part of the column names indexes which row number the iterations correspond to. Summarizing these columns might help us get a sense of the results. library(tidybayes) post %&gt;% pivot_longer(starts_with(&quot;Ymi&quot;), names_to = &quot;row&quot;) %&gt;% group_by(row) %&gt;% # yep, that&#39;s right, we&#39;re summarizing as usual mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 2) %&gt;% select(row:.upper) ## # A tibble: 84 x 4 ## row value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Ymi_negemotzmissing[10] -0.85 -2.36 0.68 ## 2 Ymi_negemotzmissing[101] 0.13 -1.52 1.76 ## 3 Ymi_negemotzmissing[117] -0.18 -1.89 1.55 ## 4 Ymi_negemotzmissing[135] 0.28 -1.36 1.89 ## 5 Ymi_negemotzmissing[139] -0.34 -1.94 1.24 ## 6 Ymi_negemotzmissing[148] -1.39 -2.85 0.08 ## 7 Ymi_negemotzmissing[150] -0.3 -1.68 1.11 ## 8 Ymi_negemotzmissing[152] 0.01 -1.6 1.59 ## 9 Ymi_negemotzmissing[153] -1.57 -3.08 -0.06 ## 10 Ymi_negemotzmissing[154] 0.59 -0.88 2.06 ## 11 Ymi_negemotzmissing[162] 0.09 -1.52 1.64 ## 12 Ymi_negemotzmissing[164] 0.37 -1.14 1.91 ## 13 Ymi_negemotzmissing[166] -0.07 -1.59 1.46 ## 14 Ymi_negemotzmissing[167] -0.15 -1.7 1.32 ## 15 Ymi_negemotzmissing[178] -0.49 -1.93 0.95 ## 16 Ymi_negemotzmissing[18] -0.85 -2.25 0.55 ## 17 Ymi_negemotzmissing[186] 0.12 -1.4 1.63 ## 18 Ymi_negemotzmissing[214] 0.96 -0.56 2.41 ## 19 Ymi_negemotzmissing[230] -0.18 -1.89 1.55 ## 20 Ymi_negemotzmissing[246] 0.61 -1.07 2.32 ## 21 Ymi_negemotzmissing[259] -0.99 -2.73 0.76 ## 22 Ymi_negemotzmissing[26] 0.62 -0.82 2.07 ## 23 Ymi_negemotzmissing[260] 0.49 -1.05 1.99 ## 24 Ymi_negemotzmissing[266] 0.24 -1.15 1.63 ## 25 Ymi_negemotzmissing[284] 0.2 -1.67 2.05 ## 26 Ymi_negemotzmissing[29] 0.3 -1.21 1.77 ## 27 Ymi_negemotzmissing[32] -0.48 -2.14 1.25 ## 28 Ymi_negemotzmissing[329] 0.21 -1.6 1.94 ## 29 Ymi_negemotzmissing[337] 0.24 -1.51 2 ## 30 Ymi_negemotzmissing[338] 0.15 -1.61 1.96 ## 31 Ymi_negemotzmissing[34] 0.27 -1.29 1.84 ## 32 Ymi_negemotzmissing[350] -0.91 -2.59 0.74 ## 33 Ymi_negemotzmissing[358] 0.98 -0.68 2.61 ## 34 Ymi_negemotzmissing[371] 0.15 -1.27 1.59 ## 35 Ymi_negemotzmissing[38] -1.58 -3.02 -0.18 ## 36 Ymi_negemotzmissing[383] 0.45 -1.12 2.05 ## 37 Ymi_negemotzmissing[394] 0.74 -0.92 2.39 ## 38 Ymi_negemotzmissing[397] 0.33 -1.39 2.04 ## 39 Ymi_negemotzmissing[398] 0.570 -1.04 2.18 ## 40 Ymi_negemotzmissing[401] -0.28 -2.02 1.42 ## 41 Ymi_negemotzmissing[406] 0.62 -0.96 2.17 ## 42 Ymi_negemotzmissing[41] 0.6 -1.1 2.25 ## 43 Ymi_negemotzmissing[424] 0.69 -1.05 2.43 ## 44 Ymi_negemotzmissing[435] -0.11 -1.85 1.61 ## 45 Ymi_negemotzmissing[440] 0.36 -1.27 1.93 ## 46 Ymi_negemotzmissing[447] -0.15 -1.78 1.4 ## 47 Ymi_negemotzmissing[469] -0.04 -1.83 1.7 ## 48 Ymi_negemotzmissing[472] 0.39 -1.06 1.84 ## 49 Ymi_negemotzmissing[476] 0.64 -0.85 2.18 ## 50 Ymi_negemotzmissing[484] -1.4 -2.95 0.15 ## 51 Ymi_negemotzmissing[50] -0.21 -1.62 1.19 ## 52 Ymi_negemotzmissing[507] -0.16 -1.66 1.37 ## 53 Ymi_negemotzmissing[51] -0.51 -2.02 1.02 ## 54 Ymi_negemotzmissing[515] 0.2 -1.37 1.7 ## 55 Ymi_negemotzmissing[519] -0.05 -1.55 1.51 ## 56 Ymi_negemotzmissing[524] -0.32 -1.79 1.16 ## 57 Ymi_negemotzmissing[540] 0.5 -1.18 2.14 ## 58 Ymi_negemotzmissing[555] 0.45 -1.15 2.07 ## 59 Ymi_negemotzmissing[56] -0.01 -1.64 1.64 ## 60 Ymi_negemotzmissing[585] 0.05 -1.35 1.45 ## 61 Ymi_negemotzmissing[593] 0.09 -1.67 1.85 ## 62 Ymi_negemotzmissing[602] -0.6 -2.03 0.83 ## 63 Ymi_negemotzmissing[605] 0.76 -0.85 2.36 ## 64 Ymi_negemotzmissing[612] 0.15 -1.52 1.88 ## 65 Ymi_negemotzmissing[613] 0.73 -0.94 2.42 ## 66 Ymi_negemotzmissing[621] -0.76 -2.21 0.66 ## 67 Ymi_negemotzmissing[629] 0.11 -1.36 1.57 ## 68 Ymi_negemotzmissing[630] 0.38 -1.1 1.85 ## 69 Ymi_negemotzmissing[643] 0.88 -0.84 2.66 ## 70 Ymi_negemotzmissing[653] -0.61 -2.34 1.15 ## 71 Ymi_negemotzmissing[679] -0.92 -2.57 0.71 ## 72 Ymi_negemotzmissing[701] -0.18 -1.73 1.37 ## 73 Ymi_negemotzmissing[742] 0.23 -1.46 1.91 ## 74 Ymi_negemotzmissing[751] 0.3 -1.42 1.98 ## 75 Ymi_negemotzmissing[752] -0.87 -2.35 0.59 ## 76 Ymi_negemotzmissing[760] 0.43 -1.29 2.15 ## 77 Ymi_negemotzmissing[774] 0.79 -1 2.56 ## 78 Ymi_negemotzmissing[779] -0.05 -1.77 1.7 ## 79 Ymi_negemotzmissing[78] 0.13 -1.55 1.82 ## 80 Ymi_negemotzmissing[792] -0.1 -1.86 1.69 ## 81 Ymi_negemotzmissing[794] 0.3 -1.41 1.98 ## 82 Ymi_negemotzmissing[799] -0.19 -1.92 1.53 ## 83 Ymi_negemotzmissing[89] -0.79 -2.34 0.73 ## 84 Ymi_negemotzmissing[94] 0.27 -1.28 1.9 That’s a lot of output. Here’s what those summaries look like in a coefficient plot. # summarize just like before post %&gt;% pivot_longer(starts_with(&quot;Ymi&quot;), names_to = &quot;row&quot;) %&gt;% group_by(row) %&gt;% mean_qi(value) %&gt;% # plot! ggplot(aes(x = row, y = value, ymin = .lower, ymax = .upper)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_pointinterval(size = 1/3) + scale_x_discrete(&quot;rank-ordered row number&quot;, breaks = NULL) + ylab(&quot;imputed value&quot;) + theme_xkcd() Each missing negemot_z value got an entire posterior distribution. And just as the model is uncertain about what those values might have been, that uncertainty was baked right into the primary submodel predicting govact_z. That’s a good thing. We want our Bayesian models to use as much information as they can and yield results with as much certainty as possible. But we don’t want our models to be more certain than the data–and priors–allow. When you use listwise deletion methods, you leave information on the table, which we don’t want. But when you use old fashioned ad hock methods like mean imputation, you underestimate the uncertainty in the model, which we also don’t want. We want the middle path. Here’s a focused look at two other important new parameters. posterior_summary(model9.9)[c(&quot;b_negemotzmissing_Intercept&quot;, &quot;sigma_negemotzmissing&quot;),] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## b_negemotzmissing_Intercept -0.001 0.036 -0.071 0.069 ## sigma_negemotzmissing 0.997 0.026 0.947 1.051 Our model has estimated the mean and standard deviations for our negemot_z_missing variable. Hopefully that isn’t a surprise. This is exactly what we asked brms to do with the negemot_z_missing | mi() ~ 1 part of the model formula. Since that submodel had no predictors, the intercept was just the mean. Correspondingly, the residual variance was the entire variance–but expressed in the usual \\(\\sigma\\) metric since we’re using brms. And since our negemot_z_missing variable is a subset of the standardized negemot_z variable, naturally the estimates for the mean and standard deviation are about 0 and 1, respectively. Another method we could have used is multiple imputation. With multiple imputation, you create a small number of alternative data sets, typically 5, into which you impute plausible values into the missing value slots. You then fit the model separately for each of the imputed data sets. Because the imputed values will vary across the data sets, that uncertainty will get appropriately transmitted to the model. I know this might sound crazy, but it typically leads to much lower model bias when compared to mean imputation or listwise deletion. But we didn’t quite use multiple imputation. With one-step Bayesian imputation using the mi() syntax, you get an entire posterior distribution for each missing value. And if you have variables in the data set that might help predict what those missing values are, you’d just plug that into the missing data submodel. Improving the imputation model can improve the subsequent substantive model. For more on the mi() approach, see Bürkner’s vignette. McElreath lectured on this topic within the context of his Statistical Rethinking text and you can find my effort to translate the Capter 14 code in McElreath’s text into brms here. For a more general introduction to missing data theory, check out van Burren’s bookdown book Flexible Imputation of Missing Data. Second Edition or Enders’ great Applied Missing Data Analysis. You can also find Enders lecturing on missing data here. The take home message is there is no need to ignore missing data or use outdated procedures like listwise deletion. Be a champion and model your missing data with brms. 9.4 More than one moderator None of this is a problem for brms. But instead of using the model=i syntax in Hayes’s PROCESS, you just have to specify your model formula in brm(). 9.4.1 Additive multiple moderation. It’s trivial to add sex, its interaction with negemot, and the two covariates (i.e., posemot and ideology) to the model. We can even do it within update(). model9.10 &lt;- update(model9.1, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex + negemot:age, cores = 4) Our output matches nicely with the formula at the bottom of page 232 and the PROCESS output in Figure 9.2. print(model9.10, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ negemot + sex + age + posemot + ideology + negemot:sex + negemot:age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.271 0.329 4.640 5.917 1.000 2684 2923 ## negemot 0.094 0.082 -0.063 0.254 1.001 2319 2620 ## sex -0.749 0.194 -1.133 -0.377 1.000 2022 2489 ## age -0.018 0.006 -0.030 -0.006 1.000 2415 2391 ## posemot -0.023 0.027 -0.076 0.030 1.002 4245 2890 ## ideology -0.207 0.026 -0.259 -0.155 1.000 3926 3024 ## negemot:sex 0.206 0.050 0.110 0.306 1.000 2013 1998 ## negemot:age 0.005 0.002 0.002 0.008 1.001 2269 2566 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.049 0.026 0.997 1.100 1.001 4068 2708 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). On page 325, Hayes discussed the unique variance each of the two moderation terms accounted for after controlling for the other covariates. In order to get our Bayesian version of these, we’ll have to fit two additional models, one after removing each of the interaction terms. model9.11 &lt;- update(model9.10, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex, cores = 4) model9.12 &lt;- update(model9.10, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:age, cores = 4) Here we’ll extract the bayes_R2() iterations for each of the three models, place them all in a single tibble, and then do a little arithmetic to get the difference scores. After all that data wrangling, we’ll summarize() as usual. r2_without_age_interaction &lt;- bayes_R2(model9.11, summary = F) %&gt;% data.frame() r2_without_sex_interaction &lt;- bayes_R2(model9.12, summary = F) %&gt;% data.frame() r2_with_both_interactions &lt;- bayes_R2(model9.10, summary = F) %&gt;% data.frame() r2 &lt;- tibble(r2_without_age_interaction = r2_without_age_interaction$R2, r2_without_sex_interaction = r2_without_sex_interaction$R2, r2_with_both_interactions = r2_with_both_interactions$R2) %&gt;% mutate(`delta R2 due to age interaction` = r2_with_both_interactions - r2_without_age_interaction, `delta R2 due to sex interaction` = r2_with_both_interactions - r2_without_sex_interaction) r2 %&gt;% pivot_longer(`delta R2 due to age interaction`:`delta R2 due to sex interaction`) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 delta R2 due to age interaction 0.007 -0.049 0.064 0.95 mean qi ## 2 delta R2 due to sex interaction 0.011 -0.044 0.068 0.95 mean qi Recall that \\(R^2\\) is in a 0-to-1 metric. It’s a proportion. If you want to convert that to a percentage, as in percent of variance explained, you’d just multiply by 100. To make it explicit, let’s do that. r2 %&gt;% pivot_longer(`delta R2 due to age interaction`:`delta R2 due to sex interaction`) %&gt;% group_by(name) %&gt;% mutate(percent = value * 100) %&gt;% mean_qi(percent) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name percent .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 delta R2 due to age interaction 0.655 -4.91 6.42 0.95 mean qi ## 2 delta R2 due to sex interaction 1.13 -4.38 6.8 0.95 mean qi Hopefully it’s clear how our proportions turned percentages correspond to the numbers on page 325. However, note how our 95% credible intervals do not cohere with the \\(p\\)-values from Hayes’s \\(F\\)-tests. If we want to prep for our version of Figure 9.3, we’ll need to carefully specify the predictor values we’ll pass through the fitted() function. Here we do so and save them in nd. nd &lt;- crossing(negemot = seq(from = .5, to = 6.5, length.out = 30), sex = 0:1) %&gt;% expand(nesting(negemot, sex), age = c(30, 50, 70)) %&gt;% mutate(posemot = mean(glbwarm$posemot), ideology = mean(glbwarm$ideology)) str(nd) ## Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 180 obs. of 5 variables: ## $ negemot : num 0.5 0.5 0.5 0.5 0.5 ... ## $ sex : int 0 0 0 1 1 1 0 0 0 1 ... ## $ age : num 30 50 70 30 50 70 30 50 70 30 ... ## $ posemot : num 3.13 3.13 3.13 3.13 3.13 ... ## $ ideology: num 4.08 4.08 4.08 4.08 4.08 ... With our nd values in hand, we’re ready to make our version of Figure 9.3. fitted(model9.10, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% # these lines will make the strip text match with those with Hayes&#39;s Figure mutate(sex = if_else(sex == 0, str_c(&quot;Females, W = &quot;, sex), str_c(&quot;Males, W = &quot;, sex)), age = str_c(&quot;Age, Z, = &quot;, age)) %&gt;% # finally, we plot! ggplot(aes(x = negemot, group = sex)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = sex), alpha = 1/3, color = &quot;transparent&quot;) + geom_line(aes(y = Estimate, color = sex), size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 3:6) + labs(x = expression(paste(&quot;Negative Emotions about Climate Change, &quot;, italic(X))), y = expression(paste(&quot;Support for Government Action to Mitigate Climate Change, &quot;, italic(Y)))) + theme_xkcd() + theme(legend.position = &quot;top&quot;, legend.title = element_blank()) + facet_grid(age ~ .) Recall that the conditional effect of \\(X\\) for various values of \\(W\\) and \\(Z\\) is \\[\\theta_{X \\rightarrow Y} = b_1 + b_4 W + b_5 Z.\\] In the terms of model9.10 where sex = \\(W\\) and age = \\(Z\\), we can restate that as \\[ \\theta_{\\text{negemot} \\rightarrow \\text{govact}} = b_\\text{negemot} + b_{\\text{negemot} \\times \\text{sex}} \\text{sex} + b_{\\text{negemot} \\times \\text{age}} \\text{age}. \\] This is easiest to show with posterior_samples() and a little algebra. As in the middle of page 329, here we solve for both sexes and age == 50. post &lt;- posterior_samples(model9.10) post %&gt;% # algebra mutate(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 50, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 50) %&gt;% # more algebra mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% # this just orders the output mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.535 0.466 0.605 0.95 mean qi ## 2 women 0.329 0.257 0.401 0.95 mean qi ## 3 men - women 0.206 0.11 0.306 0.95 mean qi Switching our discussion to \\(b_5\\) (i.e., \\(b_{\\text{negemot} \\times \\text{age}}\\)), Hayes showed its value for two groups 10 years apart. Here it is for model9.10. post %&gt;% # algebra transmute(`10 * b_5` = `b_negemot:age` * 10) %&gt;% mean_qi() %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## `10 * b_5` .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.047 0.016 0.077 0.95 mean qi Further down on page 329, Hayes solved for the conditional effect of negemot for women at 50 versus 30. post %&gt;% mutate(women_50 = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 50, women_30 = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 30) %&gt;% mutate(`women_50 - women_30` = women_50 - women_30) %&gt;% pivot_longer(women_50:`women_50 - women_30`) %&gt;% mutate(name = factor(name, levels = c(&quot;women_50&quot;, &quot;women_30&quot;, &quot;women_50 - women_30&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 women_50 0.329 0.257 0.401 0.95 mean qi ## 2 women_30 0.235 0.15 0.323 0.95 mean qi ## 3 women_50 - women_30 0.094 0.032 0.154 0.95 mean qi Here it is for men. post %&gt;% mutate(men_50 = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 50, men_30 = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 30) %&gt;% mutate(`men_50 - men_30` = men_50 - men_30) %&gt;% pivot_longer(men_50:`men_50 - men_30`) %&gt;% mutate(name = factor(name, levels = c(&quot;men_50&quot;, &quot;men_30&quot;, &quot;men_50 - men_30&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men_50 0.535 0.466 0.605 0.95 mean qi ## 2 men_30 0.441 0.342 0.541 0.95 mean qi ## 3 men_50 - men_30 0.094 0.032 0.154 0.95 mean qi If you look closely, you’ll see women_50 - women_30 is the same as men_50 - men_30. 9.4.2 Moderated moderation. To fit the moderated moderation model in brms, just add to two new interaction terms to the formula. model9.13 &lt;- update(model9.10, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex + negemot:age + sex:age + negemot:sex:age, cores = 4) Check the summary. print(model9.13, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ negemot + sex + age + posemot + ideology + negemot:sex + negemot:age + sex:age + negemot:sex:age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.557 0.491 3.595 5.502 1.002 1157 1574 ## negemot 0.273 0.118 0.042 0.501 1.002 1038 1464 ## sex 0.536 0.654 -0.739 1.798 1.003 906 1353 ## age -0.003 0.010 -0.022 0.015 1.002 1079 1674 ## posemot -0.020 0.028 -0.074 0.036 1.000 3677 2622 ## ideology -0.205 0.027 -0.259 -0.151 1.000 3395 2239 ## negemot:sex -0.133 0.168 -0.459 0.203 1.003 887 1267 ## negemot:age 0.001 0.002 -0.004 0.006 1.002 1024 1655 ## sex:age -0.025 0.012 -0.049 -0.001 1.002 869 1274 ## negemot:sex:age 0.007 0.003 0.000 0.013 1.003 852 1233 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.047 0.026 0.998 1.100 1.002 3545 2935 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our print() output matches fairly well with the OLS results on pages 332 and 333. Here’s our new Bayesian \\(R^2\\). bayes_R2(model9.13) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.416 0.02 0.376 0.455 Because we haven’t changed the predictor variables in the model–just added interactions among them–there’s no need to redo our nd values. Rather, all we need to do is pass them through fitted() based on our new model9.13 and plot. Without further ado, here’s our Figure 9.6. fitted(model9.13, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% # these lines will make the strip text match with those with Hayes&#39;s Figure mutate(sex = if_else(sex == 0, str_c(&quot;Females, W = &quot;, sex), str_c(&quot;Males, W = &quot;, sex)), age = str_c(&quot;Age, Z, = &quot;, age)) %&gt;% # behold, Figure 9.6! ggplot(aes(x = negemot, group = sex)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = sex), alpha = 1/3, color = &quot;transparent&quot;) + geom_line(aes(y = Estimate, color = sex), size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 3:6) + labs(x = expression(paste(&quot;Negative Emotions about Climate Change, &quot;, italic(X))), y = expression(paste(&quot;Support for Government Action to Mitigate Climate Change, &quot;, italic(Y)))) + theme_xkcd() + theme(legend.position = &quot;top&quot;, legend.title = element_blank()) + facet_grid(age ~ .) For the pick-a-point values Hayes covered on page 338, recall that when using posterior_sample(), our \\(b_4\\) is b_negemot:sex and our \\(b_7\\) is b_negemot:sex:age. post &lt;- posterior_samples(model9.13) post %&gt;% mutate(`age = 30` = `b_negemot:sex` + `b_negemot:sex:age` * 30, `age = 50` = `b_negemot:sex` + `b_negemot:sex:age` * 50, `age = 70` = `b_negemot:sex` + `b_negemot:sex:age` * 70) %&gt;% pivot_longer(contains(&quot;=&quot;), names_to = &quot;theta_XW_on_Y_given&quot;) %&gt;% group_by(theta_XW_on_Y_given) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## theta_XW_on_Y_given value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 age = 30 0.069 -0.088 0.231 0.95 mean qi ## 2 age = 50 0.204 0.104 0.3 0.95 mean qi ## 3 age = 70 0.338 0.181 0.496 0.95 mean qi Our method for making a JN technique plot with fitted() way back in Chapter 7 isn’t going to work, here. At least not as far as I can see. Rather, we’re going to have to skillfully manipulate our post object. For those new to R, this might be a little confusing at first. So I’m going to make a crude attempt first and then get more sophisticated. Crude attempt: post %&gt;% mutate(`age = 30` = `b_negemot:sex` + `b_negemot:sex:age` * 30, `age = 50` = `b_negemot:sex` + `b_negemot:sex:age` * 50, `age = 70` = `b_negemot:sex` + `b_negemot:sex:age` * 70) %&gt;% pivot_longer(contains(&quot;=&quot;), names_to = &quot;theta_XW_on_Y_given&quot;) %&gt;% mutate(`theta XW on Y given` = str_extract(theta_XW_on_Y_given, &quot;\\\\d+&quot;) %&gt;% as.double()) %&gt;% group_by(`theta XW on Y given`) %&gt;% mean_qi(value) %&gt;% # the plot ggplot(aes(x = `theta XW on Y given`)) + geom_hline(yintercept = 0) + geom_vline(xintercept = 38.114) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 1/2) + geom_line(aes(y = value), size = 1) + coord_cartesian(xlim = 20:85, ylim = c(-.25, .75)) + theme_xkcd() Notice how we just took the code from our pick-a-point analysis and dumped it into a plot. So one obvious approach would be to pick like 30 or 50 age values to plug into transmute() and just do the same thing. If you’re super afraid of coding, that’d be one intuitive but extremely verbose attempt. I have done stuff like that earlier in my R career. There’s no shame in being extremely verbose and redundant if that’s what makes sense. Another way is to think in terms of functions. When we made age = 30 within transmute(), we took a specific age value (i.e., 30) and plugged it into the formula b_negemot:sex + b_negemot:sex:age * i where \\(i\\) = 30. And when we made age = 50 we did exactly the same thing but switched out the 30 for a 50. So what we need is a function that will take a range of values for \\(i\\), plug them into our b_negemot:sex + b_negemot:sex:age * i formula, and then neatly return the output. A nice base R function for that is sapply(). sapply(15:90, function(i) { post$`b_negemot:sex` + post$`b_negemot:sex:age` * i } ) %&gt;% data.frame() %&gt;% str() ## &#39;data.frame&#39;: 4000 obs. of 76 variables: ## $ X1 : num -0.12839 0.00543 0.13117 0.00424 -0.0081 ... ## $ X2 : num -0.12 0.0113 0.1354 0.0075 -0.0028 ... ## $ X3 : num -0.1117 0.0171 0.1397 0.0108 0.0025 ... ## $ X4 : num -0.10331 0.02294 0.14396 0.01403 0.00781 ... ## $ X5 : num -0.0949 0.0288 0.1482 0.0173 0.0131 ... ## $ X6 : num -0.0866 0.0346 0.1525 0.0206 0.0184 ... ## $ X7 : num -0.0782 0.0405 0.1567 0.0238 0.0237 ... ## $ X8 : num -0.0699 0.0463 0.161 0.0271 0.029 ... ## $ X9 : num -0.0615 0.0521 0.1653 0.0303 0.0343 ... ## $ X10: num -0.0531 0.058 0.1695 0.0336 0.0396 ... ## $ X11: num -0.0448 0.0638 0.1738 0.0369 0.0449 ... ## $ X12: num -0.0364 0.0696 0.1781 0.0401 0.0502 ... ## $ X13: num -0.0281 0.0755 0.1823 0.0434 0.0555 ... ## $ X14: num -0.0197 0.0813 0.1866 0.0467 0.0608 ... ## $ X15: num -0.0113 0.0872 0.1909 0.0499 0.0661 ... ## $ X16: num -0.00298 0.09299 0.19512 0.05318 0.07142 ... ## $ X17: num 0.00538 0.09883 0.19938 0.05645 0.07672 ... ## $ X18: num 0.0137 0.1047 0.2036 0.0597 0.082 ... ## $ X19: num 0.0221 0.1105 0.2079 0.063 0.0873 ... ## $ X20: num 0.0305 0.1163 0.2122 0.0662 0.0926 ... ## $ X21: num 0.0388 0.1222 0.2164 0.0695 0.0979 ... ## $ X22: num 0.0472 0.128 0.2207 0.0728 0.1032 ... ## $ X23: num 0.0555 0.1339 0.225 0.076 0.1085 ... ## $ X24: num 0.0639 0.1397 0.2292 0.0793 0.1138 ... ## $ X25: num 0.0723 0.1455 0.2335 0.0825 0.1191 ... ## $ X26: num 0.0806 0.1514 0.2378 0.0858 0.1244 ... ## $ X27: num 0.089 0.1572 0.242 0.0891 0.1297 ... ## $ X28: num 0.0973 0.163 0.2463 0.0923 0.135 ... ## $ X29: num 0.1057 0.1689 0.2505 0.0956 0.1403 ... ## $ X30: num 0.1141 0.1747 0.2548 0.0989 0.1456 ... ## $ X31: num 0.122 0.181 0.259 0.102 0.151 ... ## $ X32: num 0.131 0.186 0.263 0.105 0.156 ... ## $ X33: num 0.139 0.192 0.268 0.109 0.162 ... ## $ X34: num 0.148 0.198 0.272 0.112 0.167 ... ## $ X35: num 0.156 0.204 0.276 0.115 0.172 ... ## $ X36: num 0.164 0.21 0.28 0.118 0.177 ... ## $ X37: num 0.173 0.216 0.285 0.122 0.183 ... ## $ X38: num 0.181 0.221 0.289 0.125 0.188 ... ## $ X39: num 0.189 0.227 0.293 0.128 0.193 ... ## $ X40: num 0.198 0.233 0.297 0.131 0.199 ... ## $ X41: num 0.206 0.239 0.302 0.135 0.204 ... ## $ X42: num 0.214 0.245 0.306 0.138 0.209 ... ## $ X43: num 0.223 0.251 0.31 0.141 0.215 ... ## $ X44: num 0.231 0.256 0.314 0.145 0.22 ... ## $ X45: num 0.239 0.262 0.319 0.148 0.225 ... ## $ X46: num 0.248 0.268 0.323 0.151 0.23 ... ## $ X47: num 0.256 0.274 0.327 0.154 0.236 ... ## $ X48: num 0.265 0.28 0.332 0.158 0.241 ... ## $ X49: num 0.273 0.286 0.336 0.161 0.246 ... ## $ X50: num 0.281 0.291 0.34 0.164 0.252 ... ## $ X51: num 0.29 0.297 0.344 0.167 0.257 ... ## $ X52: num 0.298 0.303 0.349 0.171 0.262 ... ## $ X53: num 0.306 0.309 0.353 0.174 0.268 ... ## $ X54: num 0.315 0.315 0.357 0.177 0.273 ... ## $ X55: num 0.323 0.321 0.361 0.18 0.278 ... ## $ X56: num 0.331 0.327 0.366 0.184 0.283 ... ## $ X57: num 0.34 0.332 0.37 0.187 0.289 ... ## $ X58: num 0.348 0.338 0.374 0.19 0.294 ... ## $ X59: num 0.357 0.344 0.378 0.193 0.299 ... ## $ X60: num 0.365 0.35 0.383 0.197 0.305 ... ## $ X61: num 0.373 0.356 0.387 0.2 0.31 ... ## $ X62: num 0.382 0.362 0.391 0.203 0.315 ... ## $ X63: num 0.39 0.367 0.396 0.207 0.321 ... ## $ X64: num 0.398 0.373 0.4 0.21 0.326 ... ## $ X65: num 0.407 0.379 0.404 0.213 0.331 ... ## $ X66: num 0.415 0.385 0.408 0.216 0.336 ... ## $ X67: num 0.423 0.391 0.413 0.22 0.342 ... ## $ X68: num 0.432 0.397 0.417 0.223 0.347 ... ## $ X69: num 0.44 0.402 0.421 0.226 0.352 ... ## $ X70: num 0.448 0.408 0.425 0.229 0.358 ... ## $ X71: num 0.457 0.414 0.43 0.233 0.363 ... ## $ X72: num 0.465 0.42 0.434 0.236 0.368 ... ## $ X73: num 0.474 0.426 0.438 0.239 0.374 ... ## $ X74: num 0.482 0.432 0.442 0.242 0.379 ... ## $ X75: num 0.49 0.437 0.447 0.246 0.384 ... ## $ X76: num 0.499 0.443 0.451 0.249 0.389 ... Okay, so that looks a little monstrous. What we did in the first argument was tell sapply() which values we’d like to use in some function. We chose each integer ranging from 15 to 90–which, if you do the math, is 76 values. We then told sapply() to plug those values into a custom function, which we defined as function(i) {post$b_negemot:sex + post$b_negemot:sex:age * i}. In our custom function, i was a placeholder for each of those 76 integers. But remember that post has 4,000 rows, each one corresponding to one of the 4,000 posterior iterations. Thus, for each of our 76 i-values, we got 4,000 results. After all that sapply() returned a matrix. Since we like to work within the tidyverse and use ggplot2, we just went ahead and put those results in a tibble. With our sapply() output in hand, all we need to do is a little more indexing and summarizing and we’re ready to plot. The result is our very own version of Figure 9.7. sapply(15:90, function(i) { post$`b_negemot:sex` + post$`b_negemot:sex:age` * i }) %&gt;% data.frame() %&gt;% set_names(15:90) %&gt;% pivot_longer(everything()) %&gt;% mutate(age = as.double(name)) %&gt;% group_by(age) %&gt;% mean_qi(value) %&gt;% ggplot(aes(x = age)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_vline(xintercept = 38.114, color = &quot;grey75&quot;) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 1/2) + geom_line(aes(y = value), size = 1) + coord_cartesian(xlim = 20:85, ylim = c(-.25, .75)) + labs(x = expression(paste(&quot;Age, &quot;, italic(Z))), y = &quot;Conditional Two-way Interaction Between\\nNegative Emotions and Sex&quot;) + theme_xkcd() Or for kicks and giggles, another way to get a clearer sense of how our data informed the shape of the plot, here we replace our geom_ribbon() + geom_line() code with geom_pointrange(). sapply(15:90, function(i) { post$`b_negemot:sex` + post$`b_negemot:sex:age` * i }) %&gt;% data.frame() %&gt;% set_names(15:90) %&gt;% pivot_longer(everything()) %&gt;% mutate(age = as.double(name)) %&gt;% group_by(age) %&gt;% mean_qi(value) %&gt;% ggplot(aes(x = age)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_vline(xintercept = 38.114, color = &quot;grey75&quot;) + geom_pointrange(aes(y = value, ymin = .lower, ymax = .upper), shape = 16, size = 1/3) + coord_cartesian(xlim = 20:85, ylim = c(-.25, .75)) + labs(x = expression(paste(&quot;Age, &quot;, italic(Z))), y = &quot;Conditional Two-way Interaction Between\\nNegative Emotions and Sex&quot;) + theme_xkcd() Although I probably wouldn’t try to use a plot like this in a manuscript, I hope it makes clear how the way we’ve been implementing the JN technique is just the pick-a-point approach in bulk. No magic, here. For all you tidyverse fanatics out there, don’t worry. There are more tidyverse-centric ways to get the plot values than with sapply(). We’ll get to them soon enough. It’s advantageous to have good old base R sapply() up your sleeve, too. And new R users, it’s helpful to know that sapply() is one part of the apply() family of base R functions, which you might learn more about here or here or here. Now the conditional effect of \\(X\\) on \\(Y\\) given \\(W\\) and \\(Z\\) is \\[\\theta_{X \\rightarrow Y} = b_1 + b_4 W + b_5 Z + b_7 WZ.\\] In the terms of model9.13 where sex = \\(W\\) and age = \\(Z\\), we can restate that as \\[ \\theta_{\\text{negemot} \\rightarrow \\text{govact}} = b_\\text{negemot} + b_{\\text{negemot} \\times \\text{sex}} \\text{sex} + b_{\\text{negemot} \\times \\text{age}} \\text{age} + b_{\\text{negemot} \\times \\text{sex} \\times \\text{age}} \\text{sex} \\times \\text{age}. \\] Following Hayes at the bottom of page 341, here is the difference in the effect of negative emotions between men and women among 30 year olds (i.e., \\(\\theta_{XW \\rightarrow Y} | (Z = 30)\\)). post %&gt;% # algebra mutate(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 30 + `b_negemot:sex:age` * 1 * 30, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 30 + `b_negemot:sex:age` * 0 * 30) %&gt;% # more algebra mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% # this just orders the output mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.369 0.245 0.49 0.95 mean qi ## 2 women 0.3 0.192 0.404 0.95 mean qi ## 3 men - women 0.069 -0.088 0.231 0.95 mean qi In contrast, here is \\(\\theta_{XW \\rightarrow Y} | (Z = 50)\\). post %&gt;% mutate(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 50 + `b_negemot:sex:age` * 1 * 50, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 50 + `b_negemot:sex:age` * 0 * 50) %&gt;% mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.521 0.452 0.588 0.95 mean qi ## 2 women 0.318 0.245 0.392 0.95 mean qi ## 3 men - women 0.204 0.104 0.3 0.95 mean qi Finally, here we compute \\(\\theta_{XW \\rightarrow Y} | (Z = 70)\\). post %&gt;% transmute(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 70 + `b_negemot:sex:age` * 1 * 70, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 70 + `b_negemot:sex:age` * 0 * 70) %&gt;% mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.674 0.580 0.77 0.95 mean qi ## 2 women 0.336 0.206 0.468 0.95 mean qi ## 3 men - women 0.338 0.181 0.496 0.95 mean qi 9.5 Comparing conditional effects In this section, [Hayes discussed] a test of the difference between two conditional effects in a moderation model. The method [Hayes described] is called a “slope difference test” by Dawson (Dawson, 2014; Dawson &amp; Richter, 2006), who offers some guidelines on how to conduct this test for the moderated moderation model. (p. 342) As usual, we will follow along, but with alternative methods to the statistical testing paradigm. We will steadfastly continue summarizing and plotting the posterior distribution from various vantage points. 9.5.1 Comparing conditional effects in the additive multiple moderation model. When we’re interested in estimating the difference in the conditional effec of \\(X\\) on \\(Y\\) (i.e., \\(\\theta_{X \\rightarrow Y}\\)) for \\(W = w_1\\) and \\(Z = z_1\\) versus when \\(W = w_2\\) and \\(Z = z_2\\), that follows the formula \\[\\begin{align*} \\Delta \\theta_{X \\rightarrow Y} &amp; = (b_1 + b_4 w_1 + b_5 z_1) - (b_1 + b_4 w_2 + b_5 z_2) \\\\ &amp; = b_4 (w_1 - w_2) + b_5 (z_1 - z_2). \\end{align*}\\] As in other cases, we don’t have to worry about special considerations for computing the standard errors for out Bayesian models. All we need to do is follow the simple algebraic manipulations of the posterior distribution. Because of the correlation structure within the parameters, the uncertainty in the conditional distribution will work itself out. 9.5.2 Comparing conditional effects in the moderated moderation model. We’ll update our formula from last section to \\[\\begin{align*} \\Delta \\theta_{X \\rightarrow Y} &amp; = (b_1 + b_4 w_1 + b_5 z_1 + b_7 w_1 z_1) - (b_1 + b_4 w_2 + b_5 z_2 + b_7 w_2 z_2) \\\\ &amp; = b_4 (w_1 - w_2) + b_5 (z_1 - z_2) + b_7 (w_1 z_1 - w_2 z_2). \\end{align*}\\] 9.5.3 Implementation in PROCESS brms. Since we don’t have the contrast feature automated like in PROCESS, we’ll have to carefully follow the equations above to specify the values properly in R. Here we’ll use the equation in the first line, \\[\\Delta \\theta_{X \\rightarrow Y} = (b_1 + b_4 w_1 + b_5 z_1 + b_7 w_1 z_1) - (b_1 + b_4 w_2 + b_5 z_2 + b_7 w_2 z_2).\\] w1 &lt;- 1 z1 &lt;- 30 w2 &lt;- 0 z2 &lt;- 50 post %&gt;% mutate(`30-year-old men` = b_negemot + `b_negemot:sex` * w1 + `b_negemot:age` * z1 + `b_negemot:sex:age` * w1 * z1, `50-year-old women` = b_negemot + `b_negemot:sex` * w2 + `b_negemot:age` * z2 + `b_negemot:sex:age` * w2 * z2) %&gt;% mutate(contrast = `30-year-old men` - `50-year-old women`) %&gt;% pivot_longer(`30-year-old men`:contrast) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, .025), ul = quantile(value, .975)) %&gt;% mutate_if(is.double, round, digits = 4) ## # A tibble: 3 x 5 ## name mean sd ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 30-year-old men 0.369 0.0622 0.245 0.490 ## 2 50-year-old women 0.318 0.0374 0.245 0.392 ## 3 contrast 0.0507 0.0718 -0.092 0.189 Notice how our posterior \\(SD\\) corresponded nicely to the standard error in Hayes’s contrast test. And we didn’t even have to worry about using the frightening Formula 9.21 on page 345. That information was contained in the posterior distribution all along. All we had to do was combine the parameter iterations with a little algebra and then summarize(). For good measure, we’ll compute using the equation in the second line, \\[\\Delta \\theta_{X \\rightarrow Y} = b_4 (w_1 - w_2) + b_5 (z_1 - z_2) + b_7 (w_1 z_1 - w_2 z_2).\\] post %&gt;% mutate(contrast = `b_negemot:sex` * (w1 - w2) + `b_negemot:age` * (z1 - z2) + `b_negemot:sex:age` * (w1 * z1 - w2 * z2)) %&gt;% pivot_longer(contrast) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, .025), ul = quantile(value, .975)) %&gt;% mutate_if(is.double, round, digits = 4) ## # A tibble: 1 x 5 ## name mean sd ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 contrast 0.0507 0.0718 -0.092 0.189 Same results. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 bayesplot_1.7.0 xkcd_0.0.6 extrafont_0.17 brms_2.10.3 Rcpp_1.0.2 ## [7] forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 ## [13] tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ggridges_0.5.1 rsconnect_0.8.15 ## [4] ggstance_0.3.2 htmlTable_1.13.1 markdown_1.1 ## [7] base64enc_0.1-3 rstudioapi_0.10 rstan_2.19.2 ## [10] svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 splines_3.6.0 ## [16] bridgesampling_0.7-2 knitr_1.23 shinythemes_1.1.2 ## [19] zeallot_0.1.0 Formula_1.2-3 jsonlite_1.6 ## [22] broom_0.5.2 Rttf2pt1_1.3.7 cluster_2.0.8 ## [25] shiny_1.3.2 compiler_3.6.0 httr_1.4.0 ## [28] backports_1.1.5 assertthat_0.2.1 Matrix_1.2-17 ## [31] lazyeval_0.2.2 cli_1.1.0 later_1.0.0 ## [34] acepack_1.4.1 htmltools_0.4.0 prettyunits_1.0.2 ## [37] tools_3.6.0 igraph_1.2.4.1 coda_0.19-3 ## [40] gtable_0.3.0 glue_1.3.1.9000 reshape2_1.4.3 ## [43] cellranger_1.1.0 vctrs_0.2.0 nlme_3.1-139 ## [46] extrafontdb_1.0 crosstalk_1.0.0 xfun_0.10 ## [49] ps_1.3.0 rvest_0.3.4 mime_0.7 ## [52] miniUI_0.1.1.1 lifecycle_0.1.0 gtools_3.8.1 ## [55] zoo_1.8-6 scales_1.0.0 colourpicker_1.0 ## [58] hms_0.4.2 promises_1.1.0 Brobdingnag_1.2-6 ## [61] parallel_3.6.0 inline_0.3.15 RColorBrewer_1.1-2 ## [64] shinystan_2.5.0 gridExtra_2.3 loo_2.1.0 ## [67] StanHeaders_2.19.0 rpart_4.1-15 latticeExtra_0.6-28 ## [70] stringi_1.4.3 dygraphs_1.1.1.6 checkmate_1.9.4 ## [73] pkgbuild_1.0.5 rlang_0.4.1 pkgconfig_2.0.3 ## [76] matrixStats_0.55.0 evaluate_0.14 lattice_0.20-38 ## [79] labeling_0.3 rstantools_2.0.0 htmlwidgets_1.5 ## [82] tidyselect_0.2.5 processx_3.4.1 plyr_1.8.4 ## [85] magrittr_1.5 R6_2.4.0 generics_0.0.2 ## [88] Hmisc_4.3-0 foreign_0.8-71 pillar_1.4.2 ## [91] haven_2.1.0 withr_2.1.2 xts_0.11-2 ## [94] nnet_7.3-12 survival_3.1-8 abind_1.4-5 ## [97] modelr_0.1.4 crayon_1.3.4 arrayhelpers_1.0-20160527 ## [100] utf8_1.1.4 rmarkdown_1.13 grid_3.6.0 ## [103] readxl_1.3.1 data.table_1.12.2 callr_3.3.2 ## [106] threejs_0.3.1 digest_0.6.21 xtable_1.8-4 ## [109] httpuv_1.5.2 stats4_3.6.0 munsell_0.5.0 ## [112] shinyjs_1.0 "],
["multicategorical-focal-antecedents-and-moderators.html", "10 Multicategorical Focal Antecedents and Moderators 10.1 Moderation of the effect of a multicategorical antecedent variable 10.2 An example from the sex disrimination in the workplace study 10.3 Visualizing the model 10.4 Probing the interaction 10.5 When the moderator is multicategorical References Session info", " 10 Multicategorical Focal Antecedents and Moderators In this chapter, [Hayes] extend[ed] the principles of moderation analysis described in Chapters 7 and 8 to testing interaction involving a multicategorical focal antecedent variable or moderator. As you will see, the principles discussed in those chapters generalize quite readily, although the model necessarily requires more than one product to capture an interaction between two variables. This makes the formulas a bit more complex, and the visualizing and probing process a bit more involved. But with comfort with the fundamentals described so far, you should not find it difficult to master this extension of multiple regression analysis. (p. 350) 10.1 Moderation of the effect of a multicategorical antecedent variable Take the case of a continuous or dichotomous moderator \\(W\\) and a multicategorical \\(X\\) “with \\(g\\) groups, include \\(g − 1\\) variables coding membership in the groups, the moderator variable \\(W\\), and \\(g − 1\\) products between the \\(g − 1\\) group codes and moderator \\(W\\) in a regression model” (p. 351) following the form \\[ Y = i_Y + \\sum_{i = 1}^{g - 1} b_i D_i + b_g W + \\sum_{j = g + 1}^{2g - 1} b_j D_{j - g} W + e_Y, \\] where \\(D_i\\) denotes the \\(i\\)th dummy variable. Given the case where \\(g = 4\\), that formula can be re-expressed as \\[\\begin{align*} Y &amp; = i_Y + b_1 D_1 + b_2 D_2 + b_3 D_3 + b_4 W + b_5 D_1 W + b_6 D_2 W + b_7 D_3 W + e_Y, \\;\\;\\;\\text{or} \\\\ &amp; = i_Y + (b_1 + b_5 W) D_1 + (b_2 + b_6 W) D_2 + (b_3 + b_7 W) D_3 + b_4 W + e_Y. \\end{align*}\\] 10.2 An example from the sex disrimination in the workplace study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) ## Observations: 129 ## Variables: 6 ## $ subnum &lt;dbl&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, … ## $ protest &lt;dbl&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1,… ## $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.… ## $ angry &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1,… ## $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.… ## $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.… With a little if_else(), computing the dummies d1 and d2 is easy enough. protest &lt;- protest %&gt;% mutate(d1 = if_else(protest == 1, 1, 0), d2 = if_else(protest == 2, 1, 0)) Load brms. library(brms) With model10.1 and model10.2 we fit the multicategorical multivariable model and the multicategorical moderation models, respectively. model10.1 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + d1 + d2 + sexism, cores = 4) model10.2 &lt;- update(model10.1, newdata = protest, liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism, cores = 4) Behold the \\(R^2\\)s. r2 &lt;- bayes_R2(model10.1, summary = F) %&gt;% data.frame() %&gt;% bind_cols( bayes_R2(model10.2, summary = F) %&gt;% data.frame() ) %&gt;% set_names(str_c(&quot;Model 10.&quot;, 1:2)) %&gt;% mutate(`The R2 difference` = `Model 10.2` - `Model 10.1`) r2 %&gt;% pivot_longer(everything()) %&gt;% # this line isn&#39;t necessary, but it sets the order the summaries appear in mutate(name = factor(name, levels = c(&quot;Model 10.1&quot;, &quot;Model 10.2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Model 10.1 0.07 0.065 0.012 0.156 ## 2 Model 10.2 0.159 0.157 0.067 0.265 ## 3 The R2 difference 0.088 0.09 -0.034 0.21 Interestingly, even though our posterior means and medians for the model-specific \\(R^2\\) values differed some from the OLS estimates in the text, their difference corresponded quite nicely to the one in the text. Let’s take a look at their distributions. r2 %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value)) + geom_density(size = 0, fill = &quot;grey33&quot;) + scale_y_continuous(NULL, breaks = NULL) + facet_wrap(~name, scales = &quot;free_y&quot;) + theme_minimal() The model coefficient summaries cohere well with those in Table 10.1. print(model10.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ 1 + d1 + d2 + sexism ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.768 0.627 3.552 6.004 1.000 5422 2679 ## d1 0.498 0.224 0.072 0.942 1.001 4566 3204 ## d2 0.447 0.220 0.016 0.868 1.001 3801 2993 ## sexism 0.107 0.119 -0.127 0.343 1.000 5456 2883 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.043 0.066 0.925 1.181 1.001 5120 3260 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model10.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ d1 + d2 + sexism + d1:sexism + d2:sexism ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 7.748 1.071 5.689 9.875 1.002 1354 2194 ## d1 -4.195 1.518 -7.194 -1.275 1.002 1360 1729 ## d2 -3.561 1.407 -6.330 -0.892 1.004 1378 1857 ## sexism -0.481 0.209 -0.896 -0.080 1.003 1348 2329 ## d1:sexism 0.915 0.291 0.350 1.501 1.002 1337 1789 ## d2:sexism 0.792 0.277 0.255 1.331 1.004 1276 1874 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.007 0.065 0.888 1.146 1.002 3190 2503 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 10.3 Visualizing the model To get our version of the values in Table 10.2, we’ll first recreate columns for \\(d_1\\) through \\(W\\) (SEXISM) and save then as a tibble, nd. ( nd &lt;- tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1)) %&gt;% expand(nesting(d1, d2), sexism = quantile(protest$sexism, probs = c(.16, .5, .84))) ) ## # A tibble: 9 x 3 ## d1 d2 sexism ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 4.31 ## 2 0 0 5.12 ## 3 0 0 5.87 ## 4 0 1 4.31 ## 5 0 1 5.12 ## 6 0 1 5.87 ## 7 1 0 4.31 ## 8 1 0 5.12 ## 9 1 0 5.87 With nd in hand, we’ll feed the predictor values into fitted() for the typical posterior summaries. fitted(model10.2, newdata = nd) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 5.676 0.227 5.236 6.119 ## [2,] 5.285 0.162 4.974 5.588 ## [3,] 4.925 0.232 4.470 5.376 ## [4,] 5.527 0.202 5.141 5.927 ## [5,] 5.780 0.156 5.470 6.084 ## [6,] 6.013 0.220 5.575 6.445 ## [7,] 5.421 0.247 4.935 5.900 ## [8,] 5.773 0.158 5.463 6.079 ## [9,] 6.098 0.201 5.708 6.504 The values in our Estimate column correspond to those in the \\(\\hat Y\\) column in the table. We, of course, add summaries of uncertainty to the point estimates. If we want to make a decent line plot for our version of Figure 10.3, we’ll need many more values for sexism, which will appear on the x-axis. nd &lt;- tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1)) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) This time we’ll save the results from fitted() as a tlbble and wrangle a bit to get ready for the plot. f &lt;- fitted(model10.2, newdata = nd, probs = c(.025, .25, .75, .975)) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% mutate(condition = if_else(d1 == 1, &quot;Individual Protest&quot;, if_else(d2 == 1, &quot;Collective Protest&quot;, &quot;No Protest&quot;))) %&gt;% # this line is not necessary, but it will help order the facets of the plot mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) glimpse(f) ## Observations: 90 ## Variables: 10 ## $ Estimate &lt;dbl&gt; 6.064727, 6.014962, 5.965197, 5.915432, 5.865667, 5.815901, 5.766136, 5.716371,… ## $ Est.Error &lt;dbl&gt; 0.3660584, 0.3468298, 0.3278937, 0.3093040, 0.2911269, 0.2734448, 0.2563601, 0.… ## $ Q2.5 &lt;dbl&gt; 5.364726, 5.345646, 5.331805, 5.316183, 5.300102, 5.282467, 5.266224, 5.251607,… ## $ Q25 &lt;dbl&gt; 5.812528, 5.776542, 5.739331, 5.704200, 5.668177, 5.630328, 5.590915, 5.552826,… ## $ Q75 &lt;dbl&gt; 6.315876, 6.254369, 6.192635, 6.128761, 6.065838, 6.004212, 5.945169, 5.880642,… ## $ Q97.5 &lt;dbl&gt; 6.784732, 6.699703, 6.614906, 6.528555, 6.442336, 6.356916, 6.271567, 6.186775,… ## $ d1 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ d2 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0… ## $ sexism &lt;dbl&gt; 3.500000, 3.603448, 3.706897, 3.810345, 3.913793, 4.017241, 4.120690, 4.224138,… ## $ condition &lt;fct&gt; No Protest, No Protest, No Protest, No Protest, No Protest, No Protest, No Prot… For Figure 10.3 and many to follow for this chapter, we’ll superimpose 50% intervals on top of 95% intervals. # this will help us add the original data points to the plot protest &lt;- protest %&gt;% mutate(condition = ifelse(protest == 0, &quot;No Protest&quot;, ifelse(protest == 1, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # this will help us with the x-axis breaks &lt;- tibble(values = quantile(protest$sexism, probs = c(.16, .5, .84))) %&gt;% mutate(labels = values %&gt;% round(2) %&gt;% as.character()) # Here we plot f %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/3) + geom_ribbon(aes(ymin = Q25, ymax = Q75), alpha = 1/3) + geom_line(aes(y = Estimate)) + geom_point(data = protest, aes(y = liking), size = 2/3) + scale_x_continuous(breaks = breaks$values, labels = breaks$labels) + coord_cartesian(xlim = 4:6, ylim = c(2.5, 7.2)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + facet_wrap(~condition) + theme_minimal() By adding the data to the plots, they are both more informative and now serve as a posterior predictive check. 10.4 Probing the interaction These will involve both onmibus tests and pairwise comparisons. 10.4.1 The pick-a-point approach. “The pick-a-point approach requires you to choose values of the moderator \\(W\\) and then estimate the conditional effect of \\(X\\) on \\(Y\\) at those values and conduct an inferential test” [evaluate the posterior distribution] (p. 368). 10.4.1.1 Omnibus inference. Hayes used the omnibus testing framework to assess how important coefficients \\(b_1\\) and \\(b_2\\) were to our interaction model, model1. Before fitting the models, he discussed why he preferred to fit models after centering sexism (i.e., \\(W\\)) to 4.25. Here we’ll call our centered variable sexism_p, where _p stands in for “prime”. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 4.25) From here on, model10.3 is the moderation model without the lower-order d1 and d2 terms; model10.4 is the full moderation model. But we’re going to be fitting both these models three different ways, based on how we centersexism. So for this first set where we centered sexism on 4.25, we’ll give them the suffix a. # the model without d1 + d2 model10.3a &lt;- update(model10.2, newdata = protest, liking ~ 1 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4) # the full model with d1 + d2 model10.4a &lt;- update(model10.2, newdata = protest, liking ~ 1 + d1 + d2 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4) The coefficient summaries for model10.4a correspond to the top section of Table 10.3 (p. 373). fixef(model10.4a) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.703 0.231 5.259 6.167 ## d1 -0.306 0.348 -0.979 0.369 ## d2 -0.194 0.307 -0.798 0.380 ## sexism_p -0.472 0.206 -0.879 -0.069 ## d1:sexism_p 0.903 0.294 0.348 1.479 ## d2:sexism_p 0.779 0.275 0.253 1.318 We can compare their Bayesian \\(R^2\\) distributions like we usually do. library(tidybayes) r2 &lt;- bayes_R2(model10.3a, summary = F) %&gt;% data.frame() %&gt;% bind_cols( bayes_R2(model10.4a, summary = F) %&gt;% data.frame() ) %&gt;% set_names(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;) %&gt;% mutate(`The R2 difference` = `Model with d1 + d2` - `Model without d1 + d2`) r2 %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(key) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## key value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Model without d1 + d2 0.139 0.053 0.241 0.95 median qi ## 2 Model with d1 + d2 0.155 0.065 0.251 0.95 median qi ## 3 The R2 difference 0.015 -0.122 0.145 0.95 median qi Our results differ a bit from those in the text (p. 370), but the substantive interpretation is the same. The d1 and d2 parameters added little predictive power to the model in terms of \\(R^2\\). We can also use information criteria to compare the models. Here are the results from using the LOO-CV. model10.3a &lt;- add_criterion(model10.3a, &quot;loo&quot;) model10.4a &lt;- add_criterion(model10.4a, &quot;loo&quot;) loo_compare(model10.3a, model10.4a) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model10.3a 0.0 0.0 -186.0 11.0 6.5 2.0 372.0 22.0 ## model10.4a -1.4 0.8 -187.4 10.9 7.9 2.0 374.8 21.8 The LOO-CV difference between the two models was pretty small and its standard error was of about the same magnitude of its difference. Thus, the LOO-CV gives the same general message as the \\(R^2\\). The d1 and d2 parameters were sufficiently small and uncertain enough that constraining them to zero did little in terms of reducing the explanatory power of the statistical model. Here’s the same thing all over again, but this time after centering sexism on 5.120. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 5.120) Now fit the models. # the model without d1 + d2 model10.3b &lt;- update(model10.2, newdata = protest, liking ~ 1 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4) # the full model with d1 + d2 model10.4b &lt;- update(model10.2, newdata = protest, liking ~ 1 + d1 + d2 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4) These coefficient summaries correspond to the middle section of Table 10.3 (p. 373). fixef(model10.4b) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.288 0.159 4.982 5.603 ## d1 0.485 0.223 0.053 0.935 ## d2 0.491 0.220 0.054 0.911 ## sexism_p -0.481 0.208 -0.890 -0.070 ## d1:sexism_p 0.907 0.290 0.329 1.478 ## d2:sexism_p 0.786 0.283 0.221 1.323 Here are the Bayesian \\(R^2\\) summaries and the summary for their difference. r2 &lt;- bayes_R2(model10.3b, summary = F) %&gt;% data.frame() %&gt;% bind_cols( bayes_R2(model10.4b, summary = F) %&gt;% data.frame() ) %&gt;% set_names(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;) %&gt;% mutate(`The R2 difference` = `Model with d1 + d2` - `Model without d1 + d2`) r2 %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Model without d1 + d2 0.099 0.028 0.196 0.95 median qi ## 2 Model with d1 + d2 0.155 0.066 0.256 0.95 median qi ## 3 The R2 difference 0.057 -0.078 0.181 0.95 median qi This time, our \\(\\Delta R^2\\) distribution was more similar to the results Hayes reported in the text (p. 370, toward the bottom). Here’s the updated LOO-CV. model10.3b &lt;- add_criterion(model10.3b, &quot;loo&quot;) model10.4b &lt;- add_criterion(model10.4b, &quot;loo&quot;) loo_compare(model10.3b, model10.4b) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model10.4b 0.0 0.0 -187.4 10.9 7.9 1.9 374.8 21.7 ## model10.3b -1.2 3.0 -188.6 11.8 6.0 1.9 377.3 23.7 Here again our Bayesian \\(R^2\\) and loo() results cohere, both suggesting the d1 and d2 parameters were of little predictive utility. Note how this differs a little from the second \\(F\\)-test on page 370. Here’s what happens when we center sexism on 5.896. First center. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 5.896) Fit the models. # the model without d1 + d2 model10.3c &lt;- update(model10.2, newdata = protest, liking ~ 1 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4) # the full model with d1 + d2 model10.4c &lt;- update(model10.2, newdata = protest, liking ~ 1 + d1 + d2 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4) These coefficient summaries correspond to the lower section of Table 10.3 (p. 373). fixef(model10.4c) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.290 0.159 4.977 5.602 ## d1 0.483 0.219 0.068 0.915 ## d2 0.490 0.217 0.073 0.917 ## sexism_p -0.471 0.214 -0.893 -0.057 ## d1:sexism_p 0.898 0.295 0.323 1.473 ## d2:sexism_p 0.775 0.278 0.228 1.309 Again, compute the \\(R^2\\) distributions and their difference-score distribution. r2 &lt;- bayes_R2(model10.3c, summary = F) %&gt;% data.frame() %&gt;% bind_cols( bayes_R2(model10.4c, summary = F) %&gt;% data.frame() ) %&gt;% set_names(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;) %&gt;% mutate(`The R2 difference` = `Model with d1 + d2` - `Model without d1 + d2`) r2 %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Model without d1 + d2 0.101 0.027 0.196 0.95 median qi ## 2 Model with d1 + d2 0.154 0.062 0.256 0.95 median qi ## 3 The R2 difference 0.054 -0.079 0.175 0.95 median qi That \\(\\Delta R^2\\) distribution matches up nicely with the one Hayes reported at the bottom of page 370. Now compare the models with the LOO. model10.3c &lt;- add_criterion(model10.3c, &quot;loo&quot;) model10.4c &lt;- add_criterion(model10.4c, &quot;loo&quot;) loo_compare(model10.3c, model10.4c) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model10.4c 0.0 0.0 -187.6 11.0 8.2 2.1 375.1 22.0 ## model10.3c -1.1 2.9 -188.7 11.8 6.0 1.9 377.3 23.7 Although our Bayesian \\(R^2\\) difference is now predominantly positive, the LOO-CV difference for the two models remains uncertain. Here’s a look at the two parameters in question using a handmade coefficient plot. posterior_samples(model10.4c) %&gt;% pivot_longer(b_d1:b_d2) %&gt;% mutate(name = str_remove(name, &quot;b_&quot;)) %&gt;% ggplot(aes(name, y = value)) + stat_summary(fun.y = median, fun.ymin = function(i) {quantile(i, probs = .025)}, fun.ymax = function(i) {quantile(i, probs = .975)}, color = &quot;grey33&quot;) + stat_summary(geom = &quot;linerange&quot;, fun.ymin = function(i) {quantile(i, probs = .25)}, fun.ymax = function(i) {quantile(i, probs = .75)}, color = &quot;grey33&quot;, size = 1.25) + xlab(NULL) + coord_flip(ylim = 0:2) + theme_minimal() For Figure 10.4, we’ll drop our faceting approach and just make one big plot. Heads up: I’m going to drop the 50% intervals from this plot. They’d just make it too busy. f %&gt;% ggplot(aes(x = sexism, alpha = condition)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), size = 0) + geom_line(aes(y = Estimate)) + scale_alpha_manual(values = c(.2, .5, .8)) + scale_x_continuous(breaks = breaks$values, labels = breaks$labels) + coord_cartesian(xlim = 4:6, ylim = c(4.5, 6.7)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + theme_minimal() + theme(legend.title = element_blank(), legend.position = &quot;top&quot;, legend.direction = &quot;vertical&quot;) 10.4.1.2 Pairwise inference. Hayes continues to reference Table 10.3. In the last subsection, we reproduced those results one model at a time. Why not practice doing it altogether? There are a lot of ways you could do this. A good first try is to extend the fixef() approach from before with a little help from bind_rows(). # start with `model4a` fixef(model10.4a) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) %&gt;% bind_rows( # add `model4b` fixef(model10.4b) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;), # add `model4c` fixef(model10.4c) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) ) %&gt;% # wrangle a bit mutate(`w&#39;` = str_c(&quot;w - &quot;, c(4.25, 5.12, 5.896)) %&gt;% rep(., each = 6)) %&gt;% select(`w&#39;`, everything()) %&gt;% mutate_if(is.double, round, digits = 3) ## w&#39; parameter Estimate Est.Error Q2.5 Q97.5 ## 1 w - 4.25 Intercept 5.703 0.231 5.259 6.167 ## 2 w - 4.25 d1 -0.306 0.348 -0.979 0.369 ## 3 w - 4.25 d2 -0.194 0.307 -0.798 0.380 ## 4 w - 4.25 sexism_p -0.472 0.206 -0.879 -0.069 ## 5 w - 4.25 d1:sexism_p 0.903 0.294 0.348 1.479 ## 6 w - 4.25 d2:sexism_p 0.779 0.275 0.253 1.318 ## 7 w - 5.12 Intercept 5.288 0.159 4.982 5.603 ## 8 w - 5.12 d1 0.485 0.223 0.053 0.935 ## 9 w - 5.12 d2 0.491 0.220 0.054 0.911 ## 10 w - 5.12 sexism_p -0.481 0.208 -0.890 -0.070 ## 11 w - 5.12 d1:sexism_p 0.907 0.290 0.329 1.478 ## 12 w - 5.12 d2:sexism_p 0.786 0.283 0.221 1.323 ## 13 w - 5.896 Intercept 5.290 0.159 4.977 5.602 ## 14 w - 5.896 d1 0.483 0.219 0.068 0.915 ## 15 w - 5.896 d2 0.490 0.217 0.073 0.917 ## 16 w - 5.896 sexism_p -0.471 0.214 -0.893 -0.057 ## 17 w - 5.896 d1:sexism_p 0.898 0.295 0.323 1.473 ## 18 w - 5.896 d2:sexism_p 0.775 0.278 0.228 1.309 This code works okay, but it’s redundant. Here’s a streamlined approach where we use a combination of nested tibbles and the purrr::map() function to work with our three model fits–model10.4a, model10.4b, and model10.4c–in bulk. t &lt;- tibble(`w&#39;` = str_c(&quot;w - &quot;, c(4.25, 5.12, 5.896)), name = str_c(&quot;model10.4&quot;, letters[1:3])) %&gt;% mutate(fit = map(name, get)) %&gt;% mutate(s = map(fit, ~fixef(.) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;))) %&gt;% unnest(s) %&gt;% select(`w&#39;`, parameter:Q97.5) t %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 18 x 6 ## `w&#39;` parameter Estimate Est.Error Q2.5 Q97.5 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 w - 4.25 Intercept 5.70 0.231 5.26 6.17 ## 2 w - 4.25 d1 -0.306 0.348 -0.979 0.369 ## 3 w - 4.25 d2 -0.194 0.307 -0.798 0.38 ## 4 w - 4.25 sexism_p -0.472 0.206 -0.879 -0.069 ## 5 w - 4.25 d1:sexism_p 0.903 0.294 0.348 1.48 ## 6 w - 4.25 d2:sexism_p 0.779 0.275 0.253 1.32 ## 7 w - 5.12 Intercept 5.29 0.159 4.98 5.60 ## 8 w - 5.12 d1 0.485 0.223 0.053 0.935 ## 9 w - 5.12 d2 0.491 0.22 0.054 0.911 ## 10 w - 5.12 sexism_p -0.481 0.208 -0.89 -0.07 ## 11 w - 5.12 d1:sexism_p 0.907 0.290 0.329 1.48 ## 12 w - 5.12 d2:sexism_p 0.786 0.283 0.221 1.32 ## 13 w - 5.896 Intercept 5.29 0.159 4.98 5.60 ## 14 w - 5.896 d1 0.483 0.219 0.068 0.915 ## 15 w - 5.896 d2 0.49 0.217 0.073 0.917 ## 16 w - 5.896 sexism_p -0.471 0.214 -0.893 -0.057 ## 17 w - 5.896 d1:sexism_p 0.898 0.295 0.323 1.47 ## 18 w - 5.896 d2:sexism_p 0.775 0.278 0.228 1.31 Summary tables like this are precise and very common in the literature. But you can get lost in all those numbers. A coefficient plot can be better. This first version is pretty close to the Table 10.3 format. t %&gt;% # this will help us order our y-axis mutate(parameter = factor(parameter, levels = c(&quot;d2:sexism_p&quot;, &quot;d1:sexism_p&quot;, &quot;sexism_p&quot;, &quot;d2&quot;, &quot;d1&quot;, &quot;Intercept&quot;)), # this is just for aesthetics `w&#39;` = str_c(&quot;w&#39; = &quot;, `w&#39;`)) %&gt;% # plot! ggplot(aes(x = parameter, y = Estimate, ymin = Q2.5, ymax = Q97.5)) + geom_pointrange() + labs(x = NULL, y = NULL) + coord_flip() + theme_minimal() + theme(axis.text.y = element_text(hjust = 0)) + facet_wrap(~`w&#39;`, nrow = 1) Notice how this arrangement makes it easiest to compare coefficients within models. If we wanted to make it easier to compare coefficients across models, we might arrange the plot like so. t %&gt;% # this will help us order our y-axis mutate(parameter = factor(parameter, levels = c(&quot;Intercept&quot;, &quot;d1&quot;, &quot;d2&quot;, &quot;sexism_p&quot;, &quot;d1:sexism_p&quot;, &quot;d2:sexism_p&quot;))) %&gt;% # plot! ggplot(aes(x = `w&#39;`, y = Estimate, ymin = Q2.5, ymax = Q97.5)) + geom_pointrange() + labs(x = NULL, y = NULL) + coord_flip() + theme_minimal() + theme(axis.text.y = element_text(hjust = 0)) + facet_wrap(~parameter, ncol = 1) Oh man–with sweet plots like these, who needs tables! This makes it much easier to see what happened as we changed values we centered sexism on. In the middle paragraph on page 374, Hayes pointed out “that \\(b_1\\) and \\(b_2\\) differ in these analyses, but \\(b_3\\), \\(b_4\\), and \\(b_5\\) are unaffected by the centering”. Our coefficient plot clarified that in a way I don’t think a table ever could. But before we move on, let’s back up a little in the text. “To make this more concrete, consider the effect of Catherine’s behavior on how she is perceived among people who are relatively high in their perceptions of the pervasiveness of sex discrimination in society” (p. 372). For this, Hayes defined “relatively high” as \\(W = 5.896\\). To get those estimates for each condition, we’ll use fitted(). Since the number of unique predictor values is small for this example, we’ll just plug them directly into the newdata argument rather than first saving them as a nd object. fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 5.896)) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 4.912 0.236 4.450 5.373 ## [2,] 6.110 0.205 5.712 6.523 ## [3,] 6.021 0.224 5.574 6.457 Those posterior summaries match up nicely with the point estimates Hayes presented at the bottom of page 372. Hayes further expounded So by using the regression centering strategy described earlier in the context of an omnibus test of equality of values of \\(\\hat Y\\), the regression coefficients \\(b_1\\) and \\(b_2\\) provide pairwise inferences consistent with the coding system used to represent the three groups, conditioned on the value that \\(W\\) is centered around. In the next few sentences, he focused on what happened when \\(W = 4.250\\) (i.e., in model4a). Recall that the two coefficients in question, \\(b_1\\) and \\(b_2\\), are named d1 and d2 when we pull their summaries with fixef(). fixef(model10.4a)[c(&quot;d1&quot;, &quot;d2&quot;), ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## d1 -0.306 0.348 -0.979 0.369 ## d2 -0.194 0.307 -0.798 0.380 Hayes then clarified that in this model \\[\\begin{align*} b_1 &amp; = \\theta_{D_1 \\rightarrow Y} | (W = 4.250) = 5.400 - 5.698 = -0.299 \\;\\;\\; \\text{ and} \\\\ b_2 &amp; = \\theta_{D_2 \\rightarrow Y} | (W = 4.250) = 5.513 - 5.698 = -0.185. \\end{align*}\\] That is, it is the same as a difference score of each of the experimental conditions minus the “No protest” condition. To further show the difference-score quality of these coefficients, we can continue using fitted() in conjunction with the original model10.2 to get the group comparisons for when \\(W = 4.250\\). Since these involve computing difference scores, we’ll have to use summary = F and do some wrangling. fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 4.25), summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 5 x 4 ## name value .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No Protest 5.70 5.25 6.16 ## 2 Individual Protest 5.40 4.89 5.90 ## 3 Collective Protest 5.51 5.11 5.92 ## 4 difference_a -0.308 -0.988 0.361 ## 5 difference_b -0.195 -0.806 0.419 Within simulation variance, difference_a is the same as \\(b_{1 | \\text{model10.4a}}\\) and difference_b is the same as \\(b_{2 | \\text{model10.4a}}\\). Here’s the same thing for when \\(W = 5.120\\). fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 5.120), summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 5 x 4 ## name value .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No Protest 5.28 4.97 5.59 ## 2 Individual Protest 5.77 5.46 6.08 ## 3 Collective Protest 5.78 5.47 6.08 ## 4 difference_a 0.488 0.052 0.947 ## 5 difference_b 0.494 0.056 0.94 Finally, here it is for when \\(W = 5.986\\). fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 5.986), summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 5 x 4 ## name value .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No Protest 4.87 4.38 5.35 ## 2 Individual Protest 6.15 5.73 6.59 ## 3 Collective Protest 6.05 5.58 6.51 ## 4 difference_a 1.28 0.654 1.96 ## 5 difference_b 1.18 0.478 1.86 10.4.2 The Johnson-Neyman technique. As discussed in section 7.4, a problem with the pick-a-point approach to probing an interaction is having to choose values of the moderator. When the moderator is a continuum, you may not have any basis for choosing some values rather than others, and the choice you make will certainly influence the results of the probing exercise to some extent… Actively choosing a different system or con- vention, such as using the sample mean of \\(W\\), a standard deviation below the mean, and a standard deviation above the mean also does not eliminate the problem. But the Johnson–Neyman (JN) technique avoids this problem entirely. (p. 376) 10.4.2.1 Omnibus inference. Consider the first sentence of the section: Applied to probing an interaction between a multicategorical \\(X\\) and a continuous \\(W\\), an omnibus version of the JM technique involves finding the value or values of \\(W\\) where their \\(F\\)-ratio comparing the \\(g\\) estimated values of \\(Y\\) is just statistically significant. (p. 376) Since we’re not using \\(F\\)-tests with our approach to Bayesian modeling, the closest we might have is a series of \\(R^2\\) difference tests, which would require refitting the model multiple times over many ways of centering the \\(W\\)-variable, sexism. I suppose you could do this if you wanted, but it just seems silly, to me. I’ll leave this one up to the interested reader. 10.4.2.2 Pairwise inference. Hayes didn’t make plots for this section, but if you’re careful constructing your nd and with the subsequent wrangling, you can make the usual plots. Since we have two conditions we’d like to compare with No Protest, we’ll make two plots. Here’s the comparison using Individual Protest, first. nd &lt;- tibble(d1 = 0:1, d2 = 0) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) # the transition value Hayes identified in the text Hayes_value &lt;- 5.065 # we need some new data nd &lt;- tibble(d1 = 0:1, d2 = 0) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) # plug those data into `fitted()` fitted(model10.2, newdata = nd, summary = F) %&gt;% # wrangle data.frame() %&gt;% gather(key, estimate) %&gt;% bind_cols( nd %&gt;% expand(nesting(d1, d2, sexism), iter = 1:4000) ) %&gt;% mutate(condition = if_else(d1 == 0, &quot;No Protest&quot;, &quot;Individual Protest&quot;)) %&gt;% select(-c(key, d1:d2)) %&gt;% spread(key = condition, value = estimate) %&gt;% mutate(difference = `Individual Protest` - `No Protest`) %&gt;% # plot! ggplot(aes(x = sexism, y = difference)) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i) {quantile(i, probs = .025)}, fun.ymax = function(i) {quantile(i, probs = .975)}, alpha = 1/3) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i) {quantile(i, probs = .25)}, fun.ymax = function(i) {quantile(i, probs = .75)}, alpha = 1/3) + stat_summary(geom = &quot;line&quot;, fun.y = median) + scale_x_continuous(breaks = c(4, Hayes_value, 6), labels = c(&quot;4&quot;, Hayes_value, &quot;6&quot;)) + coord_cartesian(xlim = 4:6) + labs(subtitle = expression(paste(&quot;Our JN-technique plot for &quot;, italic(&quot;Individual Protest&quot;), &quot; compared with &quot;, italic(&quot;No Protest&quot;)))) + theme_minimal() Now we’re ready to compare No Protest to Collective Protest. The main data difference is which values we assigned to the d1 and d2 columns in nd. For kicks, we should practice another way to get the median line and interval ribbons. The stat_summary() approach from above works great, but it’s verbose. The tidybayes::stat_lineribbon() function will give us the same results with fewer lines of code. # the transition value Hayes identified in the text Hayes_value &lt;- 5.036 # new data nd &lt;- tibble(d1 = 0, d2 = 0:1) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) # this part is the same as before fitted(model10.2, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% gather(key, estimate) %&gt;% bind_cols( nd %&gt;% expand(nesting(d1, d2, sexism), iter = 1:4000) ) %&gt;% # there are some mild differences, here mutate(condition = if_else(d2 == 0, &quot;No Protest&quot;, &quot;Collective Protest&quot;)) %&gt;% select(-c(key, d1:d2)) %&gt;% pivot_wider(names_from = condition, values_from = estimate) %&gt;% mutate(difference = `Collective Protest` - `No Protest`) %&gt;% # plot! ggplot(aes(x = sexism, y = difference)) + # look how compact this is! stat_lineribbon(.width = c(0.5, 0.95), alpha = 1/3, fill = &quot;black&quot;) + scale_x_continuous(breaks = c(4, Hayes_value, 6), labels = c(&quot;4&quot;, Hayes_value, &quot;6&quot;)) + coord_cartesian(xlim = 4:6) + labs(subtitle = expression(paste(&quot;Our JN-technique plot for &quot;, italic(&quot;Collective Protest&quot;), &quot; compared with &quot;, italic(&quot;No Protest&quot;)))) + theme_minimal() And here we do it one last time between the two active protest conditions. For good measure, we will continue experimenting with different ways of plotting the results. This time well first summarize the posterior median and intervals with tidybayes::median_qi() before plotting. We’ll then feed those results into our plot with the aid of tidybayes::geom_lineribbon() and a follow-up scale_fill_manual() line. nd &lt;- tibble(d1 = 1:0, d2 = 0:1) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) fitted(model10.2, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(d1, d2, sexism), iter = 1:4000) ) %&gt;% mutate(condition = if_else(d1 == 0, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;)) %&gt;% select(-c(key, d1:d2)) %&gt;% pivot_wider(names_from = condition, values_from = value) %&gt;% mutate(difference = `Collective Protest` - `Individual Protest`) %&gt;% # group and summarise, here group_by(sexism) %&gt;% median_qi(difference, .width = c(.5, .95)) %&gt;% # plot! ggplot(aes(x = sexism, y = difference)) + # look how simple these two lines are geom_lineribbon(show.legend = F) + scale_fill_manual(values = c(&quot;grey75&quot;, &quot;grey50&quot;)) + coord_cartesian(xlim = 4:6) + labs(subtitle = expression(paste(&quot;Our JN-technique plot for &quot;, italic(&quot;Collective Protest&quot;), &quot; compared with &quot;, italic(&quot;Individual Protest&quot;)))) + theme_minimal() Little difference between those conditions. 10.5 When the moderator is multicategorical From a substantive standpoint the combination of a multicategorical variable \\(X\\) and a dichotomous or continuous moderator \\(W\\) versus a dichotomous or continuous variable \\(X\\) and a multicategorical moderator \\(W\\) might seem different. From a modeling perspective, the difference is trivial. As Hayes pointed out, “when we claim from a statistical test of moderation that \\(X\\)’s effect is moderated by \\(W\\), then it is also true that \\(W\\)’s effect is moderated by \\(X\\). This is the symmetry property of interactions” (p. 381). This symmetry holds when we’re not using the hypothesis-testing framework, too. 10.5.1 An example. Just as a refresher, here’s the print() output for model2. print(model10.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ d1 + d2 + sexism + d1:sexism + d2:sexism ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 7.748 1.071 5.689 9.875 1.002 1354 2194 ## d1 -4.195 1.518 -7.194 -1.275 1.002 1360 1729 ## d2 -3.561 1.407 -6.330 -0.892 1.004 1378 1857 ## sexism -0.481 0.209 -0.896 -0.080 1.003 1348 2329 ## d1:sexism 0.915 0.291 0.350 1.501 1.002 1337 1789 ## d2:sexism 0.792 0.277 0.255 1.331 1.004 1276 1874 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.007 0.065 0.888 1.146 1.002 3190 2503 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The Bayesian \\(R^2\\): bayes_R2(model10.2) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.159 0.051 0.067 0.265 And the \\(R^2\\) difference between this and the model excluding the interaction terms: bayes_R2(model10.1, summary = F) %&gt;% data.frame() %&gt;% bind_cols( bayes_R2(model10.2, summary = F) %&gt;% data.frame() ) %&gt;% set_names(str_c(&quot;Model 10.&quot;, 1:2)) %&gt;% transmute(difference = `Model 10.2` - `Model 10.1`) %&gt;% mean_qi(difference) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## difference .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.088 -0.034 0.21 0.95 mean qi Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3. # this will help us with the `geom_text()` annotation slopes &lt;- tibble(slope = c(fixef(model10.2)[&quot;sexism&quot;, &quot;Estimate&quot;] + fixef(model10.2)[&quot;d1:sexism&quot;, &quot;Estimate&quot;], fixef(model10.2)[&quot;sexism&quot;, &quot;Estimate&quot;] + fixef(model10.2)[&quot;d2:sexism&quot;, &quot;Estimate&quot;], fixef(model10.2)[&quot;sexism&quot;, &quot;Estimate&quot;]), x = c(4.8, 4.6, 5), y = c(6.37, 6.25, 4.5), condition = c(&quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;No Protest&quot;)) %&gt;% mutate(label = str_c(&quot;This slope is about &quot;, slope %&gt;% round(digits = 3)), condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # Here we plot f %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/3) + geom_ribbon(aes(ymin = Q25, ymax = Q75), alpha = 1/3) + geom_line(aes(y = Estimate)) + geom_text(data = slopes, aes(x = x, y = y, label = label)) + coord_cartesian(xlim = 4:6) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(X), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + facet_wrap(~condition) + theme_minimal() 10.5.2 Probing the interaction and interpreting the regression coefficients. We computed the posterior means for the slopes when prepping for the figure, above. Here’s how we might get more complete posterior summaries. Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3. post &lt;- posterior_samples(model10.2) %&gt;% transmute(`No Protest` = b_sexism + `b_d1:sexism` * 0 + `b_d2:sexism` * 0, `Individual Protest` = b_sexism + `b_d1:sexism` * 1 + `b_d2:sexism` * 0, `Collective Protest` = b_sexism + `b_d1:sexism` * 0 + `b_d2:sexism` * 1) post %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 No Protest -0.481 -0.896 -0.08 0.95 mean qi ## 2 Individual Protest 0.434 0.041 0.841 0.95 mean qi ## 3 Collective Protest 0.311 -0.048 0.672 0.95 mean qi Here are the differences among the three protest groups. post %&gt;% transmute(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Individual Protest - Collective Protest` = `Individual Protest` - `Collective Protest`) %&gt;% pivot_longer(everything()) %&gt;% # again, not necessary, but useful for reordering the summaries mutate(name = factor(name, levels = c(&quot;Individual Protest - No Protest&quot;, &quot;Collective Protest - No Protest&quot;, &quot;Individual Protest - Collective Protest&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Individual Protest - No Protest 0.915 0.35 1.50 0.95 mean qi ## 2 Collective Protest - No Protest 0.792 0.255 1.33 0.95 mean qi ## 3 Individual Protest - Collective Protest 0.123 -0.423 0.679 0.95 mean qi References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ggridges_0.5.1 ## [4] rsconnect_0.8.15 ggstance_0.3.2 markdown_1.1 ## [7] base64enc_0.1-3 rstudioapi_0.10 rstan_2.19.2 ## [10] svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 bridgesampling_0.7-2 ## [16] knitr_1.23 shinythemes_1.1.2 zeallot_0.1.0 ## [19] bayesplot_1.7.0 jsonlite_1.6 broom_0.5.2 ## [22] shiny_1.3.2 compiler_3.6.0 httr_1.4.0 ## [25] backports_1.1.5 assertthat_0.2.1 Matrix_1.2-17 ## [28] lazyeval_0.2.2 cli_1.1.0 later_1.0.0 ## [31] htmltools_0.4.0 prettyunits_1.0.2 tools_3.6.0 ## [34] igraph_1.2.4.1 coda_0.19-3 gtable_0.3.0 ## [37] glue_1.3.1.9000 reshape2_1.4.3 cellranger_1.1.0 ## [40] vctrs_0.2.0 nlme_3.1-139 crosstalk_1.0.0 ## [43] xfun_0.10 ps_1.3.0 rvest_0.3.4 ## [46] mime_0.7 miniUI_0.1.1.1 lifecycle_0.1.0 ## [49] gtools_3.8.1 zoo_1.8-6 scales_1.0.0 ## [52] colourpicker_1.0 hms_0.4.2 promises_1.1.0 ## [55] Brobdingnag_1.2-6 parallel_3.6.0 inline_0.3.15 ## [58] shinystan_2.5.0 gridExtra_2.3 loo_2.1.0 ## [61] StanHeaders_2.19.0 stringi_1.4.3 dygraphs_1.1.1.6 ## [64] pkgbuild_1.0.5 rlang_0.4.1 pkgconfig_2.0.3 ## [67] matrixStats_0.55.0 evaluate_0.14 lattice_0.20-38 ## [70] rstantools_2.0.0 htmlwidgets_1.5 labeling_0.3 ## [73] tidyselect_0.2.5 processx_3.4.1 plyr_1.8.4 ## [76] magrittr_1.5 R6_2.4.0 generics_0.0.2 ## [79] pillar_1.4.2 haven_2.1.0 withr_2.1.2 ## [82] xts_0.11-2 abind_1.4-5 modelr_0.1.4 ## [85] crayon_1.3.4 arrayhelpers_1.0-20160527 utf8_1.1.4 ## [88] rmarkdown_1.13 grid_3.6.0 readxl_1.3.1 ## [91] callr_3.3.2 threejs_0.3.1 digest_0.6.21 ## [94] xtable_1.8-4 httpuv_1.5.2 stats4_3.6.0 ## [97] munsell_0.5.0 viridisLite_0.3.0 shinyjs_1.0 "],
["fundamentals-of-conditional-process-analysis.html", "11 Fundamentals of Conditional Process Analysis 11.1 Examples of conditional process models in the literature 11.2 Conditional direct and indirect effects 11.3 Example: Hiding your feelings from your work team 11.4 Estimation of a conditional process model using PROCESS 11.5 Quantifying and visualizing (conditional) indirect and direct effects. 11.6 Statistical inference References Session info", " 11 Fundamentals of Conditional Process Analysis Thus far in this book, mediation and moderation have been treated as distinct, separate, and independent concepts with different analytical procedures and interpretations. Yet processes modeled with mediation analysis likely are contingent and hence moderated, in that they operate differently for different people or in different contexts or circumstances. A more complete analysis, therefore, should attempt to model the mechanisms at work linking \\(X\\) to \\(Y\\) while simultaneously allowing those effects to be contingent on context, circumstance, or individual differences. (p. 395) 11.1 Examples of conditional process models in the literature You can look up the various examples in the literature on your own. The main point is moderation can be combined with mediation in a number of different ways. But these examples [we skipped for the sake of brevity] only scratch the surface of what is possible. Think about the number of possibilities when you increase the number of mediators, distinguish between moderation of paths in a parallel versus serial multiple mediator model, or allow for multiple moderators of different paths or the same path, and so forth. The possibilities are nearly endless. But regardless of the configuration of moderated paths or complexity of the model, conditional process analysis involves the estimation and interpretation of direct and indirect effects, just as in a simple mediation analysis. However, when causal effects in a mediation model are moderated, they will be conditional on those moderators. Thus, an understanding of the concepts of the conditional direct effect and the conditional indirect effect is required before one should attempt to under- take a conditional process analysis. (p. 401, emphasis in the original) 11.2 Conditional direct and indirect effects When a direct or indirect effect is conditional, analysis and interpretation of the results of the modeling process should be based on a formal estimate of and inference about conditional direct and/or conditional in- direct effects. In this section, [Hayes illustrated] the computation of conditional direct and indirect effects for example models that combine moderation and mediation. (p. 403) 11.3 Example: Hiding your feelings from your work team Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) teams &lt;- read_csv(&quot;data/teams/teams.csv&quot;) glimpse(teams) ## Observations: 60 ## Variables: 4 ## $ dysfunc &lt;dbl&gt; -0.23, -0.13, 0.00, -0.33, 0.39, 1.02, -0.35, -0.23, 0.39, -0.08, -0.23, 0.09, -0.29, -0.06… ## $ negtone &lt;dbl&gt; -0.51, 0.22, -0.08, -0.11, -0.48, 0.72, -0.18, -0.13, 0.52, -0.26, 1.08, 0.53, -0.19, 0.15,… ## $ negexp &lt;dbl&gt; -0.49, -0.49, 0.84, 0.84, 0.17, -0.82, -0.66, -0.16, -0.16, -0.16, -0.16, 0.50, 0.84, 0.50,… ## $ perform &lt;dbl&gt; 0.12, 0.52, -0.08, -0.08, 0.12, 1.12, -0.28, 0.32, -1.08, -0.28, -1.08, -0.28, -0.28, -0.88… Load the brms package. library(brms) Recall that we fit mediation models with brms using multivariate syntax. In previous attempts, we’ve defined and saved the model components outside of the brm() function and then plugged then into brm() using their identifier. Just to shake things up a bit, we’ll just do all the steps right in brm(), this time. model11.1 &lt;- brm(data = teams, family = gaussian, bf(negtone ~ 1 + dysfunc) + bf(perform ~ 1 + dysfunc + negtone + negexp + negtone:negexp) + set_rescor(FALSE), chains = 4, cores = 4) print(model11.1, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negtone ~ 1 + dysfunc ## perform ~ 1 + dysfunc + negtone + negexp + negtone:negexp ## Data: teams (Number of observations: 60) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negtone_Intercept 0.025 0.063 -0.104 0.150 1.002 6391 2962 ## perform_Intercept -0.012 0.060 -0.129 0.104 1.001 6329 2866 ## negtone_dysfunc 0.622 0.172 0.274 0.963 1.002 6698 2815 ## perform_dysfunc 0.367 0.182 0.008 0.721 1.000 4817 3385 ## perform_negtone -0.438 0.135 -0.701 -0.166 1.002 4929 3156 ## perform_negexp -0.019 0.120 -0.254 0.212 1.001 5368 3143 ## perform_negtone:negexp -0.516 0.245 -1.004 -0.029 1.000 4989 3347 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negtone 0.487 0.047 0.406 0.590 1.000 6107 2860 ## sigma_perform 0.460 0.045 0.380 0.562 1.000 5601 3187 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our model summary coheres nicely with Table 11.1 and the formulas on page 409. Here are the \\(R^2\\) distribution summaries. bayes_R2(model11.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2negtone 0.194 0.079 0.041 0.349 ## R2perform 0.321 0.078 0.152 0.459 On page 410 Hayes reported two sample means. Compute them like so. mean(teams$negexp) %&gt;% round(digits = 3) # w_bar ## [1] -0.008 mean(teams$perform) %&gt;% round(digits = 3) # m_bar ## [1] -0.032 For our Figure 11.4 and other similar figures in this chapter, we’ll use spaghetti plots. Recall that with a spaghetti plots for linear models, we only need two values for the variable on the x-axis, rather than the typical 30+. nd &lt;- crossing(negtone = c(-.8, .8), negexp = quantile(teams$negexp, probs = c(.16, .50, .84))) %&gt;% mutate(dysfunc = mean(teams$dysfunc)) Here’s our Figure 11.4, which uses only the first 40 HMC iterations for the spaghetti-plot lines. # `fitted()` fitted(model11.1, newdata = nd, resp = &quot;perform&quot;, summary = F) %&gt;% # wrangle as_tibble() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(negtone, negexp), iter = 1:4000) ) %&gt;% mutate(negexp = factor(str_c(&quot;expresivity = &quot;, negexp), levels = c(&quot;expresivity = -0.49&quot;, &quot;expresivity = -0.06&quot;, &quot;expresivity = 0.6&quot;))) %&gt;% filter(iter &lt; 41) %&gt;% # plot ggplot(aes(x = negtone, y = value, group = iter)) + geom_line(color = &quot;skyblue3&quot;, size = 1/4) + coord_cartesian(xlim = c(-.5, .5), ylim = c(-.6, .6)) + labs(x = expression(paste(&quot;Negative Tone of the Work Climate (&quot;, italic(M), &quot;)&quot;)), y = &quot;Team Performance&quot;) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;)) + facet_wrap(~negexp) Also, the plot theme in this chapter is a nod to the style John Kruschke frequently uses in his papers and texts. Using Hayes’s notation from the top of page 412, we can express \\(M\\)’s conditional effect on \\(Y\\) as \\[\\theta_{M \\rightarrow Y} = b_1 + b_3 W,\\] where \\(M\\) is negtone, \\(Y\\) is perform, and \\(W\\) is negexp. We can extract our posterior summaries for \\(b_1\\) and \\(b_3\\) like so. fixef(model11.1)[c(&quot;perform_negtone&quot;, &quot;perform_negtone:negexp&quot;), ] ## Estimate Est.Error Q2.5 Q97.5 ## perform_negtone -0.4378715 0.1351663 -0.701215 -0.16589701 ## perform_negtone:negexp -0.5157503 0.2453382 -1.004435 -0.02860408 11.4 Estimation of a conditional process model using PROCESS We just fit the model in the last section. No need to repeat. 11.5 Quantifying and visualizing (conditional) indirect and direct effects. The analysis presented thus far has been piecemeal, in that [Hayes] addressed how to estimate the regression coefficients for each equation in this conditional process model and how to interpret them using standard principles of regression analysis, moderation analysis, and so forth. But a complete analysis goes further by integrating the estimates of each of the effects in the model (i.e., \\(X \\rightarrow M, \\theta_{M \\rightarrow Y}\\)) to yield the direct and indirect effects of \\(X\\) on \\(Y\\). That is, the individual effects as quantified with the regression coefficients (conditional or otherwise) in equations 11.10 and 11.11 are not necessarily of immediate interest or relevance. Estimating them is a means to an end. What matters is the estimation of the direct and indirect effects, for they convey information about how \\(X\\) influences \\(Y\\) directly or through a mediator and how those effects are contingent on a moderator. (pp. 417–418) 11.5.0.1 The conditional indirect effect of \\(X\\). One way to make a version of Table 11.2 is to work with the posterior_samples(), simply summarizing the distributions with means. post &lt;- posterior_samples(model11.1) post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(conditional_effect = b1 + b3 * w, conditional_indirect_effect = a * (b1 + b3 * w)) %&gt;% select(-(b1:b3)) %&gt;% pivot_longer(-w) %&gt;% group_by(w, name) %&gt;% summarise(mean = mean(value) %&gt;% round(digits = 3)) %&gt;% pivot_wider(names_from = name, values_from = mean) ## # A tibble: 3 x 4 ## # Groups: w [3] ## w a conditional_effect conditional_indirect_effect ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.531 0.622 -0.164 -0.103 ## 2 -0.006 0.622 -0.435 -0.271 ## 3 0.6 0.622 -0.747 -0.465 That kind of summary isn’t the most Bayesian of us. post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(conditional_effect = b1 + b3 * w, conditional_indirect_effect = a * (b1 + b3 * w)) %&gt;% select(-(b1:b3)) %&gt;% pivot_longer(-w) %&gt;% mutate(label = str_c(&quot;W = &quot;, w), w = fct_reorder(label, w)) %&gt;% ggplot(aes(x = value)) + geom_vline(xintercept = 0, color = &quot;grey50&quot;, linetype = 2) + geom_histogram(color = &quot;white&quot;, fill = &quot;skyblue3&quot;) + scale_y_continuous(NULL, breaks = NULL) + xlab(&quot;posterior&quot;) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;)) + facet_grid(w~name) Here the posterior distribution for each is on full display. 11.5.0.2 The direct effect. The direct effect of \\(X\\) on \\(Y\\) (i.e., dysfunc on perform) for this model is b_perform_dysfunc in brms. Here’s how to get its summary values from posterior_summary(). posterior_summary(model11.1)[&quot;b_perform_dysfunc&quot;, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.367 0.182 0.008 0.721 11.5.1 Visualizing the direct and indirect effects. For Figure 11.7 we’ll use the first 400 HMC iterations. post &lt;- post %&gt;% mutate(`-0.7` = b_negtone_dysfunc * (b_perform_negtone + `b_perform_negtone:negexp` * -0.7), `0.7` = b_negtone_dysfunc * (b_perform_negtone + `b_perform_negtone:negexp` * 0.7)) post %&gt;% select(b_perform_dysfunc, `-0.7`:`0.7`) %&gt;% pivot_longer(-b_perform_dysfunc) %&gt;% mutate(negexp = name %&gt;% as.double(), iter = rep(1:4000, times = 2)) %&gt;% filter(iter &lt; 401) %&gt;% ggplot(aes(x = negexp, group = iter)) + geom_hline(aes(yintercept = b_perform_dysfunc), color = &quot;skyblue3&quot;, size = .3, alpha = .3) + geom_line(aes(y = value), color = &quot;skyblue3&quot;, size = .3, alpha = .3) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(paste(&quot;Nonverbal Negative Expressivity (&quot;, italic(W), &quot;)&quot;)), y = &quot;Effect of Dysfunctional Behavior on Team Performance&quot;) + theme_bw() + theme(panel.grid = element_blank()) Since the b_perform_dysfunc values are constant across \\(W\\), the individual HMC iterations end up perfectly parallel in the spaghetti plot. This is an example of a visualization I’d avoid making with a spaghetti plot for a professional presentation. But hopefully it has some pedagogical value, here. 11.6 Statistical inference 11.6.1 Inference about the direct effect. We’ve already been expressing undertainty in terms of percentile-based 95% intervals and histograms. Here’s a plot of the direct effect, b_perform_dysfunc. library(tidybayes) post %&gt;% ggplot(aes(x = b_perform_dysfunc)) + geom_histogram(binwidth = .025, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointintervalh(aes(y = 0), point_interval = mode_hdi, .width = .95) + scale_x_continuous(breaks = mode_hdi(post$b_perform_dysfunc, .width = .95)[1, 1:3], labels = mode_hdi(post$b_perform_dysfunc, .width = .95)[1, 1:3] %&gt;% round(3)) + scale_y_continuous(NULL, breaks = NULL) + xlab(&quot;The direct effect (i.e., b_perform_dysfunc)&quot;) + theme_bw() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line.x = element_line(size = 1/4)) Since we’re plotting in a style similar to Kruschke, we switched from emphasizing the posterior mean or median to marking off the posterior mode, which is Kruschkes’ preferred measure of central tendency. We also ditched our typical percentile-based 95% intervals for highest posterior density intervals. The stat_pointintervalh() function from the Matthew Kay’s tidybayes package made it easy to compute those values with the point_interval = mode_hdi argument. Note how we also used tidybayes::mode_hdi() to compute those values and plug them into scale_x_continuous(). 11.6.2 Inference about the indirect effect. Much like above, we can make a plot of the conditional indirect effect \\(ab_3\\). post &lt;- post %&gt;% mutate(ab_3 = b_negtone_dysfunc * `b_perform_negtone:negexp`) post %&gt;% ggplot(aes(x = ab_3)) + geom_histogram(binwidth = .025, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointintervalh(aes(y = 0), point_interval = mode_hdi, .width = .95) + scale_x_continuous(expression(paste(&quot;The indirect effect, &quot;, italic(ab)[3])), breaks = mode_hdi(post$ab_3, .width = .95)[1, 1:3], labels = mode_hdi(post$ab_3, .width = .95)[1, 1:3] %&gt;% round(3)) + scale_y_continuous(NULL, breaks = NULL) + theme_bw() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line.x = element_line(size = 1/4)) 11.6.3 Probing moderation of mediation. One of the contributions of Preacher et al. (2007) to the literature on moderated mediation analysis was their discussion of inference for conditional indirect effects. They suggested two approaches, one a normal theory-based approach that is an analogue of the Sobel test in unmoderated mediation analysis, and another based on bootstrapping. (p. 426) One of the contributions of this project is moving away from NHST in favor of Bayesian modeling. Since we’ve already been referencing him with our plot themes, you might check out Kruschke’s textbook for more discussion on Bayes versus NHST. 11.6.3.1 Normal theory approach. As we’re square within the Bayesian modeling paradigm, we have no need to appeal to normal theory for the posterior \\(SD\\)s or 95% intervals. 11.6.3.2 Bootstrap confidence intervals Two types of Bayesian credible intervals. We produced the posterior means corresponding to those in Table 11.3 some time ago. Here they are, again, with percentile-based 95% intervals via tidybayes::mean_qi(). post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(`a(b1 + b3w)` = a * (b1 + b3 * w)) %&gt;% group_by(w) %&gt;% mean_qi(`a(b1 + b3w)`) %&gt;% select(w:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 4 ## w `a(b1 + b3w)` .lower .upper ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.531 -0.103 -0.409 0.161 ## 2 -0.006 -0.271 -0.526 -0.077 ## 3 0.6 -0.465 -0.823 -0.172 If we wanted to summarize those same effects with posterior modes and 95% highest posterior density intervals, instead, we’d replace our mean_qi() lnie with mode_hdi(). post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(`a(b1 + b3w)` = a * (b1 + b3 * w)) %&gt;% group_by(w) %&gt;% mode_hdi(`a(b1 + b3w)`) %&gt;% select(w:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 4 ## w `a(b1 + b3w)` .lower .upper ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.531 -0.072 -0.374 0.195 ## 2 -0.006 -0.261 -0.497 -0.06 ## 3 0.6 -0.479 -0.793 -0.152 And we might plot these with something like this. post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(`a(b1 + b3w)` = a * (b1 + b3 * w)) %&gt;% select(w:`a(b1 + b3w)`) %&gt;% mutate(label = str_c(&quot;W = &quot;, w), w = fct_reorder(label, w)) %&gt;% ggplot(aes(x = `a(b1 + b3w)`)) + geom_vline(xintercept = 0, color = &quot;grey50&quot;, linetype = 2) + geom_histogram(binwidth = .05, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointintervalh(aes(y = 0), point_interval = mode_hdi, .width = .95) + scale_x_continuous(&quot;The conditional indirect effect&quot;, limits = c(-1.25, .75)) + scale_y_continuous(NULL, breaks = NULL) + coord_flip() + theme_bw() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line.y = element_line(size = 1/4), strip.text = element_text(hjust = 0), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;)) + facet_wrap(~w, nrow = 1) This, of course, leads us right into the next section. 11.6.3.3 A Johnson-Neyman approach. On page 429, Hayes discussed how Preacher et al. (2007)’s attempt to apply the JN technique in this context presumed the sampling distribution of the conditional indirect effect is normal. Given that the sampling distribution of the conditional indirect effect is not normal, the approach they describe yields, at best, an approximate solution. To [Hayes’s] knowledge, no one has ever proposed a bootstrapping-based analogue of the Johnson-Neyman method for probing the moderation of an indirect effect. However, our Bayesian HMC approach makes no such assumption. All we need to do is manipulate the posterior as usual. Here it is, this time using all 4000 iterations. post %&gt;% transmute(iter = 1:n(), `-0.8` = b_perform_negtone + `b_perform_negtone:negexp` * -0.8, `0.8` = b_perform_negtone + `b_perform_negtone:negexp` * 0.8) %&gt;% pivot_longer(-iter) %&gt;% mutate(key = name %&gt;% as.double()) %&gt;% ggplot(aes(x = key, y = value, group = iter)) + geom_line(color = &quot;skyblue3&quot;, size = 1/6, alpha = 1/15) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(italic(W)), y = &quot;The conditional indirect effect&quot;) + theme_bw() + theme(panel.grid = element_blank()) Glorious. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ggridges_0.5.1 rsconnect_0.8.15 ## [5] ggstance_0.3.2 markdown_1.1 base64enc_0.1-3 rstudioapi_0.10 ## [9] rstan_2.19.2 svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 bridgesampling_0.7-2 knitr_1.23 ## [17] shinythemes_1.1.2 zeallot_0.1.0 bayesplot_1.7.0 jsonlite_1.6 ## [21] broom_0.5.2 shiny_1.3.2 compiler_3.6.0 httr_1.4.0 ## [25] backports_1.1.5 assertthat_0.2.1 Matrix_1.2-17 lazyeval_0.2.2 ## [29] cli_1.1.0 later_1.0.0 htmltools_0.4.0 prettyunits_1.0.2 ## [33] tools_3.6.0 igraph_1.2.4.1 coda_0.19-3 gtable_0.3.0 ## [37] glue_1.3.1.9000 reshape2_1.4.3 cellranger_1.1.0 vctrs_0.2.0 ## [41] nlme_3.1-139 crosstalk_1.0.0 xfun_0.10 ps_1.3.0 ## [45] rvest_0.3.4 mime_0.7 miniUI_0.1.1.1 lifecycle_0.1.0 ## [49] gtools_3.8.1 zoo_1.8-6 scales_1.0.0 colourpicker_1.0 ## [53] hms_0.4.2 promises_1.1.0 Brobdingnag_1.2-6 parallel_3.6.0 ## [57] inline_0.3.15 shinystan_2.5.0 gridExtra_2.3 loo_2.1.0 ## [61] StanHeaders_2.19.0 stringi_1.4.3 dygraphs_1.1.1.6 pkgbuild_1.0.5 ## [65] rlang_0.4.1 pkgconfig_2.0.3 matrixStats_0.55.0 HDInterval_0.2.0 ## [69] evaluate_0.14 lattice_0.20-38 rstantools_2.0.0 htmlwidgets_1.5 ## [73] labeling_0.3 tidyselect_0.2.5 processx_3.4.1 plyr_1.8.4 ## [77] magrittr_1.5 R6_2.4.0 generics_0.0.2 pillar_1.4.2 ## [81] haven_2.1.0 withr_2.1.2 xts_0.11-2 abind_1.4-5 ## [85] modelr_0.1.4 crayon_1.3.4 arrayhelpers_1.0-20160527 utf8_1.1.4 ## [89] rmarkdown_1.13 grid_3.6.0 readxl_1.3.1 callr_3.3.2 ## [93] threejs_0.3.1 digest_0.6.21 xtable_1.8-4 httpuv_1.5.2 ## [97] stats4_3.6.0 munsell_0.5.0 shinyjs_1.0 "],
["further-examples-of-conditional-process-analysis.html", "12 Further Examples of Conditional Process Analysis 12.1 Revisiting the disaster framing study 12.2 Moderation of the direct and indirect effects in a conditional process model 12.3 Statistical inference 12.4 Mediated moderation References Session info", " 12 Further Examples of Conditional Process Analysis In this chapter [Hayes built] on the foundation laid by stepping through an analysis of a more complicated conditional process model that include[d] moderation of both the indirect effects in a simple mediation model. [He did] so by first using a piecemeal approach that focuse[d] on each pathway in the model. With some understanding gained by this examination of the components in the process, [he brought] the pieces together into an integrated conditional process analysis… When an indirect effect of \\(X\\) on \\(Y\\) through \\(M\\) is moderated, we call this phenomenon moderated mediation. In such a scenario, the mechanism represented by the \\(X \\rightarrow M \\rightarrow Y\\) chain of events operates to varying degrees (or not at all) for certain people or in certain contexts. A similar-sounding phenomenon is mediated moderation, which refers to the scenario in which an interaction between X and some moderator \\(W\\) on \\(Y\\) is carried through a mediator \\(M\\). [We’ll see] in this chapter that a mediated moderation analysis is really nothing other than a mediation analysis with the product of two variables serving as the causal agent of focus. (p. 432) 12.1 Revisiting the disaster framing study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) ## Observations: 211 ## Variables: 5 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, … ## $ frame &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0… ## $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5.4, 3.4, 7… ## $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.65, 3.15, 2… ## $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1.0, 6.4, 3… Load brms. library(brms) At the top of page 433, Hayes fit a simple univariable model \\[Y = b_0 + b_1 X + e_Y,\\] where the \\(X\\) is frame the \\(Y\\) is donate. Here’s the model. model12.1 &lt;- brm(data = disaster, family = gaussian, donate ~ 1 + frame, chains = 4, cores = 4) Check the summary. print(model12.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: donate ~ 1 + frame ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.563 0.128 4.312 4.817 1.001 3632 2727 ## frame 0.084 0.181 -0.262 0.433 1.001 3158 3003 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.328 0.066 1.208 1.465 1.002 3384 2761 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Hayes interpteted the coefficient for frame through the lens of a \\(t\\) statistic and accompanying \\(p\\)-value. We’ll just plot the posterior. For the figures in this chapter, we’ll take theme cues from the vignettes from Matthew Kay’s tidybayes package. library(tidybayes) theme_set(theme_tidybayes() + cowplot::panel_border()) posterior_samples(model12.1) %&gt;% ggplot(aes(x = b_frame, y = 0)) + geom_halfeyeh() + geom_vline(xintercept = 0, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) Now we fit the moderation model \\[Y = b_0 + b_1 X + + b_2 W + b_3 XW + e_Y,\\] where skeptic is the \\(W\\) variable. model12.2 &lt;- brm(data = disaster, family = gaussian, donate ~ 1 + frame + skeptic + frame:skeptic, chains = 4, cores = 4) Our model12.2 summary matches nicely with the text. print(model12.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: donate ~ 1 + frame + skeptic + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.028 0.227 4.585 5.477 1.003 2191 2424 ## frame 0.681 0.331 0.019 1.328 1.004 1823 2369 ## skeptic -0.138 0.058 -0.251 -0.026 1.002 2231 2822 ## frame:skeptic -0.171 0.084 -0.334 -0.010 1.004 1766 2023 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.243 0.061 1.130 1.369 1.001 3268 2555 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Here’s our Figure 12.2. nd &lt;- tibble(frame = rep(0:1, each = 30), skeptic = rep(seq(from = 0, to = 7, length.out = 30), times = 2)) fitted(model12.2, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(frame = ifelse(frame == 0, str_c(&quot;Natural causes (X = &quot;, frame, &quot;)&quot;), str_c(&quot;Climate change (X = &quot;, frame, &quot;)&quot;))) %&gt;% mutate(frame = factor(frame, levels = c(&quot;Natural causes (X = 0)&quot;, &quot;Climate change (X = 1)&quot;))) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(color = frame)) + scale_fill_brewer(palette = &quot;Set2&quot;) + scale_color_brewer(palette = &quot;Set2&quot;) + coord_cartesian(xlim = 1:6, ylim = c(3.5, 5.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Willingness to Donate to Victims&quot;) + theme(legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot;, legend.title = element_blank()) In Hayes’s Figure 12.2, he emphasized the differences at the three levels of skeptic. If you want the full difference score distributions in a pick-a-point-approach sort of way, you might plot the densities with tidybayes::geom_halfeyeh(), which places coefficient plots at the base of the densities. In this case, we show the posterior medians with the dots, the 50% intervals with the thick horizontal lines, and the 95% intervals with the thinner horizontal lines. nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .86))) fitted(model12.2, summary = F, newdata = nd) %&gt;% as_tibble() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(frame, skeptic), iter = 1:4000) ) %&gt;% select(-key) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`) %&gt;% ggplot(aes(x = difference, y = skeptic, fill = skeptic %&gt;% as.character())) + geom_halfeyeh(point_interval = median_qi, .width = c(0.95, 0.5)) + scale_fill_brewer() + scale_y_continuous(breaks = quantile(disaster$skeptic, probs = c(.16, .5, .86)), labels = quantile(disaster$skeptic, probs = c(.16, .5, .86)) %&gt;% round(2)) + theme(legend.position = &quot;none&quot;) Here’s our simple mediation model, model12.3, using the multivariate syntax right in the brm() function. model12.3 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame) + bf(donate ~ 1 + frame + justify) + set_rescor(FALSE), chains = 4, cores = 4) print(model12.3, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame ## donate ~ 1 + frame + justify ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.802 0.088 2.631 2.980 1.001 6148 2617 ## donate_Intercept 7.233 0.233 6.780 7.693 1.001 6654 3125 ## justify_frame 0.133 0.128 -0.122 0.385 1.000 5654 2656 ## donate_frame 0.214 0.134 -0.049 0.472 1.000 6514 3247 ## donate_justify -0.953 0.074 -1.100 -0.806 1.000 6443 2862 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.934 0.047 0.849 1.030 1.002 6558 2948 ## sigma_donate 0.986 0.048 0.897 1.086 1.000 6022 3470 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Consider the Bayesian \\(R^2\\) summaries. bayes_R2(model12.3) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2justify 0.010 0.011 0.000 0.041 ## R2donate 0.449 0.038 0.366 0.518 If you want the indirect effect with its intervals, you use posterior_samples() and data wrangle, as usual. posterior_samples(model12.3) %&gt;% mutate(ab = b_justify_frame * b_donate_justify) %&gt;% mean_qi(ab) ## # A tibble: 1 x 6 ## ab .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.126 -0.363 0.117 0.95 mean qi 12.2 Moderation of the direct and indirect effects in a conditional process model Our conditional process model follows the form \\[\\begin{align*} M &amp; = i_M + a_1 X + a_2 W + a_3 XW + e_M \\\\ Y &amp; = i_Y + c_1&#39; X + c_2&#39; W + c_3&#39; XW + b M + e_Y. \\end{align*}\\] We don’t need to do anything particularly special to fit a model like this with brms. It just requires we do a careful job specifying the formulas in our bf() arguments. If you find this syntax a little too cumbersome, you can always specify the formulas outside of brm(), save them as one or multiple objects, and plug those objects into brm(). model12.4 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame + skeptic + frame:skeptic) + bf(donate ~ 1 + frame + justify + skeptic + frame:skeptic) + set_rescor(FALSE), chains = 4, cores = 4) The model summary: print(model12.4, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame + skeptic + frame:skeptic ## donate ~ 1 + frame + justify + skeptic + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.453 0.149 2.159 2.743 1.000 3284 3055 ## donate_Intercept 7.290 0.277 6.760 7.847 1.002 3854 3312 ## justify_frame -0.561 0.215 -0.997 -0.136 1.000 2945 2751 ## justify_skeptic 0.105 0.038 0.030 0.181 1.000 3207 2944 ## justify_frame:skeptic 0.200 0.055 0.092 0.307 1.000 2755 2553 ## donate_frame 0.165 0.271 -0.380 0.707 1.000 3349 2550 ## donate_justify -0.922 0.086 -1.089 -0.755 1.004 4814 2861 ## donate_skeptic -0.042 0.047 -0.132 0.052 1.001 3608 3336 ## donate_frame:skeptic 0.014 0.071 -0.123 0.147 1.000 3134 2858 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.818 0.041 0.742 0.902 1.002 5502 2832 ## sigma_donate 0.988 0.047 0.900 1.087 1.001 5336 3242 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Here are the Bayesian \\(R^2\\) summaries. bayes_R2(model12.4) ## Estimate Est.Error Q2.5 Q97.5 ## R2justify 0.2478896 0.04512928 0.1567011 0.3321230 ## R2donate 0.4523112 0.03782308 0.3716471 0.5206738 12.2.1 Estimation using PROCESS. We just fit that model. Next! 12.2.2 Quantifying direct and indirect effects. Here are summaries for \\(a_1\\) through \\(a_3\\). fixef(model12.4)[c(3:5), ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## justify_frame -0.561 0.215 -0.997 -0.136 ## justify_skeptic 0.105 0.038 0.030 0.181 ## justify_frame:skeptic 0.200 0.055 0.092 0.307 This is \\(b\\). fixef(model12.4)[&quot;donate_justify&quot;, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## -0.922 0.086 -1.089 -0.755 We’ll need to employ posterior_samples() to compute \\((a_1 + a_3 W)b\\), as shown in Table 12.2. post &lt;- posterior_samples(model12.4) %&gt;% mutate(`indirect effect when W is 1.592` = (b_justify_frame + `b_justify_frame:skeptic` * 1.592) * b_donate_justify, `indirect effect when W is 2.800` = (b_justify_frame + `b_justify_frame:skeptic` * 2.800) * b_donate_justify, `indirect effect when W is 5.200` = (b_justify_frame + `b_justify_frame:skeptic` * 5.200) * b_donate_justify) post %&gt;% pivot_longer(starts_with(&quot;indirect&quot;)) %&gt;% group_by(name) %&gt;% median_qi(value, .prob = .95) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 indirect effect when W is 1.592 0.224 -0.05 0.51 0.95 median qi ## 2 indirect effect when W is 2.800 0.003 -0.215 0.223 0.95 median qi ## 3 indirect effect when W is 5.200 -0.434 -0.735 -0.158 0.95 median qi And if you really want that full-on Table 12.2 layout, try this. post %&gt;% mutate(a1 = b_justify_frame, a3 = `b_justify_frame:skeptic`, b = b_donate_justify, c1 = b_donate_frame, c3 = `b_donate_frame:skeptic`) %&gt;% expand(nesting(a1, a3, b, c1, c3), w = c(1.592, 2.800, 5.200)) %&gt;% mutate(`a1 + a3w` = a1 + a3 * w, `(a1 + a3w)b` = (a1 + a3 * w) * b, `direct effect` = c1 + c3 * w) %&gt;% select(-(a1:a3), -(c1:c3)) %&gt;% pivot_longer(-w) %&gt;% group_by(w, name) %&gt;% summarise(mean = mean(value) %&gt;% round(digits = 3)) %&gt;% pivot_wider(names_from = name, values_from = mean) %&gt;% select(w, `a1 + a3w`, b, everything()) ## # A tibble: 3 x 5 ## # Groups: w [3] ## w `a1 + a3w` b `(a1 + a3w)b` `direct effect` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.59 -0.243 -0.922 0.225 0.187 ## 2 2.8 -0.002 -0.922 0.002 0.204 ## 3 5.2 0.477 -0.922 -0.44 0.239 12.2.2.1 The conditional direct effect of \\(X\\). We already computed this in the last code block, above. But since we just focused on the posterior means, here’s a summary of their medians and 95% intervals. post &lt;- post %&gt;% mutate(`direct effect when W is 1.592` = b_donate_frame + `b_donate_frame:skeptic` * 1.592, `direct effect when W is 2.800` = b_donate_frame + `b_donate_frame:skeptic` * 2.800, `direct effect when W is 5.200` = b_donate_frame + `b_donate_frame:skeptic` * 5.200) post %&gt;% pivot_longer(starts_with(&quot;direct&quot;)) %&gt;% group_by(name) %&gt;% median_qi(value, .width = .95) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) ## # A tibble: 3 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 direct effect when W is 1.592 0.181 -0.176 0.547 ## 2 direct effect when W is 2.800 0.204 -0.077 0.48 ## 3 direct effect when W is 5.200 0.239 -0.141 0.617 We can always plot, too. w &lt;- c(1.592, 2.800, 5.200) post %&gt;% expand(nesting(b_donate_frame, `b_donate_frame:skeptic`), w = w) %&gt;% mutate(`conditional direct effect` = b_donate_frame + `b_donate_frame:skeptic` * w) %&gt;% ggplot(aes(x = `conditional direct effect`, y = w, fill = w %&gt;% as.character())) + geom_halfeyeh(point_interval = median_qi, .width = c(0.95, 0.5)) + scale_y_continuous(breaks = w) + scale_fill_brewer() + theme(legend.position = &quot;none&quot;) 12.2.3 Visualizing the direct and indirect effects. We’ll need to do some post wrangling before we’re ready to make our Figure 12.7. We’ll save the results as effects. effects &lt;- post %&gt;% expand(nesting(b_justify_frame, `b_justify_frame:skeptic`, b_donate_justify, b_donate_frame, `b_donate_frame:skeptic`), w = seq(from = 0, to = 6, length.out = 30)) %&gt;% mutate(`direct effect` = b_donate_frame + `b_donate_frame:skeptic` * w, `indirect effect` = (b_justify_frame + `b_justify_frame:skeptic` * w) * b_donate_justify) %&gt;% pivot_longer(c(`direct effect`, `indirect effect`)) %&gt;% mutate(name = factor(name, levels = c(&quot;direct effect&quot;, &quot;indirect effect&quot;))) %&gt;% select(w:value) head(effects) ## # A tibble: 6 x 3 ## w name value ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 0 direct effect -0.442 ## 2 0 indirect effect 1.32 ## 3 0.207 direct effect -0.410 ## 4 0.207 indirect effect 1.25 ## 5 0.414 direct effect -0.377 ## 6 0.414 indirect effect 1.18 Now we plot. # we&#39;ll need this for `geom_text()` text &lt;- tibble(x = c(4.2, 4.7), y = c(.28, -.28), angle = c(3.6, 335), name = factor(c(&quot;direct effect&quot;, &quot;indirect effect&quot;), levels = c(&quot;direct effect&quot;, &quot;indirect effect&quot;))) # plot! effects %&gt;% ggplot(aes(x = w, color = name, fill = name)) + stat_lineribbon(aes(y = value), .width = .95, alpha = 1/3) + geom_text(data = text, aes(x = x, y = y, angle = angle, label = name), size = 5) + scale_fill_brewer(type = &quot;qual&quot;) + scale_color_brewer(type = &quot;qual&quot;) + coord_cartesian(xlim = c(1, 5.5), ylim = c(-.6, .4)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Effects of Disaster Frame on Willingness to Donate&quot;) + theme(legend.position = &quot;none&quot;) Note how wide those 95% intervals are relative to the scale of the y-axis, which I specifically kept within the same range as Figure 12.7 in the text. To me the message is clear: include credible-interval ribbons in your regression slope plots. They help depict how uncertain the posterior is in a way a simple line slopes just don’t. 12.3 Statistical inference 12.3.1 Inference about the direct effect. We’ve already computed the 95% intervals for the direct effect, \\(\\theta_{X \\rightarrow Y}\\), conditional on the three levels of \\(W\\). Here’s a different look at those intervals, superimposed on the 80% and 50% intervals, using the tidybayes::stat_interval() function. post %&gt;% pivot_longer(starts_with(&quot;direct&quot;)) %&gt;% mutate(name = str_remove(name, &quot;direct effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = name, y = value, group = name)) + stat_interval(.width = c(.95, .80, .5)) + scale_color_brewer(&quot;Interval&quot;) + coord_cartesian(xlim = c(1, 5.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Conditional Direct Effect of Disaster Frame on\\nWillingness to Donate&quot;) 12.3.2 Inference about the indirect effect. 12.3.2.1 A statistical test of moderated mediation. To get a sense of \\(a_3 b\\), we just: post &lt;- post %&gt;% mutate(a3b = `b_justify_frame:skeptic` * b_donate_justify) post %&gt;% select(a3b) %&gt;% median_qi(a3b) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## a3b .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.184 -0.293 -0.083 0.95 median qi Here we’ll combine stat_intervalh() and stat_pointintervalh() to visualize \\(a_3 b\\) with a coefficient plot. post %&gt;% ggplot(aes(x = a3b, y = 1)) + stat_intervalh(.width = c(.95, .8, .5)) + stat_pointintervalh(point_interval = median_qi, .width = c(.95, .8, .5), position = position_nudge(y = -.75)) + scale_color_brewer(&quot;Interval&quot;) + scale_y_discrete(NULL, breaks = NULL) + coord_cartesian(xlim = c(-.5, 0)) + labs(title = expression(paste(&quot;Coefficient plot for &quot;, italic(a)[3], italic(b), &quot; (i.e., the index of moderated mediation)&quot;)), x = NULL) + theme(legend.position = &quot;none&quot;) 12.3.2.2 Probing moderation of mediation. As we discussed in Chapter 11, our Bayesian version of the JN technique should be fine because HMC does not impose the normality assumption on the parameter posteriors. In this instance, I’ll leave the JN technique plot as an exercise for the interested reader. Here we’ll just follow along with the text and pick a few points. We computed and inspected these 95% intervals, above. Here’s another way we might geom_halfeyeh() to look at their entire densities. post %&gt;% pivot_longer(starts_with(&quot;indirect&quot;)) %&gt;% rename(`conditional indirect effect` = value) %&gt;% mutate(W = str_remove(name, &quot;indirect effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = `conditional indirect effect`, y = W, fill = W %&gt;% as.character())) + geom_vline(xintercept = 0, linetype = 2) + geom_halfeyeh(point_interval = median_qi, .width = 0.95) + scale_fill_brewer() + scale_y_continuous(breaks = c(1.592, 2.8, 5.2), labels = c(1.6, 2.8, 5.2)) + coord_flip() + # coord_cartesian(xlim = -1:1) + theme(legend.position = &quot;none&quot;, panel.grid.minor.y = element_blank()) 12.3.3 Pruning the model. Fitting the model without the interaction term is just a small change to one of our formula arguments. model12.5 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame + skeptic + frame:skeptic) + bf(donate ~ 1 + frame + justify + skeptic) + set_rescor(FALSE), chains = 4, cores = 4) Here are the results. print(model12.5, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame + skeptic + frame:skeptic ## donate ~ 1 + frame + justify + skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.458 0.150 2.173 2.756 1.000 3631 3491 ## donate_Intercept 7.264 0.230 6.812 7.714 1.000 5233 2990 ## justify_frame -0.568 0.221 -0.996 -0.135 1.000 3310 3230 ## justify_skeptic 0.104 0.038 0.028 0.177 1.000 3501 3304 ## justify_frame:skeptic 0.202 0.055 0.092 0.311 1.001 3085 3041 ## donate_frame 0.208 0.136 -0.060 0.467 1.000 5063 2999 ## donate_justify -0.918 0.080 -1.075 -0.764 1.000 4733 3281 ## donate_skeptic -0.037 0.037 -0.110 0.036 1.002 4771 3219 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.816 0.040 0.743 0.897 1.001 5608 3152 ## sigma_donate 0.988 0.049 0.897 1.089 1.001 4733 2958 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Since we’re altering the model, we may as well use information criteria to compare the two versions. model12.4 &lt;- add_criterion(model12.4, &quot;loo&quot;) model12.5 &lt;- add_criterion(model12.5, &quot;loo&quot;) loo_compare(model12.4, model12.5) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model12.5 0.0 0.0 -557.5 16.5 10.8 1.3 1115.0 33.1 ## model12.4 -1.3 0.3 -558.8 16.6 12.0 1.5 1117.6 33.2 The difference in LOO-CV values for the two models was modest. There’s little predictive reason to choose one over the other. You could argue in favor of model12.5 because it’s simpler than model12.4. Since we’ve got a complex model either way, one might also consider which one was of primary theoretical interest. 12.4 Mediated moderation Mediation is moderated if the indirect effect of \\(X\\) on \\(Y\\) through one or more mediators is contingent on a moderator. With evidence of moderated mediation, one can claim that the \\(X \\rightarrow M \\rightarrow Y\\) chain of events functions differently or to varying degrees for different people, in different contexts or conditions, or whatever the moderator variable represents. Although similar in name and pronunciation to moderated mediation, the term mediated moderation refers to the phenomenon in which an interaction between \\(X\\) and a moderator \\(W\\) in a model of \\(Y\\) is carried through a mediator. (p. 459, emphasis in the original) Hayes later opined: Although there is an abundance of published examples of mediated moderation analysis, their frequency of occurrence in the literature should not be confused with meaningfulness of the procedure itself. I will argue toward the end of this section that rarely is the phenomenon of mediated moderation interesting when interpreted as such. It is almost always substantively more meaningful to conceptualize a mediated moderation process in terms of moderated mediation. But before doing this, I will describe how a mediated moderation analysis is undertaken. (p. 460) 12.4.1 Mediated moderation as the indirect effect of a product. Hayes explains this in the next subsection, but we’ve already fit this model presented in this subsection. We called it model12.4. Here’s the summary. print(model12.4, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame + skeptic + frame:skeptic ## donate ~ 1 + frame + justify + skeptic + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.453 0.149 2.159 2.743 1.000 3284 3055 ## donate_Intercept 7.290 0.277 6.760 7.847 1.002 3854 3312 ## justify_frame -0.561 0.215 -0.997 -0.136 1.000 2945 2751 ## justify_skeptic 0.105 0.038 0.030 0.181 1.000 3207 2944 ## justify_frame:skeptic 0.200 0.055 0.092 0.307 1.000 2755 2553 ## donate_frame 0.165 0.271 -0.380 0.707 1.000 3349 2550 ## donate_justify -0.922 0.086 -1.089 -0.755 1.004 4814 2861 ## donate_skeptic -0.042 0.047 -0.132 0.052 1.001 3608 3336 ## donate_frame:skeptic 0.014 0.071 -0.123 0.147 1.000 3134 2858 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.818 0.041 0.742 0.902 1.002 5502 2832 ## sigma_donate 0.988 0.047 0.900 1.087 1.001 5336 3242 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 12.4.2 Why mediated moderation is neither interesting nor meaningful. Mediated moderation and moderated mediation are statistically the same. The only difference between them is how they are interpreted, and on what part of the model your attention is focused. Moderated mediation focuses on the conditional nature of an indirect effect–how an indirect effect is moderated. If you think of the terms “mediation” and “indirect effect” as essentially synonymous conceptually, then moderated mediation means a moderated indirect effect. Interpretive focus in a moderated mediation analysis is directed at estimating the indirect effect and how that effect varies as a function of a moderator. Mediated moderation, by contrast, asks about the mechanism through which an interaction between \\(X\\) and a moderator \\(W\\) operates, where the product of \\(X\\) and \\(W\\) is construed as the causal agent sending its effect to \\(Y\\) through \\(M\\). Focus in mediated moderation is the estimation of the indirect effect of the product of \\(X\\) and \\(W\\).(p. 465) Hayes later concluded that we should avoid the articulation of hypotheses or research questions in terms of the mediation of the effect of a product, abandoning the term mediated moderation entirely, and instead [reframe] such hypotheses and research questions in terms of the contingencies of an indirect effect–moderated mediation. (p. 467, emphasis in the original) References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ggridges_0.5.1 rsconnect_0.8.15 ## [5] ggstance_0.3.2 markdown_1.1 base64enc_0.1-3 rstudioapi_0.10 ## [9] rstan_2.19.2 svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 bridgesampling_0.7-2 knitr_1.23 ## [17] shinythemes_1.1.2 zeallot_0.1.0 bayesplot_1.7.0 jsonlite_1.6 ## [21] broom_0.5.2 shiny_1.3.2 compiler_3.6.0 httr_1.4.0 ## [25] backports_1.1.5 assertthat_0.2.1 Matrix_1.2-17 lazyeval_0.2.2 ## [29] cli_1.1.0 later_1.0.0 htmltools_0.4.0 prettyunits_1.0.2 ## [33] tools_3.6.0 igraph_1.2.4.1 coda_0.19-3 gtable_0.3.0 ## [37] glue_1.3.1.9000 reshape2_1.4.3 cellranger_1.1.0 vctrs_0.2.0 ## [41] nlme_3.1-139 crosstalk_1.0.0 xfun_0.10 ps_1.3.0 ## [45] rvest_0.3.4 mime_0.7 miniUI_0.1.1.1 lifecycle_0.1.0 ## [49] gtools_3.8.1 zoo_1.8-6 scales_1.0.0 colourpicker_1.0 ## [53] hms_0.4.2 promises_1.1.0 Brobdingnag_1.2-6 parallel_3.6.0 ## [57] inline_0.3.15 RColorBrewer_1.1-2 shinystan_2.5.0 gridExtra_2.3 ## [61] loo_2.1.0 StanHeaders_2.19.0 stringi_1.4.3 dygraphs_1.1.1.6 ## [65] pkgbuild_1.0.5 rlang_0.4.1 pkgconfig_2.0.3 matrixStats_0.55.0 ## [69] evaluate_0.14 lattice_0.20-38 rstantools_2.0.0 htmlwidgets_1.5 ## [73] labeling_0.3 cowplot_0.9.4 tidyselect_0.2.5 processx_3.4.1 ## [77] plyr_1.8.4 magrittr_1.5 R6_2.4.0 generics_0.0.2 ## [81] pillar_1.4.2 haven_2.1.0 withr_2.1.2 xts_0.11-2 ## [85] abind_1.4-5 modelr_0.1.4 crayon_1.3.4 arrayhelpers_1.0-20160527 ## [89] utf8_1.1.4 rmarkdown_1.13 grid_3.6.0 readxl_1.3.1 ## [93] callr_3.3.2 threejs_0.3.1 digest_0.6.21 xtable_1.8-4 ## [97] httpuv_1.5.2 stats4_3.6.0 munsell_0.5.0 shinyjs_1.0 "],
["conditional-process-analysis-with-a-multicategorical-antecedent.html", "13 Conditional Process Analysis with a Multicategorical Antecedent 13.1 Revisiting sexual discrimination in the workplace 13.2 Looking at the components of the indirect effect of \\(X\\) 13.3 Relative conditional indirect effects 13.4 Testing and probing moderation of mediation 13.5 Relative conditional direct effects References Session info", " 13 Conditional Process Analysis with a Multicategorical Antecedent With his opening lines, Hayes prepared us: At the end of any great fireworks show is the grand finale, where the pyrotechnicians throw everything remaining in their arsenal at you at once, leaving you amazed, dazed, and perhaps temporarily a little hard of hearing. Although this is not the final chapter of this book, I am now going to throw everything at you at once with an example of the most complicated conditional process model I will cover in this book. (p. 469) Enjoy the fireworks. 13.1 Revisiting sexual discrimination in the workplace Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) ## Observations: 129 ## Variables: 6 ## $ subnum &lt;dbl&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, … ## $ protest &lt;dbl&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1,… ## $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.… ## $ angry &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1,… ## $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.… ## $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.… With a little ifelse(), we can make the d1 and d2 contrast-coded dummies. protest &lt;- protest %&gt;% mutate(d1 = ifelse(protest == 0, -2/3, 1/3), d2 = ifelse(protest == 0, 0, ifelse(protest == 1, -1/2, 1/2))) Now load brms. library(brms) Our statistical model follows two primary equations, \\[\\begin{align*} M &amp; = i_M + a_1 D_1 + a_2 D_2 + a_3 W + a_4 D_1 W + a_5 D_2 W + e_M \\\\ Y &amp; = i_Y + c_1&#39; D_1 + c_2&#39; D_2 + c_3&#39; W + c_4&#39; D_1 W + c_5&#39; D_2 W + b M + e_Y. \\end{align*}\\] Here’s how we might specify the sub-model formulas with bf(). m_model &lt;- bf(respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism) y_model &lt;- bf(liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism + respappr) Now we’re ready to fit our primary model, the conditional process model with a multicategorical antecedent. model13.1 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) Here’s the model summary, which coheres reasonably well with the output in Table 13.1. print(model13.1, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism ## liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism + respappr ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## respappr_Intercept 4.621 0.676 3.323 5.952 1.001 5032 2988 ## liking_Intercept 3.481 0.642 2.231 4.725 1.000 5526 2823 ## respappr_d1 -2.941 1.485 -5.844 0.119 1.000 2890 2585 ## respappr_d2 1.654 1.663 -1.595 4.912 1.002 3184 2347 ## respappr_sexism 0.039 0.131 -0.221 0.295 1.001 5038 2707 ## respappr_d1:sexism 0.856 0.288 0.270 1.425 1.000 2861 2703 ## respappr_d2:sexism -0.240 0.319 -0.863 0.373 1.003 3186 2359 ## liking_d1 -2.722 1.204 -5.122 -0.422 1.002 3379 2730 ## liking_d2 0.015 1.309 -2.596 2.565 1.001 3089 2830 ## liking_sexism 0.073 0.106 -0.137 0.281 1.001 5836 2702 ## liking_respappr 0.366 0.072 0.226 0.502 1.001 4902 2692 ## liking_d1:sexism 0.524 0.237 0.076 0.997 1.001 3245 2690 ## liking_d2:sexism -0.032 0.251 -0.522 0.460 1.001 3035 2828 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_respappr 1.149 0.073 1.017 1.302 1.000 4880 3006 ## sigma_liking 0.917 0.059 0.812 1.040 1.000 4714 3427 ## ## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample ## is a crude measure of effective sample size, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Why not look at the output with a coefficient plot? library(tidybayes) post &lt;- posterior_samples(model13.1) post %&gt;% pivot_longer(starts_with(&quot;b_&quot;)) %&gt;% mutate(criterion = ifelse(str_detect(name, &quot;respappr&quot;), &quot;criterion: respappr&quot;, &quot;criterion: liking&quot;), criterion = factor(criterion, levels = c(&quot;criterion: respappr&quot;, &quot;criterion: liking&quot;)), name = str_remove(name, &quot;b_respappr_&quot;), name = str_remove(name, &quot;b_liking_&quot;), name = factor(name, levels = c(&quot;Intercept&quot;, &quot;respappr&quot;, &quot;d2:sexism&quot;, &quot;d1:sexism&quot;, &quot;sexism&quot;, &quot;d2&quot;, &quot;d1&quot;))) %&gt;% ggplot(aes(x = value, y = name, group = name)) + geom_halfeyeh(.width = .95, scale = &quot;width&quot;, relative_scale = .75, color = &quot;white&quot;) + coord_cartesian(xlim = c(-7, 6)) + labs(x = NULL, y = NULL) + theme_black() + theme(axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank(), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;grey20&quot;)) + facet_wrap(~criterion) The Bayesian \\(R^2\\) distributions are reasonably close to the estimates in the text. bayes_R2(model13.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2respappr 0.321 0.054 0.208 0.419 ## R2liking 0.296 0.054 0.185 0.394 13.2 Looking at the components of the indirect effect of \\(X\\) A mediation process contains at least two “stages.” The first stage is the effect of the presumed causal antecedent variable \\(X\\) on the proposed mediator \\(M\\), and the second stage is the effect of the mediator \\(M\\) on the final consequent variable \\(Y\\). More complex models, such as the serial mediation model, will contain more stages. In a model such as the one that is the focus of this chapter with only a single mediator, the indirect effect of \\(X\\) on \\(Y\\) through \\(M\\) is quantified as the product of the effects in these two stages. When one or both of the stages of a mediation process is moderated, making sense of the indirect effect requires getting intimate with each of the stages, so that when they are integrated or multiplied together, you can better understand how differences or changes in \\(X\\) map on to differences in \\(Y\\) through a mediator differently depending on the value of a moderator. (p. 480) 13.2.1 Examining the first stage of the mediation process. When making a newdata object to feed into fitted() with more complicated models, it can be useful to review the model formula like so. model13.1$formula ## respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism ## liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism + respappr Now we’ll prep for and make our version of Figure 13.3. nd &lt;- tibble(d1 = c(1/3, -2/3, 1/3), d2 = c(1/2, 0, -1/2)) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) f1 &lt;- fitted(model13.1, newdata = nd, resp = &quot;respappr&quot;) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(condition = ifelse(d2 == 0, &quot;No Protest&quot;, ifelse(d2 == -1/2, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) protest &lt;- protest %&gt;% mutate(condition = ifelse(protest == 0, &quot;No Protest&quot;, ifelse(protest == 1, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) f1 %&gt;% ggplot(aes(x = sexism, group = condition)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), linetype = 3, color = &quot;white&quot;, fill = &quot;transparent&quot;) + geom_line(aes(y = Estimate), color = &quot;white&quot;) + geom_point(data = protest, aes(x = sexism, y = respappr), color = &quot;red&quot;, size = 2/3) + coord_cartesian(xlim = 4:6) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = expression(paste(&quot;Perceived Appropriateness of Response (&quot;, italic(M), &quot;)&quot;))) + theme_black() + theme(panel.grid = element_blank()) + facet_wrap(~condition) In order to get the \\(\\Delta R^2\\) distribution analogous to the change in \\(R^2\\) \\(F\\)-test Hayes discussed on page 482, we’ll have to first refit the model without the interaction for the \\(M\\) criterion. Here are the sub-models. m_model &lt;- bf(respappr ~ 1 + d1 + d2 + sexism) y_model &lt;- bf(liking ~ 1 + d1 + d2 + respappr + sexism + d1:sexism + d2:sexism) Now we fit model13.2. model13.2 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) With model13.2 in hand, we’re ready to compare \\(R^2\\) distributions. # extract the R2 draws and wrangle r2 &lt;- bayes_R2(model13.1, resp = &quot;respappr&quot;, summary = F) %&gt;% as_tibble() %&gt;% set_names(&quot;model13.1&quot;) %&gt;% bind_cols( bayes_R2(model13.2, resp = &quot;respappr&quot;, summary = F) %&gt;% as_tibble() %&gt;% set_names(&quot;model13.2&quot;) ) %&gt;% mutate(difference = model13.1 - model13.2) # plot! r2 %&gt;% ggplot(aes(x = difference)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .width = 0.95) + scale_x_continuous(expression(paste(Delta, italic(R)^2)), breaks = median_qi(r2$difference, .width = .95)[1, 1:3], labels = median_qi(r2$difference, .width = .95)[1, 1:3] %&gt;% round(2)) + scale_y_continuous(NULL, breaks = NULL) + theme_black() + theme(panel.grid = element_blank()) And we might also compare the models by their information criteria. model13.1 &lt;- add_criterion(model13.1, c(&quot;waic&quot;, &quot;loo&quot;)) model13.2 &lt;- add_criterion(model13.2, c(&quot;waic&quot;, &quot;loo&quot;)) loo_compare(model13.1, model13.2, criterion = &quot;loo&quot;) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model13.1 0.0 0.0 -380.3 14.8 16.3 2.8 760.6 29.6 ## model13.2 -2.5 4.0 -382.8 14.8 14.0 2.5 765.6 29.6 loo_compare(model13.1, model13.2, criterion = &quot;waic&quot;) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic ## model13.1 0.0 0.0 -380.1 14.7 16.1 2.7 760.2 29.5 ## model13.2 -2.5 4.0 -382.6 14.7 13.8 2.4 765.2 29.4 The Bayesian \\(R^2\\), the LOO-CV, and the WAIC all suggest there’s little difference between the two models with respect to their predictive utility. In such a case, I’d lean on theory to choose between them. If inclined, one could also do Bayesian model averaging. Within our Bayesian modeling paradigm, we don’t have a direct analogue to the \\(F\\)-tests Hayes presented on page 483. But a little fitted() and follow-up wrangling will give us some difference scores. # we need new `nd` data nd &lt;- tibble(d1 = c(1/3, -2/3, 1/3), d2 = c(1/2, 0, -1/2)) %&gt;% expand(nesting(d1, d2), sexism = c(4.250, 5.120, 5.896)) %&gt;% mutate(condition = ifelse(d2 == 0, &quot;No Protest&quot;, ifelse(d2 &lt; 0, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # this time we&#39;ll use `summary = F` f1 &lt;- fitted(model13.1, newdata = nd, resp = &quot;respappr&quot;, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(condition, sexism), iter = 1:4000) ) %&gt;% select(-key) %&gt;% pivot_wider(names_from = condition, values_from = value) %&gt;% mutate(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Collective Protest - Individual Protest` = `Collective Protest` - `Individual Protest`) # a tiny bit more wrangling and we&#39;re ready f1 %&gt;% pivot_longer(cols = contains(&quot;-&quot;)) %&gt;% # plot the difference distributions! ggplot(aes(x = value)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .width = .95) + geom_vline(xintercept = 0, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + facet_grid(sexism~name) + theme_black() + theme(panel.grid = element_blank()) Now we have f1, it’s easy to get the typical numeric summaries for the differences. f1 %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% pivot_longer(-sexism) %&gt;% group_by(name, sexism) %&gt;% mean_qi() %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value) ## # A tibble: 9 x 5 ## # Groups: name [3] ## name sexism mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Collective Protest - Individual Protest 4.25 -0.38 -1.16 0.421 ## 2 Collective Protest - Individual Protest 5.12 -1.23 -1.73 -0.72 ## 3 Collective Protest - Individual Protest 5.90 -1.99 -2.68 -1.25 ## 4 Collective Protest - No Protest 4.25 -1.01 -1.72 -0.334 ## 5 Collective Protest - No Protest 5.12 -1.65 -2.15 -1.16 ## 6 Collective Protest - No Protest 5.90 -2.22 -2.93 -1.51 ## 7 Individual Protest - No Protest 4.25 -0.634 -1.40 0.111 ## 8 Individual Protest - No Protest 5.12 -0.425 -0.918 0.073 ## 9 Individual Protest - No Protest 5.90 -0.239 -0.905 0.433 The three levels of Collective Protest - Individual Protest correspond nicely with some of the analyses Hayes presented on pages 484–486. However, they don’t get at the differences Hayes expressed as \\(\\theta_{D_{1}\\rightarrow M}\\) to. For those, we’ll have to work directly with the posterior_samples(). post &lt;- posterior_samples(model13.1) post %&gt;% transmute(`4.250` = b_respappr_d1 + `b_respappr_d1:sexism` * 4.250, `5.210` = b_respappr_d1 + `b_respappr_d1:sexism` * 5.120, `5.896` = b_respappr_d1 + `b_respappr_d1:sexism` * 5.896) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value, `Difference in how Catherine&#39;s behavior is perceived between being told she protested or not when W is:` = name) ## # A tibble: 3 x 4 ## `Difference in how Catherine&#39;s behavior is perceived between being told she p… mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.250 0.697 0.06 1.35 ## 2 5.210 1.44 1.01 1.86 ## 3 5.896 2.10 1.46 2.73 At the end of the subsection, Hayes highlighted \\(a_5\\). Here it is. post %&gt;% ggplot(aes(x = `b_respappr_d2:sexism`)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .width = 0.95) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = -1:1) + xlab(expression(paste(&quot;b_respappr_d2:sexism (i.e., &quot;, italic(a)[5], &quot;)&quot;))) + theme_black() + theme(panel.grid = element_blank()) 13.2.2 Estimating the second stage of the mediation process. Now here’s \\(b\\). post %&gt;% ggplot(aes(x = b_liking_respappr)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .width = 0.95) + scale_x_continuous(expression(paste(&quot;b_liking_respappr (i.e., &quot;, italic(b), &quot;)&quot;)), breaks = c(-1, median(post$b_liking_respappr), 1), labels = c(-1, median(post$b_liking_respappr) %&gt;% round(3), 1)) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = -1:1) + theme_black() + theme(panel.grid = element_blank()) 13.3 Relative conditional indirect effects When \\(X\\) is a multicategorical variable representing \\(g = 3\\) groups, there are two indirect effects, which we called relative indirect effects in Chapter 10. But these relative indirect effects are still products of effects. In this example, because one of these effects is a function, then the relative indirect effects become a function as well. (p. 487, emphasis in the original) Before we use Hayes’s formulas at the top of page 488 to re-express the posterior in terms of the relative conditional indirect effects, we might want to clarify which of the post columns correspond to the relevant parameters. \\(a_1\\) = b_respappr_d1 \\(a_2\\) = b_respappr_d2 \\(a_4\\) = b_respappr_d1:sexism \\(a_5\\) = b_respappr_d2:sexism \\(b\\) = b_liking_respappr To get our posterior transformations, we’ll use the expand()-based approach from Chapter 12. Here’s the preparatory data wrangling. indirect &lt;- post %&gt;% expand(nesting(b_respappr_d1, b_respappr_d2, `b_respappr_d1:sexism`, `b_respappr_d2:sexism`, b_liking_respappr), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% mutate(`Protest vs. No Protest` = (b_respappr_d1 + `b_respappr_d1:sexism` * sexism) * b_liking_respappr, `Collective vs. Individual Protest` = (b_respappr_d2 + `b_respappr_d2:sexism` * sexism) * b_liking_respappr) %&gt;% pivot_longer(contains(&quot;Protest&quot;)) %&gt;% select(sexism:value) %&gt;% group_by(name, sexism) %&gt;% median_qi(value) head(indirect) ## # A tibble: 6 x 8 ## # Groups: name [1] ## name sexism value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Collective vs. Individual Protest 3.5 0.285 -0.115 0.772 0.95 median qi ## 2 Collective vs. Individual Protest 3.60 0.276 -0.0999 0.737 0.95 median qi ## 3 Collective vs. Individual Protest 3.71 0.268 -0.0888 0.709 0.95 median qi ## 4 Collective vs. Individual Protest 3.81 0.259 -0.0778 0.677 0.95 median qi ## 5 Collective vs. Individual Protest 3.91 0.250 -0.0682 0.649 0.95 median qi ## 6 Collective vs. Individual Protest 4.02 0.243 -0.0610 0.622 0.95 median qi Now we’ve saved our results in indirect, we just need to plug them into ggplot() to make our version of Figure 13.4. indirect %&gt;% ggplot(aes(x = sexism, group = name)) + geom_ribbon(aes(ymin = .lower, ymax = .upper), color = &quot;white&quot;, fill = &quot;transparent&quot;, linetype = 3) + geom_line(aes(y = value), color = &quot;white&quot;) + coord_cartesian(xlim = 4:6, ylim = c(-.6, .8)) + labs(title = &quot;These are just the conditional indirect effects&quot;, x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Relative Conditional Effect on Liking&quot;) + theme_black() + theme(panel.grid = element_blank(), legend.position = &quot;none&quot;) + facet_grid(~name) Do not that unlike the figure in the text, we’re only displaying the conditional indirect effects. Once you include the 95% intervals, things get too cluttered to add in other effects. Here’s how we might make our version of Table 13.2 based on posterior means. post %&gt;% expand(nesting(b_respappr_d1, b_respappr_d2, `b_respappr_d1:sexism`, `b_respappr_d2:sexism`, b_liking_respappr), w = c(4.250, 5.125, 5.896)) %&gt;% rename(b = b_liking_respappr) %&gt;% mutate(`relative effect of d1` = (b_respappr_d1 + `b_respappr_d1:sexism` * w), `relative effect of d2` = (b_respappr_d2 + `b_respappr_d2:sexism` * w)) %&gt;% mutate(`conditional indirect effect of d1` = `relative effect of d1` * b, `conditional indirect effect of d2` = `relative effect of d2` * b) %&gt;% pivot_longer(cols = c(contains(&quot;of d&quot;), b)) %&gt;% group_by(w, name) %&gt;% summarise(mean = mean(value) %&gt;% round(digits = 3)) %&gt;% pivot_wider(names_from = name, values_from = mean) %&gt;% select(w, `relative effect of d1`, `relative effect of d2`, everything()) ## # A tibble: 3 x 6 ## # Groups: w [3] ## w `relative effect o… `relative effect o… b `conditional indirect … `conditional indirect… ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.25 0.697 0.634 0.366 0.255 0.232 ## 2 5.12 1.45 0.424 0.366 0.529 0.155 ## 3 5.90 2.10 0.239 0.366 0.77 0.087 13.4 Testing and probing moderation of mediation Surely by now you knew we weren’t going to be satisfied with summarizing the model with a bunch of posterior means. 13.4.1 A test of moderation of the relative indirect effect. In this section Hayes referred to \\(a_4 b\\) and \\(a_5b\\) as the indexes of moderated mediation of the indirect effects of Protest vs. No Protest and Collective vs. Individual Protest, respectively. To express their uncertainty we’ll just work directly with the posterior_samples(), which we’ve saved as post. post &lt;- post %&gt;% mutate(a4b = `b_respappr_d1:sexism` * b_liking_respappr, a5b = `b_respappr_d2:sexism` * b_liking_respappr) post %&gt;% pivot_longer(a4b:a5b, names_to = &quot;parameter&quot;) %&gt;% group_by(parameter) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(parameter:.upper) ## # A tibble: 2 x 4 ## parameter value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a4b 0.313 0.089 0.576 ## 2 a5b -0.088 -0.341 0.141 Here they are in a geom_halfeyeh() plot. post %&gt;% pivot_longer(a4b:a5b, names_to = &quot;parameter&quot;) %&gt;% ggplot(aes(x = value, y = parameter)) + geom_halfeyeh(point_interval = median_qi, .width = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_y_discrete(NULL, expand = c(.1, .1)) + xlab(NULL) + theme_black() + theme(axis.ticks.y = element_blank(), panel.grid.minor.y = element_blank(), panel.grid.major.y = element_blank()) 13.4.2 Probing moderation of mediation. We already computed the relevant 95% credible intervals at the end of section 13.3. We could inspect those in a geom_halfeyeh() plot, too. # we did this all before post %&gt;% expand(nesting(b_respappr_d1, b_respappr_d2, `b_respappr_d1:sexism`, `b_respappr_d2:sexism`, b_liking_respappr), w = c(4.250, 5.125, 5.896)) %&gt;% rename(b = b_liking_respappr) %&gt;% mutate(`relative effect of d1` = (b_respappr_d1 + `b_respappr_d1:sexism` * w), `relative effect of d2` = (b_respappr_d2 + `b_respappr_d2:sexism` * w)) %&gt;% mutate(`conditional indirect effect of d1` = `relative effect of d1` * b, `conditional indirect effect of d2` = `relative effect of d2` * b) %&gt;% pivot_longer(contains(&quot;conditional&quot;)) %&gt;% # now plot instead of summarizing ggplot(aes(x = value, y = w)) + geom_halfeyeh(point_interval = median_qi, .width = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + labs(x = &quot;Relative Conditional Effect on Liking&quot;, y = &quot;Sexism&quot;) + coord_flip() + theme_black() + theme(panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank()) + facet_wrap(~name) 13.5 Relative conditional direct effects In order to get the \\(R^2\\) difference distribution analogous to the change in \\(R^2\\) \\(F\\)-test Hayes discussed on pages 495–496, we’ll have to first refit the model without the interaction for the \\(Y\\) criterion, liking. m_model &lt;- bf(respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism) y_model &lt;- bf(liking ~ 1 + d1 + d2 + respappr + sexism) model13.3 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) Here’s the \\(\\Delta R^2\\) density for our \\(Y\\), liking. # wrangle bayes_R2(model13.1, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% set_names(&quot;model13.1&quot;) %&gt;% bind_cols( bayes_R2(model13.3, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% set_names(&quot;model13.3&quot;) ) %&gt;% mutate(difference = model13.1 - model13.3) %&gt;% # plot ggplot(aes(x = difference, y = 0)) + geom_halfeyeh(point_interval = median_qi, .width = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = c(-.5, .5)) + xlab(expression(paste(Delta, italic(R)^2))) + theme_black() + theme(panel.grid = element_blank()) We’ll also compare the models by their information criteria. model13.3 &lt;- add_criterion(model13.3, c(&quot;waic&quot;, &quot;loo&quot;)) loo_compare(model13.1, model13.3, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## model13.1 0.0 0.0 ## model13.3 -0.7 2.8 loo_compare(model13.1, model13.3, criterion = &quot;waic&quot;) ## elpd_diff se_diff ## model13.1 0.0 0.0 ## model13.3 -0.8 2.8 As when we went through these steps for resp = &quot;respappr&quot;, above, the Bayesian \\(R^2\\), the LOO-CV, and the WAIC all suggest there’s little difference between the two models with respect to predictive utility. In such a case, I’d lean on theory to choose between them. If inclined, one could also do Bayesian model averaging. Our approach to plotting the relative conditional direct effects will mirror what we did for the relative conditional indirect effects, above. Here are the brm() parameters that correspond to the parameter names of Hayes’s notation. \\(c_1\\) = b_liking_d1 \\(c_2\\) = b_liking_d2 \\(c_4\\) = b_liking_d1:sexism \\(c_5\\) = b_liking_d2:sexism With all clear, we’re ready to make our version of Figure 13.4 with respect to the conditional direct effects. # wrangle post %&gt;% expand(nesting(b_liking_d1, b_liking_d2, `b_liking_d1:sexism`, `b_liking_d2:sexism`), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% mutate(`Protest vs. No Protest` = b_liking_d1 + `b_liking_d1:sexism` * sexism, `Collective vs. Individual Protest` = b_liking_d2 + `b_liking_d2:sexism` * sexism) %&gt;% pivot_longer(contains(&quot;Protest&quot;)) %&gt;% group_by(name, sexism) %&gt;% median_qi(value) %&gt;% # plot ggplot(aes(x = sexism, y = value, ymin = .lower, ymax = .upper)) + geom_ribbon(color = &quot;white&quot;, fill = &quot;transparent&quot;, linetype = 3) + geom_line(color = &quot;white&quot;) + coord_cartesian(xlim = 4:6, ylim = c(-.6, .8)) + labs(title = &quot;These are just the conditional direct effects&quot;, x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Relative Conditional Effect on Liking&quot;) + theme_black() + theme(panel.grid = element_blank(), legend.position = &quot;none&quot;) + facet_grid(~name) Holy smokes, them are some wide 95% CIs! No wonder the information criteria and \\(R^2\\) comparisons were so uninspiring. Notice that the y-axis is on the parameter space. When Hayes made his Figure 13.5, he put the y-axis on the liking space, instead. When we want things in the parameter space, we work with the output of posterior_samples(); when we want them in the criterion space, we use fitted(). # we need new `nd` data nd &lt;- tibble(d1 = c(1/3, -2/3, 1/3), d2 = c(1/2, 0, -1/2)) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% mutate(respappr = mean(protest$respappr), condition = ifelse(d2 == 0, &quot;No Protest&quot;, ifelse(d2 &lt; 0, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # feed `nd` into `fitted()` f &lt;- fitted(model13.1, newdata = nd, resp = &quot;liking&quot;, summary = T) %&gt;% as_tibble() %&gt;% bind_cols(nd) # plot! f %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), linetype = 3, color = &quot;white&quot;, fill = &quot;transparent&quot;) + geom_line(aes(y = Estimate), color = &quot;white&quot;) + geom_point(data = protest, aes(y = liking), color = &quot;red&quot;, size = 2/3) + coord_cartesian(xlim = 4:6, ylim = 4:7) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = expression(paste(&quot;Evaluation of the Attorney (&quot;, italic(Y), &quot;)&quot;))) + theme_black() + theme(panel.grid = element_blank()) + facet_wrap(~condition) Relative to the text, we expanded the range of the y-axis a bit to show more of that data (and there’s even more data outside of our expanded range). Also note how after doing so and after including the 95% CI bands, the crossing regression line effect in Hayes’s Figure 13.5 isn’t as impressive looking any more. On pages 497–498, Hayes discussed more omnibus \\(F\\)-tests. Much like with the \\(M\\) criterion, we won’t come up with Bayesian \\(F\\)-tests, but we might go ahead and make pairwise comparisons at the three percentiles Hayes prefers. # we need new `nd` data nd &lt;- tibble(d1 = c(1/3, -2/3, 1/3), d2 = c(1/2, 0, -1/2)) %&gt;% expand(nesting(d1, d2), sexism = c(4.250, 5.120, 5.896)) %&gt;% mutate(respappr = mean(protest$respappr), condition = ifelse(d2 == 0, &quot;No Protest&quot;, ifelse(d2 &lt; 0, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # this time we&#39;ll use `summary = F` f &lt;- fitted(model13.1, newdata = nd, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% bind_cols( nd %&gt;% expand(nesting(condition, sexism), iter = 1:4000) ) %&gt;% select(-key) %&gt;% pivot_wider(names_from = condition, values_from = value) %&gt;% mutate(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Collective Protest - Individual Protest` = `Collective Protest` - `Individual Protest`) # a tiny bit more wrangling and we&#39;re ready to plot the difference distributions f %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% gather(key, value, -sexism) %&gt;% mutate(sexism = str_c(&quot;W = &quot;, sexism)) %&gt;% ggplot(aes(x = value)) + geom_halfeyeh(aes(y = 0), color = &quot;white&quot;, point_interval = median_qi, .width = .95) + geom_vline(xintercept = 0, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + facet_grid(sexism~key) + theme_black() + theme(panel.grid = element_blank()) Now we have f, it’s easy to get the typical numeric summaries for the differences. f %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% pivot_longer(-sexism) %&gt;% group_by(name, sexism) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value) ## # A tibble: 9 x 5 ## # Groups: name [3] ## name sexism mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Collective Protest - Individual Protest 4.25 -0.122 -0.715 0.469 ## 2 Collective Protest - Individual Protest 5.12 -0.15 -0.543 0.251 ## 3 Collective Protest - Individual Protest 5.90 -0.175 -0.723 0.358 ## 4 Collective Protest - No Protest 4.25 -0.555 -1.15 0.028 ## 5 Collective Protest - No Protest 5.12 -0.112 -0.570 0.337 ## 6 Collective Protest - No Protest 5.90 0.282 -0.367 0.927 ## 7 Individual Protest - No Protest 4.25 -0.433 -1.05 0.182 ## 8 Individual Protest - No Protest 5.12 0.037 -0.394 0.46 ## 9 Individual Protest - No Protest 5.90 0.457 -0.168 1.06 We don’t have \\(p\\)-values, but who needs them? All the differences are small in magnitude and have wide 95% intervals straddling zero. To get the difference scores Hayes presented on pages 498–500, one execute something like this. post %&gt;% transmute(d1_4.250 = b_liking_d1 + `b_liking_d1:sexism` * 4.250, d1_5.120 = b_liking_d1 + `b_liking_d1:sexism` * 5.120, d1_5.896 = b_liking_d1 + `b_liking_d1:sexism` * 5.896, d2_4.250 = b_liking_d2 + `b_liking_d2:sexism` * 4.250, d2_5.120 = b_liking_d2 + `b_liking_d2:sexism` * 5.120, d2_5.896 = b_liking_d2 + `b_liking_d2:sexism` * 5.896) %&gt;% pivot_longer(everything(), names_sep = &quot;_&quot;, names_to = c(&quot;protest dummy&quot;, &quot;sexism&quot;)) %&gt;% group_by(`protest dummy`, sexism) %&gt;% mean_qi() %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(`protest dummy`:.upper) %&gt;% rename(mean = value) ## # A tibble: 6 x 5 ## # Groups: protest dummy [2] ## `protest dummy` sexism mean .lower .upper ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 d1 4.250 -0.494 -1.03 0.021 ## 2 d1 5.120 -0.037 -0.438 0.353 ## 3 d1 5.896 0.369 -0.199 0.941 ## 4 d2 4.250 -0.122 -0.715 0.469 ## 5 d2 5.120 -0.15 -0.543 0.251 ## 6 d2 5.896 -0.175 -0.723 0.358 Each of those was our Bayesian version of an iteration of what you might call \\(\\theta_{D_i \\rightarrow Y} | W\\). References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_1.1.0 brms_2.10.3 Rcpp_1.0.2 forcats_0.4.0 stringr_1.4.0 dplyr_0.8.3 ## [7] purrr_0.3.3 readr_1.3.1 tidyr_1.0.0 tibble_2.1.3 ggplot2_3.2.1 tidyverse_1.2.1 ## ## loaded via a namespace (and not attached): ## [1] colorspace_1.4-1 ellipsis_0.3.0 ggridges_0.5.1 ## [4] rsconnect_0.8.15 ggstance_0.3.2 markdown_1.1 ## [7] base64enc_0.1-3 rstudioapi_0.10 rstan_2.19.2 ## [10] svUnit_0.7-12 DT_0.9 fansi_0.4.0 ## [13] lubridate_1.7.4 xml2_1.2.0 bridgesampling_0.7-2 ## [16] knitr_1.23 shinythemes_1.1.2 zeallot_0.1.0 ## [19] bayesplot_1.7.0 jsonlite_1.6 broom_0.5.2 ## [22] shiny_1.3.2 compiler_3.6.0 httr_1.4.0 ## [25] backports_1.1.5 assertthat_0.2.1 Matrix_1.2-17 ## [28] lazyeval_0.2.2 cli_1.1.0 later_1.0.0 ## [31] htmltools_0.4.0 prettyunits_1.0.2 tools_3.6.0 ## [34] igraph_1.2.4.1 coda_0.19-3 gtable_0.3.0 ## [37] glue_1.3.1.9000 reshape2_1.4.3 cellranger_1.1.0 ## [40] vctrs_0.2.0 nlme_3.1-139 crosstalk_1.0.0 ## [43] xfun_0.10 ps_1.3.0 rvest_0.3.4 ## [46] mime_0.7 miniUI_0.1.1.1 lifecycle_0.1.0 ## [49] gtools_3.8.1 zoo_1.8-6 scales_1.0.0 ## [52] colourpicker_1.0 hms_0.4.2 promises_1.1.0 ## [55] Brobdingnag_1.2-6 parallel_3.6.0 inline_0.3.15 ## [58] shinystan_2.5.0 gridExtra_2.3 loo_2.1.0 ## [61] StanHeaders_2.19.0 stringi_1.4.3 dygraphs_1.1.1.6 ## [64] pkgbuild_1.0.5 rlang_0.4.1 pkgconfig_2.0.3 ## [67] matrixStats_0.55.0 evaluate_0.14 lattice_0.20-38 ## [70] rstantools_2.0.0 htmlwidgets_1.5 labeling_0.3 ## [73] tidyselect_0.2.5 processx_3.4.1 plyr_1.8.4 ## [76] magrittr_1.5 R6_2.4.0 generics_0.0.2 ## [79] pillar_1.4.2 haven_2.1.0 withr_2.1.2 ## [82] xts_0.11-2 abind_1.4-5 modelr_0.1.4 ## [85] crayon_1.3.4 arrayhelpers_1.0-20160527 utf8_1.1.4 ## [88] rmarkdown_1.13 grid_3.6.0 readxl_1.3.1 ## [91] callr_3.3.2 threejs_0.3.1 digest_0.6.21 ## [94] xtable_1.8-4 httpuv_1.5.2 stats4_3.6.0 ## [97] munsell_0.5.0 shinyjs_1.0 "],
["miscellaneous-topics-and-some-frequently-asked-questions.html", "14 Miscellaneous Topics and Some Frequently Asked Questions 14.1 A strategy for approaching a conditional process analysis 14.2 How do I write about this? 14.3 Should I use structural equation modeling instead of regression analysis? 14.4 The pitfalls of subgroups analysis 14.5 Can a variable simultaneously mediate and moderate another variable’s effect? 14.6 Interaction between \\(X\\) and \\(M\\) in mediation analysis? 14.7 Repeated measures designs 14.8 Dichotomous, ordinal, count, and survival outcomes Reference Session info", " 14 Miscellaneous Topics and Some Frequently Asked Questions The vast majority of scientists would probably argue that when push comes to shove, the theoretical horse should pull the statistical cart. Statistical methods are mathematical tools, some of them quite amazing in what they do, which can help us to discern order amid the apparent chaos in a batch of data. But ultimately, the stories that statistical methods help us tell are told by our brains, not by the mathematics, and our brains are good at making sense of things–of coming up with stories to explain what we perceive. The problem is that the same pattern of results can be interpreted in many different ways, especially if the pattern is found after an extensive round of exploratory data analysis. Without a theoretical orientation to guide our attempts at making sense of our data or, better still, to guide our research design and data collection efforts, our awesome storytelling ability can lead us astray by invoking explanations for findings that may sound good but that are mere conjecture even if we can find a theoretical hook on which to hang them post hoc. I won’t argue against this perspective, as I believe it is for the most part right on the money. But I also believe that statistical methods can play an important role in theory development as well–that the statistical cart need not always, should not always, and often does not follow the theoretical horse. When we learn something new analytically, this can change the way we think of things theoretically and how we then go about testing the ideas that our newfound awareness of an analytical method inspired (cf. Slater, Hayes, &amp; Snyder, 2008, p. 2). (pp. 507–508) 14.1 A strategy for approaching a conditional process analysis Things don’t always turn out as we expected and articulated in hypotheses 1, 2, and 3. And sometimes after looking at the data, our thinking about the process at work changes and new hypotheses come to mind that are worth testing. Scientists routinely switch back and forth between the context of justification and the context of discovery, testing hypotheses conceived before the data were analyzed while also exploring one’s data to see what else can be learned from patterns observed but not anticipated. In the next paragraph, we see Hayes anticipated criticism at this paragraph and some of the subsections to follow. My two cents are that problems arise when we approach statistics from a \\(p\\)-value-based hypothesis-testing perspective, when we pose exploratory research as confirmatory, when we engage in closed science practices, and when we only present the analyses that “worked.” For some engaging thoughts on iterative Bayesian workflows, you might check out Navarro’s blog series, Paths in strange spaces; here’s part 1. 14.1.1 Step 1: Construct your conceptual diagram of the process. Build up your model slowly and with the aid of visuals. 14.1.2 Step 2: Translate the conceptual model into a statistical model. We don’t estimate the conceptual model. [Presuming mediation,] a conceptual model must be translated into a statistical model in the form of at least two equations, depending on the number of proposed mediators in the model. With an understanding of the principles of moderation and mediation analysis described in this book, you should be able to do this without too much difficulty. (p. 510) 14.1.3 Step 3: Estimate the statistical model. Hayes used OLS-based procedures throughout the text. We have been using Bayesian software. Though I prefer brms, you might also check out blavaan, rstanarm, or rstan. As a group, these will allow you to fit many more kinds of regression models than available through the OLS paradigm. 14.1.4 Step 4: Determine whether expected moderation exists. I’m not a fan of this “whether [x] exists” talk. First, it seems way to black and white. For more thoughts along those lines, check out Gelman’s The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Second, it places too much faith in the analyis of a single data set. For more on those lines, consider what Hayes wrote in the middle of this subsection: Just because an interaction is not significant, that doesn’t mean your proposed moderator does not moderate the path you proposed it moderates. Parsimony might dictate that your model should be cleansed of this interaction, but null hypotheses tests are fallible, and sometimes real effects are so weak that we don’t have the power to detect them given the limitations of our resources or other things out of our control. (p. 511) This is all posed in the language of NHST, but the basic points still hold for other paradigms. If you have a theory-informed model, I recommend showing the results for that model regardless of the sizes of the parameters. I have concerns about the next subsection. 14.1.4.1 Step 4A. If you have decided to prune your model of nonsignificant interactions, then go back to step 1 and start fresh by redrawing your conceptual diagram in light of the evidence you now have and proceed through these steps again. A certain moral or ethical logic might dictate that you not pretend when describing your analysis that this is where you started in the first place. Yet Bem (1987) makes the argument that spending lots of time talking about ideas that turned out to be “wrongheaded” isn’t going to produce a particularly interesting paper. You’ll have to sort out for yourself where you stand on this continuum of scientific ethics. (p. 512) Hayes is quite right: “You’ll have to sort out for yourself where you stand on this continuum of scientific ethics.” At this point in the social-psychology replication crisis–a crisis of which Bem’s shoddy work has played no small part (see here or here or here or here or here)–, it’s shocking to read Hayes endorsing this advice. At a bare minimum, I recommend presenting your failed theory-based models in supplemental materials. You can upload them to the Open Science Framework for free. 14.1.5 Step 5: Probe and interpret interactions involving components of the indirect effect. At this stage, probe any interactions involving components of the indirect effect of \\(X\\) so that you will have some understanding of the contingencies of the various effects that are the components of the larger conditional process model you are estimating. This exercise will help inform and clarify your interpretation of the conditional indirect effect(s) of \\(X\\) later on. (p. 512) 14.1.6 Step 6: Quantify and test conditional indirect effects (if relevant). Within the paradigm I have introduces throughout this text, “testing” effects is never relevant. However, one can and should think in terms of the magnitudes of the parameters in the model. Think in terms of effect sizes. For a frequentist introduction to effect-size thinking, Geoff Cumming’s work is a fine place to start, such as his The new statistics: Why and how. For a Bayesian alternative, check out Kruschke and Liddell’s The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. 14.1.7 Step 7: Quantify and test conditional direct effects (if relevant). “If your model includes moderation of the direct effect of X, you will want to probe this interaction by estimating the conditional direct effects” (p. 513). 14.1.8 Step 8: Tell your story. Real science does not proceed in the manner described in re- search methods and statistics textbooks. Rather, we routinely straddle the fence between the hypothetico-deductive approach and a more discovery- oriented or inquisitive mindset that is open to any story the data may inform. Sometimes the story we originally conceived prior to data analysis is simply wrong and we know it after analyzing the data. No one wants to read (as Daryl Bem once put it rather bluntly) “a personal history about your stillborn thoughts” (Bem, 1987, p. 173). Sometimes our data speak to us in ways that change the story we thought we were going to tell into something much more interesting, and hopefully more accurate. (p. 514) I largely agree, though I still recommend against following Bem’s recommendations. Yes, we need to present out work compellingly. But do resist the urge to un-transparently reinvent your research hypotheses for the sake of flashy rhetoric. If you have evidence agains one of the theoretical models in your field, let them know! For an example of scientists embracing the failure of theory, check out Klein and colleagues’ Many Labs 4: Failure to replicate mortality salience effect with and without original author involvement. Of course, there is always the danger of capitalizing on chance when you let your explorations of the data influence the story you tell. We are great at explaining patterns we see. Our brains are wired to do it. So replication is important, and it may be the only way of establishing the generality of our findings and claims in the end. (p. 514) Yes indeed. So please stop following the poor examples of Bem and others. Present your research honestly and transparently. 14.2 How do I write about this? I have become convinced that the ability to communicate in writing is at least as if not more important than the ability to manipulate numbers and think in abstractions. You don’t have to be a good data analyst to be a good scientist, but your future on the front lines of science is limited if you can’t write effectively. (p. 515) Agreed. On page 518, Hayes gave an example of how to write up the results of a mediation analysis in a narrative style. Here’s a more Bayesian version: From a simple [Bayesian] mediation analysis conducted using [Hamiltonian Monte Carlo], article location indirectly influenced intentions to buy sugar through its effect on beliefs about how others would be influenced. As can be seen in Figure 3.3 and Table 3.2, participants told that the article would be published on the front page believed others would be more influenced to buy sugar than those told that the article would appear in an economic supplement (\\(a\\) = 0.477[, 95% CI [0.277, 0.677]]), and participants who believed others would be more influenced by the story expressed a stronger intention to go buy sugar themselves (\\(b\\) = 0.506[, 95% CI [0.306, 0.706]]). [The credible interval] for the indirect effect (\\(ab\\) = 0.241) based on 5,000 bootstrap samples was entirely above zero (0.007 to 0.526). [The evidence suggested] that article location [had little influence on] intention to buy sugar independent of its effect on presumed media influence (\\(c&#39;\\) = 0.254[, 95% CI [-0.154, 0.554]]). In addition to throwing in talk about Bayes, I added 95% credible interval information for all point estimates (i.e., posterior means or medians) and shifted the language away from a dichotomous NHST style to emphasize the magnitude and uncertainty of the conditional direct effect (\\(c&#39;\\)). A little further down we read: Third, throughout this book, I emphasize estimation and interpretation of effects in their unstandardized metric, and I report unstandardized effects when I report the results in my own research. There is a widespread belief that standardized effects are best reported, because the measurement scales used in most sciences are arbitrary and not inherently meaningful, or that standardized effects are more comparable across studies or investigators using different methods. But standardization simply changes one arbitrary measurement scale into another arbitrary scale, and because standardized effects are scaled in terms of variability in the sample, they are not comparable across studies conducted by different investigators regardless of whether the same measurement scales are used. (p. 519) To my mind, this leads directly to thoughts about effect sizes. I recommend you ponder long and hard on how to interpret your results in terms of effect sizes. If your research is anything like mine, it’s not always clear what the best approach might be. To get your juices flowing, you might check out Kelley and Preacher’s (2012) On effect size. 14.2.1 Reporting a mediation analysis. Mediation is a causal phenomenon. You will find some people skeptical of the use of mediation analysis in studies based on data that are purely correlational in nature and involve no experimental manipulation or measurement over time. Some people are quite fanatical about this, and if you are unlucky enough to get such an extreme reviewer when trying to publish your work, there may not be much you can to do to convince him or her otherwise. (p. 520) In recent years, I’ve shifted more and more in the direction of the ‘fanatics.’ That might seem odd given I’ve poured all this time and effort into translating a book highlighting and endorsing cross-sectional mediation. I think cross-sectional mediation is a fine teaching tool; it’s a good place for budding data analysts to start. But please do not stop there. Do not stop with this book. Mediation is causal process and causal processes are necessarily longitudinal. A fine place to dip your toes into those waters are the works of Maxwell, Cole, and Mitchell (e.g., here or here or here). If you care about the causal process under your study, please collect longitudinal data. If you learn best by snarky twitter discussions, go here. 14.2.2 Reporting a moderation analysis. Some of the more interesting studies you will find show that what is commonly assumed turns out to be true only sometimes, or that a well-known manipulation only works for some types of people. When writing about moderation, you have the opportunity to tell the scientific world that things aren’t as simple as perhaps they have seemed or been assumed to be, and that there are conditions that must be placed on our understanding of the world. (p. 522) I don’t care for the NHST framing in many of the paragraphs to follow. If you find it a struggle to move beyond this way of thinking, I recommend soaking in Gelman’s (2014) editorial commentary, The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Later we read: The interpretation of the regression coefficients for \\(X\\) and \\(W\\) in a model that includes \\(XW\\) are highly dependent on the scaling of \\(X\\) and \\(W\\). If you have centered a variable, say so. If one or both of these variables is dichotomous, tell the reader what numerical codes were used to represent the two groups. Preferably, choose codes for the two groups that differ by one unit. The more information you give to the reader about how your variables are scaled or coded, the more the reader will be able to look at your results in the text, tables, or figures, discern their meaning, and interpret them correctly. (0. 524) Agreed. And if you’re working under tight word-limit constraints, just give all these details–and others such as centering, standardizing, priors, formal model formulas, HMC chain diagnostic checks, posterior-predictive checks–in supplemental material posted to a stable online repository, such as the Open Science Framework. Other than that, please consider plotting your interactions. Hayes gave some examples of that in the text, but I think his approach was inadequate. Include measures of uncertainty (e.g., 95% credible intervals) in your visualizations. For examples of this beyond those I reported in this text, check out this nice tutorial by McCabe, Kim, and King. For visualization ideas specific to the brms/tidybayes framework, check out Kay’s Extracting and visualizing tidy draws from brms models. 14.2.3 Reporting a conditional process analysis. One of the challenges you are likely to face when writing about a conditional process analysis is staying within the page allowance that most journal editors provide. A well-written analysis will usually contain multiple tables, perhaps a figure or two to depict the conceptual model and perhaps an interaction or two, and enough text to describe what was found in substantive terms while also providing sufficient detail about the analysis for the reader to understand what was done. Many reviewers, editors, and readers will not be familiar with this approach and may need to be educated within the text, further lengthening the manuscript. Yet I am also amazed how much I am able to cut from my own writing with sufficient editing, so don’t be wedded to every word you write, and don’t be afraid to delete that sentence or two you spent much time pondering, crafting, and fine-tuning but that upon third or fourth reading really isn’t necessary to convey what needs to be conveyed. That said, I would err on the side of presenting more information rather than less whenever space allows it. (p. 526) As recommended just above, you can also cover all this with online supplemental material posted to a stable online repository, such as the Open Science Framework. I can’t recommend this enough. 14.3 Should I use structural equation modeling instead of regression analysis? First to clarify, one can do structural equation modeling (SEM) as a Bayesian. At the time of this writing, brms is only capable of limited forms of SEM. In fact, all the multivariate models we have fit this far can be thought of as special cases of Bayesian SEM (see here). However, it appears brms will offer expanded SEM capabilities sometime in the future. To keep up with the Bürkner’s progress, you might intermittently check in to this issue on the brms GitHub page. And of course, you can always check out the blavaan package. 14.4 The pitfalls of subgroups analysis If at all possible, just don’t do this. Hayes covered the following reasons why: “First, the subgroups approach may not accurately reflect the process purportedly at work” (p. 531). “Second, a direct or indirect effect may be descriptively different in the two groups but may not actually be different when subjected to a formal statistical test of differences” (pp. 531–532). For more on this point, check out Gelman and Stern’s (2006) The difference between “significant” and “not significant” is not itself statistically significant. “Third, the subgroups approach conflates statistical significance with sample size” (p. 532). “Finally, this approach requires that the proposed moderator be categorical” (p. 532). 14.5 Can a variable simultaneously mediate and moderate another variable’s effect? “Just because something is mathematically possible doesn’t mean that it is sensible theoretically or substantively interpretable when it happens” (p. 540). I suspect part of this issue has to do with confusion around the longitudinal nature of mediation al processes and a confounding of state versus trait (i.e., within- and between-case variation). See the Cole, Maxwell and Mitchell papers referenced, above, to start thinking about mediation within the context of longitudinal data. The issue of within- versus between-case variation is huge and IMO under-appreciated in the mediation literature. If you’re ready to blow your mind a little, I can think of no better place to start learning about this than Ellen Hamaker’s engaging chapter, Why researchers should think “within-person”: A paradigmatic rationale. 14.6 Interaction between \\(X\\) and \\(M\\) in mediation analysis? The mathematics of this approach relies on the counterfactual or potential outcomes approach to causal analysis that is popular in statistics, less widely known in the social science research community, and, to many, a little harder to digest. For discussions of this approach, see Imai, Keele, and Tingley (2010), Muthé́n and Asparouhov (2015), Valeri and VanderWeele (2013), and VanderWeele (2015). 14.7 Repeated measures designs In all examples throughout this book, cases were measured on mediator(s) \\(M\\) and outcome \\(Y\\) only once. In nonexperimental studies, they were measured once on the causal antecedent \\(X\\), whereas in experimental studies they were assigned to one of two or three experimental conditions used as \\(X\\) in the model. Although such research designs are common, also common are “repeated measures” designs that involve measuring cases more than once on the variables in a mediation model. There are several forms such designs take, and there are approaches to mediation and conditional process analysis that can be used depending on the form of the design. (p. 541) On the next page, Hayes introduced the multilevel approach to mediation. For more on this topic, check out this paper from Vuorre and Bolger, Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience which introduced a package for Bayesian multilevel mediation models, bmlm. Yes, you can do this in brms. Hayes also discussed the cross-lag panel model for longitudinal mediation (e.g., Valente &amp; MacKinnon, 2017). I have not tried it, but I believe you could do this with current versions of brms. Here’s a thread on the Stan forums discussing how from a multilevel perspective. For a more detailed discussion of mediation in panel designs like this, see Cole and Maxwell (2003), Little, Preacher, Selig, and Card (2007), and Selig and Preacher (2009). Another analytical option is available when \\(M\\) and \\(Y\\) are measured at least three times, regardless of the number of measurements of \\(X\\). Parallel process latent growth modeling allows for \\(X\\) (either in a single measurement or manipulation, or its change over time) to influence the trajectory in change in the mediator, which in turn can influence the trajectory in the change in \\(Y\\) over time. [Yes, brms can do this]. See Cheong et al. (2003) and Selig and Preacher (2009) for discussions of the mathematics of mediation analysis in a latent growth context. (p. 545, emphasis in the original) 14.8 Dichotomous, ordinal, count, and survival outcomes [Our version of] this book is focused squarely and exclusively on linear regression analysis using the [single-level Gaussian likelihood] as the computational backbone of mediation, moderation, and conditional process analysis. In all examples that included a mediation component, all mediator(s) \\(M\\) and final consequent variable \\(Y\\) were always treated as continuous dimensions with at least interval level measurement properties. But no doubt you will find yourself in a situation where \\(M\\) and/or \\(Y\\) is dichotomous, or an ordinal scale with only a few scale points, or perhaps a count variable. Although such variables can be modeled with [the Gaussian likelihood], doing so is controversial because there are better methods that respect the special statistical considerations that come up when such variables are on the left sides of equations. (p. 545) Going beyond the Gaussian likelihood is often framed in terms of the generalized linear model (GLM). To wade into the GLM from within a Bayesian framework, I recommend McElreath’s (2015) Statistical rethinking: A Bayesian course with examples in R and Stan and Kruschke’s (2014) [Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan]. I have bookdown translations of both into brms, freely available here and here, respectively. Liberate yourself from the tyranny of the Gauss. Embrace the GLM. Reference Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() ## R version 3.6.0 (2019-04-26) ## Platform: x86_64-apple-darwin15.6.0 (64-bit) ## Running under: macOS High Sierra 10.13.6 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRblas.0.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/3.6/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] compiler_3.6.0 magrittr_1.5 tools_3.6.0 htmltools_0.4.0 Rcpp_1.0.2 stringi_1.4.3 ## [7] rmarkdown_1.13 knitr_1.23 stringr_1.4.0 xfun_0.10 digest_0.6.21 rlang_0.4.1 ## [13] evaluate_0.14 "]
]
