# Multicategorical Focal Antecedents and Moderators

## Moderation of the effect of a multicategorical antecedent variable



## An example from the sex disrimination in the workplace study

Here we load a couple necessary packages, load the data, and take a `glimpse()`.


```r
library(tidyverse)

protest <- read_csv("data/protest/protest.csv")

glimpse(protest)
```

```
## Observations: 129
## Variables: 6
## $ subnum   <int> 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66...
## $ protest  <int> 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, ...
## $ sexism   <dbl> 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, ...
## $ angry    <int> 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, ...
## $ liking   <dbl> 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, ...
## $ respappr <dbl> 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, ...
```

With a little `ifelse()`, computing the dummies `D1` and `D2` is easy enough.


```r
protest <-
  protest %>% 
  mutate(D1 = ifelse(protest == 1, 1, 0),
         D2 = ifelse(protest == 2, 1, 0))
```

Load brms.


```r
library(brms)
```

With `model1` and `model2` we fit the multicategorical multivariable model and the multicategorical moderation models, respectively.


```r
model1 <-
  brm(data = protest, family = gaussian,
      liking ~ 1 + D1 + D2 + sexism,
      chains = 4, cores = 4)

model2 <-
  update(model1,
         newdata = protest,
         liking ~ 1 + D1 + D2 + sexism + D1:sexism + D2:sexism,
         chains = 4, cores = 4)
```

$R^2$s:


```r
r2s <-
  bayes_R2(model1, summary = F) %>% 
  as_tibble() %>% 
  rename(`Model 1` = R2) %>% 
  bind_cols(
    bayes_R2(model2, summary = F) %>% 
      as_tibble() %>% 
      rename(`Model 2` = R2)
  ) %>% 
  mutate(`The R2 difference` = `Model 2` - `Model 1`)
  
r2s %>% 
  gather()  %>% 
  # This line isn't necessary, but it sets the order the summaries appear in
  mutate(key = factor(key, levels = c("Model 1", "Model 2", "The R2 difference"))) %>% 
  group_by(key) %>% 
  summarize(mean = mean(value),
            median = median(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value,  probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 3 x 5
##   key                mean median     ll    ul
##   <fct>             <dbl>  <dbl>  <dbl> <dbl>
## 1 Model 1           0.071  0.067  0.012 0.156
## 2 Model 2           0.155  0.154  0.064 0.256
## 3 The R2 difference 0.084  0.084 -0.039 0.202
```

Interestingly, even though our posterior means and medians for the model-specific $R^2$ values differed some from the OLS estimates in the text, their difference corresponded quite nicely to the one in the text. Let's take a look at their distributions.


```r
r2s %>% 
  gather() %>% 
  ggplot(aes(x = value)) +
  geom_density(size = 0, fill = "grey33") +
  scale_y_continuous(NULL, breaks = NULL) +
  facet_wrap(~key, scales = "free_y") +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-5-1.png" width="768" />

The model coefficient summaries cohere well with those in Table 10.1. 


```r
print(model1, digits = 3)
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: liking ~ 1 + D1 + D2 + sexism 
##    Data: protest (Number of observations: 129) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample  Rhat
## Intercept    4.749     0.619    3.557    5.962       4000 1.000
## D1           0.497     0.233    0.036    0.958       4000 1.000
## D2           0.448     0.227    0.003    0.891       4000 1.000
## sexism       0.110     0.118   -0.118    0.340       4000 1.000
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample  Rhat
## sigma    1.044     0.067    0.918    1.184       4000 0.999
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

```r
print(model2, digits = 3)
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: liking ~ D1 + D2 + sexism + D1:sexism + D2:sexism 
##    Data: protest (Number of observations: 129) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample  Rhat
## Intercept    7.709     1.055    5.721    9.828       1502 1.001
## D1          -4.110     1.522   -7.057   -1.093       1551 1.000
## D2          -3.498     1.429   -6.246   -0.722       1415 1.001
## sexism      -0.473     0.206   -0.889   -0.077       1485 1.001
## D1:sexism    0.897     0.291    0.319    1.462       1524 1.001
## D2:sexism    0.778     0.279    0.239    1.318       1406 1.001
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample  Rhat
## sigma    1.006     0.064    0.890    1.143       2865 1.000
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

## Visualizing the model

To get our version of the values in Table 10.2, we'll first recreate columns for $D_{1}$ through $W$ (SEXISM) and save then as a tibble, `nd`.


```r
(
  nd <-
  tibble(D1 = rep(c(0, 1, 0), each = 3),
         D2 = rep(c(0, 0, 1), each = 3),
         sexism = rep(quantile(protest$sexism, probs = c(.16, .5, .84)), 
                      times = 3))
  )
```

```
## # A tibble: 9 x 3
##      D1    D2 sexism
##   <dbl> <dbl>  <dbl>
## 1     0     0   4.31
## 2     0     0   5.12
## 3     0     0   5.87
## 4     1     0   4.31
## 5     1     0   5.12
## 6     1     0   5.87
## 7     0     1   4.31
## 8     0     1   5.12
## 9     0     1   5.87
```

With `nd` in hand, we'll feed the predictor values into `fitted()` for the typical posterior summaries. 


```r
fitted(model2, newdata = nd) %>% round(digits = 3)
```

```
##       Estimate Est.Error  Q2.5 Q97.5
##  [1,]    5.673     0.221 5.245 6.106
##  [2,]    5.289     0.159 4.974 5.606
##  [3,]    4.934     0.231 4.474 5.390
##  [4,]    5.428     0.246 4.959 5.914
##  [5,]    5.772     0.155 5.474 6.072
##  [6,]    6.091     0.198 5.697 6.487
##  [7,]    5.528     0.198 5.148 5.930
##  [8,]    5.776     0.149 5.484 6.065
##  [9,]    6.005     0.213 5.593 6.427
```

But is we want to make a decent line plot, we'll need many more values for `sexism`, which will appear on the x-axis.


```r
nd <-
  tibble(sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                      times = 9),
         D1 = rep(rep(c(0, 1, 0), each = 3),
                  each = 30),
         D2 = rep(rep(c(0, 0, 1), each = 3),
                  each = 30))
```

This time we'll save the results from `fitted()` as a tlbble and wrangle a bit to get ready for Figure 10.3.


```r
model2_fitted <- 
  fitted(model2, newdata = nd, probs = c(.025, .25, .75, .975)) %>% 
  as_tibble() %>% 
  bind_cols(nd) %>% 
  mutate(condition = rep(c("No Protest", "Individual Protest", "Collective Protest"),
                         each = 3*30)) %>% 
  # This line is not necessary, but it will help order the facets of the plot
  mutate(condition = factor(condition, levels = c("No Protest", "Individual Protest", "Collective Protest"))) 

glimpse(model2_fitted)
```

```
## Observations: 270
## Variables: 10
## $ Estimate  <dbl> 6.054450, 6.005548, 5.956646, 5.907744, 5.858842, 5.809940, 5.761038, 5.71213...
## $ Est.Error <dbl> 0.3576588, 0.3386639, 0.3199649, 0.3016169, 0.2836879, 0.2662626, 0.2494467, ...
## $ Q2.5      <dbl> 5.366049, 5.352536, 5.338721, 5.324167, 5.308774, 5.295117, 5.279485, 5.26047...
## $ Q25       <dbl> 5.812538, 5.778561, 5.743566, 5.707137, 5.670806, 5.634155, 5.595954, 5.55770...
## $ Q75       <dbl> 6.290437, 6.231015, 6.170806, 6.110722, 6.052133, 5.991066, 5.932566, 5.87289...
## $ Q97.5     <dbl> 6.758325, 6.675455, 6.589070, 6.505128, 6.419579, 6.333093, 6.251963, 6.17586...
## $ sexism    <dbl> 3.500000, 3.603448, 3.706897, 3.810345, 3.913793, 4.017241, 4.120690, 4.22413...
## $ D1        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ D2        <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,...
## $ condition <fct> No Protest, No Protest, No Protest, No Protest, No Protest, No Protest, No Pr...
```

For Figure 10.3 and many to follow for this chapter, we'll superimpose 50% intervals on top of 95% intervals.


```r
# This will help us add the original data points to the plot
protest <-
  protest %>% 
  mutate(condition = ifelse(protest == 0, "No Protest",
                            ifelse(protest == 1, "Individual Protest", 
                                   "Collective Protest"))) %>% 
  mutate(condition = factor(condition, levels = c("No Protest", "Individual Protest", "Collective Protest"))) 
  

# This will help us with the x-axis
breaks <-
  tibble(values = quantile(protest$sexism, probs = c(.16, .5, .84))) %>% 
  mutate(labels = values %>% round(2) %>% as.character())

# Here we plot
model2_fitted %>% 
  ggplot(aes(x = sexism)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/3) +
  geom_ribbon(aes(ymin = Q25, ymax = Q75),
              alpha = 1/3) +
  geom_line(aes(y = Estimate)) +
  geom_point(data = protest,
             aes(y = liking),
             size = 2/3) +
  scale_x_continuous(breaks = breaks$values,
                     labels = breaks$labels) +
  coord_cartesian(xlim = 4:6,
                  ylim = c(2.5, 7.2)) +
  labs(x = expression(paste("Perceived Pervasiveness of Sex Discrimination in Society (", italic(W), ")")),
       y = "Evaluation of the Attorney") +
  facet_wrap(~condition) +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-11-1.png" width="960" />

By adding the data to the plots, they are both more informative and now serve as a posterior predictive check.

## Probing the interaction

### The pick-a-point approach.

#### Omnibus inference.

Hayes used the omnibus testing framework to assess how important coefficients $b_{1}$ and $b_{2}$ were to our interaction model, `model1`. Before fitting the models, he discussed why he preferred to fit models after centering `sexism` (i.e., $W$) to 4.25. Here we'll call our centered variable `sexism_p`, where `_p` stands in for "prime".


```r
protest <-
  protest %>% 
  mutate(sexism_p = sexism - 4.25)
```

From here on, `model3` is the moderation model without the lower-order `D1` and `D2` terms; `model4` is the full moderation model.


```r
# The model without D1 + D2
model3 <-
  update(model2,
         newdata = protest,
         liking ~ 1 + sexism_p + D1:sexism_p + D2:sexism_p,
         chains = 4, cores = 4)

# The full model with D1 + D2
model4 <-
  update(model2,
         newdata = protest,
         liking ~ 1 + D1 + D2 + sexism_p + D1:sexism_p + D2:sexism_p,
         chains = 4, cores = 4)
```

The coefficient summaries for `model4` correspond to the top section of Table 10.3 (p. 373).


```r
fixef(model4) %>% round(digits = 3)
```

```
##             Estimate Est.Error   Q2.5  Q97.5
## Intercept      5.692     0.230  5.227  6.141
## D1            -0.290     0.343 -0.962  0.386
## D2            -0.180     0.311 -0.791  0.424
## sexism_p      -0.466     0.209 -0.882 -0.046
## D1:sexism_p    0.892     0.288  0.320  1.458
## D2:sexism_p    0.774     0.277  0.232  1.339
```

We can compare their Bayesian $R^2$ distributions like we usually do.


```r
r2s <-
  bayes_R2(model3, summary = F) %>% 
  as_tibble() %>% 
  rename(`Model without D1 + D2` = R2) %>% 
  bind_cols(
    bayes_R2(model4, summary = F) %>% 
      as_tibble() %>% 
      rename(`Model with D1 + D2` = R2)
  ) %>% 
  mutate(`The R2 difference` = `Model with D1 + D2` - `Model without D1 + D2`)
  
r2s %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("Model without D1 + D2", "Model with D1 + D2", "The R2 difference"))) %>% 
  group_by(key) %>% 
  summarize(median = median(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value,  probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 3 x 4
##   key                   median     ll    ul
##   <fct>                  <dbl>  <dbl> <dbl>
## 1 Model without D1 + D2  0.14   0.051 0.244
## 2 Model with D1 + D2     0.154  0.063 0.255
## 3 The R2 difference      0.013 -0.123 0.149
```

Our results differ a bit from those in the text, but the substantive interpretation is the same. The `D1` and `D2` parameters added little predictive power to the model in terms of $R^2$. We can also use information criteria to compare the models. Here are the results from using the LOO-CV.


```r
loo(model3, model4,
    reloo = T)
```

```
##                  LOOIC    SE
## model3          371.84 22.04
## model4          374.88 21.90
## model3 - model4  -3.05  1.56
```

[When I ran the `loo()` without the `reloo` argument, I got a warning message about an observation with an overly-large pareto $k$ value. Setting `reloo = T` fixed the problem.]

The LOO-CV difference between the two models was pretty small and its standard error was of about the same magnitude of its difference. Thus, the LOO-CV gives the same general message as the $R^2$. The `D1` and `D2` parameters were sufficiently small and uncertain enough that constraining them to zero did little in terms of reducing the explanatory power of the statistical model. 

Here's the same thing all over again, but this time after centering `sexism` on 5.120.


```r
protest <-
  protest %>% 
  mutate(sexism_p = sexism - 5.120)

# The model without D1 + D2
model3 <-
  update(model2,
         newdata = protest,
         liking ~ 1 + sexism_p + D1:sexism_p + D2:sexism_p,
         chains = 4, cores = 4)

# The full model with D1 + D2
model4 <-
  update(model2,
         newdata = protest,
         liking ~ 1 + D1 + D2 + sexism_p + D1:sexism_p + D2:sexism_p,
         chains = 4, cores = 4)
```

These coefficient summaries correspond to the middle section of Table 10.3 (p. 373).


```r
fixef(model4) %>% round(digits = 3)
```

```
##             Estimate Est.Error   Q2.5  Q97.5
## Intercept      5.285     0.154  4.977  5.579
## D1             0.488     0.220  0.053  0.913
## D2             0.492     0.213  0.074  0.916
## sexism_p      -0.469     0.203 -0.867 -0.064
## D1:sexism_p    0.894     0.289  0.330  1.458
## D2:sexism_p    0.769     0.275  0.216  1.311
```

Here are the Bayesian $R^2$ summaries and the summary for their difference. 


```r
r2s <-
  bayes_R2(model3, summary = F) %>% 
  as_tibble() %>% 
  rename(`Model without D1 + D2` = R2) %>% 
  bind_cols(
    bayes_R2(model4, summary = F) %>% 
      as_tibble() %>% 
      rename(`Model with D1 + D2` = R2)
  ) %>% 
  mutate(`The R2 difference` = `Model with D1 + D2` - `Model without D1 + D2`)
  
r2s %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("Model without D1 + D2", "Model with D1 + D2", "The R2 difference"))) %>% 
  group_by(key) %>% 
  summarize(median = median(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value,  probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 3 x 4
##   key                   median     ll    ul
##   <fct>                  <dbl>  <dbl> <dbl>
## 1 Model without D1 + D2  0.1    0.029 0.193
## 2 Model with D1 + D2     0.153  0.066 0.253
## 3 The R2 difference      0.053 -0.074 0.175
```

And the LOO-CV:


```r
loo(model3, model4)
```

```
##                  LOOIC    SE
## model3          377.42 23.75
## model4          374.37 21.72
## model3 - model4   3.05  6.05
```

Here again our Bayesian $R^2$ and `loo()` results cohere, both suggesting the `D1` and `D2` parameters were of little predictive utility. Note how this differs a little from the second $F$-test on page 370. 

Here's what happens when we center `sexism` on 5.896.


```r
protest <-
  protest %>% 
  mutate(sexism_p = sexism - 5.896)

# The model without D1 + D2
model3 <-
  update(model2,
         newdata = protest,
         liking ~ 1 + sexism_p + D1:sexism_p + D2:sexism_p,
         chains = 4, cores = 4)

# The full model with D1 + D2
model4 <-
  update(model2,
         newdata = protest,
         liking ~ 1 + D1 + D2 + sexism_p + D1:sexism_p + D2:sexism_p,
         chains = 4, cores = 4)
```

These coefficient summaries correspond to the lower section of Table 10.3 (p. 373).


```r
fixef(model4) %>% round(digits = 3)
```

```
##             Estimate Est.Error   Q2.5  Q97.5
## Intercept      4.922     0.231  4.468  5.368
## D1             1.177     0.314  0.568  1.785
## D2             1.092     0.320  0.468  1.726
## sexism_p      -0.471     0.208 -0.879 -0.072
## D1:sexism_p    0.898     0.290  0.344  1.475
## D2:sexism_p    0.774     0.277  0.220  1.306
```

Again, the $R^2$ distributions and their difference-score distribution.


```r
r2s <-
  bayes_R2(model3, summary = F) %>% 
  as_tibble() %>% 
  rename(`Model without D1 + D2` = R2) %>% 
  bind_cols(
    bayes_R2(model4, summary = F) %>% 
      as_tibble() %>% 
      rename(`Model with D1 + D2` = R2)
  ) %>% 
  mutate(`The R2 difference` = `Model with D1 + D2` - `Model without D1 + D2`)
  
r2s %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("Model without D1 + D2", "Model with D1 + D2", "The R2 difference"))) %>% 
  group_by(key) %>% 
  summarize(median = median(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value,  probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 3 x 4
##   key                   median    ll    ul
##   <fct>                  <dbl> <dbl> <dbl>
## 1 Model without D1 + D2  0.028 0.003 0.09 
## 2 Model with D1 + D2     0.153 0.061 0.255
## 3 The R2 difference      0.121 0.018 0.23
```


```r
loo(model3, model4)
```

```
##                  LOOIC    SE
## model3          387.41 26.61
## model4          374.56 21.89
## model3 - model4  12.85 10.94
```

Although our Bayesian $R^2$ difference is now predominantly positive, the LOO-CV difference for the two models remains uncertain. Here's a look at the two parameters in question using a handmade coefficient plot.


```r
posterior_samples(model4) %>% 
  select(b_D1:b_D2) %>% 
  gather() %>% 
  mutate(key = str_remove(key, "b_")) %>% 
  
  ggplot(aes(key, y = value)) +
  stat_summary(fun.y = median,
               fun.ymin = function(i){quantile(i, probs = .025)},
               fun.ymax = function(i){quantile(i, probs = .975)},
               color = "grey33") +
  stat_summary(geom = "linerange",
               fun.ymin = function(i){quantile(i, probs = .25)},
               fun.ymax = function(i){quantile(i, probs = .75)},
               color = "grey33",
               size = 1.25) +
  xlab(NULL) +
  coord_flip(ylim = 0:2) +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-25-1.png" width="576" />

For Figure 10.4, we'll drop our faceting approach and just make one big plot. Heads up: I'm going to drop the 50% intervals from this plot. They'd just make it too busy.


```r
model2_fitted %>% 
  ggplot(aes(x = sexism, alpha = condition)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              size = 0) +
  geom_line(aes(y = Estimate)) +
  scale_alpha_manual(values = c(.2, .5, .8)) +
  scale_x_continuous(breaks = breaks$values,
                     labels = breaks$labels) +
  coord_cartesian(xlim = 4:6,
                  ylim = c(4.5, 6.7)) +
  labs(x = expression(paste("Perceived Pervasiveness of Sex Discrimination in Society (", italic(W), ")")),
       y = "Evaluation of the Attorney") +
  theme_minimal() +
  theme(legend.title = element_blank(),
        legend.position = "top",
        legend.direction = "vertical")
```

<img src="10_files/figure-html/unnamed-chunk-26-1.png" width="576" />

#### Pairwise inference.

To "consider the effect of Catherine's behavior on how she is perceived among people who are relatively high in their perceptions of the pervasiveness of sex discrimination in society (p. 372)", we'll use `fitted()`. Since the number of unique predictor values is small for this example, we'll just plug them directly into the `newdata` argument rather than first saving them as a `nd` object.


```r
fitted(model2,
       newdata = tibble(D1 = c(0, 1, 0),
                        D2 = c(0, 0, 1),
                        sexism = 5.896)) %>% 
  round(digits = 3)
```

```
##      Estimate Est.Error  Q2.5 Q97.5
## [1,]    4.922     0.235 4.455 5.383
## [2,]    6.102     0.202 5.698 6.506
## [3,]    6.013     0.216 5.596 6.440
```

Note that for these analyses, we just used `model2`, the model based on the un-centered `sexism` variable. We can also continue using `fitted()` in conjunction with the original `model2` to get the group comparisons for when $W$ = 4.250. Since these involve computing difference scores, we'll have to use `summary = F` and do some wrangling.


```r
fitted(model2,
       newdata = tibble(D1 = c(0, 1, 0),
                        D2 = c(0, 0, 1),
                        sexism = 4.25),
       summary = F) %>% 
  as_tibble() %>% 
  rename(`No Protest` = V1, 
         `Individual Protest` = V2,
         `Collective Protest` = V3) %>% 
  mutate(difference_a = `Individual Protest` - `No Protest`,
         difference_b = `Collective Protest` - `No Protest`) %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("No Protest", "Individual Protest", "Collective Protest", 
                                      "difference_a", "difference_b"))) %>% 
  group_by(key) %>% 
  summarize(mean = mean(value),
            sd = sd(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value, probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 5 x 5
##   key                  mean    sd     ll    ul
##   <fct>               <dbl> <dbl>  <dbl> <dbl>
## 1 No Protest          5.7   0.229  5.26  6.15 
## 2 Individual Protest  5.40  0.255  4.92  5.91 
## 3 Collective Protest  5.51  0.205  5.12  5.93 
## 4 difference_a       -0.297 0.349 -0.974 0.391
## 5 difference_b       -0.19  0.314 -0.784 0.427
```

Here's the same thing for when $W$ = 5.120.


```r
fitted(model2,
       newdata = tibble(D1 = c(0, 1, 0),
                        D2 = c(0, 0, 1),
                        sexism = 5.120),
       summary = F) %>% 
  as_tibble() %>% 
  rename(`No Protest` = V1, 
         `Individual Protest` = V2,
         `Collective Protest` = V3) %>% 
  mutate(difference_a = `Individual Protest` - `No Protest`,
         difference_b = `Collective Protest` - `No Protest`) %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("No Protest", "Individual Protest", "Collective Protest", 
                                      "difference_a", "difference_b"))) %>% 
  group_by(key) %>% 
  summarize(mean = mean(value),
            sd = sd(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value, probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 5 x 5
##   key                 mean    sd    ll    ul
##   <fct>              <dbl> <dbl> <dbl> <dbl>
## 1 No Protest         5.29  0.159 4.97  5.61 
## 2 Individual Protest 5.77  0.155 5.47  6.07 
## 3 Collective Protest 5.78  0.149 5.48  6.06 
## 4 difference_a       0.484 0.224 0.047 0.92 
## 5 difference_b       0.488 0.22  0.065 0.936
```

Finally, here it is for when $W$ = 5.986.


```r
fitted(model2,
       newdata = tibble(D1 = c(0, 1, 0),
                        D2 = c(0, 0, 1),
                        sexism = 5.986),
       summary = F) %>% 
  as_tibble() %>% 
  rename(`No Protest` = V1, 
         `Individual Protest` = V2,
         `Collective Protest` = V3) %>% 
  mutate(difference_a = `Individual Protest` - `No Protest`,
         difference_b = `Collective Protest` - `No Protest`) %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("No Protest", "Individual Protest", "Collective Protest", 
                                      "difference_a", "difference_b"))) %>% 
  group_by(key) %>% 
  summarize(mean = mean(value),
            sd = sd(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value, probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 5 x 5
##   key                 mean    sd    ll    ul
##   <fct>              <dbl> <dbl> <dbl> <dbl>
## 1 No Protest          4.88 0.249 4.38   5.36
## 2 Individual Protest  6.14 0.214 5.71   6.57
## 3 Collective Protest  6.04 0.228 5.60   6.49
## 4 difference_a        1.26 0.326 0.62   1.92
## 5 difference_b        1.16 0.341 0.499  1.84
```

### The Johnson-Neyman technique.

#### Omnibus inference.

Consider the first sentence of the section:

>Applied to probing an interaction between a multicategorical $X$ and a continuous $W$, an omnibus version of the JM technique involves finding the value or values of $W$ where their $F$-ratio comparing the $g$ estimated values of $Y$ is just statistically significant.

Since we're not using $F$-tests with our approach to Bayesian modeling, the closest we might have is a series of $R^2$ difference tests, which would require refitting the model multiple times over many ways of centering the $W$-variable, `sexism`. I suppose you could do this if you wanted, but it just seems silly, to me. I'll leave this one up to the interested reader.

#### Pairwise inference.

Hayes didn't make plots for this section, but if you're careful constructing your `nd` and with the subsequent wrangling, you can make the usual plots. Since we have two conditions we'd like to compare with *No Protest*, we'll make two plots. Here's the comparison using *Individual Protest*, first.


```r
# the transition value Hayes identified in the text
Hayes_value <- 5.065

nd <-
  tibble(D1 = rep(0:1, each = 30),
         D2 = rep(0, times = 30*2),
         sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                      times = 2))

# we need some new data
fitted(model2,
       newdata = nd,
       summary = F) %>% 
  as_tibble() %>% 
  gather() %>% 
  mutate(sexism = rep(rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                          each = 4000),
                      times = 2)) %>% 
  mutate(condition = rep(c("No Protest", "Individual Protest"),
                         each = 4000*30)) %>% 
  mutate(iter = rep(1:4000, times = 30*2)) %>% 
  select(-key) %>% 
  rename(estimate = value) %>% 
  spread(key = condition, value = estimate) %>% 
  mutate(difference = `Individual Protest` - `No Protest`) %>% 
  
  # the plot
  ggplot(aes(x = sexism, y = difference)) +
  stat_summary(geom = "ribbon",
               fun.ymin = function(i){quantile(i, probs = .025)},
               fun.ymax = function(i){quantile(i, probs = .975)},
               alpha = 1/3) +
  stat_summary(geom = "ribbon",
               fun.ymin = function(i){quantile(i, probs = .25)},
               fun.ymax = function(i){quantile(i, probs = .75)},
               alpha = 1/3) +
  stat_summary(geom = "line",
               fun.y = median) +
  scale_x_continuous(breaks = c(4, Hayes_value, 6),
                     labels = c("4", Hayes_value, "6")) +
  coord_cartesian(xlim = 4:6) +
  labs(subtitle = expression(paste("Our JN-technique plot for ", italic("Individual Protest"), " compared with ", italic("No Protest")))) +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-31-1.png" width="576" />

Now we're ready to compare *No Protest* to *Collective Protest*. The main difference is with the `rep()` code in the `D1` and `D2` columns in `nd`. Other than that, we just switched out a few "Individual" labels with "Collective".


```r
# the transition value Hayes identified in the text
Hayes_value <- 5.036

nd <-
  tibble(D1 = rep(0, times = 30*2),
         D2 = rep(0:1, each = 30),
         sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                      times = 2))

fitted(model2,
       newdata = nd,
       summary = F) %>% 
  as_tibble() %>% 
  gather() %>% 
  mutate(sexism = rep(rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                          each = 4000),
                      times = 2)) %>% 
  mutate(condition = rep(c("No Protest", "Collective Protest"),
                         each = 4000*30)) %>% 
  mutate(iter = rep(1:4000, times = 30*2)) %>% 
  select(-key) %>% 
  rename(estimate = value) %>% 
  spread(key = condition, value = estimate) %>% 
  mutate(difference = `Collective Protest` - `No Protest`) %>% 

  ggplot(aes(x = sexism, y = difference)) +
  stat_summary(geom = "ribbon",
               fun.ymin = function(i){quantile(i, probs = .025)},
               fun.ymax = function(i){quantile(i, probs = .975)},
               alpha = 1/3) +
  stat_summary(geom = "ribbon",
               fun.ymin = function(i){quantile(i, probs = .25)},
               fun.ymax = function(i){quantile(i, probs = .75)},
               alpha = 1/3) +
  stat_summary(geom = "line",
               fun.y = median) +
  scale_x_continuous(breaks = c(4, Hayes_value, 6),
                     labels = c("4", Hayes_value, "6")) +
  coord_cartesian(xlim = 4:6) +
  labs(subtitle = expression(paste("Our JN-technique plot for ", italic("Collective Protest"), " compared with ", italic("No Protest")))) +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-32-1.png" width="576" />

And here we do it one last time between the two active protest conditions.


```r
nd <-
  tibble(D1 = rep(1:0, each = 30),
         D2 = rep(0:1, each = 30),
         sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                      times = 2))

fitted(model2,
       newdata = nd,
       summary = F) %>% 
  as_tibble() %>% 
  gather() %>% 
  mutate(sexism = rep(rep(seq(from = 3.5, to = 6.5, length.out = 30), 
                          each = 4000),
                      times = 2)) %>% 
  mutate(condition = rep(c("Individual Protest", "Collective Protest"),
                         each = 4000*30)) %>% 
  mutate(iter = rep(1:4000, times = 30*2)) %>% 
  select(-key) %>% 
  rename(estimate = value) %>% 
  spread(key = condition, value = estimate) %>% 
  mutate(difference = `Collective Protest` - `Individual Protest`) %>% 
  
  ggplot(aes(x = sexism, y = difference)) +
  stat_summary(geom = "ribbon",
               fun.ymin = function(i){quantile(i, probs = .025)},
               fun.ymax = function(i){quantile(i, probs = .975)},
               alpha = 1/3) +
  stat_summary(geom = "ribbon",
               fun.ymin = function(i){quantile(i, probs = .25)},
               fun.ymax = function(i){quantile(i, probs = .75)},
               alpha = 1/3) +
  stat_summary(geom = "line",
               fun.y = median) +
  coord_cartesian(xlim = 4:6) +
  labs(subtitle = expression(paste("Our JN-technique plot for ", italic("Collective Protest"), " compared with ", italic("Individual Protest")))) +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-33-1.png" width="576" />

Not much difference there. 

## When the moderator is multicategorical

### An example.

Just as a refresher, here's the `print()` output for `model2`.


```r
print(model2, digits = 3)
```

```
##  Family: gaussian 
##   Links: mu = identity; sigma = identity 
## Formula: liking ~ D1 + D2 + sexism + D1:sexism + D2:sexism 
##    Data: protest (Number of observations: 129) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1;
##          total post-warmup samples = 4000
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample  Rhat
## Intercept    7.709     1.055    5.721    9.828       1502 1.001
## D1          -4.110     1.522   -7.057   -1.093       1551 1.000
## D2          -3.498     1.429   -6.246   -0.722       1415 1.001
## sexism      -0.473     0.206   -0.889   -0.077       1485 1.001
## D1:sexism    0.897     0.291    0.319    1.462       1524 1.001
## D2:sexism    0.778     0.279    0.239    1.318       1406 1.001
## 
## Family Specific Parameters: 
##       Estimate Est.Error l-95% CI u-95% CI Eff.Sample  Rhat
## sigma    1.006     0.064    0.890    1.143       2865 1.000
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).
```

The Bayesian $R^2$:


```r
bayes_R2(model2) %>% round(digits = 3)
```

```
##    Estimate Est.Error  Q2.5 Q97.5
## R2    0.155     0.049 0.064 0.256
```

And the $R^2$ difference between this and the model excluding the interaction terms:


```r
bayes_R2(model1, summary = F) %>% 
  as_tibble() %>% 
  rename(`Model 1` = R2) %>% 
  bind_cols(
    bayes_R2(model2, summary = F) %>% 
      as_tibble() %>% 
      rename(`Model 2` = R2)
  ) %>% 
  transmute(difference = `Model 2` - `Model 1`) %>% 
  summarize(mean = mean(difference),
            ll = quantile(difference, probs = .025),
            ul = quantile(difference,  probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 1 x 3
##    mean     ll    ul
##   <dbl>  <dbl> <dbl>
## 1 0.084 -0.039 0.202
```

Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3.


```r
# This will help us with the `geom_text()` annotation
slopes <-
  tibble(slope = c(fixef(model2)["sexism", "Estimate"] + fixef(model2)["D1:sexism", "Estimate"],
                   fixef(model2)["sexism", "Estimate"] + fixef(model2)["D2:sexism", "Estimate"],
                   fixef(model2)["sexism", "Estimate"]),
         x = c(4.8, 4.6, 5),
         y = c(6.37, 6.25, 4.5),
         condition = c("Individual Protest", "Collective Protest", "No Protest")) %>% 
  mutate(label = str_c("This slope is about ", slope %>% round(digits = 3)),
         condition = factor(condition, levels = c("No Protest", "Individual Protest", "Collective Protest")))

# Here we plot
model2_fitted %>% 
  ggplot(aes(x = sexism)) +
  geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5),
              alpha = 1/3) +
  geom_ribbon(aes(ymin = Q25, ymax = Q75),
              alpha = 1/3) +
  geom_line(aes(y = Estimate)) +
  geom_text(data = slopes,
            aes(x = x,
                y = y,
                label = label)) +
  coord_cartesian(xlim = 4:6) +
  labs(x = expression(paste("Perceived Pervasiveness of Sex Discrimination in Society (", italic(X), ")")),
       y = "Evaluation of the Attorney") +
  facet_wrap(~condition) +
  theme_minimal()
```

<img src="10_files/figure-html/unnamed-chunk-37-1.png" width="960" />

### Probing the interaction and interpreting the regression coefficients.

We computed the posterior means for the slopes when prepping for the figure, above. Here's how we might get more complete posterior summaries. Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3.


```r
post <- 
  posterior_samples(model2) %>% 
  transmute(`No Protest` = b_sexism + `b_D1:sexism`*0 + `b_D2:sexism`*0,
            `Individual Protest` = b_sexism + `b_D1:sexism`*1 + `b_D2:sexism`*0,
            `Collective Protest` = b_sexism + `b_D1:sexism`*0 + `b_D2:sexism`*1)

post %>% 
  gather() %>% 
  mutate(key = factor(key, levels = c("No Protest", "Individual Protest", "Collective Protest"))) %>% 
  group_by(key) %>% 
  summarise(mean = mean(value),
            sd = sd(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value, probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 3 x 5
##   key                  mean    sd     ll     ul
##   <fct>               <dbl> <dbl>  <dbl>  <dbl>
## 1 No Protest         -0.473 0.206 -0.889 -0.077
## 2 Individual Protest  0.424 0.204  0.007  0.824
## 3 Collective Protest  0.306 0.182 -0.063  0.655
```

Here are the differences among the three protest groups.


```r
post %>% 
  transmute(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`,
            `Collective Protest - No Protest` = `Collective Protest` - `No Protest`,
            `Individual Protest - Collective Protest` = `Individual Protest` - `Collective Protest`) %>% 
  gather() %>% 
  # again, not necessary, but useful for reordering the summaries
  mutate(key = factor(key, levels = c("Individual Protest - No Protest", "Collective Protest - No Protest", "Individual Protest - Collective Protest"))) %>% 
  group_by(key) %>% 
  summarise(mean = mean(value),
            sd = sd(value),
            ll = quantile(value, probs = .025),
            ul = quantile(value, probs = .975)) %>% 
  mutate_if(is.double, round, digits = 3)
```

```
## # A tibble: 3 x 5
##   key                                      mean    sd     ll    ul
##   <fct>                                   <dbl> <dbl>  <dbl> <dbl>
## 1 Individual Protest - No Protest         0.897 0.291  0.319 1.46 
## 2 Collective Protest - No Protest         0.778 0.279  0.239 1.32 
## 3 Individual Protest - Collective Protest 0.119 0.277 -0.431 0.643
```

## References {-}

[Hayes, A. F. (2018). *Introduction to mediation, moderation, and conditional process analysis: A regression-based approach.* (2nd ed.). New York, NY, US: The Guilford Press.](http://afhayes.com/introduction-to-mediation-moderation-and-conditional-process-analysis.html)

## Session info {-}


```r
sessionInfo()
```

```
## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.4
## 
## Matrix products: default
## BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
##  [1] brms_2.4.0      Rcpp_0.12.18    bindrcpp_0.2.2  forcats_0.3.0   stringr_1.3.1   dplyr_0.7.6    
##  [7] purrr_0.2.5     readr_1.1.1     tidyr_0.8.1     tibble_1.4.2    ggplot2_3.0.0   tidyverse_1.2.1
## 
## loaded via a namespace (and not attached):
##  [1] nlme_3.1-137         matrixStats_0.54.0   xts_0.10-2           lubridate_1.7.4     
##  [5] threejs_0.3.1        httr_1.3.1           rprojroot_1.3-2      rstan_2.17.3        
##  [9] tools_3.5.1          backports_1.1.2      utf8_1.1.4           R6_2.2.2            
## [13] DT_0.4               lazyeval_0.2.1       colorspace_1.3-2     withr_2.1.2         
## [17] tidyselect_0.2.4     gridExtra_2.3        mnormt_1.5-5         Brobdingnag_1.2-5   
## [21] compiler_3.5.1       cli_1.0.0            rvest_0.3.2          shinyjs_1.0         
## [25] xml2_1.2.0           labeling_0.3         colourpicker_1.0     bookdown_0.7        
## [29] scales_0.5.0         dygraphs_1.1.1.5     mvtnorm_1.0-8        psych_1.8.4         
## [33] ggridges_0.5.0       digest_0.6.15        StanHeaders_2.17.2   foreign_0.8-70      
## [37] rmarkdown_1.10       base64enc_0.1-3      pkgconfig_2.0.1      htmltools_0.3.6     
## [41] htmlwidgets_1.2      rlang_0.2.1          readxl_1.1.0         rstudioapi_0.7      
## [45] shiny_1.1.0          bindr_0.1.1          zoo_1.8-2            jsonlite_1.5        
## [49] gtools_3.8.1         crosstalk_1.0.0      inline_0.3.15        magrittr_1.5        
## [53] loo_2.0.0            bayesplot_1.5.0      Matrix_1.2-14        munsell_0.5.0       
## [57] abind_1.4-5          stringi_1.2.3        yaml_2.1.19          plyr_1.8.4          
## [61] grid_3.5.1           parallel_3.5.1       promises_1.0.1       crayon_1.3.4        
## [65] miniUI_0.1.1.1       lattice_0.20-35      haven_1.1.2          hms_0.4.2           
## [69] knitr_1.20           pillar_1.2.3         igraph_1.2.1         markdown_0.8        
## [73] shinystan_2.5.0      codetools_0.2-15     reshape2_1.4.3       stats4_3.5.1        
## [77] rstantools_1.5.0     glue_1.2.0           evaluate_0.10.1      modelr_0.1.2        
## [81] httpuv_1.4.4.2       cellranger_1.1.0     gtable_0.2.0         assertthat_0.2.0    
## [85] xfun_0.3             mime_0.5             xtable_1.8-2         broom_0.4.5         
## [89] coda_0.19-1          later_0.7.3          rsconnect_0.8.8      shinythemes_1.1.1   
## [93] bridgesampling_0.4-0
```
