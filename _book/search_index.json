[["index.html", "Recoding Introduction to Mediation, Moderation, and Conditional Process Analysis version 1.2.0 Welcome Why this? My assumptions about you How to use and understand this project Times change and so do we Thank-you’s are in order License and citation", " Recoding Introduction to Mediation, Moderation, and Conditional Process Analysis version 1.2.0 A Solomon Kurz 2021-08-02 Welcome Andrew Hayes’s (2018) text, Introduction to mediation, moderation, and conditional process analysis: A regression-based approach, has become a staple in social science graduate education. Hayes’s work has been from a frequentist OLS perspective. This book is an effort to connect his work with the Bayesian paradigm. Herein I refit his models with my favorite R (R Core Team, 2020) package for Bayesian regression, Paul Bürkner’s brms (Bürkner, 2017, 2018, 2020). I also prefer data wrangling and plotting using the tidyverse (Wickham, 2019; Wickham et al., 2019). But to be clear, this project is not meant to stand alone. It’s a supplement to the textbook. The source code of the project is available here. This project is powered by the great Yihui Xie’s bookdown package (Xie, 2016, 2020), which makes it easy to turn R markdown files into HTML, PDF, and EPUB. You might also check out Xie, Allaire, and Grolemund’s (2020) R markdown: The definitive guide. Why this? I’m not a statistician and I have no formal background in computer science. But I met a great statistics mentor in grad school who was enthusiastic, knowledgeable, and very generous with his time. In one of his stats electives, we used Hayes’s first edition text and I learned a lot in that semester. Yet a large portion of my training has been out of the classroom, working with messy real-world data, and looking online for help. One of the great resources I happened on was idre, the UCLA Institute for Digital Education. They perform a variety of services, but I benefited the most from was their portfolio of richly annotated textbook examples. Their online tutorials are among the earliest inspirations for this project. More so than my old statistics seminar lecture notes, high-quality and freely-available resources like this are where most of my day-to-day data analysis skills come from. We need more resources like this. Hayes’s work has become influential in many corners of the academy, including my own–psychology. His PROCESS macro (2018) has been aimed at SPSS (IBM Corporation, 2020) and SAS (SAS/IML Software, 2020) users, which is understandable given their popularity in the social sciences. Over the past few years, I’ve moved away from proprietary programs like SPSS to R. R free, open source, and I find it a more flexible and useful tool for data analysis. In fairness, Hayes expanded his second edition to include R code, which is a great move forward. But his work is done from a frequentist OLS perspective and there have been a lot of exciting developments in the world of applied Bayesian statistics. If you’re an R user and want to learn about Bayesian data analysis, I think Bürkner’s brms is the best package around. It’s flexible, uses reasonably-approachable syntax, has sensible defaults, and offers a wide array of post-processing convenience functions. In addition, the R code in Hayes’s second edition does not leverage the power of the tidyverse. The purpose of this project is to connect Hayes’s insights into regression with the Bayesian paradigm. We’ll do so within the free and open-source R ecosystem, highlighting the Bayesian brms package, and using functions from the tidyverse and friends (e.g., tidybayes, Kay, 2020b) to streamline our code. My assumptions about you If you’re looking at this project, I’m guessing you’re either a graduate student or a post-graduate academic or researcher of some sort, which comes with the presumption you have at least a 101-level foundation in statistics. If you’re rusty, check out Legler and Roback’s free (2019) text, Broadening your statistical horizons: Generalized linear models and multilevel models* or Navarro’s free (2019) text, Learning statistics with R. I’m also presuming you are at least vaguely familiar with Bayesian statistics. For those totally new to Bayesian regression and HMC estimation, look at Bürkner’s (2017) paper, watch a few of these engaging lectures, or even start with either of my (2021, 2020b) books based on the two (2020, 2015) editions of McElreath’s Statistical rethinking. I’m also presuming a basic working fluency in R and a vague idea about what the tidyverse is. If you’re totally new to R, consider starting with Peng’s (2019) R programming for data science. And the best introduction to the tidyvese-style of data analysis I’ve found is Grolemund and Wickham’s (2017) R for data science. That said, you do not need to be totally fluent in statistics or R. Otherwise why would you need this project, anyway? IMO, the most important things are curiosity, a willingness to try, and persistent tinkering. I love this stuff. Hopefully you will, too. How to use and understand this project This project is not meant to stand alone. It’s a supplement to the second edition of Hayes’s text. I follow the structure of his text, chapter by chapter, translating his analyses into brms and tidyverse code. However, many of the sections in the text are composed entirely of equations and prose, leaving us nothing to translate. When we run into those sections, the corresponding sections in this project will be sparse or blank. I imagine students might reference this project as they progress through Hayes’s text. I also imagine working data analysts might use this project in conjunction with Hayes’s text as they flip to the specific sections that seem relevant to solving their data challenges. I reproduce the bulk of the figures in the text, too. The plots in the first few chapters are the closest to those in the text. However, I’m passionate about data visualization and like to play around with color palettes, formatting templates, and other conventions quite a bit. As a result, the plots in each chapter have their own look and feel. I also like to highlight some of the unique strengths Bayesian analyses brings to the table, such as the ease with which you can depict uncertainty with density plots, interval ribbons around regression lines, and spaghetti plots. For more on some of these topics, chapters 3, 7, and 28 in R4DS, Healy’s (2018) Data visualization: A practical introduction, or Wickham’s (2016) ggplot2: Elegant graphics for data analysis. In this project, I use a handful of formatting conventions gleaned from R4DS and R markdown: The definitive guide. I put R and R packages (e.g., tidybayes) in boldface. R code blocks and their output appear in a gray background. E.g., 2 + 2 ## [1] 4 Functions are in a typewriter font and followed by parentheses, all atop a gray background (e.g., brm()). When I want to make explicit what packages a given function comes from, I insert the double-colon operator :: between the package name and the function (e.g., brms::fitted()). R objects, such as data or function arguments, are in typewriter font atop a gray background (e.g., d or size = 2). Hyperlinks are denoted by their typical blue-colored font. Times change and so do we For a brief rundown of the version history, we have: 1.0.0. I released the 1.0.0 version of this book in July of 2018. It was a complete first draft. 1.1.0. In December 21, 2019, came the 1.1.0 update. It included a lot of changes, the most notable of which were that, all models were refit with brms 2.10.3, the introduction to Bayesian information criteria reflected the updates introduced in brms 2.10.0, I updated the multivariate model code with the mvbind() and mvbf() functions, I made greater use of the handy tidybayes package for post-processing models, I updated and simplified a lot of the tidyverse code, all fit objects were assigned sequential names and were saved in .rda files in the fits folder on GitHub, I substantially increased the amount of Hayes quotes, I added more statistical formulas throughout the text, I added a version of Chapter 14, which includes warnings about relying on cross-sectional mediation, and the various R objects were assigned simpler and more standardized names. 1.2.0. Welcome to version 1.2.0! Noteworthy changes are that all models have been refit with brms 2.15.0; we have updated the in-text citations and reference sections using BibTex (BibTeX, 2020), Better BibTeX (Heyns, 2020), and zotero (Roy Rosenzweig Center for History and New Media, 2020); I fixed code breaks due to various updates in the tidyverse packages; and I fixed a handful of typos and other small gaffes. What’s next? It’s unclear what future versions of this book may hold. Candidates include more talk about model priors, examples of multilevel mediation, examples of longitudinal mediation, and sterner warnings against cross-sectional mediation. We’ll see. In the meantime, feel free to make suggestions or report typos and coding goofs at https://github.com/ASKurz/recoding-Hayes-2018/issues. Thank-you’s are in order Before we move on, I’d like to thank the following for their helpful contributions: Jose Storopoli (@storopoli) For information on how you might help improve this ebook, go to https://github.com/ASKurz/recoding-Hayes-2018/blob/master/CONTRIBUTING.md. License and citation This book is licensed under the Creative Commons Zero v1.0 Universal license. You can learn the details, here. In short, you can use my work. Just make sure you give me the appropriate credit the same way you would for any other scholarly resource. Here’s the citation information: @book{kurzRecodingIntroduction2021, title = {Recoding {{Introduction to Mediation, Moderation, and Conditional Process Analysis}}}, author = {Kurz, A. Solomon}, year = {2021}, month = {aug}, edition = {version 1.2.0}, url = {https://bookdown.org/content/b472c7b3-ede5-40f0-9677-75c3704c7e5c} } References BibTeX. (2020). http://www.bibtex.org/ Bürkner, P.-C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01 Bürkner, P.-C. (2018). Advanced Bayesian multilevel modeling with the R package brms. The R Journal, 10(1), 395–411. https://doi.org/10.32614/RJ-2018-017 Bürkner, P.-C. (2020). brms: Bayesian regression models using ’Stan’. https://CRAN.R-project.org/package=brms Grolemund, G., &amp; Wickham, H. (2017). R for data science. O’Reilly. https://r4ds.had.co.nz Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Healy, K. (2018). Data visualization: A practical introduction. Princeton University Press. https://socviz.co/ Heyns, E. (2020). Better BibTeX for zotero. https://retorque.re/zotero-better-bibtex/ IBM Corporation. (2020). IBM SPSS Statistics for Windows. https://www.ibm.com/products/spss-statistics Kay, M. (2020b). tidybayes: Tidy data and ’geoms’ for Bayesian models. https://mjskay.github.io/tidybayes/ Kurz, A. S. (2021). Statistical rethinking with brms, ggplot2, and the tidyverse: Second Edition (version 0.2.0). https://bookdown.org/content/4857/ Kurz, A. S. (2020b). Statistical rethinking with brms, ggplot2, and the tidyverse (version 1.2.0). https://doi.org/10.5281/zenodo.3693202 Legler, J., &amp; Roback, P. (2019). Broadening your statistical horizons: Generalized linear models and multilevel models. https://bookdown.org/roback/bookdown-bysh/ McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/ McElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. https://xcelab.net/rm/statistical-rethinking/ Navarro, D. (2019). Learning statistics with R. https://learningstatisticswithr.com Peng, R. D. (2019). R programming for data science. https://bookdown.org/rdpeng/rprogdatascience/ R Core Team. (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/ Roy Rosenzweig Center for History and New Media. (2020). Zotero. https://www.zotero.org/ SAS/IML software. (2020). https://www.sas.com/ Wickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2-book.org/ Wickham, H. (2019). tidyverse: Easily install and load the ’tidyverse’. https://CRAN.R-project.org/package=tidyverse Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686 Xie, Y. (2016). bookdown: Authoring books and technical documents with R markdown. Chapman and Hall/CRC. https://bookdown.org/yihui/bookdown/ Xie, Y. (2020). bookdown: Authoring books and technical documents with R Markdown. https://CRAN.R-project.org/package=bookdown Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2020). R markdown: The definitive guide. Chapman and Hall/CRC. https://bookdown.org/yihui/rmarkdown/ "],["introduction.html", "1 Introduction Session info", " 1 Introduction Research that establishes the mechanism or mechanisms by which effects operate or the conditions that facilitate and inhibit such effects deepens our understanding of the phenomena scientists study. Mediation analysis and moderation analysis are used to establish evidence or test hypotheses about such mechanisms and boundary conditions. Conditional process analysis is used when one’s research goal is to describe the boundary conditions of the mechanism or mechanisms by which a variable transmits its effect on another. Using a regression-based path-analytic framework, this book introduces the principles of mediation analysis, moderation analysis, and their unification as conditional process analysis. (Andrew F. Hayes, 2018, p. 3) Since there’s no code or data plots in this chapter, there’s nothing to translate. Enjoy an old video of Hayes promoting conditional process analysis, instead. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] magrittr_2.0.1 ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.22 assertthat_0.2.1 digest_0.6.27 R6_2.5.0 ## [5] jsonlite_1.7.2 evaluate_0.14 httr_1.4.2 rlang_0.4.11 ## [9] stringi_1.6.2 curl_4.3 jquerylib_0.1.4 bslib_0.2.4 ## [13] rmarkdown_2.8 tools_4.0.4 stringr_1.4.0 glue_1.4.2 ## [17] xfun_0.23 compiler_4.0.4 vembedr_0.1.4 htmltools_0.5.1.1 ## [21] knitr_1.33 sass_0.3.1 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 "],["fundamentals-of-linear-regression.html", "2 Fundamentals of Linear Regression 2.1 Correlation and prediction 2.2 The simple linear regression model 2.3 Alternative explanations for association 2.4 Multiple linear regression 2.5 Measures of model fit 2.6 Statistical inference 2.7 Multicategorical antecedent variables 2.8 Assumptions for interpretation and statistical inference Session info Footnote", " 2 Fundamentals of Linear Regression Linear regression is the foundation of most of the methods [Hayes described in his] book, so a solid understanding of the fundamentals of linear regression is essential. I assume that most readers have been exposed to linear regression in some form before discovering this book, and so some of the material will be review. Even so, I encourage everyone to read this chapter. (Andrew F. Hayes, 2018, p. 30) Since we’re adding Bayes and the tidyverse into the mix, walking through this chapter will be double important, for us. 2.1 Correlation and prediction Here we load a couple necessary packages, load the data, and take a peek. library(tidyverse) glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) ## Rows: 815 ## Columns: 7 ## $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1.0, 2.6, 5… ## $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.67, 3.00, 1… ## $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.67, 2.00, 1… ## $ ideology &lt;dbl&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, 5, 4, 5, 4… ## $ age &lt;dbl&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 38, 63, 71,… ## $ sex &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0… ## $ partyid &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1, 1, 1… If you are new to tidyverse-style syntax, possibly the oddest component is the pipe (i.e., %&gt;%). I’m not going to explain the %&gt;% in this project, but you might learn more about in this brief clip, starting around minute 21:25 in this talk by Wickham, or in Section 5.6.1 from Grolemund &amp; Wickham (2017). Really, all of Chapter 5 of R4DS is great for new R and new tidyverse users, and Chapter 3 is a nice introduction to plotting with ggplot2. Here is our version of Figure 2.1. glbwarm %&gt;% group_by(negemot, govact) %&gt;% count() %&gt;% ggplot(aes(x = negemot, y = govact, size = n)) + geom_point(show.legend = F) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + theme_bw() There are other ways to handle the overplotting issue, such as jittering. glbwarm %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + theme_bw() The cor() function is a simple way to compute a Pearson’s correlation coefficient. cor(glbwarm$negemot, glbwarm$govact) ## [1] 0.5777458 If you want more plentiful output, the cor.test() function returns a \\(t\\)-value, the degrees of freedom, the corresponding \\(p\\)-value and the 95% confidence intervals, in addition to the Pearson’s correlation coefficient. cor.test(glbwarm$negemot, glbwarm$govact) ## ## Pearson&#39;s product-moment correlation ## ## data: glbwarm$negemot and glbwarm$govact ## t = 20.183, df = 813, p-value &lt; 2.2e-16 ## alternative hypothesis: true correlation is not equal to 0 ## 95 percent confidence interval: ## 0.5301050 0.6217505 ## sample estimates: ## cor ## 0.5777458 To get the Bayesian version, we’ll open our focal statistical package, Bürkner’s brms. I should briefly note that you could also do many of these analyses with other packages, such as blavaan (Merkle et al., 2020; Merkle &amp; Rosseel, 2018) or rstanarm (Brilleman et al., 2018; Gabry &amp; Goodrich, 2020). I just prefer brms. library(brms) We’ll start simple and just use the default priors and settings, but with the addition of parallel sampling via cores = 4 and telling brms to save our output as an extermal file with the file argument. model2.1 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot, govact) ~ 1, cores = 4, file = &quot;fits/model02.01&quot;) We can examine a summary of the output with the print() function. print(model2.1) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot ~ 1 ## govact ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemot_Intercept 3.56 0.05 3.46 3.67 1.00 3847 2915 ## govact_Intercept 4.59 0.05 4.49 4.68 1.00 3860 3202 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemot 1.53 0.04 1.46 1.60 1.00 3646 3217 ## sigma_govact 1.36 0.03 1.30 1.43 1.00 3536 3062 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemot,govact) 0.58 0.02 0.53 0.62 1.00 3606 3334 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In regression models, we typically use predictor variables to explain variation in our criterion variables. It’s pretty much never the case that our predictors explain all the variation. The variation that’s left over is often called residual variation, residual variance, residuals, error, or even \\(\\epsilon\\). Throughout the text, Hayes typically referred to it as \\(e\\). More formally, when we use likelihood-based estimators, such as maximum likelihood (popular with multilevel modeling and structural equation modeling) or Bayesian estimators, we express the models for our criterion variables in terms of likelihood functions. Probably the most common likelihood function, and the one consistent with the models in Hayes’s text, is the Gaussian likelihood. With that likelihood we say our criterion variable \\(y_i\\) is normally distributed with a mean \\(\\mu\\) and standard deviation \\(\\sigma\\). We might express that formally as \\[ y_i \\sim \\operatorname{Normal} (\\mu, \\sigma), \\] where \\(\\sim\\) stands for “is distributed as” and \\(i\\) indexes the \\(i\\)th row in the data. When we add predictors to the model, they are typically used to model the mean \\(\\mu\\). Thus, in the case there we have a sole predictor \\(x_i\\) which varies across participants, we’d expand our model formula to \\[\\begin{align*} y_i &amp; \\sim \\operatorname{Normal} (\\mu_i, \\sigma) \\\\ \\mu_i &amp; = \\beta_0 + \\beta_1 x_i, \\end{align*}\\] where \\(\\beta_0\\) is the intercept and \\(\\beta_1\\) is the slope for predictor \\(x\\), which varies across cases. In this formulation, \\(\\sigma\\) is the standard deviation after accounting for the systemic variation explained by \\(x_i\\). That is, it’s the residual variance (i.e., \\(\\epsilon\\)), but in a standard-deviation metric. Why in a standard deviation metric?, you ask. There are technical reasons why brms expresses it as a standard deviation which I’m not going to go into, here. Just beware that whereas many frequentist software packages express the residual variation in a variance metric, it’s expressed in a standard-deviation metric in brms. Just go with it and move on. Within the brms framework, \\(\\sigma\\) of the Gaussian likelihood is considered a “family-specific” parameter. As it turns out, there are many other fine likelihood functions in addition to the Gaussian and not all of them have a \\(\\sigma\\) parameter. For example, there is no \\(\\sigma\\) for the Poisson1 distribution, which is popular likelihood function for count variables. Because Bürkner made the brms package capable of a variety of likelihood functions, it behooved him to give this section of the output a generic name. When you have a regression model with multiple Gaussian criterion variables, those variables will typically have some degree of covariation. It’s often termed residual covariance, particularly within the structural equation modeling paradigm.2 But when you have an intercept-only regression model with multiple variables, that residual covariance is just a covariance. And when you express those variation parameters in terms of standard deviations \\(\\sigma\\), their covariance is expressed as a correlation \\(\\rho\\). Since our multivariate model is of two variables, we have one \\(\\rho\\) parameter for the \\(\\sigma\\)s, rescor(negemot,govact), which is our Bayesian analogue to the Pearson’s correlation. To learn more about the multivariate syntax in brms, check out Bürkner’s (2021b) vignette, Estimating multivariate models with brms, or execute vignette(\"brms_multivariate\"). Or just hold your horses until we get into mediation. All of our mediation models will use one version of the multivariate syntax or another. But to clarify the output, above: ‘Estimate’ = the posterior mean, analogous to the frequentist point estimate, ‘Est.Error’ = the posterior \\(SD\\), analogous to the frequentist standard error, ‘l-95% CI’ = the lower-level of the percentile-based 95% Bayesian credible interval, and ‘u-95% CI’ = the upper-level of the same. 2.2 The simple linear regression model Here is how one might get the simple OLS coefficients in base R with the lm() function. (model2.2 &lt;- lm(data = glbwarm, govact ~ 1 + negemot)) ## ## Call: ## lm(formula = govact ~ 1 + negemot, data = glbwarm) ## ## Coefficients: ## (Intercept) negemot ## 2.7573 0.5142 For more detailed output, put the model object model2.2 into the summary() function. summary(model2.2) ## ## Call: ## lm(formula = govact ~ 1 + negemot, data = glbwarm) ## ## Residuals: ## Min 1Q Median 3Q Max ## -4.3285 -0.6731 0.1018 0.7554 3.2142 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.75732 0.09866 27.95 &lt;2e-16 *** ## negemot 0.51424 0.02548 20.18 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 1.111 on 813 degrees of freedom ## Multiple R-squared: 0.3338, Adjusted R-squared: 0.333 ## F-statistic: 407.3 on 1 and 813 DF, p-value: &lt; 2.2e-16 Here’s the Bayesian model in brms. model2.3 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot, cores = 4, file = &quot;fits/model02.03&quot;) There are several ways to get a brms model summary. A go-to is with the summary() function, just like we did with our OLS model. summary(model2.3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 2.75 0.10 2.56 2.95 1.00 4151 2948 ## negemot 0.51 0.03 0.47 0.56 1.00 4033 3164 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.11 0.03 1.06 1.17 1.00 4139 2902 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The print() function works very much the same way. To get a more focused look, you can use the posterior_summary() function: posterior_summary(model2.3) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 2.7540133 0.09928784 2.563757 2.9547102 ## b_negemot 0.5149687 0.02542118 0.465310 0.5645472 ## sigma 1.1127290 0.02734424 1.060580 1.1670321 ## lp__ -1245.9491225 1.22875310 -1249.141482 -1244.5570274 That also yields the log posterior, lp__, which you can learn more about in this section of the (2020) vignette by the Stan Development Team, RStan: the R interface to Stan or this brief blog post by Xulong Wang. We won’t focus on the lp__ directly in this project. But its influence will be lurking in the shadows. But anyways, the Q2.5 and Q97.5, are the lower- and upper-levels of the 95% credible intervals. The Q prefix stands for quantile (see this thread). In this case, these are a renamed version of the l-95% CI and u-95% CI columns from our summary() output. To make a quick plot of the regression line, one can use the convenient brms::conditional_effects() function. conditional_effects(model2.3) If you want to customize that output, you might nest it in plot(). plot(conditional_effects(model2.3), points = T, point_args = c(height = .05, width = .05, alpha = 1/2, size = 1/3)) It’s also useful to be able to work with the output of a brms model directly. For our first step, we’ll put our posterior draws into a data frame with the posterior_samples() function. post &lt;- posterior_samples(model2.3) head(post) ## b_Intercept b_negemot sigma lp__ ## 1 2.767022 0.5145552 1.094959 -1244.656 ## 2 2.867891 0.4886331 1.087075 -1245.484 ## 3 2.623920 0.5498508 1.126685 -1245.598 ## 4 2.499840 0.5814869 1.082886 -1248.757 ## 5 2.609229 0.5429867 1.117016 -1245.807 ## 6 2.889080 0.4979026 1.085575 -1246.963 Next, we’ll use the fitted() function to simulate model-implied summaries for the expected govact value, given particular predictor values. Our first model only has negemot as a predictor, and we’ll ask for the expected govact values for negemot ranging from 0 to 7. nd &lt;- tibble(negemot = seq(from = 0, to = 7, length.out = 30)) f &lt;- fitted(model2.3, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) head(f) ## Estimate Est.Error Q2.5 Q97.5 negemot ## 1 2.754013 0.09928784 2.563757 2.954710 0.0000000 ## 2 2.878316 0.09367707 2.698105 3.067791 0.2413793 ## 3 3.002619 0.08813636 2.833752 3.181095 0.4827586 ## 4 3.126922 0.08267978 2.968901 3.294023 0.7241379 ## 5 3.251224 0.07732515 3.103658 3.407770 0.9655172 ## 6 3.375527 0.07209519 3.236972 3.520894 1.2068966 The first two columns should look familiar to the output from summary(model2.3), above. The next two columns, Q2.5 and Q97.5, are the lower- and upper-levels of the 95% credible intervals, like we got from posterior_samples(). The final column is the result of the bind_cols(nd) code. Here’s our bespoke version of Figure 2.4. glbwarm %&gt;% group_by(negemot, govact) %&gt;% count() %&gt;% ggplot(aes(x = negemot)) + geom_point(aes(y = govact, size = n), show.legend = F) + geom_ribbon(data = f, aes(ymin = Q2.5, ymax = Q97.5), fill = &quot;grey75&quot;, alpha = 3/4) + geom_line(data = f, aes(y = Estimate)) + annotate(&quot;text&quot;, x = 2.2, y = 7.5, label = &quot;Cases with positive residuals&quot;, color = &quot;red3&quot;) + annotate(&quot;text&quot;, x = 4.75, y = .8, label = &quot;Cases with negative residuals&quot;, color = &quot;blue3&quot;) + labs(x = expression(&quot;NEGEMOT: Negative emotions about climate change (&quot;*italic(&quot;X&quot;)*&quot;)&quot;), y = expression(&quot;GOVACT: Support for governmentaction (&quot;*italic(&quot;Y&quot;)*&quot;)&quot;)) + coord_cartesian(xlim = range(glbwarm$negemot)) + theme_bw() Note how that figure is a combination of the original glbwarm data and our f output. 2.2.1 Interpretation of the constant and regression coefficient. “The regression constant is conceptually equivalent to the \\(Y\\)-intercept in the equation for a line. It quantifies the estimated value of \\(Y\\) when \\(X = 0\\)” (p. 39). 2.2.2 The standardized regression model. Thus far, the interpretation of the regression coefficients in a regression model has been couched in unstandardized or raw metric form. Many regression routines will also produce a version of the model in standardized form. The standardized regression model is what results when all variables are first standardized prior to estimation of the model by expressing each measurement in units of standard deviations from the sample mean. (p. 40, emphasis in the original) brms will not produce standardized solutions on the fly. To get them, you will have to manually standardize the variables before entering them into the model. 2.2.3 Simple linear regression with a dichotomous antecedent variable. In the glbwarm data, sex is a dichotomous variable. glbwarm %&gt;% ggplot(aes(x = sex)) + geom_bar() + theme_bw() In these data, sex is coded females = 0, males = 1. Here we add sex to the model. model2.4 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + sex, cores = 4, file = &quot;fits/model02.04&quot;) Check the summary. print(model2.4) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + sex ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.72 0.07 4.58 4.84 1.00 4426 3139 ## sex -0.27 0.10 -0.45 -0.09 1.00 4394 3241 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.36 0.03 1.30 1.42 1.00 4813 2607 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our model summary is very close to that in the text. If you just wanted the coefficients, you might use the fixef() function. fixef(model2.4) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.718 0.067 4.584 4.844 ## sex -0.267 0.095 -0.452 -0.086 Though not necessary, we used the round() function to reduce the number of significant digits in the output. You can get a little more information with the posterior_summary() function. But since Bayesian estimation yields an entire posterior distribution, you can visualize that distribution in any number of ways. Because we’ll be using ggplot2, we’ll need to put the posterior draws into a data frame before plotting. post &lt;- posterior_samples(model2.4) We could summarize the posterior with box plots post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% pivot_longer(cols = c(male, female)) %&gt;% ggplot(aes(x = name, y = value)) + geom_boxplot(aes(fill = name)) + theme_bw() + theme(legend.position = &quot;none&quot;) or with overlapping density plots post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% pivot_longer(cols = c(male, female)) %&gt;% ggplot(aes(x = value, group = name, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = 3/4) + theme_bw() or even with violin plots with superimposed posterior medians and 95% intervals. post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% pivot_longer(cols = c(male, female)) %&gt;% ggplot(aes(x = name, y = value)) + geom_violin(aes(fill = name), color = &quot;transparent&quot;, alpha = 3/4) + stat_summary(fun = median, fun.min = function(i){quantile(i, probs = .025)}, fun.max = function(i){quantile(i, probs = .975)}) + theme_bw() + theme(legend.position = &quot;none&quot;) For even more ideas, see Matthew Kay’s tidybayes and ggdist packages. As Hayes discussed on page 42, you can also get a sense of the model estimates for women and men with a little addition. Here we continue to use the round() function to simplify the output. # for women round(fixef(model2.4)[1, ], digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## 4.72 0.07 4.58 4.84 # for men round(fixef(model2.4)[1, ] + fixef(model2.4)[2, ], digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## 4.45 0.16 4.13 4.76 Hayes then considered that although the model will always generate the group means, the regression coefficient and regression constant will depend on how the two groups are coded. For instance, suppose females were coded \\(X = −1\\) and males were coded \\(X = 1\\). (p. 42) To follow along, we’ll first recode sex, saving it as sex_recode. glbwarm &lt;- glbwarm %&gt;% mutate(sex_recode = if_else(sex == 0, -1, 1)) Now fit the new model. model2.5 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + sex_recode, cores = 4, file = &quot;fits/model02.05&quot;) Check the primary coefficients. fixef(model2.5) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.5836570 0.04712046 4.4894107 4.67767899 ## sex_recode -0.1341268 0.04747433 -0.2239347 -0.04134183 They match up well with the results in the middle of page 42. Now the Intercept in the output, what Hayes called \\(i_Y\\) is the unweighted mean of the means, \\(\\big (\\overline Y_\\text{male} + \\overline Y_\\text{female} \\big ) \\big / 2\\), and the coefficient sex_recode (i.e., what Hayes called \\(b\\)) is one half the difference between those means. Here’s how to work with the posterior draws from this model to reproduce the group mean estimates. posterior_samples(model2.5) %&gt;% transmute(male = b_Intercept + b_sex_recode * 1, female = b_Intercept + b_sex_recode * -1) %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value, group = name, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = 3/4) + theme_bw() You’ll see it looks just like the plot from above. 2.2.3.1 A caution about the standardized regression coefficient. The standardized regression coefficient is a function of both the mean difference and the distribution of the cases across the groups. This is an undesirable property of \\(\\tilde b\\) when \\(X\\) is dichotomous. I recommend that the standardized regression coefficient for a dichotomous antecedent variable not be interpreted or reported. If you desire an index of a mean difference in standard deviation units, I recommend standardizing \\(Y\\) but not the dichotomous \\(X\\) and then interpreting the unstandardized regression coefficient in a model estimating \\(Z_Y\\) from \\(X\\). In such a model, \\(b\\) is a partially standardized regression coefficient. (pp. 43–44, emphasis in the original) Here’s how to fit the partially-standardized model, first with lm(). # standardize the Y glbwarm &lt;- glbwarm %&gt;% mutate(govact_z = (govact - mean(govact)) / sd(govact)) # fit the model lm(data = glbwarm, govact_z ~ 1 + sex) ## ## Call: ## lm(formula = govact_z ~ 1 + sex, data = glbwarm) ## ## Coefficients: ## (Intercept) sex ## 0.09629 -0.19717 Now we’ll fit the model as Bayesians with brms::brm(). model2.6 &lt;- brm(data = glbwarm, family = gaussian, govact_z ~ 1 + sex, cores = 4, file = &quot;fits/model02.06&quot;) fixef(model2.6) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 0.09806048 0.04916014 0.002503287 0.19352628 ## sex -0.19819950 0.07238316 -0.338236658 -0.05537654 The constant \\(i_Y\\) is the mean standardized \\(Y\\) for females, and \\(b\\) is the mean difference between males and females in standard deviations of \\(Y\\). So men are estimated to differ from women by 0.197 standard deviations in their support for government action. The negative sign for \\(b\\) means males are lower than females, on average, in their support. (p. 44) The result from our Bayesian model was the same as the OLS results up to two decimal places. This will often be the case. One is not more correct. They are the results of using different procedures. 2.2.4 A note on symbolic representations. This section is worthy of repeating in full. A brief digression is in order at this point. It is important when reporting the results of an analysis to define the symbols you use unless there is a strong convention, for a failure to do so can invite confusion. Different uses of \\(b\\) and \\(\\beta\\) in regression analysis are an important case in point. There is much inconsistency in the substantive and methodology literature as to how regression coefficients are symbolized in unstandardized versus standardized form. Some use \\(b\\) or \\(B\\) to refer to the unstandardized regression coefficient and \\(\\beta\\) to refer to the standardized regression coefficient. Others, rather than using \\(\\beta\\), spell it out by referencing “beta weights” or just talk about the “betas.” Some use \\(\\beta\\) to refer to a population regression coefficient, to distinguish it from a sample estimate, others use \\(\\beta\\) as the unstandardized regression weight, and there are still others who use \\(\\hat \\beta\\) to refer to a sample unstandardized regression coefficient and leave the hat off for its corresponding population or “true” value. In this book, I use \\(\\tilde \\beta\\) for the standardized regression weight. Ultimately, the symbols we use are for the most part arbitrary. We can use any symbols we want. My point is that you should not assume others will know what symbols you use mean, for your familiar symbols to represent certain concepts may not be understood as representing those concepts by all. The same applies to terms such as “beta coefficient” or other verbalizations of symbols. Best to define your symbols in advance, or otherwise let your reader know what your symbols mean when used in text and tables. This will help others better understand and interpret your work. (p. 44) 2.3 Alternative explanations for association That “correlation does not imply causation” is etched into the brains of all scientists. If variables \\(X\\) and \\(Y\\) are correlated, that doesn’t mean that \\(X\\) causes \\(Y\\) or that \\(Y\\) causes \\(X\\). The ability to infer cause–effect is not even a statistical matter in the end. Rather, it is the design of one’s study, the data collection procedures one employs, and theoretical plausibility that most directly influence whether a cause–effect claim can be made and with what degree of confidence, not the size or sign of a statistical index of association. (p. 45) On page 46, Hayes produced a couple correlations. Here’s how to get them from base R. cor(glbwarm$sex, glbwarm$negemot) ## [1] -0.1173564 cor(glbwarm$sex, glbwarm$govact) ## [1] -0.09861854 Again, if we wanted to get full Bayesian estimates, we’d fit an intercept-only multivariate model. model2.7 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot, govact, sex) ~ 1, cores = 4, file = &quot;fits/model02.07&quot;) print(model2.7, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot ~ 1 ## govact ~ 1 ## sex ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemot_Intercept 3.559 0.053 3.459 3.662 1.000 4218 3306 ## govact_Intercept 4.588 0.048 4.496 4.683 1.001 4700 3239 ## sex_Intercept 0.488 0.017 0.455 0.521 1.000 5659 3163 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemot 1.531 0.037 1.459 1.605 1.001 4469 3391 ## sigma_govact 1.362 0.033 1.298 1.430 1.000 4338 3168 ## sigma_sex 0.502 0.012 0.479 0.526 1.001 6077 2916 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemot,govact) 0.576 0.024 0.528 0.620 1.002 4178 3378 ## rescor(negemot,sex) -0.117 0.034 -0.186 -0.051 1.001 6999 3105 ## rescor(govact,sex) -0.099 0.033 -0.163 -0.033 1.000 6400 3478 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). For our purposes, the action is in the ‘rescor(\\(i\\), \\(j\\))’ portions of the ‘Family Specific Parameters’ section. Anyway, if you wanted to get all the Pearson’s correlations among the glbwarm variables, rather than piecewise cor() approach, you could use the lowerCor() function from the psych package (Revelle, 2021). psych::lowerCor(glbwarm[, 1:7], digits = 3) ## govct posmt negmt idlgy age sex prtyd ## govact 1.000 ## posemot 0.043 1.000 ## negemot 0.578 0.128 1.000 ## ideology -0.418 -0.029 -0.349 1.000 ## age -0.097 0.042 -0.057 0.212 1.000 ## sex -0.099 0.074 -0.117 0.133 0.166 1.000 ## partyid -0.360 -0.036 -0.324 0.619 0.154 0.109 1.000 2.4 Multiple linear regression The simple linear regression model is easily extended to the estimation of a consequent variable using more than one antecedent variable. Including more than one antecedent in a regression model allows you to simultaneously investigate the role of multiple influences on a consequent variable. An additional and important benefit of the multiple regression model is that it provides various measures of partial association that quantify the component of the association between an antecedent and a consequent that is unique to that antecedent relative to other antecedent variables in the model. (p. 48, emphasis in the original) Using Hayes’ notation, the model we’re about follows the basic equation \\[\\hat Y = i_Y + b_1 X_1 + b_2 X_2 + b_3 X_3 + b_4 X_4 + b_4 X_5.\\] For us, there’s technically more involved because our Bayesian paradigm includes priors, which we’re not focusing on at the moment. Anyway, there’s nothing particularly special about jumping from univariable to multivariable models with brms. You just keep tacking on predictors with the + operator. model2.8 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + posemot + ideology + sex + age, cores = 4, file = &quot;fits/model02.08&quot;) print(model2.8) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + posemot + ideology + sex + age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.06 0.20 3.67 4.45 1.00 5516 3355 ## negemot 0.44 0.03 0.39 0.49 1.00 5423 3142 ## posemot -0.03 0.03 -0.08 0.03 1.00 5623 2992 ## ideology -0.22 0.03 -0.27 -0.17 1.00 5696 2899 ## sex -0.01 0.08 -0.16 0.14 1.00 5693 2963 ## age -0.00 0.00 -0.01 0.00 1.00 5491 3287 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.07 0.03 1.02 1.12 1.00 6250 2795 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Following Hayes on pages 50 and 51, here is the posterior mean (i.e., what you might call the Bayesian point estimate) for someone with negative emotions = 3, positive emotions = 4, ideology = 2, is male (i.e., sex = 1), and is 30 years of age. fixef(model2.8)[1] + fixef(model2.8)[2] * 3 + fixef(model2.8)[3] * 4 + fixef(model2.8)[4] * 2 + fixef(model2.8)[5] * 1 + fixef(model2.8)[6] * 30 ## [1] 4.794097 Here’s the same deal for a man of the same profile, but with one point higher on negemot. fixef(model2.8)[1] + fixef(model2.8)[2] * 4 + fixef(model2.8)[3] * 4 + fixef(model2.8)[4] * 2 + fixef(model2.8)[5] * 1 + fixef(model2.8)[6] * 30 ## [1] 5.234862 If you want a full expression of the model uncertainty in terms of the shape of the posterior distribution and the 95% intervals, you’ll probably just want to use posterior_samples() and do a little data processing. post &lt;- posterior_samples(model2.8) post &lt;- post %&gt;% mutate(our_posterior = b_Intercept + b_negemot * 4 + b_posemot * 4 + b_ideology * 2 + b_sex * 1 + b_age * 30) # this intermediary step will make it easier to specify the break points and their labels for the x-axis post_summary &lt;- quantile(post$our_posterior, probs = c(.025, .5, .975)) %&gt;% as_tibble() %&gt;% mutate(labels = value %&gt;% round(digits = 3) %&gt;% as.character()) # plot! ggplot(data = post, aes(x = our_posterior)) + geom_density(fill = &quot;black&quot;) + geom_vline(xintercept = post_summary$value, size = c(.5, .75, .5), linetype = c(2, 1, 2), color = &quot;white&quot;) + scale_x_continuous(NULL, breaks = post_summary$value, labels = post_summary$labels) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The expected govact score for a 30-year-old man for\\nwhom negemot and posemot both equal 4 and ideology\\nequals 2. The solid and dashed white vertical lines are the\\nposterior median and 95% intervals, respectively.&quot;) + theme_bw() In the text, Hayes showed that individuals based on these two profiles would be expected to differ by 0.441 (i.e., \\(5.244 - 4.803 = 0.441\\)). That’s fine if you’re only working with OLS point estimates. But a proper Bayesian approach would express the difference in terms of an entire poster distribution, or at least a point estimate accompanied by some sort of intervals. Here we’ll just work with the posterior to create a difference distribution. You could do that with a little deft posterior_samples() wrangling. Here we’ll employ fitted(). nd &lt;- tibble(negemot = c(3, 4), posemot = 4, ideology = 2, sex = 1, age = 30) fitted(model2.8, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% set_names(str_c(&quot;condition_&quot;, letters[1:2])) %&gt;% mutate(difference = condition_b - condition_a) %&gt;% ggplot(aes(x = difference)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + ggtitle(&quot;The posterior density for the difference between\\nthe two conditions.&quot;) + theme_bw() 2.4.1 The standardized regression model. As brms doesn’t automatically give us the standardized coefficients the way OLS output often does, we’ll have to be proactive. One solution is just to standardized the data themselves and then re-fit the model with those standardized variables. That leads us to the issue of how one standardized variables to begin with. Recall that standardizing entails subtracting the mean of a variable from that variable and then dividing that value by the standard deviation. We don’t want to do that by hand. So one handy way is to make a custom function to do that work for us. sandardize &lt;- function(x) { (x - mean(x)) / sd(x) } To learn more about making custom functions in R, check our Chapter 19 of R4DS. Here we’ll employ our custom standardize() function to make standardized versions of our variables. glbwarm &lt;- glbwarm %&gt;% mutate(posemot_z = sandardize(posemot), negemot_z = sandardize(negemot), ideology_z = sandardize(ideology), sex_z = sandardize(sex), age_z = sandardize(age)) Now we’ve got us our standardized variables, let’s fit a standardized model. model2.9 &lt;- brm(data = glbwarm, family = gaussian, govact_z ~ 1 + negemot_z + posemot_z + ideology_z + sex_z + age_z, cores = 4, file = &quot;fits/model02.09&quot;) Here are the newly standardized coefficient summaries, minus the Intercept. fixef(model2.9)[-1, ] %&gt;% round(3) ## Estimate Est.Error Q2.5 Q97.5 ## negemot_z 0.495 0.030 0.436 0.554 ## posemot_z -0.026 0.027 -0.079 0.029 ## ideology_z -0.242 0.030 -0.300 -0.184 ## sex_z -0.004 0.028 -0.059 0.050 ## age_z -0.016 0.029 -0.071 0.040 Our coefficients match up nicely with those on page 52 in the text. Just as with Hayes’s OLS estimates, we should not attempt to interpret the standardized sex_z coefficient from our Bayesian model. Here’s how we’d fit a partially-standardized model–a model in which all variables except for sex are standardized. model2.10 &lt;- update(model2.9, newdata = glbwarm, formula = govact_z ~ 1 + negemot_z + posemot_z + ideology_z + sex + age_z, cores = 4, file = &quot;fits/model02.10&quot;) Notice our use of the update() function. If you want to hastily fit a brms model of the same basic form of a prior model, you can just update some of the parameters of that original fit. In this case, all we did was swap out one of the predictors. To accommodate that change, we used the newdata argument so the model had access to the new variable and then we fed in the new formula. Anyway, here are the coefficient summaries, including the Intercept, for the partially-standardized model. fixef(model2.10) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 0.004 0.040 -0.073 0.081 ## negemot_z 0.494 0.030 0.434 0.553 ## posemot_z -0.026 0.028 -0.079 0.027 ## ideology_z -0.242 0.031 -0.304 -0.180 ## sex -0.007 0.057 -0.124 0.106 ## age_z -0.016 0.028 -0.071 0.039 As Hayes wrote, now sex = -0.007 has a sensible interpretation. “We can say that men and women differ by [-0.007] standard deviations in their support for government action when all other variables in the model are held constant (p. 53).” On page 54, Hayes gave us the equation to transform unstandardized coefficients to standardized ones: \\[ \\tilde b_i = b_i \\left ( \\frac{SD_{X_{i}}}{SD_{Y}} \\right ) \\] Let’s give it a whirl with negemot. # here&#39;s the coefficient for `negemot` from the standardized model, `model2.9` fixef(model2.9)[&quot;negemot_z&quot;, &quot;Estimate&quot;] ## [1] 0.4950501 # here&#39;s the coefficient for `negemot` from the unstandardized model, `model2.8` fixef(model2.8)[&quot;negemot&quot;, &quot;Estimate&quot;] ## [1] 0.4407648 # and here we use Hayes&#39; formula to standardize the unstandardized coefficient fixef(model2.8)[&quot;negemot&quot;, &quot;Estimate&quot;] * (sd(glbwarm$negemot) / sd(glbwarm$govact)) ## [1] 0.4951932 Looks like we got it within rounding error–pretty good! However, that was just the posterior mean, the Bayesian point estimate. If we want to more fully express the uncertainty around the mean–and we do–, we’ll need to work with the posterior draws. # the posterior draws from the unstandardized model posterior_samples(model2.8) %&gt;% # using Hayes&#39; formula to standardize `b_negemot` mutate(`hand-made b_negemot_z` = b_negemot * (sd(glbwarm$negemot) / sd(glbwarm$govact))) %&gt;% # tacking on the `b_negemot_z` column from the standardized `model2.9` models posterior draws bind_cols(posterior_samples(model2.9) %&gt;% select(b_negemot_z)) %&gt;% # converting the data to the long format and grouping by `name` pivot_longer(c(`hand-made b_negemot_z`, b_negemot_z)) %&gt;% group_by(name) %&gt;% # here we summarize the results summarise(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 5 ## name mean sd ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b_negemot_z 0.495 0.03 0.436 0.554 ## 2 hand-made b_negemot_z 0.495 0.03 0.436 0.552 Our summary confirms that we can apply Hayes’s formula to a posterior_samples() column in order to get fuller summary statistics for a hand-converted standardized coefficient. This would be in full compliance with, say, APA recommendations to include 95% intervals with all effect sizes–the standardized regression coefficient being the effect size, here. 2.5 Measures of model fit In the Bayesian world, we don’t tend to appeal to the \\(SS_{residual}\\), the \\(MS_{residual}\\), or the standard error of estimate. We do sometimes, however, appeal to the \\(R^2\\). I’m not going to go into the technical details here, but you should be aware that the Bayesian \\(R^2\\) is not calculated the same as the OLS \\(R^2\\). If you want to dive in, check out the (2019) paper by Gelman, Goodrich, Gabry, and Vehtari, R-squared for Bayesian regression models. Here’s how to get it with brms. bayes_R2(model2.8, summary = T) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.389 0.021 0.347 0.428 It even comes with 95% intervals, which will make the editors at APA journals happy. If you want to go beyond summary statistics and take a look at the full posterior, just set summary = F and data wrangle and plot as usual. bayes_R2(model2.8, summary = F) %&gt;% data.frame() %&gt;% ggplot(aes(x = R2)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Behold: The Bayesian &quot;, italic(&quot;R&quot;)^{2}, &quot; distribution for model 2.8&quot;)), x = NULL) + coord_cartesian(xlim = 0:1) + theme_bw() Another way we examine model fit is with graphical posterior predictive checks. Posterior predictive checking is a very general approach, which you might learn more about from Gabry et al. (2019) or with a few keyword searches in on Gelman’s blog. One basic way is to use the model in order to simulate data and then compare those data with the original data–the basic idea being that good fitting models should produce data similar to the original data. Recall how we’ve used fitted() to make regression lines and expected values? We’ll, now we’ll use predict() to simulate data based on our models. predict(model2.8, summary = F, nsamples = 3) %&gt;% data.frame() %&gt;% set_names(1:nrow(glbwarm)) %&gt;% mutate(simulation = str_c(&quot;simulation: &quot;, 1:n())) %&gt;% pivot_longer(-simulation, names_to = &quot;row&quot;, values_to = &quot;govact&quot;) %&gt;% bind_cols( bind_rows( glbwarm %&gt;% select(-govact), glbwarm %&gt;% select(-govact), glbwarm %&gt;% select(-govact)) ) %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + coord_cartesian(ylim = c(0, 9)) + theme_bw() + facet_wrap(~ simulation, ncol = 3) The question is, do these simulated data sets look like the original data? Let’s see. glbwarm %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + coord_cartesian(ylim = c(0, 9)) + theme_bw() Overall, the simulations aren’t bad. But in all three govact tends to veer above 7.5, which is where the original data appear to be bounded. But otherwise the overall shape is pretty close, at least with respect to negemot. There’s nothing special about three simulations. Three is just more than one and gives you a sense of the variance across simulations. Also, we only examined the model fit with respect to negemot. Since there are other variables in the model, we might also assess the model based on them. Another method is with the brms::pp_check() function, which allows users to access a variety of convenience functions from the bayesplot package (Gabry et al., 2019; Gabry &amp; Mahr, 2021). Here we’ll use the default settings and just tack on theme_bw() for aesthetics. pp_check(model2.8) + theme_bw() What we did was simulate 10 data sets worth of govact values, plot their densities (i.e., the thin blue lines) and compare them with the density of the original govact values. What we want is for the thin blue lines to largely align with the thick blue line. Though not perfect, the simulations from our model2.8 did a pretty okay job of reproducing the original govact distribution. For more ideas on this method, see the brms reference manual (Bürkner, 2021e) and Gabry’s (2019) vignette, Graphical posterior predictive checks using the bayesplot package. 2.6 Statistical inference Here’s a tidyverse way to do Hayes’ simulation from page 57. We’re just using OLS regression with the lm() function. You could do this with Bayesian HMC estimation, but man would it take a while. For our first step, we’ll define two custom functions. # this first one will use the `slice_sample()` function to randomly sample from `glbwarm` make_sample &lt;- function(i) { set.seed(i) slice_sample(glbwarm, n = 50, replace = F) } # this second function will fit our model, the same one from `model2.8`, to each of our subsamples glbwarm_model &lt;- function(df) { lm(govact ~ 1 + negemot + posemot + ideology + sex + age, data = df) } Now we’ll run the simulation, wrangle the output, and plot in one fell swoop. # we need an iteration index, which will double as the values we set our seed with in our `make_sample()` function tibble(iter = 1:1e4) %&gt;% group_by(iter) %&gt;% # inserting our subsamples mutate(sample = map(iter, make_sample)) %&gt;% # fitting our models mutate(model = map(sample, glbwarm_model)) %&gt;% # taking those model results and tidying them with the broom package mutate(broom = map(model, broom::tidy)) %&gt;% # unnesting allows us to access our model results unnest(broom) %&gt;% # we&#39;re only going to focus on the estimates for `negemot` filter(term == &quot;negemot&quot;) %&gt;% # here it is, Figure 2.7 ggplot(aes(x = estimate)) + geom_histogram(binwidth = .025, boundary = 0) + labs(x = &quot;Unstandardized regression coefficient for negemot&quot;, y = &quot;Frequency in 1e4 samples of size 50&quot;) + theme_bw() To learn more about this approach to simulations, see Section 25.2.1 in R4DS. 2.6.1 Testing a null hypothesis. As Bayesians, we don’t need to wed ourselves to the null hypothesis. We’re not interested in the probability of the data given the null hypothesis. Bayes’ rule, \\[p(\\theta | D) = \\frac{p(D | \\theta) p(\\theta)}{p(D)},\\] gives us the probability of the model parameters, given the data. Though I acknowledge different researchers might set out to ask different things of their data, I propose we’re generally more interested in determining the most probable parameter values than we are the probabilities tested within the NHST paradigm. posterior_samples(model2.8) %&gt;% ggplot(aes(x = b_negemot)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + geom_vline(xintercept = posterior_interval(model2.8)[&quot;b_negemot&quot;, ], color = &quot;white&quot;, linetype = 2) + scale_x_continuous(breaks = posterior_interval(model2.8)[&quot;b_negemot&quot;, ] %&gt;% as.double(), labels = posterior_interval(model2.8)[&quot;b_negemot&quot;, ] %&gt;% as.double() %&gt;% round(digits = 2) %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The most probable values for our b_negemot parameter are the ones around the peak\\nof the density. For convenience, the dashed lines denote the 95% credible intervals.\\nSure, you could ask yourself, &#39;Is zero within those intervals?&#39; But with such rich output,\\nthat seems like an impoverished question to ask.&quot;) + theme_bw() For more discussion the NHST paradigm and how it compares with variations of Bayesian statistics, check out Kruschke’s (2015) text, Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan, particularly chapters 10 through 13. You can find my (2020a) brms + tidyverse translation of that text at https://bookdown.org/content/3686/. 2.6.2 Interval estimation. Within the Bayesian paradigm, we don’t use 95% intervals based on the typical frequentist formula. With the brms package, we typically use percentile-based intervals. Take the 95% credible intervals for the negemot coefficient from model model2.8: posterior_interval(model2.8)[&quot;b_negemot&quot;, ] ## 2.5% 97.5% ## 0.3882826 0.4911189 We can actually get those intervals with the simple use of the base R quantile() function. posterior_samples(model2.8) %&gt;% summarize(the_2.5_percentile = quantile(b_negemot, probs = .025), the_97.5_percentile = quantile(b_negemot, probs = .975)) ## the_2.5_percentile the_97.5_percentile ## 1 0.3882826 0.4911189 The consequence of this is that our Bayesian credible intervals aren’t necessarily symmetric, which is fine because the posterior distribution for a given parameter isn’t always symmetric. But not all Bayesian intervals are percentile based. John Kruschke, for example, often recommends highest posterior density intervals in his work. The brms package doesn’t have a convenience function for these, but you can compute them with help from the HDInterval package (Meredith &amp; Kruschke, 2018). library(HDInterval) hdi(posterior_samples(model2.8)[ , &quot;b_negemot&quot;], credMass = .95) ## lower upper ## 0.3895321 0.4920354 ## attr(,&quot;credMass&quot;) ## [1] 0.95 Finally, because Bayesians aren’t bound to the NHST paradigm, we aren’t bound to 95% intervals, either. For example, in both his excellent (2020) text and as a default in its accompanying rethinking package, Richard McElreath often uses 89% intervals. Alternatively, Andrew Gelman has publicly advocated for 50% intervals. The most important thing is to express the uncertainty in the posterior in a clearly-specified way. If you’d like, say, 80% intervals in your model summary, you can insert a prob argument into either print() or summary(). print(model2.8, prob = .8) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + posemot + ideology + sex + age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.06 0.20 3.80 4.33 1.00 5516 3355 ## negemot 0.44 0.03 0.41 0.47 1.00 5423 3142 ## posemot -0.03 0.03 -0.06 0.01 1.00 5623 2992 ## ideology -0.22 0.03 -0.25 -0.18 1.00 5696 2899 ## sex -0.01 0.08 -0.11 0.09 1.00 5693 2963 ## age -0.00 0.00 -0.00 0.00 1.00 5491 3287 ## ## Family Specific Parameters: ## Estimate Est.Error l-80% CI u-80% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.07 0.03 1.03 1.10 1.00 6250 2795 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Note how two of our columns changed to ‘l-80% CI’ and ‘u-80% CI.’ You can specify custom percentile levels with posterior_summary(): posterior_summary(model2.8, probs = c(.9, .8, .7, .6, .4, .3, .2, .1)) %&gt;% round(digits = 2) ## Estimate Est.Error Q90 Q80 Q70 Q60 Q40 Q30 Q20 Q10 ## b_Intercept 4.06 0.20 4.33 4.24 4.17 4.11 4.01 3.96 3.90 3.80 ## b_negemot 0.44 0.03 0.47 0.46 0.45 0.45 0.43 0.43 0.42 0.41 ## b_posemot -0.03 0.03 0.01 0.00 -0.01 -0.02 -0.03 -0.04 -0.05 -0.06 ## b_ideology -0.22 0.03 -0.18 -0.20 -0.21 -0.21 -0.23 -0.23 -0.24 -0.25 ## b_sex -0.01 0.08 0.09 0.05 0.03 0.01 -0.03 -0.05 -0.07 -0.11 ## b_age 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 ## sigma 1.07 0.03 1.10 1.09 1.08 1.08 1.06 1.05 1.05 1.03 ## lp__ -1213.20 1.81 -1211.16 -1211.65 -1212.07 -1212.44 -1213.36 -1213.91 -1214.61 -1215.75 And of course, you can use multiple interval summaries when you summarize() the output from posterior_samples(). E.g., posterior_samples(model2.8) %&gt;% select(b_Intercept:b_age) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(`l-95% CI` = quantile(value, probs = .025), `u-95% CI` = quantile(value, probs = .975), `l-50% CI` = quantile(value, probs = .25), `u-50% CI` = quantile(value, probs = .75)) %&gt;% mutate_if(is.double, round, digits = 2) ## # A tibble: 6 x 5 ## key `l-95% CI` `u-95% CI` `l-50% CI` `u-50% CI` ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b_age -0.01 0 0 0 ## 2 b_ideology -0.27 -0.17 -0.24 -0.2 ## 3 b_Intercept 3.67 4.45 3.93 4.2 ## 4 b_negemot 0.39 0.49 0.42 0.46 ## 5 b_posemot -0.08 0.03 -0.05 -0.01 ## 6 b_sex -0.16 0.14 -0.06 0.04 Throughout this project, I’m going to be lazy and default to conventional 95% intervals, with occasional appearances of 50% intervals. 2.6.3 Testing a hypothesis about a set of antecedent variables. Here we’ll make use of the update() function to hastily fit our reduced model, model2.11. model2.11 &lt;- update(model2.8, govact ~ 1 + ideology + sex + age, cores = 4, file = &quot;fits/model02.11&quot;) We can get a look at the \\(R^2\\) summaries for our competing models like this. bayes_R2(model2.8) %&gt;% round(digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.39 0.02 0.35 0.43 bayes_R2(model2.11) %&gt;% round(digits = 2) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.18 0.02 0.14 0.22 So far it looks like our fuller model, model2.8, explains more variation in the data. If we wanted to look at their distributions, we’d set summary = F in the bayes_R2() function and convert the results to a data frame or tibble. Here we use bind_cols() to put the \\(R^2\\) results for both in the same tibble. r2 &lt;- cbind(bayes_R2(model2.8, summary = F), bayes_R2(model2.11, summary = F)) %&gt;% data.frame() %&gt;% set_names(str_c(&quot;model2.&quot;, c(8, 11))) head(r2) ## model2.8 model2.11 ## 1 0.3790275 0.1827538 ## 2 0.4143660 0.1721092 ## 3 0.4014884 0.2068029 ## 4 0.3846665 0.1727220 ## 5 0.4179583 0.1710993 ## 6 0.3378314 0.1592348 With our r2 tibble in hand, we’re ready to plot. r2 %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(italic(R)^2))) + coord_cartesian(xlim = 0:1) + theme_bw() Yep, the \\(R^2\\) distribution for model2.8, the one including the emotion variables, is clearly larger than that for the more parsimonious model2.11. And it’d just take a little more data wrangling to get a formal \\(R^2\\) difference score. r2 %&gt;% mutate(difference = model2.11 - model2.8) %&gt;% ggplot(aes(x = difference)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = -1:0) + labs(title = expression(paste(Delta, italic(R)^{2})), subtitle = expression(paste(&quot;This is the amount the &quot;, italic(R)^{2}, &quot; dropped after pruning the emotion variables from the model.&quot;)), x = NULL) + theme_bw() The \\(R^2\\) approach is popular within the social sciences. But it has its limitations, the first of which is that it doesn’t correct for model complexity. The second is it’s not applicable to a range of models, such as those that do not use the Gaussian likelihood (e.g., logistic regression) or to multilevel models. Happily, information criteria offer a more general framework. The AIC is the most popular information criteria among frequentists. Within the Bayesian world, we have the DIC, the WAIC, and the LOO. The DIC is quickly falling out of favor and is not immediately available with the brms package. However, we can use the WAIC and the LOO, both of which are computed in brms via the loo package (Vehtari et al., 2017; Vehtari, Gabry, et al., 2019; Yao et al., 2018). With brms, you can compute the WAIC or LOO values and add them to your model fit object with the add_criterion() function. model2.8 &lt;- add_criterion(model2.8, c(&quot;loo&quot;, &quot;waic&quot;)) model2.11 &lt;- add_criterion(model2.11, c(&quot;loo&quot;, &quot;waic&quot;)) Here’s the main loo-summary output for model4. model2.8$criteria$loo ## ## Computed from 4000 by 815 log-likelihood matrix ## ## Estimate SE ## elpd_loo -1213.9 22.7 ## p_loo 7.7 0.6 ## looic 2427.8 45.5 ## ------ ## Monte Carlo SE of elpd_loo is 0.0. ## ## All Pareto k estimates are good (k &lt; 0.5). ## See help(&#39;pareto-k-diagnostic&#39;) for details. You get a wealth of output, more of which can be seen with str(model2.8$loo). For now, notice the “All pareto k estimates are good (k &lt; 0.5).” Pareto \\(k\\) values (see Vehtari &amp; Gabry, 2020). Each case in the data gets its own \\(k\\) value and we like it when those \\(k\\)s are low. The makers of the loo package get worried when those \\(k\\)s exceed 0.7 and as a result you will get a warning message when they do. Happily, we have no such warning messages in this example. If you want to work with the \\(k\\) values directly, you can extract them and place them into a data frame like so. model2.8$criteria$loo$diagnostics %&gt;% data.frame() %&gt;% head() ## pareto_k n_eff ## 1 -0.04436335 5230.019 ## 2 -0.01404872 6028.208 ## 3 0.17757442 5683.164 ## 4 0.26825902 3154.180 ## 5 -0.08003852 5829.860 ## 6 0.07320749 5704.676 The pareto_k values can be used to examine cases that are overly-influential on the model parameters, something akin to a Cook’s \\(D_i\\). See, for example this discussion on stackoverflow.com in which several members of the Stan team weighed in. The issue is also discussed in Vehtari et al. (2017) and in this lecture by Aki Vehtari. But anyway, we’re getting ahead of ourselves. Back to the LOO. Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the values of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower information criteria. With compare_ic(), we can compute a formal difference score between multiple loo objects. loo_compare(model2.8, model2.11) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model2.8 0.0 0.0 -1213.9 22.7 7.7 0.6 2427.8 45.5 ## model2.11 -118.7 15.9 -1332.6 20.6 5.2 0.4 2665.2 41.1 We also get a standard error. Here it looks like model2.8 was substantially better, in terms of LOO-values, than model2.11. For more on the LOO, see the loo reference manual (Gabry, 2020), Vehtari and Gabry’s handy (2020) vignette, or the scholarly papers referenced therein. Also, McElreath discussed the LOO in the second (2020) version of his text, as well as in this lecture. 2.7 Multicategorical antecedent variables “To include a multicategorical antecedent variable representing \\(g\\) groups in a regression model, it must be represented with \\(g − 1\\) variables using one of a variety of different group coding systems.” (p. 66) This isn’t strictly true, but we digress. Hayes went on… One popular system for coding groups is indicator coding, also known as dummy coding. With indicator coding, \\(g − 1\\) indicator variables containing either a zero or one represent which of the \\(g\\) groups a case belongs in, and these indicator variables are used as antecedents in a regression model. To construct indicator codes, create \\(g − 1\\) variables \\(D_i\\) for each case set to 1 if the case is in group \\(i\\), otherwise set \\(D_i\\) to zero. (p. 66, emphasis in the original) Before we get to that, we should examine our multicategorical antecedent variable, partyid. It’s coded 1 = Democrat 2 = Independent 3 = Republican. You can get a count of the cases within a give partyid like this. glbwarm %&gt;% count(partyid) ## # A tibble: 3 x 2 ## partyid n ## &lt;dbl&gt; &lt;int&gt; ## 1 1 359 ## 2 2 192 ## 3 3 264 We can get grouped means for govact like this. glbwarm %&gt;% group_by(partyid) %&gt;% summarize(mean_support_for_governmental_action = mean(govact)) ## # A tibble: 3 x 2 ## partyid mean_support_for_governmental_action ## &lt;dbl&gt; &lt;dbl&gt; ## 1 1 5.06 ## 2 2 4.61 ## 3 3 3.92 We can make dummies with the if_else() function. We’ll just go ahead and do that right within the brm() function. model2.12 &lt;- brm(data = glbwarm %&gt;% mutate(Democrat = if_else(partyid == 1, 1, 0), Republican = if_else(partyid == 3, 1, 0)), family = gaussian, govact ~ 1 + Democrat + Republican, chains = 4, cores = 4, file = &quot;fits/model02.12&quot;) Check the results. fixef(model2.12) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.6059516 0.09167832 4.4253983 4.7853478 ## Democrat 0.4583058 0.11359349 0.2321713 0.6792878 ## Republican -0.6802900 0.12127628 -0.9195148 -0.4383596 The intercept is the stand-in for Independents and the other two coefficients are difference scores. The \\(R^2\\) is okay. bayes_R2(model2.12) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.132 0.021 0.092 0.175 There’s no need to compute an \\(F\\)-test on our \\(R^2\\). The posterior mean and it’s 95% intervals are well away from zero. But you could use your bayes_R2(model2.12, summary = F) plotting skills from above to more fully inspect the posterior if you’d like. We could also use information criteria. One method would be to compare the WAIC or LOO value of model2.12 with an intercept-only model. First, we’ll need to fit that model. model2.13 &lt;- update(model2.12, govact ~ 1, chains = 4, cores = 4, file = &quot;fits/model02.13&quot;) Here we’ll compute the WAIC for each, save the results to their fit objects, and them compare them with loo_compare(). model2.12 &lt;- add_criterion(model2.12, &quot;waic&quot;) model2.13 &lt;- add_criterion(model2.13, &quot;waic&quot;) loo_compare(model2.12, model2.13, criterion = &quot;waic&quot;) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic ## model2.12 0.0 0.0 -1353.7 20.1 4.2 0.3 2707.5 40.2 ## model2.13 -55.1 10.4 -1408.8 21.3 2.0 0.1 2817.6 42.6 The WAIC comparison suggests model2.12, the one with the partyid dummies, is an improvement over the simple intercept-only model. Another way to compare the information criteria is with AIC-type weighting. The brms package offers a variety of weighting methods via the model_weights() function. mw &lt;- model_weights(model2.12, model2.13, weights = &quot;waic&quot;) mw ## model2.12 model2.13 ## 1.000000e+00 9.659371e-25 If you’re not a fan of scientific notation, you can put the results in a tibble and look at them on a plot. mw %&gt;% as.data.frame() %&gt;% rownames_to_column() %&gt;% set_names(c(&quot;model&quot;, &quot;WAIC weight&quot;)) %&gt;% ggplot(aes(x = `WAIC weight`, y = model)) + geom_point() + labs(subtitle = &quot;The weights should sum to 1. In this case virtually all the weight is placed\\nin model2.12. Recall, that these are RELATIVE weights. Add another model\\nfit into the mix and the weights might well change.&quot;, y = NULL) + theme_bw() + theme(axis.ticks.y = element_blank()) You could, of course, do all this with the LOO. 2.8 Assumptions for interpretation and statistical inference Regression is a handy tool to have in your statistical toolbox. Its utility as a “general data analytic system” (Cohen, 1968) will be apparent throughout this book. But it is a human invention that isn’t perfect, it can lead you astray if used indiscriminately, and it is founded on some assumptions that aren’t always realistic or likely to be met in the circumstances in which the method is applied. (p. 68) 2.8.1 Linearity. “When using OLS regression to model some consequent variable of interest \\(Y\\), you must be willing to assume that the relationship between the variables in the model are linear in nature, or at least approximately linear” (p. 69) 2.8.2 Normality. The brms package is quite general and allows users to fit models from a variety of likelihoods other than the Gaussian. For example, users can accommodate outliers/extreme values with Student’s t regression. You can do count regression with the Poisson or the negative binomial… For more, see McElreath’s lecture introducing the generalized linear model or Bürkner’s (2021d) vignette, Parameterization of response distributions in brms 2.8.3 Homoscedasticity. The brms package can also accommodate homoscedasticity with distributional modeling. In short, one simply models \\(\\sigma\\) in addition to the mean, \\(\\mu\\). See Bürkner’s handy (2021a) vignette, Estimating distributional models with brms on the topic. 2.8.4 Independence. The issue of independence is where the multilevel model comes on. See any relevant text, such as Statistical rethinking or Data analysis using regression and multilevel/hierarchical models (Gelman &amp; Hill, 2006). And yes, brms is fully capable of handling multilevel models (see Bürkner, 2017, 2018). Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] HDInterval_0.2.2 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 splines_4.0.4 ## [6] crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 digest_0.6.27 ## [11] htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 magrittr_2.0.1 modelr_0.1.8 ## [16] RcppParallel_5.0.2 matrixStats_0.57.0 xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 ## [21] colorspace_2.0-0 rvest_1.0.1 haven_2.3.1 xfun_0.23 callr_3.7.0 ## [26] crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 survival_3.2-10 zoo_1.8-8 ## [31] glue_1.4.2 gtable_0.3.0 emmeans_1.5.2-1 V8_3.4.0 pkgbuild_1.2.0 ## [36] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 ## [41] miniUI_0.1.1.1 xtable_1.8-4 tmvnsim_1.0-2 stats4_4.0.4 StanHeaders_2.21.0-7 ## [46] DT_0.16 htmlwidgets_1.5.3 httr_1.4.2 threejs_0.3.3 ellipsis_0.3.2 ## [51] pkgconfig_2.0.3 loo_2.4.1 farver_2.1.0 sass_0.3.1 dbplyr_2.1.1 ## [56] utf8_1.2.1 tidyselect_1.1.1 labeling_0.4.2 rlang_0.4.11 reshape2_1.4.4 ## [61] later_1.2.0 munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 cli_3.0.1 ## [66] generics_0.1.0 broom_0.7.6 ggridges_0.5.3 evaluate_0.14 fastmap_1.1.0 ## [71] processx_3.5.2 knitr_1.33 fs_1.5.0 nlme_3.1-152 mime_0.10 ## [76] projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 bayesplot_1.8.0 shinythemes_1.1.2 ## [81] rstudioapi_0.13 gamm4_0.2-6 curl_4.3 reprex_2.0.0 statmod_1.4.35 ## [86] bslib_0.2.4 stringi_1.6.2 highr_0.9 ps_1.6.0 Brobdingnag_1.2-6 ## [91] lattice_0.20-41 Matrix_1.3-2 psych_2.1.3 nloptr_1.2.2.2 markdown_1.1 ## [96] shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 ## [101] bridgesampling_1.0-0 estimability_1.3 httpuv_1.6.0 R6_2.5.0 bookdown_0.22 ## [106] promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 ## [111] MASS_7.3-53 gtools_3.8.2 assertthat_0.2.1 withr_2.4.2 mnormt_2.0.2 ## [116] shinystan_2.5.0 multcomp_1.4-16 mgcv_1.8-33 parallel_4.0.4 hms_1.1.0 ## [121] grid_4.0.4 coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 ## [126] lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 Footnote References Brilleman, S., Crowther, M., Moreno-Betancur, M., Buros Novik, J., &amp; Wolfe, R. (2018). Joint longitudinal and time-to-event models via Stan. https://github.com/stan-dev/stancon_talks/ Bürkner, P.-C. (2021a). Estimating distributional models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html Bürkner, P.-C. (2021b). Estimating multivariate models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html Bürkner, P.-C. (2021d). Parameterization of response distributions in brms. https://CRAN.R-project.org/package=brms/vignettes/brms_families.html Bürkner, P.-C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01 Bürkner, P.-C. (2018). Advanced Bayesian multilevel modeling with the R package brms. The R Journal, 10(1), 395–411. https://doi.org/10.32614/RJ-2018-017 Bürkner, P.-C. (2021e). brms reference manual, Version 2.15.0. https://CRAN.R-project.org/package=brms/brms.pdf Cohen, J. (1968). Multiple regression as a general data-analytic system. Psychological Bulletin, 70(6, Pt.1), 426–443. https://doi.org/10.1037/h0026714 Gabry, J. (2019). Graphical posterior predictive checks using the bayesplot package. https://CRAN.R-project.org/package=bayesplot/vignettes/graphical-ppcs.html Gabry, J. (2020). loo reference manual, Version 2.4.1. https://CRAN.R-project.org/package=loo/loo.pdf Gabry, J., &amp; Goodrich, B. (2020). rstanarm: Bayesian applied regression modeling via stan [Manual]. https://CRAN.R-project.org/package=rstanarm Gabry, J., &amp; Mahr, T. (2021). bayesplot: Plotting for Bayesian models. https://CRAN.R-project.org/package=bayesplot Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., &amp; Gelman, A. (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society: Series A (Statistics in Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378 Gelman, A., Goodrich, B., Gabry, J., &amp; Vehtari, A. (2019). R-squared for Bayesian regression models. The American Statistician, 73(3), 307–309. https://doi.org/10.1080/00031305.2018.1549100 Gelman, A., &amp; Hill, J. (2006). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press. https://doi.org/10.1017/CBO9780511790942 Grolemund, G., &amp; Wickham, H. (2017). R for data science. O’Reilly. https://r4ds.had.co.nz Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Kruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/ Kurz, A. S. (2020a). Doing Bayesian data analysis in brms and the tidyverse (version 0.4.0). https://bookdown.org/content/3686/ McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/ Meredith, M., &amp; Kruschke, J. (2018). HDInterval: Highest (posterior) density intervals [Manual]. https://CRAN.R-project.org/package=HDInterval Merkle, E. C., &amp; Rosseel, Y. (2018). blavaan: Bayesian structural equation models via parameter expansion. Journal of Statistical Software, 85(4), 1–30. https://doi.org/10.18637/jss.v085.i04 Merkle, E. C., Rosseel, Y., &amp; Goodrich, B. (2020). blavaan: Bayesian latent variable analysis. https://CRAN.R-project.org/package=blavaan Revelle, W. (2021). psych: Procedures for psychological, psychometric, and personality research. https://CRAN.R-project.org/package=psych Rosseel, Y., &amp; Jorgensen, T. D. (2019). lavaan: Latent variable analysis [Manual]. https://lavaan.org Stan Development Team. (2020). RStan: The R interface to Stan. https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html Vehtari, A., &amp; Gabry, J. (2020). Using the loo package (version \\(&gt;\\)= 2.0.0). https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., &amp; Gelman, A. (2019). loo: Efficient leave-one-out cross-validation and WAIC for bayesian models. https://CRAN.R-project.org/package=loo/ Vehtari, A., Gelman, A., &amp; Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4 Yao, Y., Vehtari, A., Simpson, D., &amp; Gelman, A. (2018). Using stacking to average Bayesian predictive distributions (with discussion). Bayesian Analysis, 13(3), 917–1007. https://doi.org/10.1214/17-BA1091 Hayes did not cover count regression with the Poisson likelihood in this textbook. If you’d like to learn more, one place to start is with McElreath’s lecture on binomial and Poisson models.↩︎ We will not be covering structural equation modeling (SEM) in this book If you’re interested, you might check out this video series by Erin M. Buchanan on SEM within R, particularly with the handy lavaan package (Merkle &amp; Rosseel, 2018; Rosseel &amp; Jorgensen, 2019).↩︎ "],["the-simple-mediation-model.html", "3 The Simple Mediation Model 3.1 The simple mediation model 3.2 Estimation of the direct, indirect, and total effects of \\(X\\) 3.3 Example with dichotomous \\(X\\): The influence of presumed media influence 3.4 Statistical inference 3.5 An example with continuous \\(X\\): Economic stress among small-business owners Session info", " 3 The Simple Mediation Model Hayes closed the opening with: Whereas answering questions about when or for whom is the domain of moderation analysis, questions that ask about how pertain to mediation, the focus of this and the next three chapters. In this chapter, [we’ll explore] the simple mediation model and illustrate using OLS regression-based Bayesian path analysis how the effect of an antecedent variable \\(X\\) on some final consequent \\(Y\\) can be partitioned into two paths of influence, direct and indirect. (Andrew F. Hayes, 2018, p. 78, emphasis in the original) 3.1 The simple mediation model Mediation analysis is a statistical method used to evaluate evidence from studies designed to test hypotheses about how some causal antecedent variable \\(X\\) transmits its effect on a consequent variable \\(Y\\). When thinking about whether a phenomenon or theory you are studying could be conceptualized as a mediation process, it is important to keep in mind that mediation is ultimately a causal explanation. It is assumed that the relationships in the system are causal, and, importantly, that \\(M\\) is causally located between \\(X\\) and \\(Y\\). It must be assumed, if not also empirically substantiated, that \\(X\\) causes \\(M\\), which in turn causes \\(Y\\). \\(M\\) cannot possibly carry \\(X\\)’s effect on \\(Y\\) if \\(M\\) is not located causally between \\(X\\) and \\(Y\\). (pp. 78–81, emphasis in the original) 3.2 Estimation of the direct, indirect, and total effects of \\(X\\) Given the simple three-term mediation model, the statistical model is expressed in the two equations \\[\\begin{align*} M &amp; = i_M + a X + e_M \\\\ Y &amp; = i_Y + c&#39; X + b M + e_Y. \\end{align*}\\] When using OLS software, as Hayes promotes throughout the text, these equations are estimated sequentially. However, the brms package has multivariate capabilities. As such, our results will be from a Bayesian multivariate model that simultaneously computes both equations at once. They are both part of a joint model. And when we consider more advanced models later in the text, our multivariate models will fit even more than two equations at once. None of this is a problem for brms. 3.3 Example with dichotomous \\(X\\): The influence of presumed media influence Here we load a couple necessary packages, load the data, and take a peek. library(tidyverse) pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) glimpse(pmi) ## Rows: 123 ## Columns: 6 ## $ cond &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0… ## $ pmi &lt;dbl&gt; 7.0, 6.0, 5.5, 6.5, 6.0, 5.5, 3.5, 6.0, 4.5, 7.0, 1.0, 6.0, 5.0, 7.0, 7.0, 7.0, 4.5, 3.5, 7… ## $ import &lt;dbl&gt; 6, 1, 6, 6, 5, 1, 1, 6, 6, 6, 3, 3, 4, 7, 1, 6, 3, 3, 2, 4, 4, 6, 7, 4, 5, 4, 6, 5, 5, 7, 4… ## $ reaction &lt;dbl&gt; 5.25, 1.25, 5.00, 2.75, 2.50, 1.25, 1.50, 4.75, 4.25, 6.25, 1.25, 2.75, 3.75, 5.00, 4.00, 5… ## $ gender &lt;dbl&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0… ## $ age &lt;dbl&gt; 51.0, 40.0, 26.0, 21.0, 27.0, 25.0, 23.0, 25.0, 22.0, 24.0, 22.0, 21.0, 23.0, 21.0, 22.0, 2… You can get the male/female split like so. pmi %&gt;% count(gender) ## # A tibble: 2 x 2 ## gender n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 80 ## 2 1 43 Here is the split by condition. pmi %&gt;% count(cond) ## # A tibble: 2 x 2 ## cond n ## &lt;dbl&gt; &lt;int&gt; ## 1 0 65 ## 2 1 58 Here is how to get the ungrouped mean and \\(SD\\) values for reaction and pmi, as presented in Table 3.1. pmi %&gt;% pivot_longer(c(reaction, pmi)) %&gt;% group_by(name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 pmi 5.60 1.32 ## 2 reaction 3.48 1.55 You might get the mean and \\(SD\\) values for reaction and pmi grouped by cond like this. pmi %&gt;% pivot_longer(c(reaction, pmi)) %&gt;% group_by(cond, name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 4 ## # Groups: cond [2] ## cond name mean sd ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 pmi 5.38 1.34 ## 2 0 reaction 3.25 1.61 ## 3 1 pmi 5.85 1.27 ## 4 1 reaction 3.75 1.45 Let’s load our primary statistical package, brms. library(brms) Before we begin, I should acknowledge that I greatly benefited by this great blog post on path analysis in brms by Jarrett Byrnes. With brms, we handle mediation models using the multivariate syntax (Bürkner, 2021b). There are a few ways to do this. Let’s start simple. If you look at the path model in Figure 3.3, you’ll note that reaction is predicted by pmi and cond. pmi, in turn, is predicted solely by cond. So we have two regression models, which is just the kind of thing the brms multivariate syntax is for. So first let’s specify both models, which we’ll nest in bf() functions and save as objects. y_model &lt;- bf(reaction ~ 1 + pmi + cond) m_model &lt;- bf(pmi ~ 1 + cond) Now we have our bf() objects in hand, we’ll combine them with the + operator within the brm() function. We’ll also specify set_rescor(FALSE)–we’re not interested in adding a residual correlation between reaction and pmi. model3.1 &lt;- brm(data = pmi, family = gaussian, y_model + m_model + set_rescor(FALSE), cores = 4, file = &quot;fits/model03.01&quot;) Here are our results. print(model3.1) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: reaction ~ 1 + pmi + cond ## pmi ~ 1 + cond ## Data: pmi (Number of observations: 123) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## reaction_Intercept 0.52 0.56 -0.58 1.62 1.00 4994 2990 ## pmi_Intercept 5.38 0.16 5.05 5.68 1.00 6001 2896 ## reaction_pmi 0.51 0.10 0.31 0.70 1.00 5281 2959 ## reaction_cond 0.25 0.26 -0.26 0.77 1.00 6398 3090 ## pmi_cond 0.48 0.23 0.03 0.94 1.00 6409 2711 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_reaction 1.41 0.09 1.24 1.60 1.00 4435 2908 ## sigma_pmi 1.32 0.09 1.16 1.50 1.00 6602 3028 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). If you compare our model summary with the coefficients in the path model in Figure 3.3, you’ll see our coefficients are the same. The brms summary also includes intercepts and residual variances, which are typically omitted in path diagrams even though they’re still part of the model. If you’re getting lost in all the model output, try taking out the constant and error terms. fixef(model3.1)[3:5, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## reaction_pmi 0.507 0.100 0.308 0.703 ## reaction_cond 0.253 0.261 -0.257 0.772 ## pmi_cond 0.481 0.234 0.025 0.942 In his Table 3.2, Hayes included the \\(R^2\\) values. Here are ours. bayes_R2(model3.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2reaction 0.210 0.057 0.099 0.319 ## R2pmi 0.039 0.031 0.000 0.113 It’s worth it to actually plot the \\(R^2\\) distributions. We’ll take our color palette from the ggthemes package (Arnold, 2021). library(ggthemes) bayes_R2(model3.1, summary = F) %&gt;% data.frame() %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;, alpha = 2/3) + scale_fill_colorblind() + # we got this color palette from the ggthemes package coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for model3.1&quot;)), x = NULL) + theme_classic() We went through the trouble of plotting the \\(R^2\\) distributions because it’s useful to understand that they won’t often be symmetric when they’re near their logical boundaries (i.e., 0 and 1). This is where asymmetric Bayesian credible intervals can really shine. Let’s get down to business and examine the indirect effect, the \\(ab\\) pathway. In our model, \\(a\\) = pmi_cond and \\(b\\) = reaction_pmi. You can isolate them with fixef()[i, ]. fixef(model3.1)[5, ] ## Estimate Est.Error Q2.5 Q97.5 ## 0.48067590 0.23440092 0.02533352 0.94154760 fixef(model3.1)[3, ] ## Estimate Est.Error Q2.5 Q97.5 ## 0.5071028 0.1000656 0.3084225 0.7034410 So the naive approach would be to just multiply them. (fixef(model3.1)[5, ] * fixef(model3.1)[3, ]) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.244 0.023 0.008 0.662 Now, this does get us the correct ‘Estimate’ (i.e., posterior mean). However, the posterior \\(SD\\) and 95% intervals are off. If you want to do this properly, you need to work with the poster samples themselves. We do that with the posterior_samples() function. post &lt;- posterior_samples(model3.1) glimpse(post) ## Rows: 4,000 ## Columns: 8 ## $ b_reaction_Intercept &lt;dbl&gt; 0.36559647, 0.59759057, 0.76109870, 0.79578161, -0.51777597, 1.62493958, 0.7192… ## $ b_pmi_Intercept &lt;dbl&gt; 5.312075, 5.366714, 5.313554, 5.351762, 5.505363, 5.583854, 5.617829, 5.117164,… ## $ b_reaction_pmi &lt;dbl&gt; 0.5131299, 0.4871675, 0.4702092, 0.4459453, 0.6967265, 0.2983430, 0.3938866, 0.… ## $ b_reaction_cond &lt;dbl&gt; 0.28194792, 0.13524704, 0.32367895, 0.23891725, 0.35143446, 0.19791049, 0.87464… ## $ b_pmi_cond &lt;dbl&gt; 0.42154009, 0.53567033, 0.96725973, 0.63031509, 0.29318933, 0.09468811, 0.04072… ## $ sigma_reaction &lt;dbl&gt; 1.415145, 1.379133, 1.381677, 1.294263, 1.603548, 1.173935, 1.415440, 1.358086,… ## $ sigma_pmi &lt;dbl&gt; 1.355619, 1.208127, 1.403995, 1.394962, 1.181342, 1.481303, 1.284731, 1.330499,… ## $ lp__ &lt;dbl&gt; -427.1174, -427.2585, -429.8131, -427.9630, -432.0138, -436.5891, -431.7727, -4… Here we compute the indirect effect, ab. post &lt;- post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi) Now we have ab as a properly computed vector, we can summarize it with the quantile() function. quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.234 0.011 0.519 And we can even visualize it as a density. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(3)[3]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Our indirect effect, the &quot;, italic(&quot;ab&quot;), &quot; pathway&quot;)), x = NULL) + theme_classic() It’s also worth pointing out that as the indirect effect isn’t perfectly symmetric, its mean and median aren’t quite the same. post %&gt;% summarize(mean = mean(ab), median = median(ab)) %&gt;% round(digits = 3) ## mean median ## 1 0.243 0.234 Their magnitudes are similar, but this asymmetry will be a source of contrast to our estimates and the OLS estimates Hayes reported in the text. This is also something to consider when reporting on central tendency. When the indirect effect–or any other parameter, for that matter–is quite asymmetric, you might prefer reporting the median rather than the mean. On page 90, Hayes computed the adjusted means for \\(Y\\). For both cond == 1 and cond == 0, he computed the expected values for reaction when pmi was at its mean. A natural way to do that in brms is with fitted(). First we’ll put our input values for cond and pmi in a tibble, which we’ll call nd. Then we’ll feed nd into the newdata argument within the fitted() function. nd &lt;- tibble(cond = 1:0, pmi = mean(pmi$pmi)) fitted(model3.1, newdata = nd) ## , , reaction ## ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 3.617955 0.1860720 3.269416 3.991500 ## [2,] 3.365036 0.1778951 3.014780 3.729252 ## ## , , pmi ## ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 5.856277 0.1750840 5.514630 6.196228 ## [2,] 5.375601 0.1617578 5.051166 5.683241 Because model3.1 is a multivariate model, fitted() returned the model-implied summaries for both reaction and pmi. If you just want the adjusted means for reaction, you can use the resp argument within fitted(). fitted(model3.1, newdata = nd, resp = &quot;reaction&quot;) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 3.618 0.186 3.269 3.991 ## [2,] 3.365 0.178 3.015 3.729 Note how this is where the two values in the \\(Y\\) adjusted column in Table 3.1 came from. However, if we want to reproduce how Hayes computed the total effect (i.e., \\(c&#39; + ab\\)), we’ll need to work with the posterior draws themselves, post. Recall, we’ve already saved the indirect effect as a vector, ab. The direct effect, \\(c&#39;\\), is labeled b_reaction_cond within post. To get the total effect, \\(c\\), all we need to is add those vectors together. post &lt;- post %&gt;% mutate(total_effect = b_reaction_cond + ab) Here are the posterior mean with its quantile-based 95% intervals. post %&gt;% summarize(mean = mean(total_effect), ll = quantile(total_effect, prob = .025), ul = quantile(total_effect, prob = .975)) ## mean ll ul ## 1 0.4963361 -0.05526613 1.044788 3.3.1 Estimation of the model in PROCESS for SPSS and SAS. Nothing new for us, here. 3.4 Statistical inference Our approach will not match up neatly with Hayes’s on this topic. 3.4.1 Inference about the total effect of \\(X\\) on \\(Y\\). As we mentioned in Chapter 2, we can indeed focus on rejecting \\(H_0\\) when using Bayesian statistics. I, however, am not a fan of that approach and I will not be focusing on Bayesian \\(p\\)-values. But throughout this project, we will make great efforts to express the (un)certainty in our models with various plots of posterior distributions and summary statistics, such as measures of central tendency (e.g., means) and spread (e.g., percentile-based 95% intervals). So instead of \\(t\\)- and \\(p\\)-values for \\(c&#39;\\), we are going to focus on the distribution. We already gave the mean and 95% intervals, above. Here’s a look at the density. post %&gt;% ggplot(aes(x = total_effect)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(3)[2]) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(italic(c),&quot; (i.e., the total effect)&quot;))) + theme_classic() 3.4.2 Inference about the direct effect of \\(X\\) on \\(Y\\). Like in the last section, we will just look at the posterior distribution for the direct effect (i.e., \\(c&#39;\\), b_reaction_cond). post %&gt;% ggplot(aes(x = b_reaction_cond)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(4)[4]) + geom_vline(xintercept = 0, color = &quot;white&quot;, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Yep, 0 is a credible value for &quot;, italic(&quot;c&quot;), &quot;.&quot;)), x = NULL) + theme_classic() If you wanted to quantify what proportion of the density was less than 0, you could execute something like this. post %&gt;% summarize(proportion_below_zero = mean(b_reaction_cond &lt; 0)) ## proportion_below_zero ## 1 0.1605 This is something like a Bayesian \\(p\\)-value. But of course, you could always just look at the posterior intervals. posterior_interval(model3.1)[&quot;b_reaction_cond&quot;, ] ## 2.5% 97.5% ## -0.2574458 0.7719065 3.4.3 Inference about the indirect of \\(X\\) on \\(Y\\) through \\(M\\). The indirect effect quantifies how much two cases that differ by a unit on \\(X\\) are estimated to differ on \\(Y\\) as a result of \\(X\\)’s influence on \\(M\\), which in turn influences \\(Y\\). The indirect effect is relevant as to [what extent] \\(X\\)’s effect on \\(Y\\) can be said to be transmitted through the mechanism represented by the \\(X \\rightarrow M \\rightarrow Y\\) causal chain of events. (p. 95) 3.4.3.1 The normal theory approach. This is not our approach. 3.4.3.2 Bootstrap confidence interval. This is not our approach. However, Markov chain Monte Carlo (MCMC) methods are iterative and share some characteristics with boostrapping. On page 98, Hayes outlined 6 steps for constructing the \\(ab\\) bootstrap confidence interval. Here are our responses to those steps w/r/t Bayes with MCMC–or in our case HMC (i.e., Hamiltonian Monte Carlo). If HMC or MCMC, in general, are new to you, you might check out this lecture or the Stan Reference Manual if you’re more technically oriented. Anyway, Hayes’s 6 steps: 3.4.3.2.1 Step 1. With HMC we do not take random samples of the data themselves. Rather, we take random draws from the posterior distribution. The posterior distribution is the joint probability distribution of our model. 3.4.3.2.2 Step 2. After we fit our model with the brm() function and save our posterior draws in a data frame (i.e., post &lt;- posterior_samples(my_model_fit)), we then make a new column (a.k.a. vector, variable) that is the product of our coefficients for the \\(a\\) and \\(b\\) pathways. In the example above, this looked like post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi). Let’s take a look at those columns. post %&gt;% select(b_pmi_cond, b_reaction_pmi, ab) %&gt;% slice(1:10) ## b_pmi_cond b_reaction_pmi ab ## 1 0.42154009 0.5131299 0.21630483 ## 2 0.53567033 0.4871675 0.26096120 ## 3 0.96725973 0.4702092 0.45481446 ## 4 0.63031509 0.4459453 0.28108606 ## 5 0.29318933 0.6967265 0.20427277 ## 6 0.09468811 0.2983430 0.02824953 ## 7 0.04072477 0.3938866 0.01604094 ## 8 0.90712988 0.6157761 0.55858887 ## 9 0.34774045 0.3385149 0.11771532 ## 10 0.33193994 0.4354419 0.14454057 Our data frame, post, has 4,000 rows. Why 4,000? By default, brms runs 4 HMC chains. Each chain has 2,000 iterations, 1,000 of which are warmups, which we always discard. As such, there are 1,000 good iterations left in each chain and \\(1{,}000 \\times 4 = 4{,}000\\). We can change these defaults as needed. Each row in post contains the parameter values based on one of those draws. And again, these are draws from the posterior distribution. They are not draws from the data. 3.4.3.2.3 Step 3. We don’t refit the model \\(k\\) times based on the samples from the data. We take a number of draws from the posterior distribution. Hayes likes to take 5,000 samples when he bootstraps. Happily, that number is quite similar to our default 4,000 HMC draws. Whether 5,000, 4,000 or 10,000, these are all large enough numbers that the distributions become fairly stable. With HMC, however, you might want to increase the number of iterations if either measure of effective sample size, ‘Bulk_ESS’ and ‘Tail_ESS’ in the print() output, are substantially smaller than the number of iterations. 3.4.3.2.4 Step 4. When we use the quantile() function to compute our Bayesian credible intervals, we’ve sorted. Conceptually, we’ve done this. post %&gt;% select(ab) %&gt;% arrange(ab) %&gt;% slice(1:10) ## ab ## 1 -0.17350242 ## 2 -0.14797175 ## 3 -0.11911678 ## 4 -0.11519001 ## 5 -0.10195975 ## 6 -0.09700267 ## 7 -0.09497020 ## 8 -0.09417739 ## 9 -0.08930287 ## 10 -0.07417596 3.4.3.2.5 Step 5. Yes, this is what we do, too. ci &lt;- 95 0.5 * (100 - ci) ## [1] 2.5 3.4.3.2.6 Step 6. This is also what we do. ci &lt;- 95 (100 - 0.5 * (100 - ci)) ## [1] 97.5 Also, notice the headers in the rightmost two columns in our posterior_summary() output: posterior_summary(model3.1) ## Estimate Est.Error Q2.5 Q97.5 ## b_reaction_Intercept 0.5244362 0.56344986 -0.58443361 1.6188593 ## b_pmi_Intercept 5.3756008 0.16175784 5.05116562 5.6832413 ## b_reaction_pmi 0.5071028 0.10006562 0.30842255 0.7034410 ## b_reaction_cond 0.2529186 0.26139163 -0.25744582 0.7719065 ## b_pmi_cond 0.4806759 0.23440092 0.02533352 0.9415476 ## sigma_reaction 1.4058526 0.09254048 1.24092563 1.6038985 ## sigma_pmi 1.3155903 0.08528014 1.16071637 1.4959238 ## lp__ -429.7015030 1.85596449 -434.10783413 -426.9886428 Those .025 and .975 quantiles from above are just what brms is giving us in our 95% Bayesian credible intervals. Here’s our version of Figure 3.5. # these will come in handy in the subtitle ll &lt;- quantile(post$ab, probs = .025) %&gt;% round(digits = 3) ul &lt;- quantile(post$ab, probs = .975) %&gt;% round(digits = 3) post %&gt;% ggplot(aes(x = ab)) + geom_histogram(color = &quot;white&quot;, size = .25, fill = colorblind_pal()(5)[5], binwidth = .025, boundary = 0) + geom_vline(xintercept = quantile(post$ab, probs = c(.025, .975)), linetype = 3, color = colorblind_pal()(6)[6]) + labs(subtitle = str_c(&quot;95% of the posterior draws are between &quot;, ll, &quot; and &quot;, ul), x = expression(Indirect~effect~(italic(ab))), y = &quot;Frequency in 4,000 HMC posterior draws&quot;) + theme_classic() Again, as Hayes discussed how to specify different types of intervals in PROCESS on page 102, you can ask for different kinds of intervals in your print() or summary() output with the probs argument, just as you can with quantile() when working directly with the posterior draws. Hayes discussed setting the seed in PROCESS on page 104. You can do this with the seed argument in the brm() function, too. 3.4.3.3 Alternative “asymmetric” confidence interval approaches. This section does not quite refer to us. I’m a little surprised Hayes didn’t at least dedicate a paragraph or two on Bayesian estimation. Sure, he mentioned Monte Carlo, but not within the context of Bayes. So it goes. But if you’re interested, you can read about Bayesian intervals for mediation models in Yuan and MacKinnon’s (2009) Bayesian mediation analysis. And yes, Hayes is aware of this. He has cited it in his work (e.g., Andrew F. Hayes, 2015). 3.5 An example with continuous \\(X\\): Economic stress among small-business owners Here’s the estress data. estress &lt;- read_csv(&quot;data/estress/estress.csv&quot;) glimpse(estress) ## Rows: 262 ## Columns: 7 ## $ tenure &lt;dbl&gt; 1.67, 0.58, 0.58, 2.00, 5.00, 9.00, 0.00, 2.50, 0.50, 0.58, 9.00, 1.92, 2.00, 1.42, 0.92, 2… ## $ estress &lt;dbl&gt; 6.0, 5.0, 5.5, 3.0, 4.5, 6.0, 5.5, 3.0, 5.5, 6.0, 5.5, 4.0, 3.0, 2.5, 3.5, 6.0, 4.0, 6.0, 3… ## $ affect &lt;dbl&gt; 2.60, 1.00, 2.40, 1.16, 1.00, 1.50, 1.00, 1.16, 1.33, 3.00, 3.00, 2.00, 1.83, 1.16, 1.16, 1… ## $ withdraw &lt;dbl&gt; 3.00, 1.00, 3.66, 4.66, 4.33, 3.00, 1.00, 1.00, 2.00, 4.00, 4.33, 1.00, 5.00, 1.66, 4.00, 1… ## $ sex &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0… ## $ age &lt;dbl&gt; 51, 45, 42, 50, 48, 48, 51, 47, 40, 43, 57, 36, 33, 29, 33, 48, 40, 45, 37, 42, 54, 57, 37,… ## $ ese &lt;dbl&gt; 5.33, 6.05, 5.26, 4.35, 4.86, 5.05, 3.66, 6.13, 5.26, 4.00, 2.53, 6.60, 5.20, 5.66, 5.66, 5… The model set up is just like before. There are no complications switching from a binary \\(X\\) variable to a continuous one. y_model &lt;- bf(withdraw ~ 1 + estress + affect) m_model &lt;- bf(affect ~ 1 + estress) With our y_model and m_model defined, we’re ready to fit. model3.2 &lt;- brm(data = estress, family = gaussian, y_model + m_model + set_rescor(FALSE), cores = 4, file = &quot;fits/model03.02&quot;) Let’s take a look at the results. print(model3.2, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: withdraw ~ 1 + estress + affect ## affect ~ 1 + estress ## Data: estress (Number of observations: 262) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## withdraw_Intercept 1.453 0.256 0.958 1.961 1.002 6901 2868 ## affect_Intercept 0.802 0.145 0.520 1.088 1.000 6500 2875 ## withdraw_estress -0.079 0.053 -0.180 0.025 1.001 5371 3164 ## withdraw_affect 0.771 0.105 0.571 0.976 1.002 6153 2923 ## affect_estress 0.172 0.030 0.115 0.231 1.000 6316 2920 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_withdraw 1.139 0.051 1.046 1.245 1.002 6161 2605 ## sigma_affect 0.685 0.030 0.628 0.747 1.000 7455 2883 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The ‘Rhat,’ ‘Bulk_ESS,’ and ‘Tail_ESS’ values look great. Happily, the values in our summary cohere well with those Hayes reported in Table 3.5. Here are our \\(R^2\\) values. bayes_R2(model3.2) ## Estimate Est.Error Q2.5 Q97.5 ## R2withdraw 0.1830694 0.03888225 0.10989488 0.2607779 ## R2affect 0.1161616 0.03467365 0.05349846 0.1866342 These are also quite similar to those in the text. Here’s our indirect effect. # putting the posterior draws into a data frame post &lt;- posterior_samples(model3.2) # computing the ab coefficient with multiplication post &lt;- post %&gt;% mutate(ab = b_affect_estress*b_withdraw_affect) # getting the posterior median and 95% intervals with `quantile()` quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.131 0.080 0.195 We can visualize its shape, median, and 95% intervals in a density plot. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(7)[7]) + geom_vline(xintercept = quantile(post$ab, probs = c(.025, .5, .975)), color = &quot;white&quot;, linetype = c(2, 1, 2), size = c(.5, .8, .5)) + scale_x_continuous(breaks = quantile(post$ab, probs = c(.025, .5, .975)), labels = quantile(post$ab, probs = c(.025, .5, .975)) %&gt;% round(2) %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(Behold~our~italic(&quot;ab&quot;)*&#39;!&#39;), x = NULL) + theme_classic() Here’s \\(c&#39;\\), the direct effect of esterss predicting withdraw. posterior_summary(model3.2)[&quot;b_withdraw_estress&quot;, ] ## Estimate Est.Error Q2.5 Q97.5 ## -0.07905861 0.05277480 -0.18040443 0.02491451 It has wide flapping intervals which do straddle zero. A little addition will give us the direct effect, \\(c\\). post &lt;- post %&gt;% mutate(c = b_withdraw_estress + ab) quantile(post$c, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.054 -0.054 0.162 Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggthemes_4.2.4 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 splines_4.0.4 ## [6] crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 digest_0.6.27 ## [11] htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 magrittr_2.0.1 modelr_0.1.8 ## [16] RcppParallel_5.0.2 matrixStats_0.57.0 xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 ## [21] colorspace_2.0-0 rvest_1.0.1 haven_2.3.1 xfun_0.23 callr_3.7.0 ## [26] crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 survival_3.2-10 zoo_1.8-8 ## [31] glue_1.4.2 gtable_0.3.0 emmeans_1.5.2-1 V8_3.4.0 pkgbuild_1.2.0 ## [36] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 ## [41] miniUI_0.1.1.1 xtable_1.8-4 stats4_4.0.4 StanHeaders_2.21.0-7 DT_0.16 ## [46] htmlwidgets_1.5.3 httr_1.4.2 threejs_0.3.3 ellipsis_0.3.2 pkgconfig_2.0.3 ## [51] loo_2.4.1 farver_2.1.0 sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 ## [56] tidyselect_1.1.1 labeling_0.4.2 rlang_0.4.11 reshape2_1.4.4 later_1.2.0 ## [61] munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 cli_3.0.1 generics_0.1.0 ## [66] broom_0.7.6 ggridges_0.5.3 evaluate_0.14 fastmap_1.1.0 processx_3.5.2 ## [71] knitr_1.33 fs_1.5.0 nlme_3.1-152 mime_0.10 projpred_2.0.2 ## [76] xml2_1.3.2 compiler_4.0.4 bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 ## [81] gamm4_0.2-6 curl_4.3 reprex_2.0.0 statmod_1.4.35 bslib_0.2.4 ## [86] stringi_1.6.2 highr_0.9 ps_1.6.0 Brobdingnag_1.2-6 lattice_0.20-41 ## [91] Matrix_1.3-2 nloptr_1.2.2.2 markdown_1.1 shinyjs_2.0.0 vctrs_0.3.8 ## [96] pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 estimability_1.3 ## [101] httpuv_1.6.0 R6_2.5.0 bookdown_0.22 promises_1.2.0.1 gridExtra_2.3 ## [106] codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 ## [111] assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 mgcv_1.8-33 ## [116] parallel_4.0.4 hms_1.1.0 grid_4.0.4 coda_0.19-4 minqa_1.2.4 ## [121] rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 References Arnold, J. B. (2021). ggthemes: Extra themes, scales and geoms for ’ggplot2’. https://CRAN.R-project.org/package=ggthemes Bürkner, P.-C. (2021b). Estimating multivariate models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html Hayes, Andrew F. (2015). An index and test of linear moderated mediation. Multivariate Behavioral Research, 50(1), 1–22. https://doi.org/10.1080/00273171.2014.962683 Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Yuan, Y., &amp; MacKinnon, D. P. (2009). Bayesian mediation analysis. Psychological Methods, 14(4), 301–322. https://doi.org/10.1037/a0016972 "],["causal-steps-confounding-and-causal-order.html", "4 Causal Steps, Confounding, and Causal Order 4.1 What about Barron and Kenny? 4.2 Confounding and causal order 4.3 Effect size 4.4 Statistical power 4.5 Multiple \\(X\\)s or \\(Y\\)s: Analyze separately or simultaneously? 4.6 Chapter summary Session info", " 4 Causal Steps, Confounding, and Causal Order Comfort with [the principles of the basic mediation model] allows you to conduct mediation analysis and use it to shed light on your research questions and hypotheses about causal processes. In this chapter, [we] take up a variety of complications, including testing and ruling out various alternative explanations for associations observed in a mediation analysis, effect size, and models with multiple causal agents and outcomes. (Andrew F. Hayes, 2018, p. 113) 4.1 What about Barron and Kenny? Complete and partial mediation are concepts that are deeply ingrained in the thinking of social and behavioral scientists. But I just don’t see what they offer our understanding of a phenomenon. They are too sample-size-dependent and the distinction between them has no substantive or theoretical meaning or value of any consequence. I recommend avoiding expressing hypotheses about mediation or results of a mediation analysis using these terms. (p. 121) Agreed. 4.2 Confounding and causal order One of the beautiful features of experiments is the causal interpretations they afford about differences between groups. Good experimentation is tough and requires lots of careful planning and strict control over experimental procedures, construction of stimuli, treatment of participants, and so forth. But when done well, no research design gives a researcher more confidence in the claim that differences between groups defined by \\(X\\) on some variable of interest is due to \\(X\\) rather than something else. Given that a mediation model is a causal model, the ability to make unequivocal causal claims about the effect of \\(X\\) on \\(M\\) and the direct and total effects of \\(X\\) on \\(Y\\) gives experiments tremendous appeal. Absent random assignment to values of \\(X\\), all of the associations in a mediation model are susceptible to confounding and epiphenomenal association, not just the association between \\(M\\) and \\(Y\\). Whether one’s design includes manipulation and random assignment of \\(X\\) or not, it behooves the researcher to seriously ponder these potential threats to causal inference and, if possible, do something to reduce their plausibility as alternative explanations for associations observed. (pp. 121–122, emphasis in the original) 4.2.1 Accounting for confounding and epiphenomenal association. Here we load a couple necessary packages, load the data, and take a peek at them. library(tidyverse) estress &lt;- read_csv(&quot;data/estress/estress.csv&quot;) glimpse(estress) ## Rows: 262 ## Columns: 7 ## $ tenure &lt;dbl&gt; 1.67, 0.58, 0.58, 2.00, 5.00, 9.00, 0.00, 2.50, 0.50, 0.58, 9.00, 1.92, 2.00, 1.42, 0.92, 2… ## $ estress &lt;dbl&gt; 6.0, 5.0, 5.5, 3.0, 4.5, 6.0, 5.5, 3.0, 5.5, 6.0, 5.5, 4.0, 3.0, 2.5, 3.5, 6.0, 4.0, 6.0, 3… ## $ affect &lt;dbl&gt; 2.60, 1.00, 2.40, 1.16, 1.00, 1.50, 1.00, 1.16, 1.33, 3.00, 3.00, 2.00, 1.83, 1.16, 1.16, 1… ## $ withdraw &lt;dbl&gt; 3.00, 1.00, 3.66, 4.66, 4.33, 3.00, 1.00, 1.00, 2.00, 4.00, 4.33, 1.00, 5.00, 1.66, 4.00, 1… ## $ sex &lt;dbl&gt; 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0… ## $ age &lt;dbl&gt; 51, 45, 42, 50, 48, 48, 51, 47, 40, 43, 57, 36, 33, 29, 33, 48, 40, 45, 37, 42, 54, 57, 37,… ## $ ese &lt;dbl&gt; 5.33, 6.05, 5.26, 4.35, 4.86, 5.05, 3.66, 6.13, 5.26, 4.00, 2.53, 6.60, 5.20, 5.66, 5.66, 5… As we learned in Section 2.3, the psych::lowerCor() function makes it easy to estimate the lower triangle of a correlation matrix. psych::lowerCor(estress, digits = 3) ## tenur estrs affct wthdr sex age ese ## tenure 1.000 ## estress 0.068 1.000 ## affect -0.065 0.340 1.000 ## withdraw -0.035 0.064 0.417 1.000 ## sex -0.003 0.133 0.046 0.050 1.000 ## age 0.266 0.066 -0.018 -0.035 0.083 1.000 ## ese -0.060 -0.158 -0.246 -0.243 0.028 -0.083 1.000 Let’s open brms. library(brms) Recall that if you want the correlations with Bayesian estimation and those sweet Bayesian credible intervals, you set up an intercept-only multivariate model. model4.1 &lt;- brm(data = estress, family = gaussian, mvbind(ese, estress, affect, withdraw) ~ 1, cores = 4, file = &quot;fits/model04.01&quot;) Behold the summary. print(model4.1, digits = 3) ## Family: MV(gaussian, gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: ese ~ 1 ## estress ~ 1 ## affect ~ 1 ## withdraw ~ 1 ## Data: estress (Number of observations: 262) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## ese_Intercept 5.606 0.059 5.489 5.721 1.000 6087 3218 ## estress_Intercept 4.620 0.088 4.444 4.796 1.001 5433 2679 ## affect_Intercept 1.599 0.044 1.513 1.683 1.000 4489 3143 ## withdraw_Intercept 2.321 0.077 2.167 2.469 1.000 5598 3390 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_ese 0.954 0.042 0.876 1.040 1.001 5494 3044 ## sigma_estress 1.435 0.063 1.318 1.564 1.001 6330 3316 ## sigma_affect 0.728 0.033 0.669 0.793 1.001 4932 2960 ## sigma_withdraw 1.256 0.055 1.155 1.371 1.001 6103 3199 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(ese,estress) -0.152 0.061 -0.267 -0.031 1.000 5891 2960 ## rescor(ese,affect) -0.238 0.058 -0.347 -0.120 1.001 4517 3361 ## rescor(estress,affect) 0.334 0.055 0.221 0.439 1.000 4933 3637 ## rescor(ese,withdraw) -0.235 0.058 -0.346 -0.121 1.000 4695 2900 ## rescor(estress,withdraw) 0.060 0.061 -0.060 0.179 1.000 5299 3310 ## rescor(affect,withdraw) 0.410 0.050 0.307 0.503 1.002 4271 3132 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Since we have posteriors for the correlations, why not plot them? Here we take our base theme from the ggdark package (Grantham, 2019) and our color scheme from the viridis package (Garnier, 2021). library(ggdark) posterior_samples(model4.1) %&gt;% pivot_longer(c(rescor__ese__estress, rescor__ese__affect, rescor__estress__withdraw)) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(alpha = .85, color = &quot;transparent&quot;) + scale_fill_viridis_d(option = &quot;D&quot;, direction = -1, labels = c(expression(rho[&quot;ese, affect&quot;]), expression(rho[&quot;ese, estress&quot;]), expression(rho[&quot;estress, withdraw&quot;])), guide = guide_legend(label.hjust = 0, label.theme = element_text(size = 15, angle = 0, color = &quot;white&quot;), title.theme = element_blank())) + scale_x_continuous(NULL, limits = c(-1, 1)) + scale_y_continuous(NULL, breaks = NULL) + ggtitle(&quot;Our correlation density plot&quot;) + dark_theme_gray() + theme(panel.grid = element_blank()) In the last chapter, we said there were multiple ways to set up a multivariate model in brms. Our first approach was to externally define the submodels using the bf() function, save them as objects, and then include those objects within the brm() function. Another approach is to just define the separate bf() submodels directly in the brm() function, combining them with the + operator. That’s the approach we will practice in this chapter. Here’s what it looks like for our first mediation model. model4.2 &lt;- brm(data = estress, family = gaussian, bf(withdraw ~ 1 + estress + affect + ese + sex + tenure) + bf(affect ~ 1 + estress + ese + sex + tenure) + set_rescor(FALSE), cores = 4, file = &quot;fits/model04.02&quot;) Worked like a charm. Here’s the summary. print(model4.2, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: withdraw ~ 1 + estress + affect + ese + sex + tenure ## affect ~ 1 + estress + ese + sex + tenure ## Data: estress (Number of observations: 262) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## withdraw_Intercept 2.751 0.555 1.682 3.827 1.000 8821 3075 ## affect_Intercept 1.787 0.307 1.184 2.405 1.001 8408 3091 ## withdraw_estress -0.094 0.052 -0.195 0.007 1.000 6796 3021 ## withdraw_affect 0.706 0.105 0.497 0.905 1.002 8023 3389 ## withdraw_ese -0.212 0.076 -0.362 -0.067 1.000 8207 2875 ## withdraw_sex 0.124 0.143 -0.151 0.407 1.002 7817 3372 ## withdraw_tenure -0.002 0.011 -0.023 0.019 1.002 8503 2670 ## affect_estress 0.159 0.029 0.101 0.215 1.001 7860 2735 ## affect_ese -0.155 0.044 -0.242 -0.068 1.001 8602 3044 ## affect_sex 0.014 0.087 -0.152 0.184 1.002 9100 2881 ## affect_tenure -0.011 0.006 -0.023 0.002 1.005 9255 2900 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_withdraw 1.126 0.049 1.038 1.224 1.002 8534 3015 ## sigma_affect 0.670 0.029 0.616 0.732 1.001 7602 3108 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In the printout, notice how first within intercepts and then with covariates and sigma, the coefficients are presented as for withdraw first and then affect. Also notice how the coefficients for the covariates are presented in the same order for each criterion variable. Hopefully that’ll make it easier to sift through the printout. Happily, our coefficients are quite similar to those in Table 4.1. Here are the \\(R^2\\) summaries. bayes_R2(model4.2) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2withdraw 0.212 0.038 0.137 0.286 ## R2affect 0.170 0.036 0.100 0.240 These are also in the same ballpark, but a little higher. Why not glance at their densities? bayes_R2(model4.2, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = .85) + scale_fill_viridis_d(option = &quot;A&quot;, begin = .33, direction = -1, labels = c(&quot;affect&quot;, &quot;withdaw&quot;), guide = guide_legend(title.theme = element_blank())) + scale_x_continuous(NULL, limits = 0:1) + scale_y_continuous(NULL, breaks = NULL) + ggtitle(expression(The~italic(R)^2~distributions~&quot;for&quot;~model~4.2)) + dark_theme_gray() + theme(panel.grid = element_blank()) Here we retrieve the posterior samples, compute the indirect effect, and summarize the indirect effect with quantile(). post &lt;- posterior_samples(model4.2) %&gt;% mutate(ab = b_affect_estress * b_withdraw_affect) quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) ## 50% 2.5% 97.5% ## 0.111 0.065 0.168 The results are similar to those in the text (p. 127). Here’s what it looks like. post %&gt;% ggplot(aes(x = ab)) + geom_density(aes(fill = factor(0)), color = &quot;transparent&quot;, show.legend = F) + geom_vline(xintercept = quantile(post$ab, probs = c(.5, .025, .975)), color = &quot;black&quot;, linetype = c(1, 3, 3)) + scale_fill_viridis_d(option = &quot;A&quot;, begin = .6) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(italic(ab))) + dark_theme_gray() + theme(panel.grid = element_blank()) Once again, those sweet Bayesian credible intervals get the job done. Here’s a way to get both the direct effect, \\(c&#39;\\) (i.e., b_withdraw_estress), and the total effect, \\(c\\) (i.e., \\(c&#39;\\) + \\(ab\\)) of estress on withdraw. post %&gt;% mutate(c = b_withdraw_estress + ab, c_prime = b_withdraw_estress) %&gt;% pivot_longer(c(c_prime, c)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 2 x 4 ## name mean ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c 0.018 -0.084 0.121 ## 2 c_prime -0.094 -0.195 0.007 Both appear pretty small. Which leads us to the next section… 4.3 Effect size The quantification of effect size in mediation analysis is an evolving area of thought and research. [Hayes described] two measures of effect size that apply to the direct, indirect, and total effects in a mediation model…. For an excellent discussion of measures of effect size in mediation analysis, see Preacher and Kelley (2011). [We will] use their notation below. (p. 133) 4.3.1 The partially standardized effect. We get \\(SD\\)s using the sd() function. Here’s the \\(SD\\) for our \\(Y\\) variable, withdraw. sd(estress$withdraw) ## [1] 1.24687 Here we compute the partially standardized effect sizes for \\(c&#39;\\) and \\(ab\\) by dividing those vectors in our post object by sd(estress$withdraw), which we saved as sd_y. sd_y &lt;- sd(estress$withdraw) post %&gt;% mutate(c_prime_ps = b_withdraw_estress / sd_y, ab_ps = ab / sd_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% pivot_longer(c(c_prime_ps, ab_ps, c_ps)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_ps 0.09 0.089 0.052 0.135 ## 2 c_prime_ps -0.075 -0.075 -0.156 0.005 ## 3 c_ps 0.015 0.015 -0.067 0.097 The results are similar, though not identical, to those in the text. Here we have both rounding error and estimation differences at play. The plots: post %&gt;% mutate(c_prime_ps = b_withdraw_estress / sd_y, ab_ps = ab / sd_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% pivot_longer(c(c_prime_ps, ab_ps, c_ps)) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(alpha = .85, color = &quot;transparent&quot;) + scale_fill_viridis_d(option = &quot;D&quot;, breaks = NULL) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Partially-standardized coefficients&quot;, x = NULL) + dark_theme_gray() + theme(panel.grid = element_blank()) + facet_wrap(~ name, ncol = 3) On page 135, Hayes revisited the model from Section 3.3. We’ll have to reload the data and refit that model to follow along. First, load the data. pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) Refit the model, this time with the bf() statements defined right within brm(). model4.3 &lt;- brm(data = pmi, family = gaussian, bf(reaction ~ 1 + pmi + cond) + bf(pmi ~ 1 + cond) + set_rescor(FALSE), cores = 4, file = &quot;fits/model04.03&quot;) The partially-standardized parameters require some posterior_samples() wrangling. post &lt;- posterior_samples(model4.3) sd_y &lt;- sd(pmi$reaction) post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi, c_prime = b_reaction_cond) %&gt;% mutate(ab_ps = ab / sd_y, c_prime_ps = c_prime / sd_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% pivot_longer(c(c_prime_ps, ab_ps, c_ps)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_ps 0.154 0.148 0.007 0.331 ## 2 c_prime_ps 0.161 0.16 -0.164 0.493 ## 3 c_ps 0.315 0.317 -0.042 0.657 Happily, these results are closer to those in the text than with the previous example. 4.3.2 The completely standardized effect. Note. Hayes could have made this clearer in the text, but the estress model he referred to in this section was the one from way back in Section 3.5, not the one from earlier in this chapter. One way to get a standardized solution is to standardize the variables in the data and then fit the model with those standardized variables. To do so, we’ll revisit our custom standardize(), put it to work, and fit the standardized version of the model from Section 3.5, which we’ll call model4.4. # make the function sandardize &lt;- function(x) { (x - mean(x)) / sd(x) } # use the function estress &lt;- estress %&gt;% mutate(withdraw_z = sandardize(withdraw), estress_z = sandardize(estress), affect_z = sandardize(affect)) Fit the model. model4.4 &lt;- brm(data = estress, family = gaussian, bf(withdraw_z ~ 1 + estress_z + affect_z) + bf(affect_z ~ 1 + estress_z) + set_rescor(FALSE), cores = 4, file = &quot;fits/model04.04&quot;) Here they are, our newly standardized coefficients. fixef(model4.4) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## withdrawz_Intercept 0.000 0.057 -0.115 0.117 ## affectz_Intercept 0.000 0.059 -0.113 0.118 ## withdrawz_estress_z -0.088 0.059 -0.206 0.027 ## withdrawz_affect_z 0.445 0.059 0.329 0.560 ## affectz_estress_z 0.339 0.059 0.224 0.454 Here we do the wrangling necessary to spell out the standardized effects for \\(ab\\), \\(c&#39;\\), and \\(c\\). posterior_samples(model4.4) %&gt;% mutate(ab_s = b_affectz_estress_z * b_withdrawz_affect_z, c_prime_s = b_withdrawz_estress_z) %&gt;% mutate(c_s = ab_s + c_prime_s) %&gt;% pivot_longer(c(c_prime_s, ab_s, c_s)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_s 0.151 0.149 0.091 0.22 ## 2 c_prime_s -0.088 -0.087 -0.206 0.027 ## 3 c_s 0.063 0.063 -0.057 0.183 Let’s confirm that we can recover these values by applying the formulas on page 135 to the unstandardized model, which we’ll call model4.5. First, we’ll have to fit that model since we haven’t fit that one since Chapter 3. model4.5 &lt;- brm(data = estress, family = gaussian, bf(withdraw ~ 1 + estress + affect) + bf(affect ~ 1 + estress) + set_rescor(FALSE), cores = 4, file = &quot;fits/model04.05&quot;) Check the unstandardized coefficient summaries. fixef(model4.5) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## withdraw_Intercept 1.449 0.251 0.953 1.938 ## affect_Intercept 0.800 0.146 0.511 1.080 ## withdraw_estress -0.077 0.054 -0.181 0.029 ## withdraw_affect 0.770 0.103 0.572 0.969 ## affect_estress 0.173 0.030 0.116 0.232 On pages 135–136, Hayes provided the formulas to compute the standardized effects, which are \\[\\begin{align*} c&#39;_{cs} &amp; = \\frac{SD_X(c&#39;)}{SD_{Y}} = SD_{X}(c&#39;_{ps}), \\\\ ab_{cs} &amp; = \\frac{SD_X(ab)}{SD_{Y}} = SD_{X}(ab_{ps}), \\text{and} \\\\ c_{cs} &amp; = \\frac{SD_X(c)}{SD_{Y}} = c&#39;_{cs} + ab_{ps}, \\end{align*}\\] where the \\(ps\\) subscript indicates partially standardized. Here we put them in action to standardize the unstandardized results. sd_x &lt;- sd(estress$estress) sd_y &lt;- sd(estress$withdraw) posterior_samples(model4.5) %&gt;% mutate(ab = b_affect_estress * b_withdraw_affect, c_prime = b_withdraw_estress) %&gt;% mutate(ab_s = (sd_x * ab) / sd_y, c_prime_s = (sd_x * c_prime) / sd_y) %&gt;% mutate(c_s = ab_s + c_prime_s) %&gt;% pivot_longer(c(c_prime_s, ab_s, c_s)) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 ab_s 0.152 0.15 0.092 0.224 ## 2 c_prime_s -0.088 -0.089 -0.206 0.033 ## 3 c_s 0.064 0.064 -0.063 0.189 Success! 4.3.3 Some (problematic) measures only for indirect effects. Hayes recommended against these, so I’m not going to bother working any examples. 4.4 Statistical power As Hayes discussed, power is an important but thorny issue within the frequentist paradigm. Given that we’re not particularly interested in rejecting the point-null hypothesis as Bayesians and that we bring in priors (which we’ve largely avoided explicitly mentioning in his project but have been quietly using all along), the issue is even more difficult for Bayesians. To learn more on the topic, check out Chapter 13 in Kruschke’s (2015) text; Miočević, MacKinnon, and Levy’s (2017) paper on power in small-sample Bayesian analyses; or Gelman and Carlin’s (2014) paper offering an alternative to the power paradigm. You might look at Matti Vuorre’s Sample size planning with brms project. And finally, I have a series of blog posts on Bayesian power analyses. You can find the first post here. 4.5 Multiple \\(X\\)s or \\(Y\\)s: Analyze separately or simultaneously? “Researchers sometimes propose that several causal agents (\\(X\\) variables simultaneously transmit their effects on the same outcome through the same mediator(s)” (p. 141). 4.5.1 Multiple \\(X\\) variables. The danger in including multiple \\(X\\)’s in a mediation model, as when including statistical controls, is the possibility that highly correlated \\(X\\)s will cancel out each other’s effects. This is a standard concern in linear models involving correlated predictors. Two \\(X\\) variables (or an \\(X\\) variable and a control variable) highly correlated with each other may also both be correlated with \\(M\\) or \\(Y\\), so when they are both included as predictors of \\(M\\) or \\(Y\\) in a mediation model, they compete against each other in their attempt to explain variation in \\(M\\) and \\(Y\\). Their regression coefficients quantify their unique association with the model’s mediator and outcome variable(s). at the extreme, the two variables end up performing like two boxers in the ring simultaneously throwing a winning blow at the other at precisely the same time. Both get knocked out and neither goes away appearing worthy of a prize. The stronger the associations between the variables in the model, the greater the potential of such a problem. (pp. 143–144) The same basic problems with multicollinearity applies to the Bayesian paradigm, too. 4.5.2 Estimation of a model with multiple \\(X\\) variables in PROCESS brms. Hayes discussed the limitation that his PROCESS program may only handle a single \\(X\\) variable in the x= part of the command line, for which he displayed a workaround. We don’t have such a limitation in brms. Using Hayes’s hypothetical data syntax for a model with three \\(X\\)s, the brms code would be like this. model4.6 &lt;- brm(data = data, family = gaussian, bf(dv ~ 1 + iv1 + iv2 + iv3 + med) + bf(med ~ 1 + iv1 + iv2 + iv3) + set_rescor(FALSE), cores = 4) To show it in action, let’s simulate some data. n &lt;- 1e3 set.seed(4.5) d &lt;- tibble(iv1 = rnorm(n, mean = 0, sd = 1), iv2 = rnorm(n, mean = 0, sd = 1), iv3 = rnorm(n, mean = 0, sd = 1)) %&gt;% mutate(med = rnorm(n, mean = 0 + iv1 * -1 + iv2 * 0 + iv3 * 1, sd = 1), dv = rnorm(n, mean = 0 + iv1 * 0 + iv2 * .5 + iv3 * 1 + med * .5, sd = 1)) head(d) ## # A tibble: 6 x 5 ## iv1 iv2 iv3 med dv ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.217 0.177 -1.39 -0.755 -1.77 ## 2 -0.542 1.69 0.0513 0.721 0.402 ## 3 0.891 -1.35 1.10 0.777 -0.132 ## 4 0.596 1.08 -0.203 -0.955 1.02 ## 5 1.64 -0.456 -0.428 -2.89 -3.26 ## 6 0.689 -0.681 -0.429 -0.462 -2.38 Before we proceed, if data simulation is new to you, you might check out Roger Peng’s helpful tutorial or this great post by Ariel Muldoon. Here we fit the model. model4.6 &lt;- brm(data = d, family = gaussian, bf(dv ~ 1 + iv1 + iv2 + iv3 + med) + bf(med ~ 1 + iv1 + iv2 + iv3) + set_rescor(FALSE), cores = 4, file = &quot;fits/model04.06&quot;) Behold the results. print(model4.6) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: dv ~ 1 + iv1 + iv2 + iv3 + med ## med ~ 1 + iv1 + iv2 + iv3 ## Data: d (Number of observations: 1000) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## dv_Intercept -0.01 0.03 -0.07 0.05 1.00 5563 2948 ## med_Intercept 0.00 0.03 -0.06 0.06 1.01 5932 2990 ## dv_iv1 0.02 0.04 -0.06 0.11 1.00 2936 3181 ## dv_iv2 0.56 0.03 0.50 0.62 1.00 5294 3120 ## dv_iv3 1.01 0.05 0.92 1.10 1.00 2647 2918 ## dv_med 0.46 0.03 0.40 0.53 1.00 2276 3057 ## med_iv1 -0.93 0.03 -0.99 -0.87 1.00 5722 2991 ## med_iv2 0.03 0.03 -0.03 0.09 1.00 6016 3358 ## med_iv3 0.98 0.03 0.92 1.04 1.00 5080 3188 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_dv 1.00 0.02 0.96 1.05 1.00 6096 3420 ## sigma_med 0.97 0.02 0.93 1.02 1.00 6141 2674 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Good old brms::brm() came through just fine. If you wanted to simulate data with a particular correlation structure for the iv variables, you might use the mvnorm() function from the MASS package (Ripley, 2019), about which you might learn more here. 4.5.3 Multiple \\(Y\\) variables. We’ve already been using the multivariate syntax in brms for our simple mediation models. Fitting a mediation model with multiple \\(Y\\) variables is a minor extension. To see, let’s simulate more data. n &lt;- 1e3 set.seed(4.5) d &lt;- tibble(iv = rnorm(n, mean = 0, sd = 1)) %&gt;% mutate(med = rnorm(n, mean = 0 + iv * .5, sd = 1)) %&gt;% mutate(dv1 = rnorm(n, mean = 0 + iv * -1 + med * 0, sd = 1), dv2 = rnorm(n, mean = 0 + iv * 0 + med * .5, sd = 1), dv3 = rnorm(n, mean = 0 + iv * 1 + med * 1, sd = 1)) head(d) ## # A tibble: 6 x 5 ## iv med dv1 dv2 dv3 ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.217 0.285 -1.61 0.999 0.420 ## 2 -0.542 1.42 0.594 0.836 0.0208 ## 3 0.891 -0.902 0.206 0.120 -0.954 ## 4 0.596 1.37 -0.799 0.530 3.13 ## 5 1.64 0.362 -2.06 -0.643 0.840 ## 6 0.689 -0.337 -1.12 0.487 -1.03 Fitting this model requires a slew of bf() statements. model4.7 &lt;- brm(data = d, family = gaussian, bf(dv1 ~ 1 + iv + med) + bf(dv2 ~ 1 + iv + med) + bf(dv3 ~ 1 + iv + med) + bf(med ~ 1 + iv) + set_rescor(FALSE), cores = 4, file = &quot;fits/model04.07&quot;) print(model4.7) ## Family: MV(gaussian, gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: dv1 ~ 1 + iv + med ## dv2 ~ 1 + iv + med ## dv3 ~ 1 + iv + med ## med ~ 1 + iv ## Data: d (Number of observations: 1000) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## dv1_Intercept 0.01 0.03 -0.05 0.07 1.00 7782 2950 ## dv2_Intercept 0.00 0.03 -0.06 0.06 1.00 9468 2665 ## dv3_Intercept -0.01 0.03 -0.07 0.05 1.00 8215 3088 ## med_Intercept 0.03 0.03 -0.04 0.09 1.00 8338 2614 ## dv1_iv -1.05 0.04 -1.12 -0.98 1.00 7263 3775 ## dv1_med 0.05 0.03 -0.01 0.11 1.00 6496 3123 ## dv2_iv 0.05 0.04 -0.01 0.12 1.00 7273 3579 ## dv2_med 0.53 0.03 0.47 0.59 1.00 7052 3400 ## dv3_iv 1.03 0.04 0.96 1.10 1.00 6657 3425 ## dv3_med 1.06 0.03 1.00 1.12 1.00 7032 3216 ## med_iv 0.53 0.03 0.46 0.59 1.00 9368 3051 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_dv1 0.98 0.02 0.93 1.02 1.00 9337 2811 ## sigma_dv2 0.97 0.02 0.93 1.02 1.00 8831 2717 ## sigma_dv3 1.00 0.02 0.96 1.05 1.00 9864 3125 ## sigma_med 1.00 0.02 0.96 1.04 1.00 9883 2936 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Once again, brms to the rescue! 4.6 Chapter summary Statistical mediation analysis has changed since the publication of Baron and Kenny (1986). The heyday of the causal steps “criteria to establish mediation” approach is over. Also disappearing in the 21 century is a concern about whether a process can be labeled as complete or partial mediation. Modern mediation analysis emphasizes an explicit estimation of the indirect effect, inferential tests of the indirect effect that don’t make unnecessary assumptions, and an acknowledgement that evidence of a statistically significant association between \\(X\\) and \\(Y\\) is not necessary to talk about a model intervening variable process (in which case the concepts of complete and partial mediation simply don’t make sense). (p. 146) To this, I’ll just point out Hayes is speaking from a frequentist hypothesis-testing orientation. If you would like to dwell on significance tests, you certainty can. But particularly from within the Bayesian paradigm, you just don’t need to. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] ggdark_0.2.1 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 splines_4.0.4 ## [6] crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 digest_0.6.27 ## [11] htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 magrittr_2.0.1 modelr_0.1.8 ## [16] RcppParallel_5.0.2 matrixStats_0.57.0 xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 ## [21] colorspace_2.0-0 rvest_1.0.1 haven_2.3.1 xfun_0.23 callr_3.7.0 ## [26] crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 survival_3.2-10 zoo_1.8-8 ## [31] glue_1.4.2 gtable_0.3.0 emmeans_1.5.2-1 V8_3.4.0 pkgbuild_1.2.0 ## [36] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 ## [41] miniUI_0.1.1.1 viridisLite_0.4.0 xtable_1.8-4 tmvnsim_1.0-2 stats4_4.0.4 ## [46] StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 httr_1.4.2 threejs_0.3.3 ## [51] ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 sass_0.3.1 ## [56] dbplyr_2.1.1 utf8_1.2.1 labeling_0.4.2 tidyselect_1.1.1 rlang_0.4.11 ## [61] reshape2_1.4.4 later_1.2.0 munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 ## [66] cli_3.0.1 generics_0.1.0 broom_0.7.6 ggridges_0.5.3 evaluate_0.14 ## [71] fastmap_1.1.0 processx_3.5.2 knitr_1.33 fs_1.5.0 nlme_3.1-152 ## [76] mime_0.10 projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 bayesplot_1.8.0 ## [81] shinythemes_1.1.2 rstudioapi_0.13 gamm4_0.2-6 curl_4.3 reprex_2.0.0 ## [86] statmod_1.4.35 bslib_0.2.4 stringi_1.6.2 highr_0.9 ps_1.6.0 ## [91] Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 psych_2.1.3 nloptr_1.2.2.2 ## [96] markdown_1.1 shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 lifecycle_1.0.0 ## [101] jquerylib_0.1.4 bridgesampling_1.0-0 estimability_1.3 httpuv_1.6.0 R6_2.5.0 ## [106] bookdown_0.22 promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 boot_1.3-26 ## [111] colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 assertthat_0.2.1 withr_2.4.2 ## [116] shinystan_2.5.0 mnormt_2.0.2 multcomp_1.4-16 mgcv_1.8-33 parallel_4.0.4 ## [121] hms_1.1.0 grid_4.0.4 coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 ## [126] shiny_1.6.0 lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 References Baron, R. M., &amp; Kenny, D. A. (1986). The moderatormediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations. Journal of Personality and Social Psychology, 51(6), 1173–1182. https://doi.org/10.1037/0022-3514.51.6.1173 Garnier, S. (2021). viridis: Default color maps from ’matplotlib’ [Manual]. https://CRAN.R-project.org/package=viridis Gelman, A., &amp; Carlin, J. (2014). Beyond power calculations: Assessing type S (sign) and type M (magnitude) errors. Perspectives on Psychological Science, 9(6), 641–651. https://doi.org/10.1177/1745691614551642 Grantham, N. (2019). ggdark: Dark mode for ’ggplot2’ themes [Manual]. https://CRAN.R-project.org/package=ggdark Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Kruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/ Miočević, M., MacKinnon, D. P., &amp; Levy, R. (2017). Power in Bayesian mediation analysis for small sample research. Structural Equation Modeling: A Multidisciplinary Journal, 24(5), 666–683. https://doi.org/10.1080/10705511.2017.1312407 Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: Quantitative strategies for communicating indirect effects. Psychological Methods, 16(2), 93–115. https://doi.org/10.1037/a0022658 Ripley, B. (2019). MASS: Support functions and datasets for venables and ripley’s MASS. https://CRAN.R-project.org/package=MASS "],["more-than-one-mediator.html", "5 More Than One Mediator 5.1 The parallel multiple mediator model 5.2 Example using the presumed media influence study 5.3 Statistical inference 5.4 The serial multiple mediator model 5.5 Models with parallel and serial mediation properties 5.6 Complementarity and competition among mediators Session info", " 5 More Than One Mediator In this chapter we’ll explore models with more than one mediator. [We will] focus on two forms of the multiple mediator model defined by whether the mediators are linked together in a causal chain (the serial multiple mediator model) or are merely allowed to correlate bot not causally influence another mediator in the model (the parallel multiple mediator model). [We’ll] also discuss models that blend parallel and serial processes. (Andrew F. Hayes, 2018, p. 149, emphasis in the original) 5.1 The parallel multiple mediator model Going from one to multiple mediators can be a big step up, conceptually. But from a model fitting perspective, it often isn’t that big of a deal. We just have more parameters. 5.1.1 Direct and indirect effects in a parallel multiple mediator model. With multiple mediators, we use the language of specific indirect effects. We also add the notion of a total indirect effect, following the form \\[\\text{Total indirect effect of } X \\text{ on } Y = \\sum_{i = 1}^k a_i b_i,\\] where \\(k\\) is the number of mediator variables. Thus, the total effect of \\(X\\) on \\(Y\\) is \\[c = c&#39; + \\sum_{i = 1}^k a_i b_i.\\] 5.2 Example using the presumed media influence study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) glimpse(pmi) ## Rows: 123 ## Columns: 6 ## $ cond &lt;dbl&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0… ## $ pmi &lt;dbl&gt; 7.0, 6.0, 5.5, 6.5, 6.0, 5.5, 3.5, 6.0, 4.5, 7.0, 1.0, 6.0, 5.0, 7.0, 7.0, 7.0, 4.5, 3.5, 7… ## $ import &lt;dbl&gt; 6, 1, 6, 6, 5, 1, 1, 6, 6, 6, 3, 3, 4, 7, 1, 6, 3, 3, 2, 4, 4, 6, 7, 4, 5, 4, 6, 5, 5, 7, 4… ## $ reaction &lt;dbl&gt; 5.25, 1.25, 5.00, 2.75, 2.50, 1.25, 1.50, 4.75, 4.25, 6.25, 1.25, 2.75, 3.75, 5.00, 4.00, 5… ## $ gender &lt;dbl&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0… ## $ age &lt;dbl&gt; 51.0, 40.0, 26.0, 21.0, 27.0, 25.0, 23.0, 25.0, 22.0, 24.0, 22.0, 21.0, 23.0, 21.0, 22.0, 2… Now load brms. library(brms) Bayesian correlations, recall, just take an intercepts-only multivariate model. model5.1 &lt;- brm(data = pmi, family = gaussian, mvbind(pmi, import) ~ 1, cores = 4, file = &quot;fits/model05.01&quot;) A little indexing with the posterior_summary() function will get us the Bayesian correlation with its posterior \\(SD\\) and intervals. posterior_summary(model5.1)[&quot;rescor__pmi__import&quot;, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.278 0.082 0.115 0.431 As with single mediation models, the multiple mediation model requires we carefully construct the formula for each criterion. Here we’ll use the multiple bf() approach from Chapter 3. m1_model &lt;- bf(import ~ 1 + cond) m2_model &lt;- bf(pmi ~ 1 + cond) y_model &lt;- bf(reaction ~ 1 + import + pmi + cond) And now we fit the model. model5.2 &lt;- brm(data = pmi, family = gaussian, y_model + m1_model + m2_model + set_rescor(FALSE), cores = 4, file = &quot;fits/model05.02&quot;) print(model5.2, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: reaction ~ 1 + import + pmi + cond ## import ~ 1 + cond ## pmi ~ 1 + cond ## Data: pmi (Number of observations: 123) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## reaction_Intercept -0.159 0.533 -1.225 0.878 1.001 8229 3166 ## import_Intercept 3.906 0.212 3.488 4.340 1.001 9383 2960 ## pmi_Intercept 5.379 0.164 5.058 5.696 1.001 8461 3029 ## reaction_import 0.325 0.071 0.181 0.460 1.003 7906 3403 ## reaction_pmi 0.397 0.092 0.217 0.586 1.001 7868 3379 ## reaction_cond 0.106 0.240 -0.360 0.587 1.000 7723 2872 ## import_cond 0.628 0.306 0.044 1.224 1.001 9949 3317 ## pmi_cond 0.475 0.240 0.003 0.960 1.004 9187 3054 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_reaction 1.302 0.086 1.148 1.487 1.001 9615 2684 ## sigma_import 1.730 0.112 1.524 1.968 1.001 9796 3095 ## sigma_pmi 1.317 0.089 1.160 1.506 1.001 10111 2946 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Because we have three criterion variables, we’ll have three Bayesian \\(R^2\\) posteriors. library(ggthemes) bayes_R2(model5.2, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% mutate(name = str_remove(name, &quot;R2&quot;)) %&gt;% ggplot(aes(x = value, color = name, fill = name)) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_x_continuous(NULL, limits = 0:1) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(Our~italic(R)^{2}~distributions), subtitle = &quot;The densities for import and pmi are asymmetric, small, and largely overlapping.\\nThe density for reaction is approximately Gaussian and more impressive in magnitude.&quot;) + theme_minimal() + theme(legend.title = element_blank()) It’ll take a bit of data wrangling to rename our model parameters to the \\(a\\), \\(b\\)… configuration. We’ll compute the indirect effects and \\(c\\), too. post &lt;- posterior_samples(model5.2) post &lt;- post %&gt;% mutate(a1 = b_import_cond, a2 = b_pmi_cond, b1 = b_reaction_import, b2 = b_reaction_pmi, c_prime = b_reaction_cond) %&gt;% mutate(a1b1 = a1 * b1, a2b2 = a2 * b2) %&gt;% mutate(c = c_prime + a1b1 + a2b2) Next we compute their summaries. Since Bayesians use means, medians, and sometimes the mode to describe the central tendencies of a parameter, this time we’ll mix it up and just use the median. We’ve been summarizing our posteriors within the summarize() function. This approach gives us a lot of control. It’s also on the verbose side. Another approach is to use a family of functions from the tidybayes package. Here we’ll use median_qi() to give us the posterior medians and quantile-based 95% intervals for our parameters of interest. library(tidybayes) post %&gt;% pivot_longer(a1:c) %&gt;% group_by(name) %&gt;% median_qi(value) ## # A tibble: 8 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 0.628 0.0436 1.22 0.95 median qi ## 2 a1b1 0.196 0.0133 0.449 0.95 median qi ## 3 a2 0.476 0.00292 0.960 0.95 median qi ## 4 a2b2 0.180 0.00137 0.435 0.95 median qi ## 5 b1 0.326 0.181 0.460 0.95 median qi ## 6 b2 0.396 0.217 0.586 0.95 median qi ## 7 c 0.496 -0.0437 1.02 0.95 median qi ## 8 c_prime 0.103 -0.360 0.587 0.95 median qi In the value column, we have our measure of central tendency (i.e., median). The 95% intervals are in the next two columns. With tidybayes, we can ask for different kinds of intervals and different kinds of measures of central tendency, as indicated by the .width and .point columns, respectively. For example, here’s the output for the same variables when we ask for posterior means and 80% intervals. post %&gt;% pivot_longer(a1:c) %&gt;% group_by(name) %&gt;% mean_qi(value, .width = .8) %&gt;% # for good measure mutate_if(is_double, round, digits = 3) ## # A tibble: 8 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 0.628 0.23 1.02 0.8 mean qi ## 2 a1b1 0.205 0.068 0.356 0.8 mean qi ## 3 a2 0.475 0.161 0.784 0.8 mean qi ## 4 a2b2 0.189 0.058 0.326 0.8 mean qi ## 5 b1 0.325 0.234 0.414 0.8 mean qi ## 6 b2 0.397 0.283 0.515 0.8 mean qi ## 7 c 0.5 0.154 0.847 0.8 mean qi ## 8 c_prime 0.106 -0.204 0.407 0.8 mean qi For more in this family of tidybayes functions, check out the Point summaries and intervals subsection of Kay’s (2020a) vignette, Extracting and visualizing tidy draws from brms models. In the middle paragraph of page 158, Hayes showed how the mean difference in imprt between the two cond groups multiplied by b1, the coefficient of import predicting reaction, is equal to the a1b1 indirect effect. He did that with simple algebra using the group means and the point estimates, following the formula \\[a_1 b_1 = \\left \\{ \\left [\\overline M_1 | (X = 1) \\right] - \\left[\\overline M_1 | (X = 0) \\right ] \\right \\} b_1.\\] Let’s follow along. First, we’ll get those two group means and save them as numbers to arbitrary precision. ( import_means &lt;- pmi %&gt;% group_by(cond) %&gt;% summarize(mean = mean(import)) ) ## # A tibble: 2 x 2 ## cond mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 3.91 ## 2 1 4.53 (cond_0_import_mean &lt;- import_means[1, 2] %&gt;% pull()) ## [1] 3.907692 (cond_1_import_mean &lt;- import_means[2, 2] %&gt;% pull()) ## [1] 4.534483 Here we follow the formula in the last sentence of the paragraph and then compare the results to the posterior for a1b1. post %&gt;% # use Hayes&#39;s formula to make a new vector, `handmade a1b1` mutate(`handmade a1b1` = (cond_1_import_mean - cond_0_import_mean) * b1) %&gt;% # wrangle as usual pivot_longer(c(a1b1, `handmade a1b1`)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b1 0.205 0.013 0.449 0.95 mean qi ## 2 handmade a1b1 0.204 0.113 0.288 0.95 mean qi Yep, Hayes’s formula is good at the mean. But the distributions are distinct with vastly different posterior intervals. I’m no mathematician, so take this with a grain of salt, but I suspect this has to do with how we used fixed values (i.e., the difference of the subsample means) to compute handmade a1b1, but all the components in a1b1 were estimated. Here we’ll follow the same protocol for a2b2. ( pmi_means &lt;- pmi %&gt;% group_by(cond) %&gt;% summarize(mean = mean(pmi)) ) ## # A tibble: 2 x 2 ## cond mean ## &lt;dbl&gt; &lt;dbl&gt; ## 1 0 5.38 ## 2 1 5.85 cond_0_pmi_mean &lt;- pmi_means[1, 2] %&gt;% pull() cond_1_pmi_mean &lt;- pmi_means[2, 2] %&gt;% pull() post %&gt;% mutate(`handmade a2b2` = (cond_1_pmi_mean - cond_0_pmi_mean) * b2) %&gt;% pivot_longer(c(a2b2, `handmade a2b2`)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a2b2 0.189 0.001 0.435 0.95 mean qi ## 2 handmade a2b2 0.189 0.104 0.279 0.95 mean qi To get the total indirect effect as discussed on page 160, we simply add the a1b1 and a2b2 columns. post &lt;- post %&gt;% mutate(total_indirect_effect = a1b1 + a2b2) post %&gt;% mean_qi(total_indirect_effect) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 1 x 6 ## total_indirect_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.394 0.11 0.707 0.95 mean qi To use the equations on the top of page 161, we’ll just work directly with the original vectors in post. post %&gt;% mutate(Y_bar_given_X_1 = b_import_Intercept + b_reaction_cond * 1 + b_reaction_import * b_import_Intercept + b_reaction_pmi * b_pmi_Intercept, Y_bar_given_X_0 = b_import_Intercept + b_reaction_cond * 0 + b_reaction_import * b_import_Intercept + b_reaction_pmi * b_pmi_Intercept) %&gt;% mutate(`c_prime by hand` = Y_bar_given_X_1 - Y_bar_given_X_0) %&gt;% pivot_longer(c(c_prime, `c_prime by hand`)) %&gt;% group_by(name) %&gt;% mean_qi(value) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 c_prime 0.106 -0.360 0.587 0.95 mean qi ## 2 c_prime by hand 0.106 -0.360 0.587 0.95 mean qi We computed c a while ago. post %&gt;% mean_qi(c) ## # A tibble: 1 x 6 ## c .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.500 -0.0437 1.02 0.95 mean qi And c minus c_prime is straight subtraction. post %&gt;% mutate(`c minus c_prime` = c - c_prime) %&gt;% mean_qi(`c minus c_prime`) ## # A tibble: 1 x 6 ## `c minus c_prime` .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.394 0.110 0.707 0.95 mean qi 5.3 Statistical inference We’ve been focusing on this all along with our posterior intervals. 5.3.1 Inference about the direct and total effects. We’re not going to bother with \\(p\\)-values and we’ve already computed the 95% Bayesian credible intervals, above. But we can examine our parameters with a density plot. post %&gt;% pivot_longer(c(c, c_prime)) %&gt;% ggplot(aes(x = value, fill = name, color = name)) + geom_vline(xintercept = 0, color = &quot;black&quot;) + geom_density(alpha = .5) + scale_color_ptol(NULL) + scale_fill_ptol(NULL) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(&quot;It appears zero is more credible for the direct effect&quot;~italic(c)*&quot;&#39;, than it is the total effect, &quot;*italic(c)*&quot;.&quot;), x = NULL) + coord_cartesian(xlim = -c(-1.5, 1.5)) + theme_minimal() 5.3.2 Inference about specific indirect effects. Again, no need to worry about bootstrapping within the Bayesian paradigm. We can compute high-quality percentile-based intervals with our HMC-based posterior samples. post %&gt;% pivot_longer(c(a1b1, a2b2)) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b1 0.196 0.013 0.449 0.95 median qi ## 2 a2b2 0.18 0.001 0.435 0.95 median qi 5.3.3 Pairwise comparisons between specific indirect effects. Within the Bayesian paradigm, it’s straightforward to compare indirect effects. All one has to do is compute a difference score and summarize it somehow. Here it is, a1b1 minus a2b2. post &lt;- post %&gt;% mutate(difference = a1b1 - a2b2) post %&gt;% mean_qi(difference) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## difference .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.017 -0.303 0.339 0.95 mean qi Why not plot? post %&gt;% ggplot(aes(x = difference)) + geom_vline(xintercept = 0, color = &quot;black&quot;, linetype = 2) + geom_density(color = &quot;black&quot;, fill = &quot;black&quot;, alpha = .5) + scale_x_continuous(NULL, limits = c(-1, 1)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The difference score between the indirect effects&quot;, subtitle = expression(No~italic(p)*&quot;-value or 95% intervals needed for this one.&quot;)) + theme_minimal() Although note well this does not mean their difference is exactly zero. The shape of the posterior distribution testifies our uncertainty in their difference. Our best bet is that the difference is approximately zero, but it could easily be plus or minus a quarter of a point or more. 5.3.4 Inference about the total indirect effect. Here’s the plot. post %&gt;% ggplot(aes(x = total_indirect_effect, fill = factor(0), color = factor(0))) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The total indirect effect of condition on reaction&quot;, subtitle = expression(&quot;This is the sum of&quot;~italic(a)[1]*italic(b)[1]~and~italic(a)[2]*italic(b)[2]*&quot;. It&#39;s wide and uncertain.&quot;), x = NULL) + theme_minimal() + theme(legend.position = &quot;none&quot;) 5.4 The serial multiple mediator model Examples of the parallel multiple mediator model like that described in the prior section are in abundance in the literature. A distinguishing feature of this model is the assumption that no mediator causally influences another. In practice, mediators will be correlated, but this model specified that they are not causally so. In the serial multiple mediator model, the assumption of no causal association between two or more mediators is not only relaxed, it is rejected outright a priori. The goal when an investigator estimates a serial multiple mediator model is to investigate the direct and indirect effects of \\(X\\) on \\(Y\\) while modeling a process in which \\(X\\) causes \\(M_1\\), which in turn causes \\(M_2\\), and so forth, concluding with \\(Y\\) as the final consequent. (p. 167, emphasis in the original) 5.4.1 Direct and indirect effects in a serial multiple mediator model. In a serial multiple mediator model, the total effect of \\(X\\) on \\(Y\\) partitions into direct and indirect components, just as it does in the simple and parallel multiple mediator models. Regardless of the number of mediators in the model, the direct effect is \\(c&#39;\\) and interpreted as always–the estimated difference in \\(Y\\) between two cases that differ by one unit on \\(X\\) but that are equal on all mediators in the model. The indirect effects, of which there may be many depending on the number of mediators in the model, are all constructed by multiplying the regression weights corresponding to each step in an indirect pathway. And they are all interpreted as the estimated difference in \\(Y\\) between two cases that differ by one unit on \\(X\\) through the causal sequence from \\(X\\) to mediator(s) to \\(Y\\). Regardless of the number of mediators, the sum of all the specific indirect effects is the total indirect effect of \\(X\\), and the direct and indirect effects sum to the total effect of \\(X\\). (p. 170) 5.4.2 Statistical inference. “In principle, Monte Carlo confidence intervals can be constructed for all indirect effects in a serial multiple mediator model” (p. 172). I’m pretty sure Hayes didn’t intend this to refer to Bayesian estimation, but I couldn’t resist the quote. 5.4.3 Example from the presumed media influence study. The model syntax is similar to the earlier multiple mediator model. All we change is adding import to the list of predictors in the submodel for m2_model. But this time, let’s take the approach from last chapter where we define our bf() formulas all within brm(). model5.3 &lt;- brm(data = pmi, family = gaussian, bf(import ~ 1 + cond) + bf(pmi ~ 1 + import + cond) + bf(reaction ~ 1 + import + pmi + cond) + set_rescor(FALSE), cores = 4, file = &quot;fits/model05.03&quot;) print(model5.3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: import ~ 1 + cond ## pmi ~ 1 + import + cond ## reaction ~ 1 + import + pmi + cond ## Data: pmi (Number of observations: 123) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## import_Intercept 3.91 0.22 3.50 4.33 1.00 9837 3064 ## pmi_Intercept 4.61 0.31 3.99 5.21 1.00 8070 2924 ## reaction_Intercept -0.14 0.55 -1.22 0.90 1.00 8998 3012 ## import_cond 0.63 0.31 0.03 1.24 1.00 9589 3063 ## pmi_import 0.20 0.07 0.06 0.33 1.00 7796 2979 ## pmi_cond 0.35 0.23 -0.11 0.81 1.00 7838 3162 ## reaction_import 0.32 0.07 0.18 0.47 1.00 6835 3181 ## reaction_pmi 0.40 0.10 0.20 0.59 1.00 7755 3038 ## reaction_cond 0.11 0.24 -0.37 0.58 1.00 7839 3026 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_import 1.73 0.11 1.53 1.97 1.00 9188 2670 ## sigma_pmi 1.28 0.08 1.12 1.45 1.00 8057 2837 ## sigma_reaction 1.30 0.08 1.15 1.48 1.00 7701 3114 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Behold the \\(R^2\\) posterior densities. bayes_R2(model5.3, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% mutate(name = str_remove(name, &quot;R2&quot;)) %&gt;% ggplot(aes(x = value, color = name, fill = name)) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_x_continuous(NULL, limits = 0:1) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(The~italic(R)^2*&quot; distributions for model3, the serial multiple mediator model&quot;), subtitle = &quot;The density for reaction hasn&#39;t changed from model5.2. However, look how the pmi density separated from import.&quot;) + theme_minimal() + theme(legend.title = element_blank()) As before, here we’ll save the posterior samples into a data frame and rename the parameters a bit to match Hayes’s nomenclature. post &lt;- posterior_samples(model5.3) %&gt;% mutate(a1 = b_import_cond, a2 = b_pmi_cond, b1 = b_reaction_import, b2 = b_reaction_pmi, c_prime = b_reaction_cond, d21 = b_pmi_import) Here are the parameter summaries for the pathways depicted in Figure 5.6. post %&gt;% pivot_longer(a1:d21) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 6 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 0.626 0.028 1.24 0.95 mean qi ## 2 a2 0.351 -0.106 0.808 0.95 mean qi ## 3 b1 0.324 0.182 0.47 0.95 mean qi ## 4 b2 0.395 0.204 0.589 0.95 mean qi ## 5 c_prime 0.107 -0.374 0.581 0.95 mean qi ## 6 d21 0.196 0.062 0.33 0.95 mean qi To get our version of the parameter summaries in Table 5.2, all you have to do is add the summaries for the intercepts to what we did above. post %&gt;% rename(im1 = b_import_Intercept, im2 = b_pmi_Intercept, iy = b_reaction_Intercept) %&gt;% pivot_longer(c(a1:d21, starts_with(&quot;i&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% # simplify the output select(name:.upper) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 9 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a1 0.626 0.028 1.24 ## 2 a2 0.351 -0.106 0.808 ## 3 b1 0.324 0.182 0.47 ## 4 b2 0.395 0.204 0.589 ## 5 c_prime 0.107 -0.374 0.581 ## 6 d21 0.196 0.062 0.33 ## 7 im1 3.91 3.50 4.33 ## 8 im2 4.61 3.99 5.21 ## 9 iy -0.143 -1.22 0.895 Here we compute the four indirect effects. post &lt;- post %&gt;% mutate(a1b1 = a1 * b1, a2b2 = a2 * b2, a1d21b2 = a1 * d21 * b2) %&gt;% mutate(total_indirect_effect = a1b1 + a2b2 + a1d21b2) Anticipating the skew typical of indirect effects, we’ll summarize these posteriors with medians rather than means. post %&gt;% pivot_longer(a1b1:total_indirect_effect) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 4 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a1b1 0.194 0.008 0.447 ## 2 a1d21b2 0.043 0.001 0.13 ## 3 a2b2 0.13 -0.041 0.355 ## 4 total_indirect_effect 0.383 0.091 0.734 To get the contrasts Hayes presented in page 179, we just do a little subtraction. post %&gt;% mutate(c1 = a1b1 - a2b2, c2 = a1b1 - a1d21b2, c3 = a2b2 - a1d21b2) %&gt;% pivot_longer(c1:c3) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is_double, round, digits = 3) ## # A tibble: 3 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c1 0.065 -0.244 0.368 ## 2 c2 0.141 0.004 0.375 ## 3 c3 0.085 -0.113 0.313 And just because it’s fun, we may as well plot our indirect effects. # this will help us save a little space with the plot code my_labels &lt;- c(expression(italic(a)[1]*italic(b)[1]), expression(italic(a)[1]*italic(d)[21]*italic(b)[1]), expression(italic(a)[2]*italic(b)[2]), &quot;total indirect effect&quot;) # wrangle post %&gt;% pivot_longer(a1b1:total_indirect_effect) %&gt;% # plot! ggplot(aes(x = value, fill = name, color = name)) + geom_density(alpha = .5) + scale_color_ptol(NULL, labels = my_labels, guide = guide_legend(label.hjust = 0)) + scale_fill_ptol(NULL, labels = my_labels, guide = guide_legend(label.hjust = 0)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The four indirect effects of the serial multiple mediator model&quot;, x = NULL) + theme_minimal() 5.5 Models with parallel and serial mediation properties In a model with two mediators, the only difference between a serial and a parallel multiple mediator model is the inclusion of a causal path from \\(M_1\\) to \\(M_2\\). The serial model estimates this effect, whereas the parallel model assumes it is zero, which is equivalent to leaving it out of the model entirely. With more than three mediators, a model can be a blend of parallel and serial mediation processes, depending on which paths between mediators are estimated and which are fixed to zero through their exclusion from the model. (p. 180) 5.6 Complementarity and competition among mediators This chapter has been dedicated to mediation models containing more than one mediator. At this point, the benefits of estimating multiple mechanisms of influence in a single model are no doubt apparent. But the inclusion of more than one mediator in a model does entail certain risks as well, and at times the results of multiple mediator model may appear to contradict the results obtained when estimating a simpler model with a single mediator. Some of the risks, paradoxes, and contradictions that sometimes can occur are worth some acknowledgement and discussion. (p. 183) Tread carefully, friends. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 ggthemes_4.2.4 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 ## [7] dplyr_1.0.6 purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 ## [13] tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 svUnit_1.0.3 ## [6] splines_4.0.4 crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 ## [11] digest_0.6.27 htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 checkmate_2.0.0 ## [16] magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 xts_0.12.1 ## [21] sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 rvest_1.0.1 ggdist_3.0.0 ## [26] haven_2.3.1 xfun_0.23 callr_3.7.0 crayon_1.4.1 jsonlite_1.7.2 ## [31] lme4_1.1-25 survival_3.2-10 zoo_1.8-8 glue_1.4.2 gtable_0.3.0 ## [36] emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 rstan_2.21.2 ## [41] abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 miniUI_0.1.1.1 ## [46] xtable_1.8-4 stats4_4.0.4 StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 ## [51] httr_1.4.2 threejs_0.3.3 arrayhelpers_1.1-0 posterior_1.0.1 ellipsis_0.3.2 ## [56] pkgconfig_2.0.3 loo_2.4.1 farver_2.1.0 sass_0.3.1 dbplyr_2.1.1 ## [61] utf8_1.2.1 tidyselect_1.1.1 labeling_0.4.2 rlang_0.4.11 reshape2_1.4.4 ## [66] later_1.2.0 munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 cli_3.0.1 ## [71] generics_0.1.0 broom_0.7.6 ggridges_0.5.3 evaluate_0.14 fastmap_1.1.0 ## [76] processx_3.5.2 knitr_1.33 fs_1.5.0 nlme_3.1-152 mime_0.10 ## [81] projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 bayesplot_1.8.0 shinythemes_1.1.2 ## [86] rstudioapi_0.13 gamm4_0.2-6 curl_4.3 reprex_2.0.0 statmod_1.4.35 ## [91] bslib_0.2.4 stringi_1.6.2 highr_0.9 ps_1.6.0 Brobdingnag_1.2-6 ## [96] lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 markdown_1.1 tensorA_0.36.2 ## [101] shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 ## [106] bridgesampling_1.0-0 estimability_1.3 httpuv_1.6.0 R6_2.5.0 bookdown_0.22 ## [111] promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 ## [116] MASS_7.3-53 gtools_3.8.2 assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 ## [121] multcomp_1.4-16 mgcv_1.8-33 parallel_4.0.4 hms_1.1.0 grid_4.0.4 ## [126] coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 ## [131] base64enc_0.1-3 dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Kay, M. (2020a). Extracting and visualizing tidy draws from brms models. https://mjskay.github.io/tidybayes/articles/tidy-brms.html "],["mediation-analysis-with-a-multicategorical-antecedent.html", "6 Mediation Analysis with a Multicategorical Antecedent 6.1 Relative total, direct, and indirect effects 6.2 An example: Sex discrimination in the workplace 6.3 Using a different group coding system 6.4 Some miscellaneous issues [unrelated to those Hayes covered in the text] Session info", " 6 Mediation Analysis with a Multicategorical Antecedent “Historically, investigators interested in doing a mediation analysis with a multicategorical antecedents \\(X\\) have resorted to some less optimal strategies than the one [Hayes] discuss[ed] in this chapter” (Andrew F. Hayes, 2018, p. 188). Happily, the approach outlined in this chapter avoids such gaffs. Hayes’s procedure “does not require discarding any data; the entire sample is analyzed simultaneously. Furthermore, the multicategorical nature of \\(X\\) is respected and retained (p. 189).” 6.1 Relative total, direct, and indirect effects In review of regression analysis in Chapter 2, we saw that a multicategorical antecedent variable with \\(g\\) categories can be used as an antecedent variable in a regression model if it is represented by \\(g - 1\\) variables using some kind of group coding system (see section 2.7). [Hayes] described indicator or dummy coding as one such system, where groups are represented with \\(g - 1\\) variables set to either zero or one (see Table 2.1). With indicator coding, one of the \\(g\\) groups is chosen as the reference group. Cases in the reference group receive a zero on all \\(g - 1\\) variables coding \\(X\\). Each of the remaining \\(g - 1\\) groups gets its own indicator variable that is set to 1 for cases in that group, with all other cases set to zero. Using such a system, which of the \\(g\\) groups a case is in is represented by its pattern of zeros and ones on the \\(g - 1\\) indicator variables. These \\(g - 1\\) indicator variables are then used as antecedent variables in a regression model as a stand-in for \\(X\\). (pp. 189–190, emphasis in the original) 6.1.1 Relative indirect effects. When our \\(X\\) is multicategorical, we end up with \\(g - 1\\) \\(a\\) coefficients. Presuming the \\(M\\) variable is continuous or binary, this will yield \\(g - 1\\) relative indirect effects, \\(a_j b\\). 6.1.2 Relative direct effects. Similar to above, when our \\(X\\) is multicategorical, we end up with \\(g - 1\\) \\(c&#39;\\) coefficients, each of which is a relative direct effects. 6.1.3 Relative total effects. With the two prior subsections in mind, when our \\(X\\) is multicategorical, we end up with \\(g - 1\\) \\(c\\) coefficients, each of which is a relative total effect. These follow the form \\[c_j = c_j&#39; + a_j b,\\] where \\(j\\) indexes a given group. 6.2 An example: Sex discrimination in the workplace Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) ## Rows: 129 ## Columns: 6 ## $ subnum &lt;dbl&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, 168, 97, 7,… ## $ protest &lt;dbl&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1, 1… ## $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.87, 4.87, 4… ## $ angry &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1, 1, 2, 1, 1… ## $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.50, 4.50, 4… ## $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.25, 5.00, 5… Here are the ungrouped means and \\(SD\\)s for respappr and liking shown at the bottom of Table 6.1. protest %&gt;% pivot_longer(liking:respappr) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 liking 5.64 1.05 ## 2 respappr 4.87 1.35 We compute the summaries for respappr and liking, grouped by protest, like so. protest %&gt;% pivot_longer(liking:respappr) %&gt;% group_by(protest, name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 6 x 4 ## # Groups: protest [3] ## protest name mean sd ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 liking 5.31 1.30 ## 2 0 respappr 3.88 1.46 ## 3 1 liking 5.83 0.819 ## 4 1 respappr 5.14 1.08 ## 5 2 liking 5.75 0.936 ## 6 2 respappr 5.49 0.936 It looks like Hayes has a typo in the \\(SD\\) for liking when protest == 0. It seems he accidentally entered the value for when protest == 1 in that slot. You’ll have to wait a minute to see where the adjusted \\(Y\\) values came from. With a little if_else(), computing the dummies d1 and d2 is easy enough. protest &lt;- protest %&gt;% mutate(d1 = if_else(protest == 1, 1, 0), d2 = if_else(protest == 2, 1, 0)) We’re almost ready to fit the model. Let’s load brms. library(brms) This is the first time we’ve had a simple univariate regression model in a while–no special mvbind() syntax or multiple bf() formulas, just straight up brms::brm(). model6.1 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + d1 + d2, cores = 4, file = &quot;fits/model06.01&quot;) Check the coefficient summaries. fixef(model6.1) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.3105221 0.1646877 4.987615216 5.6267716 ## d1 0.5183924 0.2306089 0.071900531 0.9716942 ## d2 0.4445530 0.2275941 -0.004987925 0.8885953 Our \\(R^2\\) differences a bit from the OLS version in the text. This shouldn’t be surprising when it’s near the boundary. bayes_R2(model6.1) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.05873881 0.03607054 0.006018393 0.1416788 Here’s its shape. For the plots in this chapter, we’ll take a few formatting cues from Edward Tufte (2001), courtesy of the ggthemes package. The theme_tufte() function will change the default font and remove some chart junk. We will take our color palette from Pokemon via the palettetown package (Lucas, 2016). library(ggthemes) library(palettetown) bayes_R2(model6.1, summary = F) %&gt;% data.frame() %&gt;% ggplot(aes(x = R2)) + geom_density(size = 0, fill = pokepal(pokemon = &quot;plusle&quot;)[2]) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + xlab(expression(italic(R)^2)) + theme_tufte() + theme(legend.title = element_blank(), plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) To use the model-implied equations to compute the means for each group on the criterion, we’ll extract the posterior samples. post &lt;- posterior_samples(model6.1) post %&gt;% mutate(Y_np = b_Intercept + b_d1 * 0 + b_d2 * 0, Y_ip = b_Intercept + b_d1 * 1 + b_d2 * 0, Y_cp = b_Intercept + b_d1 * 0 + b_d2 * 1) %&gt;% pivot_longer(contains(&quot;Y_&quot;)) %&gt;% # this line will order our output the same way Hayes did in the text (p. 197) mutate(name = factor(name, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Y_np 5.31 0.165 ## 2 Y_ip 5.83 0.159 ## 3 Y_cp 5.76 0.154 What Hayes called the “relative total effects” \\(c_1\\) and \\(c_2\\) are the d1 and d2 lines in our fixef() output, above. Here are the sub-models for the mediation model. m_model &lt;- bf(respappr ~ 1 + d1 + d2) y_model &lt;- bf(liking ~ 1 + d1 + d2 + respappr) There’s a third way to fit multivariate models in brms. It uses either the mvbrmsformula() function, or its abbreviated version, mvbf(). With these, we first define our submodels in br() statements like before. We then combine them within mvbf(), separated with a comma. If we’d like to avoid estimating a residual correlation, which we do in this project–, we then set rescore = FALSE. Here’s how it looks like for our second model. model6.2 &lt;- brm(data = protest, family = gaussian, mvbf(m_model, y_model, rescor = FALSE), cores = 4, file = &quot;fits/model06.02&quot;) print(model6.2) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: respappr ~ 1 + d1 + d2 ## liking ~ 1 + d1 + d2 + respappr ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## respappr_Intercept 3.89 0.18 3.54 4.24 1.00 5949 3113 ## liking_Intercept 3.71 0.30 3.15 4.33 1.00 6332 3358 ## respappr_d1 1.26 0.26 0.76 1.76 1.00 6080 3328 ## respappr_d2 1.60 0.25 1.11 2.08 1.00 5515 3108 ## liking_d1 -0.00 0.22 -0.43 0.42 1.00 4014 3295 ## liking_d2 -0.22 0.23 -0.67 0.23 1.00 3916 3034 ## liking_respappr 0.41 0.07 0.27 0.55 1.00 4690 3390 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_respappr 1.18 0.08 1.04 1.34 1.00 8008 3137 ## sigma_liking 0.93 0.06 0.82 1.05 1.00 6155 3168 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Behold the Bayesian \\(R^2\\) posteriors. bayes_R2(model6.2, summary = F) %&gt;% data.frame() %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(size = 0, alpha = 2/3) + annotate(&quot;text&quot;, x = .2, y = 7, label = &quot;liking&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[2], family = &quot;Times&quot;) + annotate(&quot;text&quot;, x = .355, y = 6, label = &quot;respappr&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[6], family = &quot;Times&quot;) + scale_fill_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(2, 6)]) + scale_x_continuous(NULL, limits = c(0:1)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(The~italic(R)^2*&quot; densities overlap near perfectly, both hovering around .25.&quot;)) + theme_tufte() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) To get the model summaries as presented in the second two columns in Table 6.2, we use posterior_samples(), rename a bit, and summarize. Like in the last chapter, here we’ll do so with a little help from tidybayes. library(tidybayes) post &lt;- posterior_samples(model6.2) %&gt;% mutate(a1 = b_respappr_d1, a2 = b_respappr_d2, b = b_liking_respappr, c1_prime = b_liking_d1, c2_prime = b_liking_d2, i_m = b_respappr_Intercept, i_y = b_liking_Intercept) post %&gt;% pivot_longer(a1:i_y) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 7 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1 1.26 0.759 1.76 0.95 mean qi ## 2 a2 1.60 1.11 2.08 0.95 mean qi ## 3 b 0.412 0.272 0.548 0.95 mean qi ## 4 c1_prime -0.003 -0.43 0.418 0.95 mean qi ## 5 c2_prime -0.22 -0.67 0.226 0.95 mean qi ## 6 i_m 3.89 3.54 4.24 0.95 mean qi ## 7 i_y 3.71 3.15 4.33 0.95 mean qi Working with the \\(\\overline M_{ij}\\) formulas in page 199 is quite similar to what we did above. post %&gt;% mutate(M_np = b_respappr_Intercept + b_respappr_d1 * 0 + b_respappr_d2 * 0, M_ip = b_respappr_Intercept + b_respappr_d1 * 1 + b_respappr_d2 * 0, M_cp = b_respappr_Intercept + b_respappr_d1 * 0 + b_respappr_d2 * 1) %&gt;% pivot_longer(starts_with(&quot;M_&quot;)) %&gt;% # this line will order our output the same way Hayes did in the text (p. 199) mutate(name = factor(name, levels = c(&quot;M_np&quot;, &quot;M_ip&quot;, &quot;M_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_np 3.89 0.180 ## 2 M_ip 5.15 0.181 ## 3 M_cp 5.49 0.177 The \\(\\overline Y^*_{ij}\\) formulas are more of the same. post &lt;- post %&gt;% mutate(Y_np = b_liking_Intercept + b_liking_d1 * 0 + b_liking_d2 * 0 + b_liking_respappr * mean(protest$respappr), Y_ip = b_liking_Intercept + b_liking_d1 * 1 + b_liking_d2 * 0 + b_liking_respappr * mean(protest$respappr), Y_cp = b_liking_Intercept + b_liking_d1 * 0 + b_liking_d2 * 1 + b_liking_respappr * mean(protest$respappr)) post %&gt;% pivot_longer(starts_with(&quot;Y_&quot;)) %&gt;% mutate(name = factor(name, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Y_np 5.72 0.161 ## 2 Y_ip 5.71 0.141 ## 3 Y_cp 5.50 0.144 Note, these are where the adjusted \\(Y\\) values came from in Table 6.1. This is as fine a spot as any to introduce coefficient plots. The brms, tidybayes, and bayesplot packages all offer convenience functions for coefficient plots. Before we get all lazy using convenience functions, it’s good to know how to make coefficient plots by hand. Here’s ours for those last three \\(\\overline Y^*_{ij}\\)-values. post %&gt;% pivot_longer(starts_with(&quot;Y_&quot;)) %&gt;% ggplot(aes(x = value, y = name, color = name)) + stat_summary(geom = &quot;pointrange&quot;, fun = median, fun.min = function(x) {quantile(x, probs = .025)}, fun.max = function(x) {quantile(x, probs = .975)}, size = .75) + stat_summary(geom = &quot;linerange&quot;, fun.min = function(x) {quantile(x, probs = .25)}, fun.max = function(x) {quantile(x, probs = .75)}, size = 1.5) + scale_color_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(3, 7, 9)]) + labs(x = NULL, y = NULL) + theme_tufte() + theme(axis.ticks.y = element_blank(), legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) The points are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. For kicks, we distinguished the three values by color. If we want to examine \\(R^2\\) change for dropping the dummy variables, we’ll first fit a model that omits them. model6.3 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + respappr, cores = 4, file = &quot;fits/model06.03&quot;) Here are the competing \\(R^2\\) distributions. # get the R2 draws and wrangle r2 &lt;- rbind(bayes_R2(model6.2, resp = &quot;liking&quot;, summary = F), bayes_R2(model6.3, summary = F)) %&gt;% data.frame() %&gt;% set_names(&quot;R2&quot;) %&gt;% mutate(fit = rep(c(&quot;model6.2&quot;, &quot;model6.3&quot;), each = n() / 2)) # plot! r2 %&gt;% ggplot(aes(x = R2, fill = fit)) + geom_density(size = 0, alpha = 2/3) + annotate(&quot;text&quot;, x = .18, y = 6.75, label = &quot;model3&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[7], family = &quot;Times&quot;) + annotate(&quot;text&quot;, x = .35, y = 6.75, label = &quot;model2&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[6], family = &quot;Times&quot;) + scale_fill_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(6, 7)]) + scale_x_continuous(NULL, limits = 0:1) + scale_y_continuous(NULL, breaks = NULL) + ggtitle(expression(The~italic(R)^2*&quot; densities for LIKING overlap a lot.&quot;)) + theme_tufte() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) If you want to compare then with a change score, do something like this. r2 %&gt;% mutate(iter = rep(1:4000, times = 2)) %&gt;% pivot_wider(names_from = fit, values_from = R2) %&gt;% ggplot(aes(x = model6.2 - model6.3)) + geom_density(size = 0, fill = pokepal(pokemon = &quot;plusle&quot;)[4]) + geom_vline(xintercept = 0, color = pokepal(pokemon = &quot;plusle&quot;)[8]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(The~Delta*italic(R)^2~distribution), subtitle = &quot;Doesn&#39;t appear we have a lot of change.&quot;, x = NULL) + theme_tufte() + theme(legend.title = element_blank(), plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) Now compute the posterior means and 95% intervals for \\(a_1 b\\) and \\(a_2 b\\), the conditional indirect effects. post %&gt;% mutate(a1b = a1 * b, a2b = a2 * b) %&gt;% pivot_longer(a1b:a2b) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b 0.517 0.27 0.807 0.95 mean qi ## 2 a2b 0.659 0.381 0.982 0.95 mean qi 6.3 Using a different group coding system Here we’ll make our alternative dummies, what we’ll call d_1 and d_2, with orthogonal contrast coding. protest &lt;- protest %&gt;% mutate(d_1 = if_else(protest == 0, -2/3, 1/3), d_2 = if_else(protest == 0, 0, if_else(protest == 1, -1/2, 1/2))) Here are the sub-models. m_model &lt;- bf(respappr ~ 1 + d_1 + d_2) y_model &lt;- bf(liking ~ 1 + d_1 + d_2 + respappr) Now we fit using the mvbf() approach. model6.4 &lt;- brm(data = protest, family = gaussian, mvbf(m_model, y_model, rescor = FALSE), cores = 4, file = &quot;fits/model06.04&quot;) Here are our intercepts and regression coefficient summaries. fixef(model6.4) ## Estimate Est.Error Q2.5 Q97.5 ## respappr_Intercept 4.8408491 0.10400545 4.6391636 5.0524578 ## liking_Intercept 3.6363534 0.35318446 2.9437136 4.3215543 ## respappr_d_1 1.4376291 0.21964377 1.0104644 1.8696691 ## respappr_d_2 0.3478888 0.24998359 -0.1359316 0.8558661 ## liking_d_1 -0.1120374 0.20567008 -0.5092694 0.2919660 ## liking_d_2 -0.2193080 0.19541186 -0.6081167 0.1656851 ## liking_respappr 0.4117305 0.07136229 0.2730765 0.5551897 It’s important to note that these will not correspond to the “TOTAL EFFECT MODEL” section of the PROCESS output of Figure 6.3. Hayes’s PROCESS has the mcx=3 command which tells the program to reparametrize the orthogonal contrasts. brms doesn’t have such a command. For now, we’ll have to jump to Equation 6.8 towards the bottom of page 207. Those parameters are evident in our output. For good measure, here we’ll practice with posterior_summary(). posterior_summary(model6.4) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) %&gt;% filter(str_detect(parameter, &quot;b_respappr&quot;)) ## parameter Estimate Est.Error Q2.5 Q97.5 ## 1 b_respappr_Intercept 4.8408491 0.1040055 4.6391636 5.0524578 ## 2 b_respappr_d_1 1.4376291 0.2196438 1.0104644 1.8696691 ## 3 b_respappr_d_2 0.3478888 0.2499836 -0.1359316 0.8558661 Thus it’s easy to get the \\(\\overline M_{ij}\\) means with a little posterior manipulation. post &lt;- posterior_samples(model6.4) %&gt;% mutate(M_np = b_respappr_Intercept + b_respappr_d_1 * -2/3 + b_respappr_d_2 * 0, M_ip = b_respappr_Intercept + b_respappr_d_1 * 1/3 + b_respappr_d_2 * -1/2, M_cp = b_respappr_Intercept + b_respappr_d_1 * 1/3 + b_respappr_d_2 * 1/2) post %&gt;% pivot_longer(starts_with(&quot;M_&quot;)) %&gt;% mutate(name = factor(name, levels = c(&quot;M_np&quot;, &quot;M_ip&quot;, &quot;M_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 M_np 3.88 0.182 ## 2 M_ip 5.15 0.181 ## 3 M_cp 5.49 0.173 With these in hand, we can compute \\(a_1\\) and \\(a_2\\). post &lt;- post %&gt;% mutate(a1 = (M_ip + M_cp) / 2 - M_np, a2 = M_cp - M_ip) post %&gt;% pivot_longer(a1:a2) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a1 1.44 0.220 ## 2 a2 0.348 0.250 Happily, our model output will allow us to work with Hayes’s \\(\\overline Y^*_{ij}\\) equations in the middle of page 210. post &lt;- post %&gt;% mutate(Y_np = b_liking_Intercept + b_liking_d_1 * -2/3 + b_liking_d_2 * 0 + b_liking_respappr * mean(protest$respappr), Y_ip = b_liking_Intercept + b_liking_d_1 * 1/3 + b_liking_d_2 * -1/2 + b_liking_respappr * mean(protest$respappr), Y_cp = b_liking_Intercept + b_liking_d_1 * 1/3 + b_liking_d_2 * 1/2 + b_liking_respappr * mean(protest$respappr)) post %&gt;% pivot_longer(starts_with(&quot;Y_&quot;)) %&gt;% mutate(name = factor(name, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 3 x 3 ## name mean sd ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Y_np 5.71 0.164 ## 2 Y_ip 5.71 0.141 ## 3 Y_cp 5.49 0.144 And with these in hand, we can compute \\(c&#39;_1\\) and \\(c&#39;_2\\). post &lt;- post %&gt;% mutate(c1_prime = (Y_ip + Y_cp) / 2 - Y_np, c2_prime = Y_cp - Y_ip) post %&gt;% pivot_longer(c1_prime:c2_prime) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c1_prime -0.112 0.206 ## 2 c2_prime -0.219 0.195 It appears Hayes has a typo in the formula for \\(c&#39;_2\\) on page 211. The value he has down for \\(\\overline Y^*_{IP}\\), 5.145, is incorrect. It’s not the one he displayed at the bottom of the previous page and it also contradicts the analyses herein. So it goes… These things happen. We haven’t spelled it out, but the \\(b\\) parameter is currently labeled b_liking_respappr in our post object. Here we’ll make a b column to make things easier. While we’re at it, we’ll compute the indirect effects, too. post &lt;- post %&gt;% mutate(b = b_liking_respappr) %&gt;% mutate(a1b = a1 * b, a2b = a2 * b) post %&gt;% pivot_longer(a1b:a2b) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b 0.591 0.351 0.875 0.95 mean qi ## 2 a2b 0.143 -0.051 0.368 0.95 mean qi Now we can compute and summarize() our \\(c_1\\) and \\(c_2\\). post &lt;- post %&gt;% mutate(c1 = c1_prime + a1b, c2 = c2_prime + a2b) post %&gt;% pivot_longer(c1:c2) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 c1 0.479 0.201 ## 2 c2 -0.0761 0.217 6.4 Some miscellaneous issues [unrelated to those Hayes covered in the text] Do you recall how way back in Chapter 2 we covered an alternative way to fit models with multicategorical grouping variables? Well, we did. The basic strategy is to save our grouping variable as a factor and then enter it into the model with the special 0 + syntax, which removes the typical intercept. Since this chapter is all about multicategorical variables, it might make sense to explore what happens when we use this approach. For our first step, well prepare the data. protest &lt;- protest %&gt;% mutate(group = factor(protest, levels = 0:2, labels = c(&quot;none&quot;, &quot;individual&quot;, &quot;collective&quot;))) protest %&gt;% select(protest, group) ## # A tibble: 129 x 2 ## protest group ## &lt;dbl&gt; &lt;fct&gt; ## 1 2 collective ## 2 0 none ## 3 2 collective ## 4 2 collective ## 5 2 collective ## 6 1 individual ## 7 2 collective ## 8 0 none ## 9 0 none ## 10 0 none ## # … with 119 more rows Before we fit a full mediation model, we should warm up. Here we fit a univariable model for liking. This is an alternative to what we did way back with model6.1. model6.5 &lt;- brm(data = protest, family = gaussian, liking ~ 0 + group, cores = 4, file = &quot;fits/model06.05&quot;) Check the summary. print(model6.5) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ 0 + group ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## groupnone 5.31 0.16 4.99 5.63 1.00 4289 2749 ## groupindividual 5.82 0.16 5.51 6.14 1.00 4466 2830 ## groupcollective 5.75 0.15 5.46 6.04 1.00 4168 3341 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.04 0.07 0.92 1.18 1.00 5139 3391 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). There’s no conventional intercept parameter. Rather, each of the each of the levels of group get its own conditional intercept. To get a sense of what this model is, let’s practice our coefficient plotting skills. This time we’ll compute the necessary values before plugging them into ggplot2. # compute the means for `liking` by `group` group_means &lt;- protest %&gt;% group_by(group) %&gt;% summarize(mu_liking = mean(liking)) # pull the posterior summaries and wrangle fixef(model6.5) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) %&gt;% mutate(group = str_remove(parameter, &quot;group&quot;)) %&gt;% # plot! ggplot(aes(y = group)) + # this is the main function for our coefficient plots geom_pointrange(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, color = group), size = 3/4) + geom_point(data = group_means, aes(x = mu_liking)) + scale_color_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(3, 7, 9)]) + labs(x = NULL, y = NULL) + theme_tufte() + theme(axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank(), legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) The results from the model are in colored point ranges. The black dots in the foreground are the empirical means. It looks like our model did a good job estimating the group means for liking. Let’s see how this coding approach works when you fit a full mediation model. First, define the sub-models with two bf() lines. m_model &lt;- bf(respappr ~ 0 + group) y_model &lt;- bf(liking ~ 0 + group + respappr) Now fit model6 using the mvbf() approach. model6.6 &lt;- brm(data = protest, family = gaussian, mvbf(m_model, y_model, rescor = FALSE), cores = 4, file = &quot;fits/model06.06&quot;) What will the summary hold? print(model6.6) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: respappr ~ 0 + group ## liking ~ 0 + group + respappr ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## respappr_groupnone 3.89 0.18 3.52 4.23 1.00 4039 2601 ## respappr_groupindividual 5.14 0.18 4.77 5.51 1.00 3599 2467 ## respappr_groupcollective 5.50 0.17 5.15 5.84 1.00 3960 2741 ## liking_groupnone 3.71 0.31 3.11 4.34 1.00 1673 2291 ## liking_groupindividual 3.70 0.39 2.93 4.48 1.00 1658 1967 ## liking_groupcollective 3.49 0.41 2.70 4.28 1.00 1687 2011 ## liking_respappr 0.41 0.07 0.27 0.55 1.00 1590 1950 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_respappr 1.18 0.07 1.04 1.34 1.00 3862 2463 ## sigma_liking 0.93 0.06 0.82 1.05 1.00 4106 2867 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). If you flip back to page 199, you’ll notice the posterior mean in the first three rows (i.e., respappr_groupnone through respappr_groupcollective) correspond to the estimates for \\(\\overline M_{NP}\\), \\(\\overline M_{IP}\\), and \\(\\overline M_{CP}\\), respectively. Let’s get to the \\(a_j b\\) estimates. post &lt;- posterior_samples(model6.6) %&gt;% mutate(a1 = b_respappr_groupnone, a2 = b_respappr_groupindividual, a3 = b_respappr_groupcollective, b = b_liking_respappr) %&gt;% mutate(a1b = a1 * b, a2b = a2 * b, a3b = a3 * b) post %&gt;% pivot_longer(a1b:a3b) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 a1b 1.6 1.05 2.15 0.95 mean qi ## 2 a2b 2.12 1.39 2.85 0.95 mean qi ## 3 a3b 2.26 1.49 3.04 0.95 mean qi With this parameterization, it’s a little difficult to interpret the \\(a_j b\\) estimates. None of them are in comparison to anything. However, this approach is quite useful once you compute their various difference scores. # compute the difference scores post &lt;- post %&gt;% mutate(diff_individual_minus_none = a2b - a1b, diff_collective_minus_none = a3b - a1b, diff_collective_minus_individual = a3b - a2b) # summarize post %&gt;% pivot_longer(contains(&quot;diff&quot;)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 diff_collective_minus_individual 0.147 -0.053 0.364 0.95 mean qi ## 2 diff_collective_minus_none 0.663 0.378 0.994 0.95 mean qi ## 3 diff_individual_minus_none 0.517 0.272 0.82 0.95 mean qi If you look back to our results from model6.2, you’ll see that diff_individual_minus_none and diff_collective_minus_none correspond to a1b and a2b, respectively. But with our model6.6 approach, we get the additional information of what kind of indirect effect we might have yielded had we used a different coding scheme for our original set of dummy variables. That is, we get diff_collective_minus_individual. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 palettetown_0.1.1 ggthemes_4.2.4 brms_2.15.0 Rcpp_1.0.6 ## [6] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 purrr_0.3.4 readr_1.4.0 ## [11] tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 svUnit_1.0.3 ## [6] splines_4.0.4 crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 ## [11] digest_0.6.27 htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 checkmate_2.0.0 ## [16] magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 xts_0.12.1 ## [21] sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 rvest_1.0.1 ggdist_3.0.0 ## [26] haven_2.3.1 xfun_0.23 callr_3.7.0 crayon_1.4.1 jsonlite_1.7.2 ## [31] lme4_1.1-25 survival_3.2-10 zoo_1.8-8 glue_1.4.2 gtable_0.3.0 ## [36] emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 rstan_2.21.2 ## [41] abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 miniUI_0.1.1.1 ## [46] xtable_1.8-4 stats4_4.0.4 StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 ## [51] httr_1.4.2 threejs_0.3.3 arrayhelpers_1.1-0 posterior_1.0.1 ellipsis_0.3.2 ## [56] farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 sass_0.3.1 dbplyr_2.1.1 ## [61] utf8_1.2.1 tidyselect_1.1.1 labeling_0.4.2 rlang_0.4.11 reshape2_1.4.4 ## [66] later_1.2.0 munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 cli_3.0.1 ## [71] generics_0.1.0 broom_0.7.6 ggridges_0.5.3 evaluate_0.14 fastmap_1.1.0 ## [76] processx_3.5.2 knitr_1.33 fs_1.5.0 nlme_3.1-152 mime_0.10 ## [81] projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 bayesplot_1.8.0 shinythemes_1.1.2 ## [86] rstudioapi_0.13 gamm4_0.2-6 curl_4.3 reprex_2.0.0 statmod_1.4.35 ## [91] bslib_0.2.4 stringi_1.6.2 highr_0.9 ps_1.6.0 Brobdingnag_1.2-6 ## [96] lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 markdown_1.1 tensorA_0.36.2 ## [101] shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 ## [106] bridgesampling_1.0-0 estimability_1.3 httpuv_1.6.0 R6_2.5.0 bookdown_0.22 ## [111] promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 ## [116] MASS_7.3-53 gtools_3.8.2 assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 ## [121] multcomp_1.4-16 mgcv_1.8-33 parallel_4.0.4 hms_1.1.0 grid_4.0.4 ## [126] coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 ## [131] base64enc_0.1-3 dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Lucas, T. (2016). palettetown: Use Pokemon inspired colour palettes [Manual]. https://CRAN.R-project.org/package=palettetown Tufte, E. R. (2001). The visual display of quantitative information (Second Edition). Graphics Press. https://www.edwardtufte.com/tufte/books_vdqi "],["fundamentals-of-moderation-analysis.html", "7 Fundamentals of Moderation Analysis 7.1 Conditional and unconditional effects 7.2 An example: Climate change disasters and humanitarianism 7.3 Visualizing moderation 7.4 Probing an interaction 7.5 The difference between testing for moderation and probing it 7.6 Artificial categorization and subgroups Session info Footnote", " 7 Fundamentals of Moderation Analysis The effect of \\(X\\) on some variable \\(Y\\) is moderated by \\(W\\) if its size, sign, or strength depends on or can be predicted by \\(W\\). In that case, \\(W\\) is said to be a moderator of \\(X\\)’s effect on \\(Y\\), or that \\(W\\) and \\(X\\) interact in their influence on \\(Y\\). Identifying a moderator of an effect helps to establish the boundary conditions of that effect or the circumstances, stimuli, or type of people for which the effect is large versus small, present versus absent, positive versus negative, and so forth. (Andrew F. Hayes, 2018, p. 220, emphasis in the original) 7.1 Conditional and unconditional effects If \\(X\\)’s effect on \\(Y\\) is moderated by another variable in the model, that means \\(X\\)’s effect depends on that other variable. But this model constrains \\(X\\)’s effect to be unconditional on \\(W\\), meaning that it is invariant across all values of \\(W\\). (p. 224) Hayes’s Table 7.1 and the related Figure 7.2 showcase this well. You might reproduce the data for both like this. library(tidyverse) d &lt;- crossing(x = -1:2, w = 0:2) %&gt;% mutate(A = 4 + 1 * x + 2 * w, B = 4 + 1 * x + 2 * w + 1.5 * x * w) d ## # A tibble: 12 x 4 ## x w A B ## &lt;int&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -1 0 3 3 ## 2 -1 1 5 3.5 ## 3 -1 2 7 4 ## 4 0 0 4 4 ## 5 0 1 6 6 ## 6 0 2 8 8 ## 7 1 0 5 5 ## 8 1 1 7 8.5 ## 9 1 2 9 12 ## 10 2 0 6 6 ## 11 2 1 8 11 ## 12 2 2 10 16 In previous chapters, we altered our plot themes using either built-in settings from ggplot2 or extra themes from the ggthemes package. When we wanted to change them further, we did so with extra theme() arguments. One, it’s nice to be know how to make one’s own custom theme and, two, it’d be handy to condense our code a bit. Here we’ll take a few cues from the Building a New Theme section from Peng, Kross, and Anderson’s (2017) text, Mastering software development in R. We’ll make our own theme, theme_07, by saving a handful of augmentations from the default theme_gray() theme. library(dutchmasters) theme_07 &lt;- theme_gray() + theme(axis.text = element_text(color = dutchmasters$little_street[6]), legend.background = element_rect(fill = &quot;transparent&quot;), legend.key = element_rect(fill = &quot;transparent&quot;, color = &quot;transparent&quot;), panel.background = element_rect(fill = dutchmasters$little_street[2]), panel.grid = element_blank(), plot.background = element_rect(fill = dutchmasters$little_street[7]), strip.background = element_rect(fill = alpha(dutchmasters$little_street[5], 2/3), color = &quot;transparent&quot;), text = element_text(family = &quot;Courier&quot;, color = dutchmasters$little_street[6], size = 14)) This chapter’s color palette comes from the dutchmasters package (Thoen, 2019), which was itself based of Vermeer’s (1657) The little street. To get a quick glance at the full palette, we’ll also use viz_palette(), a convenience function from the ochRe package (Allan et al., 2017). # devtools::install_github(&quot;ropenscilabs/ochRe&quot;) library(ochRe) viz_palette(dutchmasters$little_street) With our new theme_07 in hand, we’re ready to make our version of Figure 7.2. library(directlabels) d %&gt;% pivot_longer(A:B, values_to = &quot;y&quot;) %&gt;% mutate(label = str_c(&quot;W = &quot;, w), w = factor(w), strip = if_else(name == &quot;A&quot;, &quot;A: where W is a covariate&quot;, &quot;B: where W is a moderator&quot;)) %&gt;% ggplot(aes(x = x, y = y, group = w, size = w, label = label)) + geom_line(color = dutchmasters$little_street[9]) + geom_dl(method = list(dl.trans(x = x + 0.2), &quot;last.points&quot;, cex = 1, color = dutchmasters$little_street[9], fontfamily = &quot;Courier&quot;)) + scale_size_manual(values = c(.5, .75, 1)) + coord_cartesian(xlim = c(-1, 2.6), ylim = c(0, 16)) + labs(x = expression(italic(X)), y = expression(hat(italic(Y)))) + facet_wrap(~ strip) + theme_07 + # because we didn&#39;t alter the `legend.position` argument in our `theme_07`, # we need to use `theme()` to remove it theme(legend.position = &quot;none&quot;) We borrowed geom_dl() form the directlabels package (Hocking, 2021), which made it easy to insert the “W = \\(i\\)” labels to the right of the lines. I played around with the annotation in Figure 7.4 for a while and it was just way more trouble than it was worth. If you’re ever inspired to work it out, please share your code. I’m moving on. 7.1.1 Eliminating the constraint of unconditionality. We can write the generic moderation model as \\[Y = i_Y + f(W) X + b_2 W + e_Y,\\] where \\(f(W)\\) is a function of \\(W\\). Consider a simple function of the form \\(f(W) = b_1 + b_3 W\\). This function of \\(W\\) looks like a simple linear regression model where \\(b_1\\) is the constant and \\(b_3\\) is the regression coefficient for \\(W\\), except that rather than estimating some consequent variable from \\(W\\), it is a model of the effect of \\(X\\) on \\(Y\\). (p. 226) If we use that definition of \\(f(W)\\), we can update our equation to \\[\\begin{align*} Y &amp; = i_Y + (b_1 + b_3 W) X + b_2 W + e_Y, \\text{or} \\\\ Y &amp; = i_Y + b_1 X + b_2 W + b_3 XW + e_Y. \\end{align*}\\] Hayes called this the simple linear moderation model. Out of this equation we can extract \\(\\theta_{X \\rightarrow Y}\\), the conditional effect of \\(X\\) on \\(Y\\), which takes the form \\[\\theta_{X \\rightarrow Y} = b_1 + b_3 W.\\] This is what Figure 7.2 was all about. 7.1.2 Symmetry in moderation. It turns out that, mathematically, there’s no difference in speaking about \\(X\\) moderating \\(W\\) than speaking about \\(W\\) moderating \\(X\\). These are all just capital letters standing in for variables and perhaps you’ll recall from grade school that \\(a + b + ab\\) is just the same as \\(b + a + ba\\). Thus we can rearrange the simple moderation equations above to \\[Y = i_Y + b_1 X + (b_2 + b_3 X) W + e_Y\\] and speak instead about the conditional effect of \\(W\\) on \\(Y\\), \\[\\theta_{w \\rightarrow Y} = b_2 + b_3 X.\\] 7.1.3 Interpretation of the regression coefficients. With all this wacky stuff going on, we should clarify some of our terms: \\(i_Y\\) is still the expected value for \\(Y\\) with both \\(X = 0\\) and \\(W = 0\\), \\(b_1\\) is the conditional effect of \\(X\\) on \\(Y\\) when \\(W = 0\\), and \\(b_2\\) is the conditional effect of \\(W\\) on \\(Y\\) when \\(X = 0\\). It turns out \\(b_3\\) requires more words, which we’ll provide in the next subsection. 7.1.4 The importance of \\(b_3\\) wen asking about mediation. The simple moderation model allows \\(X\\)’s effect on \\(Y\\) to be a linear function of \\(W\\). Of course, allowing that effect to depend on \\(W\\) doesn’t mean that it actually does in reality. In most any sample of data, [the point estimate (i.e., posterior mean or median) for] \\(b_3\\) will be different from zero even when \\(X\\)’s effect on \\(Y\\) is independent of \\(W\\). Of interest when [modeling] a moderation hypothesis is not just allowing \\(X\\)’s effect to be contingent on \\(W\\), but also determining whether \\(b_3\\) deviates too far from zero than would be expected given that \\(b_3\\), like any statistic, is subject to sampling variance. (p. 231) 7.2 An example: Climate change disasters and humanitarianism Here we load a couple necessary packages, load the Chapman and Lickel (2016) data, and take a glimpse(). disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) ## Rows: 211 ## Columns: 5 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2… ## $ frame &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,… ## $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5.4, 3.4, 7.… ## $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.65, 3.15, 2.… ## $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1.0, 6.4, 3.… Here is how to get the ungrouped mean and \\(SD\\) values for justify and skeptic, as presented in Table 7.3. disaster %&gt;% pivot_longer(justify:skeptic) %&gt;% group_by(name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 justify 2.87 0.93 ## 2 skeptic 3.38 2.03 And here we get the same summary values, this time grouped by frame. disaster %&gt;% pivot_longer(justify:skeptic) %&gt;% group_by(frame, name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 4 ## # Groups: frame [2] ## frame name mean sd ## &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 justify 2.80 0.849 ## 2 0 skeptic 3.34 2.04 ## 3 1 justify 2.94 1.01 ## 4 1 skeptic 3.42 2.03 Let’s open brms. library(brms) Now fit the simple univariable model. model7.1 &lt;- brm(data = disaster, family = gaussian, justify ~ 1 + frame, cores = 4, file = &quot;fits/model07.01&quot;) print(model7.1) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: justify ~ 1 + frame ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 2.80 0.09 2.63 2.97 1.00 3774 2776 ## frame 0.13 0.13 -0.11 0.38 1.00 3963 2724 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.93 0.05 0.85 1.03 1.00 3620 2765 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The ‘Estimate’ (i.e., posterior mean) of the model intercept is the expected justify value for when frame is 0. The ‘Estimate’ for frame is the expected difference when frame is a 1. If all you care about is the posterior mean, you could execute fixef(model7.1)[&quot;Intercept&quot;, 1] + fixef(model7.1)[&quot;frame&quot;, 1] ## [1] 2.934172 which matches up nicely with the equation on page 233. But this wouldn’t be very Bayesian of us. It’d be more satisfying if we had an expression of the uncertainty in the value. For that, we’ll follow our usual practice of extracting the posterior samples, making nicely-named vectors, and summarizing a bit. post &lt;- posterior_samples(model7.1) %&gt;% mutate(when_x_is_0 = b_Intercept, when_x_is_1 = b_Intercept + b_frame) post %&gt;% pivot_longer(when_x_is_0:when_x_is_1) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 when_x_is_0 2.80 0.088 ## 2 when_x_is_1 2.93 0.095 Hayes referenced a \\(t\\)-test and accompanying \\(p\\)-value in the lower part of page 233. We, of course, aren’t going to do that. But we do have the 95% intervals in our print() output, above, which we can also look at with the brms::posterior_interval() function. posterior_interval(model7.1)[&quot;b_frame&quot;, ] ## 2.5% 97.5% ## -0.1104257 0.3847622 And we can always plot. post %&gt;% ggplot(aes(x = b_frame)) + geom_density(size = 0, fill = dutchmasters$little_street[1]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[11]) + scale_x_continuous(breaks = c(-.3, 0, .6)) + scale_y_continuous(NULL, breaks = NULL) + theme_07 + theme(legend.position = &quot;none&quot;) We’ll use the update() function to hastily fit model7.2 and model7.3. model7.2 &lt;- update(model7.1, newdata = disaster, formula = justify ~ 1 + frame + skeptic, cores = 4, file = &quot;fits/model07.02&quot;) model7.3 &lt;- update(model7.1, newdata = disaster, formula = justify ~ 1 + frame + skeptic + frame:skeptic, cores = 4, file = &quot;fits/model07.03&quot;) Note our use of the frame:skeptic syntax in model7.3. With that syntax we didn’t need to make an interaction variable in the data by hand. The brms package just handled it for us. An alternative syntax would have been frame*skeptic. But if you really wanted to make the interaction variable by hand, you’d do this. disaster &lt;- disaster %&gt;% mutate(interaction_variable = frame * skeptic) Once you have interaction_variable in the data, you’d specify a model formula within the brm() function like formula = justify ~ 1 + frame + skeptic + interaction_variable. I’m not going to do that, here, but you can play around yourself if so inclined. Here are the quick and dirty coefficient summaries for our two new models. posterior_summary(model7.2) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 2.1321750 0.12594154 1.8914550 2.3852145 ## b_frame 0.1174051 0.11625236 -0.1110120 0.3459309 ## b_skeptic 0.2003137 0.02839508 0.1440296 0.2554813 ## sigma 0.8414353 0.04159860 0.7649706 0.9282171 ## lp__ -265.6272830 1.42659274 -269.1917073 -263.8615255 posterior_summary(model7.3) ## Estimate Est.Error Q2.5 Q97.5 ## b_Intercept 2.4516167 0.14668648 2.17005729 2.7526710 ## b_frame -0.5645480 0.21392057 -0.97831354 -0.1458024 ## b_skeptic 0.1046097 0.03775143 0.02660806 0.1775666 ## b_frame:skeptic 0.2020772 0.05450541 0.09875548 0.3109934 ## sigma 0.8181036 0.04037604 0.74317261 0.9020807 ## lp__ -259.6144256 1.48807863 -263.07099629 -257.5339074 Just focusing on our primary model, model7.3, here’s another way to look at the coefficients. mcmc_plot(model7.3) + theme_07 By default, the brms::mcmc_plot() function returns coefficient plots which depict the parameters of a model by their posterior means (i.e., dots), 50% intervals (i.e., thick horizontal lines), and 95% intervals (i.e., thin horizontal lines). As mcmc_plot() returns a ggplot2 object, one can customize the theme and so on. We’ll extract the \\(R^2\\) iterations in the usual way once for each model, and then combine them for a plot. # for each of the three models, we create a separare R2 tibble r2_1 &lt;- bayes_R2(model7.1, summary = F) %&gt;% data.frame() r2_2 &lt;- bayes_R2(model7.2, summary = F) %&gt;% data.frame() r2_3 &lt;- bayes_R2(model7.3, summary = F) %&gt;% data.frame() # here we combine them into one tibble, indexed by `model` r2 &lt;- r2_1 %&gt;% bind_rows(r2_2) %&gt;% bind_rows(r2_3) %&gt;% mutate(model = rep(str_c(&quot;7.&quot;, 1:3), each = 4000)) # now we plot r2 %&gt;% ggplot(aes(x = R2, fill = model)) + geom_density(size = 0, alpha = 2/3) + scale_fill_manual(values = dutchmasters$little_street[c(3, 4, 8)] %&gt;% as.character()) + scale_x_continuous(expression(italic(R)^2~distribution), limits = 0:1) + scale_y_continuous(NULL, breaks = NULL) + theme_07 Here’s the \\(\\Delta R^2\\) distribution for model7.3 minus model7.2. r2_2 %&gt;% bind_cols(r2_3) %&gt;% set_names(str_c(&quot;model7.&quot;, 2:3)) %&gt;% mutate(dif = model7.3 - model7.2) %&gt;% ggplot(aes(x = dif)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(The~Delta*italic(R)^2), subtitle = &quot;Like in the text, the posterior\\nmean is about 0.05.&quot;, x = NULL) + theme_07 In addition to the \\(R^2\\), one can use information criteria to compare the models. Here we’ll use the LOO to compare all three. model7.1 &lt;- add_criterion(model7.1, &quot;loo&quot;) model7.2 &lt;- add_criterion(model7.2, &quot;loo&quot;) model7.3 &lt;- add_criterion(model7.3, &quot;loo&quot;) loo_compare(model7.1, model7.2, model7.3) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model7.3 0.0 0.0 -259.0 10.8 5.4 0.9 518.1 21.7 ## model7.2 -5.6 4.1 -264.7 11.2 4.6 0.9 529.3 22.4 ## model7.1 -27.1 9.5 -286.2 12.0 3.3 0.8 572.3 24.1 The LOO point estimate for both multivariable models were clearly lower than that for model7.1. The point estimate for the moderation model, model7.3, was within the double-digit range lower than that for model7.2, which typically suggests better fit. But notice how wide the standard error was. There’s a lot of uncertainty, there. Hopefully this isn’t surprising. Our \\(R^2\\) difference was small and uncertain, too. We can also compare them with AIC-type model weighting, which you can learn more about starting at this point in this lecture or the related (2019) vignette, Bayesian stacking and pseudo-BMA weights using the loo package (Vehtari &amp; Gabry, 2019). Here we’ll keep things simple and weight with the LOO. model_weights(model7.1, model7.2, model7.3, weights = &quot;loo&quot;) %&gt;% round(digits = 3) ## model7.1 model7.2 model7.3 ## 0.000 0.004 0.996 The model_weights() results put almost all the relative weight on model7.3. This doesn’t mean model7.3 is the “true model” or anything like that. It just suggests that it’s the better of the three with respect to the data. Here are the results of the equations in the second half of page 237. post &lt;- posterior_samples(model7.3) post %&gt;% mutate(if_2 = b_frame + `b_frame:skeptic` * 2, if_3.5 = b_frame + `b_frame:skeptic` * 3.5, if_5 = b_frame + `b_frame:skeptic` * 5) %&gt;% pivot_longer(starts_with(&quot;if_&quot;)) %&gt;% group_by(name) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% mutate(name = str_remove(name, &quot;if_&quot;)) %&gt;% rename(`conditional effect of X on Y when W =` = name) ## # A tibble: 3 x 3 ## `conditional effect of X on Y when W =` mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 2 -0.16 0.134 ## 2 3.5 0.143 0.113 ## 3 5 0.446 0.145 7.2.1 Estimation using PROCESS brms. Similar to what Hayes advertised with PROCESS, with our formula = justify ~ 1 + frame + skeptic + frame:skeptic code in model7.3, we didn’t need to hard code an interaction variable into the data. brms handled that for us. 7.2.2 Interpreting the regression coefficients. When you add an interaction term into a model, such as \\(x_1 \\cdot x_2\\), this is sometimes called a higher order term. The terms that made up the higher order term–\\(x_1\\) and \\(x_2\\), in this case–are correspondingly called the lower order terms. As Hayes pointed out, these lower order terms are conditional effects. Interpret them with care. 7.2.3 Variable scaling and the interpretation of \\(b_1\\) and \\(b_3\\). Making the mean-centered version of our \\(W\\) variable, skeptic, is a simple mutate() operation. We’ll just call it skeptic_c. disaster &lt;- disaster %&gt;% mutate(skeptic_c = skeptic - mean(skeptic)) And here’s how we might fit the model. model7.4 &lt;- update(model7.3, newdata = disaster, formula = justify ~ 1 + frame + skeptic_c + frame:skeptic_c, cores = 4, file = &quot;fits/model07.04&quot;) Here are the summaries of our fixed effects. fixef(model7.4) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.8073962 0.07701610 2.65744337 2.9562671 ## frame 0.1133822 0.11460258 -0.10819717 0.3411017 ## skeptic_c 0.1027887 0.03881743 0.02914400 0.1789173 ## frame:skeptic_c 0.2040915 0.05496150 0.09173885 0.3086697 To practice, frame and skeptic_c are lower order terms and, as such, they are conditional effects. The higher order term is frame:skeptic_c. Anyway, here are the \\(R^2\\) distributions for model7.3 and model7.4. They’re the same within simulation variance. bayes_R2(model7.3) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.249 0.045 0.158 0.334 bayes_R2(model7.4) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.249 0.044 0.161 0.335 If you’re bothered by the differences resulting from sampling variation, you might increase the number of HMC iterations from the 2,000-per-chain default. Doing so might look something like this. model7.3 &lt;- update(model7.3, chains = 4, cores = 4, warmup = 1000, iter = 10000) model7.4 &lt;- update(model7.4, chains = 4, cores = 4, warmup = 1000, iter = 10000) Before we fit model7.5, we’ll recode frame to a -.5/.5 metric and name it frame_.5. disaster &lt;- disaster %&gt;% mutate(frame_.5 = ifelse(frame == 0, -.5, .5)) Time to fit model7.5. model7.5 &lt;- update(model7.4, newdata = disaster, formula = justify ~ 1 + frame_.5 + skeptic_c + frame_.5:skeptic_c, cores = 4, file = &quot;fits/model07.05&quot;) Our posterior summaries match up nicely with the output in Hayes’s Table 7.4. fixef(model7.5) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.8661008 0.05693406 2.75424820 2.9800025 ## frame_.5 0.1162708 0.11283424 -0.10375391 0.3302863 ## skeptic_c 0.2059356 0.02710684 0.15156950 0.2584645 ## frame_.5:skeptic_c 0.2006627 0.05580013 0.09389709 0.3151269 Here’s a summary of the Bayesian \\(R^2\\). bayes_R2(model7.5) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.2493167 0.04306566 0.1624235 0.3303375 7.3 Visualizing moderation A regression model with the product to two antecedent variables in an abstract mathematical representation of one’s data that can be harder to interpret than a model without such a produce. As described earlier, the coefficients for \\(X\\) and \\(W\\) are conditional effects that may not have any substantive interpretation, and the coefficient for \\(XW\\) is interpreted as a difference between differences that can be hard to make sense of without more information. (pp. 223–224) This is why we plot. To get quick plots for the interaction effect with brms, you might use the conditional_effects() function. conditional_effects(model7.3) By default, conditional_effects() will show three levels of the variable on the right side of the interaction term. The formula in model7.3 was justify ~ frame + skeptic + frame:skeptic, with frame:skeptic as the interaction term and skeptic making up the right hand side of the term. The three levels of skeptic in the plot, above, are the mean \\(\\pm 1\\) standard deviation. See the brms reference manual for details on the conditional_effects() function (Bürkner, 2021e). On page 244, Hayes discussed using the 16th, 50th, and 84th percentiles for the moderator variable. We can compute those with quantile(). quantile(disaster$skeptic, probs = c(.16, .5, .84)) ## 16% 50% 84% ## 1.6 2.8 5.2 The first two columns in Hayes’s Table 7.5 contain the values he combined with the point estimates of his model to get the \\(\\widehat Y\\) column. The way we’ll push those values through model7.3’s posterior is with brms::fitted(). As a preparatory step, we’ll put the predictor values in a data object, nd. ( nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .84))) ) ## # A tibble: 6 x 2 ## frame skeptic ## &lt;int&gt; &lt;dbl&gt; ## 1 0 1.6 ## 2 0 2.8 ## 3 0 5.2 ## 4 1 1.6 ## 5 1 2.8 ## 6 1 5.2 Now we’ve got our nd, we’ll get our posterior estimates for \\(Y\\) with fitted(). fitted(model7.3, newdata = nd) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 2.618992 0.10059981 2.424506 2.822780 ## [2,] 2.744524 0.07975865 2.589767 2.901872 ## [3,] 2.995587 0.10562745 2.785480 3.196689 ## [4,] 2.377768 0.10841435 2.164639 2.588615 ## [5,] 2.745792 0.08410312 2.583013 2.908011 ## [6,] 3.481841 0.10967583 3.262311 3.702851 When using the default summary = TRUE settings in fitted(), the function returns posterior means, \\(SD\\)s and 95% intervals for \\(Y\\) based on each row in the nd data we specified in the newdata = nd argument. You don’t have to name your newdata nd or anything like that; it’s just my convention. Here’ a quick plot of what those values imply. fitted(model7.3, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame %&gt;% as.character())) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + theme_07 That plot is okay, but we can do better. In order to plot the model-implied effects across the full range of skeptic values presented in Figure 7.7, you need to change the range of those values in the nd data. Also, although the effect is subtle in the above example, 95% intervals often follow a bowtie shape. In order to insure the contours of that shape are smooth, it’s often helpful to specify 30 or so evenly-spaced values in the variable on the \\(x\\)-axis, skeptic in this case. We’ll employ the seq() function for that and specify length.out = 30. In addition, we add a few other flourishes to make our plot more closely resemble the one in the text. Here’s our Figure 7.7. nd &lt;- crossing(frame = 0:1, skeptic = seq(from = 0, to = 7, length.out = 30)) fitted(model7.3, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame %&gt;% as.character())) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(2, 4)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) Do you see that subtle bowtie shape? 7.4 Probing an interaction As with other modeling contexts, there the results from our moderation models, like depicted in the last plot, carry uncertainty with them. To deal with the uncertainty, it is common to follow up a test of interaction with a set of additional inferential tests to establish where in the distribution of the moderator \\(X\\) has an effect on \\(Y\\) that is different from zero and where it does not. This exercise is commonly known as “probing” an interaction, like you might squeeze an avocado or a mango in the produce section of the grocery store to assess its ripeness. The goal is to ascertain where in the distribution of the moderator \\(X\\) is related to \\(Y\\) and where it is not in an attempt to better discern the substantive interpretation of the interaction. In this section [we will cover] two approaches to probing an interaction. (p. 249) As in earlier sections and chapters, our approach will largely follow Hayes’s, but we will not be emphasizing statistical tests, \\(p\\)-values, and so on. You’ll see. 7.4.1 The pick-a-point approach. The pick-a-point approach (Bauer &amp; Curran, 2005; Rogosa, 1980), sometimes called an analysis of simple slopes or a spotlight analysis, is perhaps the most popular approach to probing an interaction and is described in most discussions of multiple regression with interactions (e.g., Aiken &amp; West, 1991; Cohen et al., 2003; Darlington &amp; Hayes, 2017; Andrew F. Hayes, 2005; Jaccard &amp; Turrisi, 2003; Spiller et al., 2013). This procedure involves selecting a value or values of the moderator \\(W\\), calculating the conditional effect of \\(X\\) on \\(Y (\\theta_{X \\rightarrow Y})\\) at that value or values, and then conducting an inferential test or generating a confidence interval. (p. 249, emphasis in the original) Though we will not be using inferential tests, we will use various ways of expressing the uncertainty in our Bayesian models, such as with 95% credible intervals and other ways of summarizing the posterior. 7.4.1.1 The pick-a-point approach implimented by regression centering working directly with the posterior. Yes, if you wanted to use the regression centering approach, you could do that in brms. Just center the necessary variables in the way Hayes described in the text, refit the model, and summarize(). I suspect this would be particularly approachable for someone new to R and to the ins and outs of data wrangling. But I’m going leave that as an exercise for the interested reader. Now that we’ve already got a posterior for our model, we can just either algebraically manipulate the vectors yielded by posterior_samples() or push predictions through fitted(). To give a sense, we’ll start off with the 16th percentile for skeptic. Recall we can get that with the quantile() function. quantile(disaster$skeptic, probs = .16) ## 16% ## 1.6 Now we just need to feed that value and different values of frame into the posterior samples of the model coefficients. We then create a difference score for the model-implied estimates given frame is either 0 or 1 and then plot that difference. post %&gt;% # use the model formula mutate(y_given_frame_0_skeptic_1.6 = b_Intercept + b_frame * 0 + b_skeptic * 1.6 + `b_frame:skeptic` * 0 * 1.6, y_given_frame_1_skeptic_1.6 = b_Intercept + b_frame * 1 + b_skeptic * 1.6 + `b_frame:skeptic` * 1 * 1.6) %&gt;% # compute the difference mutate(difference = y_given_frame_1_skeptic_1.6 - y_given_frame_0_skeptic_1.6) %&gt;% # plot! ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[7], linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify\\ngiven skeptic = 1.6&quot;, x = NULL) + theme_07 Note how nicely that distribution corresponds to the output in the lower left corner of Hayes’s Figure 7.8. If we wanted the values for other values of skeptic (e.g., 2.8 and 5.2 as in the text), we’d just rinse, wash, and repeat. A nice quality of this method is it requires you to work explicitly with the model formula. But it’s also clunky if you want to do this over many values. The fitted() function offers an alternative approach. Recall how the default fitted() settings are to return summaries of a model’s \\(Y\\)-variable given values of the predictor variables. In the previous section we put our preferred frame and skeptic values into a data object named nd and used the newdata argument to push those values through fitted(). Buy default, this yielded the typical posterior means, \\(SD\\)s, and 95% intervals for the predictions. However, if one sets summary = F, the output will differ. First. Let’s revisit what nd looks like. ( nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .84))) ) ## # A tibble: 6 x 2 ## frame skeptic ## &lt;int&gt; &lt;dbl&gt; ## 1 0 1.6 ## 2 0 2.8 ## 3 0 5.2 ## 4 1 1.6 ## 5 1 2.8 ## 6 1 5.2 Here’s what happens when we use summary = F. f &lt;- fitted(model7.3, newdata = nd, summary = F) f %&gt;% str() ## num [1:4000, 1:6] 2.54 2.64 2.56 2.58 2.76 ... f %&gt;% head() ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] 2.544529 2.605685 2.727995 2.592793 2.922759 3.582689 ## [2,] 2.642688 2.753064 2.973817 2.416421 2.770837 3.479670 ## [3,] 2.560774 2.672912 2.897188 2.472279 2.835495 3.561927 ## [4,] 2.580077 2.698479 2.935283 2.449071 2.807149 3.523305 ## [5,] 2.755264 2.800871 2.892086 2.153414 2.598460 3.488551 ## [6,] 2.601511 2.692850 2.875529 2.391907 2.748605 3.462002 With summary = F, fitted() returned a matrix of 4,000 rows (i.e., one for each posterior draw) and 6 vectors (i.e., one for each row in our nd data). So now instead of summary information, we have a full expression of the uncertainty in terms of 4,000 draws. If you prefer working within the tidyverse and plotting with ggplot2, matrices aren’t the most useful data type. Let’s wrangle a bit. f &lt;- f %&gt;% data.frame() %&gt;% set_names(mutate(nd, name = str_c(frame, &quot;_&quot;, skeptic)) %&gt;% pull(name)) %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% separate(name, into = c(&quot;frame&quot;, &quot;skeptic&quot;), sep = &quot;_&quot;) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`, # this isn&#39;t necessary, but will help with the facet labels skeptic = str_c(&quot;skeptic = &quot;, skeptic)) f %&gt;% head() ## # A tibble: 6 x 5 ## iter skeptic `0` `1` difference ## &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 skeptic = 1.6 2.54 2.59 0.0483 ## 2 1 skeptic = 2.8 2.61 2.92 0.317 ## 3 1 skeptic = 5.2 2.73 3.58 0.855 ## 4 2 skeptic = 1.6 2.64 2.42 -0.226 ## 5 2 skeptic = 2.8 2.75 2.77 0.0178 ## 6 2 skeptic = 5.2 2.97 3.48 0.506 Now we have our draws in a nice structure, we’re ready to plot. f %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[7], linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify given three different values of skeptic&quot;, x = NULL) + theme_07 + facet_wrap(~ skeptic) If you prefer summary information instead of plots, you might just use tidybayes::median_qi(). library(tidybayes) f %&gt;% group_by(skeptic) %&gt;% median_qi(difference) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## skeptic difference .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 skeptic = 1.6 -0.243 -0.53 0.051 0.95 median qi ## 2 skeptic = 2.8 -0.003 -0.228 0.229 0.95 median qi ## 3 skeptic = 5.2 0.486 0.193 0.786 0.95 median qi 7.4.2 The Johnson-Neyman technique. The JN technique generalizes this approach over many values of \\(W\\) (i.e., skeptic in this example) in order to get a sense of the trend and summarize regions of the trend in terms of \\(p\\)-value thresholds. Since we’re emphasizing modeling and deemphasizing null-hypothesis testing in this project, I’ll show a Bayesian version of the approach without the \\(p\\)-values. 7.4.2.1 Implementation in PROCESS brms. Since Figure 7.9 had skeptic values ranging from 1 to 6 with ticks on the 0.5’s, we’ll use a similar approach for our version. We will display posterior samples with fitted() for skeptic values ranging from .5 to 6.5, one for each 0.5–13 in total. But since we have two levels of frame (i.e., 0 and 1), that really gives us 26. And we don’t just want 26 summaries; we want full posterior distributions for each of those 26. We’ve got a lot of moving parts in the code, below. To help make sure everything adds up, we’ll save several important values as R objects. # this number comes from the total number of post-warmup posterior iterations from `brm()` iter &lt;- 4000 # we&#39;re choosing 13 in this example to follow some of the sensibilities in Figure 7.9. You&#39;ll see. n_skeptic_values &lt;- 13 # as before, we&#39;ll make `nd` to feed in to `fitted()` nd &lt;- crossing(frame = 0:1, skeptic = seq(from = .5, to = 6.5, length.out = n_skeptic_values)) # after the initial `fitted()` action, we need a few steps to wrangle the data into a useful format f &lt;- fitted(model7.3, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% set_names(mutate(nd, name = str_c(frame, &quot;_&quot;, skeptic)) %&gt;% pull(name)) %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% separate(name, into = c(&quot;frame&quot;, &quot;skeptic&quot;), sep = &quot;_&quot;) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`, skeptic = as.double(skeptic)) # finally, here&#39;s the plot f %&gt;% ggplot(aes(x = skeptic %&gt;% as.character, y = difference)) + geom_hline(yintercept = 0, color = dutchmasters$little_street[7]) + geom_violin(size = 0, fill = dutchmasters$little_street[6]) + stat_summary(fun = median, fun.min = function(x){quantile(x, probs = .025)}, fun.max = function(x){quantile(x, probs = .975)}, color = dutchmasters$little_street[5]) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 [Note. I got the atop() trick for the label for the \\(y\\)-axis from Drew Steen’s answer to this stackoverflow question.] This isn’t quite our version of Figure 7.9, but I’m hoping it’ll add some pedagogical value for what we’re doing. Since we specified summary = F within fitted(), we got full posterior distributions for each of our 26 conditions. Because Figure 7.9 is all about differences between each frame pair across the various values of skeptic, we needed to make a difference score for each pair; this is what we did with the last mutate() line before the plot code. This initial version of the plot shows the full posterior distribution for each difference score. The posteriors are depicted with violin plots, which are density plots set on their side and symmetrically reflected as if by a mirror to give a pleasing leaf- or violin-like shape (though beware). The light dots and vertical lines are the posterior medians and 95% intervals for each. Going from left to right, it appears we have a clearly emerging trend. We can more simply express the trend by summarizing each posterior with medians and 95% intervals. f %&gt;% group_by(skeptic) %&gt;% median_qi(difference) %&gt;% ggplot(aes(x = skeptic)) + geom_hline(yintercept = 0, color = dutchmasters$little_street[7]) + geom_vline(xintercept = c(1.171, 3.934), color = dutchmasters$little_street[7]) + geom_ribbon(aes(ymin = .lower, ymax = .upper), fill = dutchmasters$little_street[5], alpha = 1/2) + geom_line(aes(y = difference), color = dutchmasters$little_street[5], size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(-1, 1.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 Notice how the contour boundaries of the 95% intervals are a little clunky. That’s because our bowtie-shape is based on only 13 \\(x\\)-axis values. If you wanted a smoother shape, you’d specify more skeptic values in the data object you feed into fitted()’s newdata argument. For linear effects, I find 30 or so usually does it. Anyway, I got the values for the two vertical lines directly out of the text. It’s not clear to me how one might elegantly determine those values within the paradigm we’ve been using. But that leads to an important digression. The two vertical lines are quite \\(p\\)-value centric. They are an attempt to separate the \\(x\\)-axis into areas where the difference trend either is or is not statistically-significantly different from zero. That is, we’re dichotomizing–or “trichotomizing,” depending on how you look at it–a continuous phenomenon. This is somewhat at odds with the sensibilities of the Bayesians associated with Stan and brms (e.g., here). On page 259, Hayes wrote: “Although the JN technique eliminates the need to select arbitrary values of \\(W\\) when probing an interaction, it does not eliminate your need to keep your brain turned into the task and thinking critically about the answer the method gives you.” I think this is valuable advice, particularly when working within the Bayesian paradigm. Our version of Figure 7.9 gives some interesting insights into the moderation model, model7.3. I’m just not so sure I’d want to encourage people to interpret a continuous phenomenon by heuristically dividing it into discrete regions. 7.5 The difference between testing for moderation and probing it This is another section where the NHST-type paradigm contrasts with many within the contemporary Bayesian paradigm. E.g., Hayes opened the section with: “We test for evidence of moderation when we want to know whether the relationship between \\(X\\) and \\(Y\\) varies systematically as a function of a proposed moderator \\(W\\).” His use of “whether” suggests we are talking about a binary answer–either there is an effect or there isn’t. But, as Gelman (2015) has argued, the default presumption in social science [and warning, I’m a psychologist and thus biased towards thinking in terms of social science] is that treatment effects–and more generally, causal effects–vary across contexts3 . As such, asking “whether” there’s a difference or an interaction effect isn’t really the right question. Rather, we should presume variation at the outset and ask instead what the magnitude of that variation is and how much accounting for it matters for our given purposes. If the variation–read interaction effect–is tiny and of little theoretical interest, perhaps we might just ignore it and not include it in the model. Alternatively, if the variation is large or of theoretical interest, we might should include it in the model regardless of statistical significance. Another way into this topic is posterior predictive checking. We’ve already done a bit of this in previous chapters. The basic idea, recall, is that better models should give us a better sense of the patterns in the data. In the plot below, we continue to show the interaction effect with two regression lines, but this time we separate them into their own panels by frame. In addition, we add the original data which we also separate and color code by frame. nd &lt;- crossing(frame = 0:1, skeptic = seq(from = 0, to = 10, length.out = 30)) fitted(model7.3, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% mutate(frame = frame %&gt;% as.character()) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame)) + geom_point(data = disaster %&gt;% mutate(frame = frame %&gt;% as.character()), aes(y = justify, color = frame), alpha = 3/4) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = c(1, 9)) + coord_cartesian(xlim = c(1, 9)) + labs(title = &quot;model 7.3, the interaction model&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) + facet_wrap(~ frame) When we separate out the data this way, it really does appear that when frame == 1, the justify values do increase as the skeptic values increase, but not so much when frame == 0. We can use the same plotting approach, but this time with the results from the non-interaction multivariable model, model7.2. fitted(model7.2, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% mutate(frame = frame %&gt;% as.character()) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(y = Estimate, color = frame %&gt;% as.character())) + geom_point(data = disaster %&gt;% mutate(frame = frame %&gt;% as.character()), aes(y = justify, color = frame), alpha = 3/4) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = c(1, 9)) + coord_cartesian(xlim = c(1, 9)) + labs(title = &quot;model 7.2, the multivariable model&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) + facet_wrap(~ frame) This time when we allowed the intercept but not the slope to vary by frame, it appears the regression lines are missing part of the story. They look okay, but it appears that the red line on the left is sloping up to quickly and that the cream line on the right isn’t sloping steeply enough. We have missed an insight. Now imagine scenarios in which the differences by frame are more or less pronounced. Imagine those scenarios fall along a continuum. It’s not so much that you can say with certainty where on such a continuous an interaction effect would exist or not, but rather, such a continuum suggests it would appear more or less important, of greater or smaller magnitude. It’s not that the effect exists or is non-zero. It’s that it is orderly enough and of a large enough magnitude, and perhaps of theoretical interest, that it appears to matter in terms of explaining the data. And none of this is to serve as a harsh criticism of Andrew Hayes. His text is a fine effort to teach mediation and moderation from a frequentist OLS perspective. I have benefited tremendously from his work. Yet I’d also like to connect his work to some other sensibilities. Building further, consider this sentence from the text: Rather, probing moderation involves ascertaining whether the conditional effect of \\(X\\) on \\(Y\\) is different from zero at certain specified values of \\(W\\) (if using the pick-a-point approach) or exploring where in the distribution of \\(W\\) the conditional effect of \\(X\\) on \\(Y\\) transitions between statistically significant and non-significant (if using the Johnson-Neyman technique). (pp. 259–260) From an NHST/frequentist perspective, this makes clear sense. But we’re dealing with an entire posterior distribution. Consider again a figure from above. nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .84))) fitted(model7.3, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% set_names(mutate(nd, name = str_c(frame, &quot;_&quot;, skeptic)) %&gt;% pull(name)) %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% separate(name, into = c(&quot;frame&quot;, &quot;skeptic&quot;), sep = &quot;_&quot;) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`, # this isn&#39;t necessary, but will help with the facet labels skeptic = str_c(&quot;skeptic = &quot;, skeptic)) %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify given three different values of skeptic&quot;, x = NULL) + theme_07 + facet_wrap(~ skeptic) With the pick pick-a-point approach one could fixate on whether zero was a credible value within the posterior, given a particular skeptic value. And yet zero is just one point in the parameter space. One might also focus on the whole shapes of the posteriors of these three skeptic values. You could focus on where the most credible values (i.e., those at and around their peaks) are on the number line (i.e., the effect sizes) and you could also focus on the relative widths of the distributions (i.e., the precision with which the effect sizes are estimated). These sensibilities can apply to the JN technique, as well. Sure, we might be interested in how credible zero is. But there’s a lot more to notice, too. Now consider a modified version of our JN technique plot, from above. f %&gt;% ggplot(aes(x = skeptic, y = difference)) + # the main action is in `tidybayes::stat_lineribbon()` stat_lineribbon(.width = c(.1, .2, .3, .4, .5, .6, .7, .8, .9, .99), fill = dutchmasters$little_street[5], alpha = 1/5, size = 0) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(-1, 1.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 This time we emphasized the shape of the posterior with stacked semitransparent 10, 20, 30, 40, 50, 60, 70, 80, 90, and 99% intervals. We also deemphasized the central tendency–our analogue to the OLS point estimate–by removing the median line. Yes, one could focus on where the 95% intervals cross zero. And yes one could request we emphasize central tendency. But such focuses miss a lot of information about the shape–the entire smooth, seamless distribution of credible values. I suppose you could consider this our version of Figure 7.10. 7.6 Artificial categorization and subgroups There are multiple ways to dichotomize the data by skeptic. A quick simple way is to use if_else() to make a skeptic_hi dummy. disaster &lt;- disaster %&gt;% mutate(skeptic_hi = if_else(skeptic &gt;= mean(skeptic), 1, 0)) With our dummy in hand, we’re ready to fit the two models. model7.6 &lt;- brm(data = disaster %&gt;% filter(skeptic_hi == 0), family = gaussian, justify ~ 1 + frame, cores = 4, file = &quot;fits/model07.06&quot;) model7.7 &lt;- update(model7.6, newdata = disaster %&gt;% filter(skeptic_hi == 1), cores = 4, file = &quot;fits/model07.07&quot;) Behold the coefficient summaries. fixef(model7.6) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 2.622 0.096 2.434 2.806 ## frame -0.104 0.141 -0.382 0.173 fixef(model7.7) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 3.068 0.143 2.790 3.348 ## frame 0.472 0.205 0.077 0.871 You can use fitted() to get the posterior means and other summaries for the two frame groups, by model. fitted(model7.6, newdata = tibble(frame = 0:1)) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 2.622 0.096 2.434 2.806 ## [2,] 2.518 0.103 2.315 2.714 fitted(model7.7, newdata = tibble(frame = 0:1)) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 3.068 0.143 2.790 3.348 ## [2,] 3.541 0.147 3.243 3.827 Do note that though brms ‘Est.Error’ is the posterior \\(SD\\) for the coefficient, it is not the same thing as descriptive statistic \\(SD\\) of a subset of the data. Thus, although our ‘Estimates’ correspond nicely to the mean values Hayes reported in the middle of page 264, his \\(SD\\)s will not match up with our ‘Est.Error’ values, and nor should they. Anyway, our results don’t yield \\(t\\)-tests. But you don’t need those anyway. We’re working within the Bayesian regression paradigm! But if you’re really interested in the sub-model-implied differences between the two levels of frame by skeptic_hi subgroup, all you need is the frame coefficient of model7.6 and model7.7. Here we’ll use bind_rows() to combine their posterior samples and then plot. bind_rows( posterior_samples(model7.6) %&gt;% select(b_frame), posterior_samples(model7.7) %&gt;% select(b_frame) ) %&gt;% mutate(model = rep(c(&quot;model7.6&quot;, &quot;model7.7&quot;), each = 4000)) %&gt;% ggplot(aes(x = b_frame, fill = model)) + geom_density(size = 0, alpha = .8) + scale_fill_manual(NULL, values = dutchmasters$little_street[c(1, 9)] %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The difference score distributions between frame\\nlevels, color coded by mean-split skeptic&quot;, x = NULL) + theme_07 As within the frequentist paradigm, please don’t mean split as a Bayesian. When possible, use all available data and use the regression formula to model theoretically-meaningful variables in your analyses. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 brms_2.15.0 Rcpp_1.0.6 directlabels_2021.1.13 ## [5] ochRe_1.0.0 dutchmasters_0.1.0 forcats_0.5.1 stringr_1.4.0 ## [9] dplyr_1.0.6 purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 ## [13] tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 svUnit_1.0.3 ## [6] sp_1.4-4 splines_4.0.4 crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 ## [11] inline_0.3.17 digest_0.6.27 htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 ## [16] checkmate_2.0.0 magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 ## [21] sandwich_3.0-0 xts_0.12.1 prettyunits_1.1.1 colorspace_2.0-0 rvest_1.0.1 ## [26] ggdist_3.0.0 haven_2.3.1 xfun_0.23 callr_3.7.0 crayon_1.4.1 ## [31] jsonlite_1.7.2 lme4_1.1-25 survival_3.2-10 zoo_1.8-8 glue_1.4.2 ## [36] gtable_0.3.0 emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [41] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 ## [46] miniUI_0.1.1.1 viridisLite_0.4.0 xtable_1.8-4 stats4_4.0.4 StanHeaders_2.21.0-7 ## [51] DT_0.16 htmlwidgets_1.5.3 httr_1.4.2 threejs_0.3.3 arrayhelpers_1.1-0 ## [56] posterior_1.0.1 ellipsis_0.3.2 pkgconfig_2.0.3 loo_2.4.1 farver_2.1.0 ## [61] sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 tidyselect_1.1.1 labeling_0.4.2 ## [66] rlang_0.4.11 reshape2_1.4.4 later_1.2.0 munsell_0.5.0 cellranger_1.1.0 ## [71] tools_4.0.4 cli_3.0.1 generics_0.1.0 broom_0.7.6 ggridges_0.5.3 ## [76] evaluate_0.14 fastmap_1.1.0 processx_3.5.2 knitr_1.33 fs_1.5.0 ## [81] nlme_3.1-152 mime_0.10 projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 ## [86] bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 gamm4_0.2-6 curl_4.3 ## [91] reprex_2.0.0 statmod_1.4.35 bslib_0.2.4 stringi_1.6.2 highr_0.9 ## [96] ps_1.6.0 Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 ## [101] markdown_1.1 tensorA_0.36.2 shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 ## [106] lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 estimability_1.3 raster_3.4-5 ## [111] httpuv_1.6.0 R6_2.5.0 bookdown_0.22 promises_1.2.0.1 gridExtra_2.3 ## [116] codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 ## [121] assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 mgcv_1.8-33 ## [126] parallel_4.0.4 hms_1.1.0 quadprog_1.5-8 grid_4.0.4 coda_0.19-4 ## [131] minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 base64enc_0.1-3 ## [136] dygraphs_1.1.1.6 Footnote References Aiken, L. S., &amp; West, S. G. (1991). Multiple regression: Testing and interpreting interactions. SAGE. Allan, A., Cook, D., Gayler, R., Kirk, H., Peng, R., &amp; Saber, E. (2017). ochRe: Australia-themed colour palettes [Manual]. https://github.com/ropenscilabs/ochRe Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and multilevel regression: Inferential and graphical techniques. Multivariate Behavioral Research, 40(3), 373–400. https://doi.org/10.1207/s15327906mbr4003_5 Bolger, N., Zee, K. S., Rossignac-Milon, M., &amp; Hassin, R. R. (2019). Causal processes in psychology are heterogeneous. Journal of Experimental Psychology: General, 148(4), 601–618. https://doi.org/10.1037/xge0000558 Bürkner, P.-C. (2021e). brms reference manual, Version 2.15.0. https://CRAN.R-project.org/package=brms/brms.pdf Chapman, D. A., &amp; Lickel, B. (2016). Climate change and disasters: How framing affects justifications for giving or withholding aid to disaster victims. Social Psychological and Personality Science, 7(1), 13–20. https://doi.org/10.1177/1948550615590448 Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). Applied multiple regression/correlation analysis for the behavioral sciences (3rd edition). Lawrence Erlbaum Associates. https://doi.org/10.4324/9780203774441 Darlington, R. B., &amp; Hayes, A. F. (2017). Regression analysis and linear models: Concepts, applications, and implementation. Guilford Press. https://www.guilford.com/books/Regression-Analysis-and-Linear-Models/Darlington-Hayes/9781462521135/reviews Gelman, A. (2015). The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Journal of Management, 41(2), 632–643. https://doi.org/10.1177/0149206314525208 Hamaker, E. L. (2012). Why researchers should think \"within-person\": A paradigmatic rationale. In Handbook of research methods for studying daily life (pp. 43–61). The Guilford Press. https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055 Hayes, Andrew F. (2005). Statistical methods for communication science. Routledge. https://doi.org/10.4324/9781410613707 Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Hocking, T. D. (2021). Directlabels: Direct labels for multicolor plots [Manual]. https://CRAN.R-project.org/package=directlabels Jaccard, J., &amp; Turrisi, R. (2003). Interaction effects in multiple regression (2nd edition). Sage Publications. https://dx.doi.org/10.4135/9781412984522 Peng, R. D., Kross, S., &amp; Anderson, B. (2017). Mastering software development in {}R{}. https://github.com/rdpeng/RProgDA Rogosa, D. (1980). Comparing nonparallel regression lines. Psychological Bulletin, 88(2), 307–321. https://doi.org/10.1037/0033-2909.88.2.307 Spiller, S. A., Fitzsimons, G. J., Lynch, J. G., &amp; Mcclelland, G. H. (2013). Spotlights, floodlights, and the magic number zero: Simple effects tests in moderated regression. Journal of Marketing Research, 50(2), 277–288. https://doi.org/10.1509/jmr.12.0420 Thoen, E. (2019). dutchmasters [Manual]. https://github.com/EdwinTh/dutchmasters Vehtari, A., &amp; Gabry, J. (2019). Bayesian stacking and pseudo-BMA weights using the loo package. https://CRAN.R-project.org/package=loo/vignettes/loo2-weights.html Vermeer, J. (1657). The little street. If you’re an experimental psychologist, check out the great (2019) paper by Bolger, Zee, Rossignac-Milon, and Hassin, Causal processes in psychology are heterogeneous. The rest of you social scientists aren’t off the hook. Check out Ellen Hamaker’s excellent (2012) chapter, Why researchers should think “within-person”: A paradigmatic rationale. Both works suggest researchers might do well to switch out their fixed-effects models for multilevel models. Does this mean the methods we’ve been covering are of no use? No. But don’t stop here, friends. Keep learning!↩︎ "],["extending-the-fundamental-principles-of-moderation-analysis.html", "8 Extending the Fundamental Principles of Moderation Analysis 8.1 Moderation with a dichotomous moderator 8.2 Interaction between two quantitative variables 8.3 Hierarchical versus simultaneous entry 8.4 The equivalence between moderated regression analysis and a 2 X 2 factorial analysis of variance Session info", " 8 Extending the Fundamental Principles of Moderation Analysis “In this chapter, [we’ll see] how [the] principles of moderation analysis are applied when the moderator is dichotomous (rather than a continuum, as in the previous chapter) as well as when both focal antecedent and moderator are continuous” (Andrew F. Hayes, 2018, p. 267). 8.1 Moderation with a dichotomous moderator Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) library(brms) disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) ## Rows: 211 ## Columns: 5 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23,… ## $ frame &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0… ## $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5.… ## $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.65… ## $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1.… Regardless of whether the antecedent variables are continuous or binary, the equation for the simple moderation is still \\[Y = i_Y + b_1 X + b_2 W + b_3 XW + e_Y.\\] We can use that equation to fit our first moderation model with a binary \\(W\\) (i.e., frame) like so. model8.1 &lt;- brm(data = disaster, family = gaussian, justify ~ 1 + skeptic + frame + frame:skeptic, cores = 4, file = &quot;fits/model08.01&quot;) Check the summary. print(model8.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: justify ~ 1 + skeptic + frame + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 2.448 0.150 2.163 2.747 1.000 2108 2214 ## skeptic 0.106 0.038 0.030 0.181 1.002 2064 2256 ## frame -0.559 0.217 -0.983 -0.134 1.001 1817 2204 ## skeptic:frame 0.200 0.055 0.095 0.307 1.001 1813 2406 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.817 0.040 0.742 0.899 1.001 3416 2673 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). We’ll compute our Bayesian \\(R^2\\) in the typical way. bayes_R2(model8.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.25 0.044 0.163 0.332 This model should look familiar to you because it is exactly the same model estimated in the analysis presented in Chapter 7 (see Table 7.4, model 3). The only differences between these two analyses are how the corresponding question is framed, meaning which variable is deemed the focal antecedent and which is the moderator, and how these variables are symbolically labeled as \\(X\\) and \\(W\\). In the analysis in Chapter 7, the focal antecedent variable was a dichotomous variable coding the framing of the cause of the disaster (labeled \\(X\\) then, but \\(W\\) now), whereas in this analysis, the focal antecedent is a continuous variable placing each person on a continuum of climate change skepticism (labeled \\(W\\) then, but \\(X\\) now), with the moderator being a dichotomous variable coding experimental condition. So this example illustrates the symmetry property of interactions introduced in section 7.1. (p. 272) 8.1.1 Visualizing and probing the interaction. For the plots in this chapter, we’ll take our color palette from the ochRe package, which provides Australia-inspired colors. We’ll also use a few theme settings from good-old ggthemes. As in the last chapter, we’ll save our adjusted theme settings as an object, theme_08. library(ggthemes) library(ochRe) theme_08 &lt;- theme_minimal() + theme(panel.grid.minor = element_blank(), plot.background = element_rect(fill = ochre_palettes[[&quot;olsen_seq&quot;]][8], color = &quot;transparent&quot;)) Happily, the ochRe package has a handy convenience function, viz_palette(), that makes it easy to preview the colors available in a given palette. We’ll be using “olsen_qual” and “olsen_seq.” viz_palette(ochre_palettes[[&quot;olsen_qual&quot;]]) viz_palette(ochre_palettes[[&quot;olsen_seq&quot;]]) Behold our Figure 8.3. # these will come in handy with `geom_text()`, below green_slope &lt;- (fixef(model8.1)[&quot;skeptic&quot;, 1] + fixef(model8.1)[4, 1]) %&gt;% round(digits = 3) blue_slope &lt;- fixef(model8.1)[&quot;skeptic&quot;, 1] %&gt;% round(digits = 3) # define the new data nd &lt;- crossing(frame = 0:1, skeptic = c(0, 7)) # extract the `fitted()` draws fitted(model8.1, newdata = nd, summary = F) %&gt;% # wrangle data.frame() %&gt;% set_names(mutate(nd, name = str_c(frame, &quot;_&quot;, skeptic)) %&gt;% pull(name)) %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% separate(name, into = c(&quot;frame&quot;, &quot;skeptic&quot;), sep = &quot;_&quot;) %&gt;% mutate(skeptic = as.double(skeptic)) %&gt;% # plot! ggplot(aes(x = skeptic, y = value, group = interaction(frame, iter))) + geom_line(aes(color = frame), size = 1/6, alpha = 1/25) + annotate(geom = &quot;text&quot;, x = c(4, 4.6), y = c(3.5, 2.6), label = c(paste(&quot;the slope when frame = 1 is about&quot;, green_slope), paste(&quot;the slope when frame = 0 is about&quot;, blue_slope)), angle = c(28, 5), color = &quot;black&quot;) + scale_color_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][(5:6)]) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(2, 4)) + labs(title = &quot;The moderation effect in a spaghetti plot&quot;, subtitle = &quot;Using brms defaults, we have 4,000 posterior draws. Much like we have\\n4,000 draws for each model parameter, when we combine those draws\\nacross parameters, we end up with 4,000 model equations. The\\nconsequence is we can also express the line plot as 4,000\\nsemitransparent lines, one for each level of our moderator, frame.&quot;, x = expression(&quot;Climate Change Skepticism &quot;*(italic(X))), y = &quot;Strength of Justification for Withholding Aid&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) In addition to our fancy Australia-inspired colors, we’ll also play around a bit with spaghetti plots in this chapter. To my knowledge, this use of spaghetti plots is uniquely Bayesian. If you’re trying to wrap your head around what on earth we just did, take a look at the first few rows from posterior_samples() object, post. post &lt;- posterior_samples(model8.1) head(post) ## b_Intercept b_skeptic b_frame b_skeptic:frame sigma lp__ ## 1 2.659889 0.08101323 -0.7538862 0.2130312 0.7587044 -259.8373 ## 2 2.424039 0.11030638 -0.5627005 0.1673621 0.7754237 -259.0716 ## 3 2.751647 0.03041706 -0.9541742 0.3288508 0.8225988 -260.7233 ## 4 2.436618 0.08367410 -0.5994825 0.2287817 0.8560998 -258.5940 ## 5 2.251451 0.16676260 -0.5518940 0.1795620 0.8297583 -259.2091 ## 6 2.183603 0.15387596 -0.4489734 0.1568658 0.7498314 -262.0821 The head() function returned six rows, each one corresponding to the credible parameter values from a given posterior draw. The lp__ is uniquely Bayesian and beyond the scope of this project. You might think of sigma as the Bayesian analogue to what the OLS folks often refer to as error or the residual variance. Hayes doesn’t tend to emphasize it in this text, but it’s something you’ll want to pay increasing attention to as you move along in your Bayesian career. All the columns starting with b_ are the regression parameters, the model coefficients or the fixed effects. But anyways, notice that those b_ columns correspond to the four parameter values in Formula 8.2 on page 270. Here they are, but reformatted to more closely mimic the text: \\(\\hat{Y}\\) = 2.66 + 0.081\\(X\\) + -0.754\\(W\\) + 0.213XW \\(\\hat{Y}\\) = 2.424 + 0.11\\(X\\) + -0.563\\(W\\) + 0.167XW \\(\\hat{Y}\\) = 2.752 + 0.03\\(X\\) + -0.954\\(W\\) + 0.329XW \\(\\hat{Y}\\) = 2.437 + 0.084\\(X\\) + -0.599\\(W\\) + 0.229XW \\(\\hat{Y}\\) = 2.251 + 0.167\\(X\\) + -0.552\\(W\\) + 0.18XW \\(\\hat{Y}\\) = 2.184 + 0.154\\(X\\) + -0.449\\(W\\) + 0.157XW Each row of post, each iteration or posterior draw, yields a full model equation that is a credible description of the data–or at least as credible as we can get within the limits of the model we have specified, our priors (which we typically cop out on and just use defaults in this project), and how well those fit when applied to the data at hand. So when we use brms convenience functions like fitted(), we pass specific predictor values through those 4,000 unique model equations, which returns 4,000 similar but distinct expected \\(Y\\)-values. So although a nice way to summarize those 4,000 values is with summaries such as the posterior mean/median and 95% intervals, another way is to just plot an individual regression line for each of the iterations. That is what’s going on when we depict out models with a spaghetti plot. The thing I like about spaghetti plots is that they give a three-dimensional sense of the posterior. Note that each individual line is very skinny and semitransparent. When you pile a whole bunch of them atop each other, the peaked or most credible regions of the posterior are the most saturated in color. Less credible posterior regions almost seamlessly merge into the background. Also, note how the combination of many similar but distinct straight lines results in a bowtie shape. Hopefully this clarifies where that shape’s been coming from when we use geom_ribbon() to plot the 95% intervals. Back to the text, on the bottom of page 274, Hayes pointed out the conditional effect of skeptic when frame == 1 is \\(b_1 + b_3 = 0.306\\). We can show that with a little arithmetic followed up with tidybayes::mean_qi(). library(tidybayes) post &lt;- post %&gt;% mutate(`b1 + b3` = b_skeptic + `b_skeptic:frame`) post %&gt;% mean_qi(`b1 + b3`) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## `b1 + b3` .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.306 0.229 0.384 0.95 mean qi But anyways, you could recode frame in a number of ways, including if_else() or, in this case, by simple arithmetic. disaster &lt;- disaster %&gt;% mutate(frame_ep = 1 - frame) With frame_ep in hand, we’re ready to refit the model. model8.2 &lt;- update(model8.1, newdata = disaster, formula = justify ~ 1 + skeptic + frame_ep + frame_ep:skeptic, cores = 4, file = &quot;fits/model08.02&quot;) print(model8.2) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: justify ~ skeptic + frame_ep + skeptic:frame_ep ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.89 0.16 1.58 2.23 1.00 1717 2312 ## skeptic 0.31 0.04 0.22 0.38 1.00 1572 2225 ## frame_ep 0.56 0.23 0.12 0.99 1.00 1463 2174 ## skeptic:frame_ep -0.20 0.06 -0.31 -0.09 1.01 1428 1998 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.82 0.04 0.75 0.90 1.00 3258 2832 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our results match nicely with the formula on page 275. If you want to follow along with Hayes on page 276 and isolate the 95% credible intervals for the skeptic parameter, you can use the posterior_interval() function. posterior_interval(model8.2)[&quot;b_skeptic&quot;, ] %&gt;% round(digits = 3) ## 2.5% 97.5% ## 0.224 0.385 8.2 Interaction between two quantitative variables Here’s the glbwarm data. glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) ## Rows: 815 ## Columns: 7 ## $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1… ## $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.6… ## $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.6… ## $ ideology &lt;dbl&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, … ## $ age &lt;dbl&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 3… ## $ sex &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, … ## $ partyid &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, … In this section we add three covariates (i.e., \\(C\\) variables) to the basic moderation model. Although Hayes made a distinction between the \\(X\\), \\(M\\), and \\(C\\) variables in the text, that distinction is conceptual and doesn’t impact the way we enter them into brm(). Rather, the brm() formula clarifies they’re all just predictors. model8.3 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + age + negemot:age + posemot + ideology + sex, cores = 4, file = &quot;fits/model08.03&quot;) Our results cohere nicely with the Hayes’s formula in the middle of page 278 or with the results he displayed in Table 8.2. print(model8.3, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + age + negemot:age + posemot + ideology + sex ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.180 0.333 4.537 5.851 1.000 2430 2573 ## negemot 0.119 0.081 -0.039 0.274 1.000 2177 2390 ## age -0.024 0.006 -0.036 -0.012 1.001 2117 2799 ## posemot -0.022 0.028 -0.076 0.034 1.002 3774 2556 ## ideology -0.212 0.027 -0.264 -0.159 1.001 3661 2911 ## sex -0.013 0.075 -0.160 0.135 1.003 3452 2448 ## negemot:age 0.006 0.002 0.003 0.009 1.000 2129 2421 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.059 0.026 1.009 1.110 1.001 3806 2635 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Here’s the \\(R^2\\) summary. bayes_R2(model8.3) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.401 0.02 0.362 0.437 As the \\(R^2\\) is a good bit away from the boundaries, it’s nicely Gaussian. bayes_R2(model8.3, summary = F) %&gt;% as_tibble() %&gt;% ggplot(aes(x = R2)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_qual&quot;]][(1)]) + scale_x_continuous(NULL, limits = 0:1) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(&quot;Loot at how Gaussian our &quot;*italic(R)^2*&quot; is!&quot;), subtitle = expression(&quot;No need to put a &quot;*italic(p)*&quot;-value on that sucker.&quot;)) + theme_08 8.2.1 Visualizing and probing the interaction. For our version of Figure 8.5, we’ll need to adjust our nd data for fitted(). ( nd &lt;- crossing(negemot = c(1, 6), age = c(30, 50, 70)) %&gt;% mutate(posemot = mean(glbwarm$posemot), ideology = mean(glbwarm$ideology), sex = mean(glbwarm$sex)) ) ## # A tibble: 6 x 5 ## negemot age posemot ideology sex ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1 30 3.13 4.08 0.488 ## 2 1 50 3.13 4.08 0.488 ## 3 1 70 3.13 4.08 0.488 ## 4 6 30 3.13 4.08 0.488 ## 5 6 50 3.13 4.08 0.488 ## 6 6 70 3.13 4.08 0.488 Our fitted() and ggplot2 code will be quite similar to the last spaghetti plot. Only this time we’ll use filter() to reduce the number of posterior draws we show in the plot. # these will come in handy with `geom_text()`, below slope_30 &lt;- (fixef(model8.3)[&quot;negemot&quot;, 1] + fixef(model8.3)[&quot;negemot:age&quot;, 1] * 30) %&gt;% round(digits = 3) slope_50 &lt;- (fixef(model8.3)[&quot;negemot&quot;, 1] + fixef(model8.3)[&quot;negemot:age&quot;, 1] * 50) %&gt;% round(digits = 3) slope_70 &lt;- (fixef(model8.3)[&quot;negemot&quot;, 1] + fixef(model8.3)[&quot;negemot:age&quot;, 1] * 70) %&gt;% round(digits = 3) # annotation text &lt;- tibble(negemot = 6.1, value = c(5.4, 5.7, 6), age = as.character(c(30, 50, 70)), iter = 0, label = c(str_c(&quot;the slope for 30 year olds is about &quot;, slope_30), str_c(&quot;the slope for 50 year olds is about &quot;, slope_50), str_c(&quot;the slope for 70 year olds is about &quot;, slope_70))) # get the fitted draws and wrangle fitted(model8.3, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% set_names(mutate(nd, name = str_c(negemot, &quot;_&quot;, age)) %&gt;% pull(name)) %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% separate(name, into = c(&quot;negemot&quot;, &quot;age&quot;), sep = &quot;_&quot;) %&gt;% mutate(negemot = as.double(negemot)) %&gt;% filter(iter &lt;= 100) %&gt;% # plot! ggplot(aes(x = negemot, y = value, group = interaction(age, iter), color = age)) + geom_line(size = 3/4, alpha = 1/8) + geom_text(data = text, aes(label = label), hjust = 0) + scale_color_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][c(4, 1, 3)]) + scale_x_continuous(breaks = 1:6, limits = c(1, 9)) + scale_y_continuous(&quot;Support for Government Action&quot;, limits = c(2.9, 6.1)) + labs(title = &quot;The moderation effect of age on negemot&quot;, x = expression(&quot;Negative Emotions about Climate Change &quot;*(italic(X)))) + theme_08 + theme(legend.position = &quot;none&quot;) When we reduce the number of lines depicted in the plot, we lose some of the three-dimensional illusion. It’s nice, however, to get a closer look to each individual line. To each their own. We’ll continue with our spaghetti plot approach for Figure 8.7. Again, when we made the JN technique plot for Chapter 7, we computed values for the posterior mean and the 95% intervals. Because the intervals follow a bowtie shape, we had to compute the \\(Y\\)-values for many values across the \\(x\\)-axis in order to make the curve look smooth. But as long as we stick with the spaghetti plot approach, all we need are the values at the endpoints of each iteration. Although each line is straight, the combination of many lines is what produces the bowtie effect. # here is our primary data object post &lt;- posterior_samples(model8.3) %&gt;% transmute(at_15 = b_negemot + `b_negemot:age` * 15, at_90 = b_negemot + `b_negemot:age` * 90, iter = 1:n()) %&gt;% pivot_longer(-iter, names_to = &quot;age&quot;) %&gt;% mutate(age = str_remove(age, &quot;at_&quot;) %&gt;% as.double()) # here we compute the points for the posterior mean post_means &lt;- post %&gt;% group_by(age) %&gt;% summarize(value = mean(value)) %&gt;% mutate(iter = 0) # plot! post %&gt;% filter(iter &lt; 501) %&gt;% ggplot(aes(x = age, y = value, group = iter)) + geom_line(color = ochre_palettes[[&quot;olsen_qual&quot;]][1], alpha = 1/12) + geom_line(data = post_means, color = ochre_palettes[[&quot;olsen_qual&quot;]][3], size = 1.1) + scale_y_continuous(breaks = seq(from = -.25, to = 1, by = .25)) + coord_cartesian(xlim = c(20, 85), ylim = c(-.25, 1)) + labs(subtitle = &quot;Each orange line is the consequence of one of 1,000 posterior draws. All are\\ncredible regression lines for the data, but because they are semitransparent,\\nthe most credible regions are the ones with the darkest color. The line\\ncorresponding to the posterior mean is in red-orange.&quot;, x = expression(Age~(italic(W))), y = &quot;Conditional Effects of Negative Emotions on\\nSupport for Government Action&quot;) + theme_08 In other words, each of those orange lines is a credible expression of \\(\\theta_{X \\rightarrow Y}\\) (i.e., \\(b_1 + b_3 W\\)) across a continuous range of \\(W\\) values. 8.3 Hierarchical versus simultaneous entry Many investigators test a moderation hypothesis in regression analysis using a method that on the surface seems different than the procedure described thus far. This alternative approach is to build a regression model by adding the product of \\(X\\) and \\(W\\) to a model already containing \\(X\\) and \\(W\\). This procedure is sometimes called hierarchical regression or hierarchical variable entry (and easily confused by name with hierarchical linear modeling, which is an entirely different thing). The goal using this method is to determine whether allowing \\(X\\)’s effect to be contingent on \\(W\\) produces a better fitting model than one in which the effect of \\(X\\) is constrained to be unconditional on \\(W\\). According to the logic of hierarchical entry, if the contingent model accounts for more of the variation in Y than the model that forces \\(X\\)’s effect to be independent of \\(W\\), then the better model is one in which \\(W\\) is allowed to moderate \\(X\\)’s effect. Although this approach works, it is a widely believed myth that it is necessary to use this approach in order to test a moderation hypothesis. (p. 289, emphasis in the original) Although this method is not necessary, it can be handy to slowly build your model. This method can also serve nice rhetorical purposes in a paper. Anyway, here’s our multivariable but non-moderation model, model8.4. model8.4 &lt;- update(model8.1, formula = justify ~ 1 + skeptic + frame, cores = 4, file = &quot;fits/model08.04&quot;) Here we’ll compute the corresponding \\(R^2\\) and compare it with the one for the original interaction model with a difference score. r2 &lt;- tibble(moderation_model = bayes_R2(model8.1, summary = F)[, 1], multivariable_model = bayes_R2(model8.4, summary = F)[, 1]) %&gt;% # we&#39;ll need a difference score mutate(difference = moderation_model - multivariable_model) %&gt;% # putting the data in the long format and grouping will make summarizing easier pivot_longer(everything(), names_to = &quot;R2&quot;) r2 %&gt;% group_by(R2) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## R2 value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 difference 0.05 -0.072 0.166 0.95 median qi ## 2 moderation_model 0.25 0.163 0.332 0.95 median qi ## 3 multivariable_model 0.201 0.113 0.283 0.95 median qi Note that the Bayesian \\(R^2\\) performed differently than the \\(F\\)-test in the text. r2 %&gt;% filter(R2 == &quot;difference&quot;) %&gt;% ggplot(aes(x = value, fill = model)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_seq&quot;]][14]) + scale_x_continuous(NULL, limits = c(-.4, .4)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The Bayesian &quot;, Delta, italic(R)^2, &quot; distribution&quot;)), subtitle = &quot;Although most of the posterior mass is positive--suggesting the moderation model accounted for more variance than\\nthe simple multivariable model--, a substantial portion of the postrior is within the negative parameter space. Sure,\\nif we had to bet, the safer bet is on the moderation model. But that bet wouled be quite uncertain and we might well\\nloose our shirts. Also, note the width of the distribution; credible values range from -0.1 to nearly 0.2.&quot;) + theme_08 We can also compare these with the LOO, which, as is typical of information criteria, corrects for model complexity. First, we compute them and attach the results to the model fit objects. model8.1 &lt;- add_criterion(model8.1, &quot;loo&quot;) model8.4 &lt;- add_criterion(model8.4, &quot;loo&quot;) Now use the loo_compare() function to compare them directly. loo_compare(model8.1, model8.4) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model8.1 0.0 0.0 -259.0 10.8 5.4 0.9 518.0 21.7 ## model8.4 -5.7 4.1 -264.7 11.2 4.7 0.9 529.5 22.4 As a reminder, we generally prefer models with lower information criteria, which in this case is clearly the moderation model (i.e., model8.1). However, the standard error value (i.e., se_diff) for the difference (i.e., elpd_diff) is quite large, which suggests that the model with the lowest value isn’t the clear winner. Happily, these results match nicely with the Bayesian \\(R^2\\) difference score. The moderation model appears somewhat better than the multivariable model, but its superiority is hardly decisive. 8.4 The equivalence between moderated regression analysis and a 2 X 2 factorial analysis of variance I’m just not going to encourage ANOVA \\(F\\)-testing methodology. However, I will show the Bayesian regression model. First, here are the data. caskets &lt;- read_csv(&quot;data/caskets/caskets.csv&quot;) glimpse(caskets) ## Rows: 541 ## Columns: 7 ## $ policy &lt;dbl&gt; 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, … ## $ interest &lt;dbl&gt; 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.5, 3.0, 1.0, 2.0, 3.5, 1.0, 1.0, 1.5, 3.0, 1… ## $ age &lt;dbl&gt; 39, 57, 63, 56, 50, 87, 33, 64, 82, 28, 18, 52, 42, 39, 64, 72, 54, 84, 55, 27, 4… ## $ educ &lt;dbl&gt; 3, 3, 2, 5, 3, 2, 7, 2, 3, 3, 1, 1, 5, 4, 3, 2, 3, 4, 7, 2, 3, 5, 4, 5, 5, 3, 3, … ## $ male &lt;dbl&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, … ## $ conserv &lt;dbl&gt; 4, 3, 6, 3, 3, 5, 6, 3, 6, 7, 4, 2, 7, 6, 5, 6, 6, 3, 7, 6, 5, 5, 3, 4, 6, 2, 7, … ## $ kerry &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, … Fit the moderation model. model8.5 &lt;- brm(data = caskets, family = gaussian, interest ~ 1 + policy + kerry + policy:kerry, cores = 4, file = &quot;fits/model08.05&quot;) print(model8.5) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: interest ~ 1 + policy + kerry + policy:kerry ## Data: caskets (Number of observations: 541) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 1.78 0.09 1.61 1.96 1.00 2253 2963 ## policy -0.38 0.13 -0.63 -0.14 1.00 2107 2781 ## kerry 0.60 0.13 0.34 0.85 1.00 1801 2596 ## policy:kerry 0.36 0.18 0.02 0.70 1.00 1976 2575 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.04 0.03 0.98 1.10 1.00 3851 2563 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Those results don’t look anything like what Hayes reported in Tables 8.3 or 8.4. However, a little deft manipulation of the posterior samples can yield equivalent results to Hayes’s Table 8.3. post &lt;- posterior_samples(model8.5) %&gt;% mutate(Y_bar_1 = b_Intercept + b_policy * 0 + b_kerry * 0 + `b_policy:kerry` * 0 * 0, Y_bar_3 = b_Intercept + b_policy * 0 + b_kerry * 1 + `b_policy:kerry` * 0 * 1, Y_bar_2 = b_Intercept + b_policy * 1 + b_kerry * 0 + `b_policy:kerry` * 1 * 0, Y_bar_4 = b_Intercept + b_policy * 1 + b_kerry * 1 + `b_policy:kerry` * 1 * 1, Y_bar_12 = b_Intercept + b_policy * .5 + b_kerry * 0 + `b_policy:kerry` * .5 * 0, Y_bar_34 = b_Intercept + b_policy * .5 + b_kerry * 1 + `b_policy:kerry` * .5 * 1, Y_bar_13 = b_Intercept + b_policy * 0 + b_kerry * .5 + `b_policy:kerry` * 0 * .5, Y_bar_24 = b_Intercept + b_policy * 1 + b_kerry * .5 + `b_policy:kerry` * 1 * .5) Here are the cell-specific means in Table 8.3. post %&gt;% pivot_longer(Y_bar_1:Y_bar_4) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Y_bar_1 1.78 1.61 1.96 0.95 median qi ## 2 Y_bar_2 1.40 1.22 1.57 0.95 median qi ## 3 Y_bar_3 2.38 2.21 2.57 0.95 median qi ## 4 Y_bar_4 2.36 2.19 2.53 0.95 median qi And here are the marginal means from Table 8.3. post %&gt;% pivot_longer(Y_bar_12:Y_bar_24) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 4 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Y_bar_12 1.59 1.47 1.71 0.95 median qi ## 2 Y_bar_13 2.08 1.96 2.21 0.95 median qi ## 3 Y_bar_24 1.88 1.75 2.00 0.95 median qi ## 4 Y_bar_34 2.37 2.25 2.49 0.95 median qi For kicks and giggles, here are what the cell-specific means look like in box plots. post %&gt;% pivot_longer(Y_bar_1:Y_bar_4) %&gt;% ggplot(aes(x = name, y = value, fill = name)) + geom_boxplot(size = 1/3) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + labs(title = &quot;Cell-specific effects&quot;, x = NULL, y = &quot;interest&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) And here are the same for the marginal means. This time we’ll show the shapes of the posteriors with violin plots with horizontal lines depicting the median and interquartile ranges. post %&gt;% pivot_longer(Y_bar_12:Y_bar_24) %&gt;% ggplot(aes(x = name, y = value, fill = name)) + geom_violin(draw_quantiles = c(.25, .5, .75), color = ochre_palettes[[&quot;olsen_seq&quot;]][8]) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + labs(title = &quot;Marginal means&quot;, x = NULL, y = &quot;interest&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) On page 294, Hayes used point estimates to compute the simple effect of policy information among Kerry supporters and then the same thing among Bush supporters. Here’s how we’d do that when working with the full vector of posterior draws. post %&gt;% mutate(simple_effect_Kerry = Y_bar_4 - Y_bar_3, simple_effect_Bush = Y_bar_2 - Y_bar_1) %&gt;% pivot_longer(contains(&quot;simple&quot;)) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 simple_effect_Bush -0.385 -0.631 -0.138 0.95 mean qi ## 2 simple_effect_Kerry -0.026 -0.268 0.221 0.95 mean qi So then computing the main effect for policy information using the simple effects is little more than an extension of those steps. post %&gt;% transmute(main_effect = ((Y_bar_4 - Y_bar_3) + (Y_bar_2 - Y_bar_1)) / 2) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.206 -0.387 -0.022 0.95 mean qi And we get the same results by strategically subtracting the marginal means. post %&gt;% transmute(main_effect = Y_bar_24 - Y_bar_13) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.206 -0.387 -0.022 0.95 mean qi The main effect of for candidate is similarly computed using either approach. post %&gt;% transmute(main_effect = ((Y_bar_4 - Y_bar_2) + (Y_bar_3 - Y_bar_1)) / 2) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.78 0.602 0.96 0.95 mean qi post %&gt;% transmute(main_effect = Y_bar_34 - Y_bar_12) %&gt;% mean_qi(main_effect) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## main_effect .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.78 0.602 0.96 0.95 mean qi We don’t have an \\(F\\)-test for our Bayesian moderation model. But we do have an interaction term. Here’s its distribution. post %&gt;% ggplot(aes(x = `b_policy:kerry`)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_qual&quot;]][2]) + geom_vline(xintercept = fixef(model8.5)[&quot;policy:kerry&quot;, c(1, 3, 4)], color = ochre_palettes[[&quot;olsen_seq&quot;]][8], linetype = c(1, 2, 2)) + scale_x_continuous(NULL, breaks = fixef(model8.5)[&quot;policy:kerry&quot;, c(1, 3, 4)], labels = fixef(model8.5)[&quot;policy:kerry&quot;, c(1, 3, 4)] %&gt;% round(digits = 2)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The interaction term, `policy:kerry`&quot;, subtitle = &quot;The solid vertical line is the posterior mean\\nand the dashed lines to either end denote the\\npercentile-based 95% intervals.&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) Following Hayes’s work on the bottom of page 295, here’s how you’d reproduce that by manipulating our \\(\\overline Y\\) vectors. post %&gt;% transmute(reproduced_interaction_term = (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)) %&gt;% mean_qi(reproduced_interaction_term) %&gt;% mutate_if(is.double, round, digits = 2) ## # A tibble: 1 x 6 ## reproduced_interaction_term .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.36 0.02 0.7 0.95 mean qi Extending that logic, we also get the answer this way. post %&gt;% transmute(reproduced_interaction_term = (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)) %&gt;% mean_qi(reproduced_interaction_term) %&gt;% mutate_if(is.double, round, digits = 2) ## # A tibble: 1 x 6 ## reproduced_interaction_term .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.36 0.02 0.7 0.95 mean qi 8.4.1 Simple effects parameterization. We might reacquaint ourselves with the formula from model8.5. model8.5$formula ## interest ~ 1 + policy + kerry + policy:kerry The results cohere nicely with the “Model 1” results at the top of Table 8.5. fixef(model8.5) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 1.782 0.089 1.608 1.959 ## policy -0.385 0.127 -0.631 -0.138 ## kerry 0.601 0.129 0.337 0.848 ## policy:kerry 0.359 0.176 0.018 0.703 The Bayesian \\(R^2\\) portion looks on point, too. bayes_R2(model8.5) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.14 0.026 0.092 0.192 Our various Y_bar transformations from before continue to cohere with the coefficients, above, just like in the text. E.g., the policy coefficient may be returned like so. post %&gt;% transmute(b1 = b_policy, `Y_bar_2 - Y_bar_1` = Y_bar_2 - Y_bar_1) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b1 -0.385 0.127 ## 2 Y_bar_2 - Y_bar_1 -0.385 0.127 We can continue to use Hayes’s Y_bar transformations to return the kerry coefficient, too. post %&gt;% transmute(b2 = b_kerry, `Y_bar_3 - Y_bar_1` = Y_bar_3 - Y_bar_1) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b2 0.601 0.129 ## 2 Y_bar_3 - Y_bar_1 0.601 0.129 Here we compute \\(b_3\\) with the difference between the simple effects of \\(X\\) at levels of \\(W\\). post %&gt;% transmute(b3 = `b_policy:kerry`, `(Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)` = (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1) 0.359 0.176 ## 2 b3 0.359 0.176 And now \\(b_{3}\\) with the difference between the simple effects of \\(W\\) at levels of \\(X\\). post %&gt;% transmute(b3 = `b_policy:kerry`, `(Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)` = (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1) 0.359 0.176 ## 2 b3 0.359 0.176 8.4.2 Main effects parameterization. A nice feature of brms is you can transform your data right within the brm() or update() functions. Here we’ll make our two new main-effects-coded variables, policy_me and kerry_me, with the mutate() function right within update(). model8.6 &lt;- update(model8.5, newdata = caskets %&gt;% mutate(policy_me = policy - .5, kerry_me = kerry - .5), family = gaussian, interest ~ 1 + policy_me + kerry_me + policy_me:kerry_me, cores = 4, file = &quot;fits/model08.06&quot;) Transforming your data within the brms functions won’t change the original data structure. However, brms will save the data used to fit the model within the brm() object. You can access that data like so. model8.6$data %&gt;% head() ## interest policy_me kerry_me ## 1 4 0.5 0.5 ## 2 2 -0.5 0.5 ## 3 3 0.5 0.5 ## 4 1 0.5 0.5 ## 5 1 0.5 0.5 ## 6 2 -0.5 -0.5 But we digress. Here’s our analogue to the “Model 2” portion of Table 8.5. rbind( fixef(model8.6) %&gt;% round(digits = 3), bayes_R2(model8.6) %&gt;% round(digits = 3) ) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 1.980 0.044 1.895 2.067 ## policy_me -0.210 0.089 -0.384 -0.038 ## kerry_me 0.780 0.092 0.601 0.963 ## policy_me:kerry_me 0.365 0.178 0.013 0.729 ## R2 0.141 0.026 0.091 0.193 Like with model8.6, above, we’ll need a bit of algebra to compute our \\(\\overline Y_i\\) vectors. post &lt;- posterior_samples(model8.6) %&gt;% mutate(Y_bar_1 = b_Intercept + b_policy_me * -.5 + b_kerry_me * -.5 + `b_policy_me:kerry_me` * -.5 * -.5, Y_bar_3 = b_Intercept + b_policy_me * -.5 + b_kerry_me * .5 + `b_policy_me:kerry_me` * -.5 * .5, Y_bar_2 = b_Intercept + b_policy_me * .5 + b_kerry_me * -.5 + `b_policy_me:kerry_me` * .5 * -.5, Y_bar_4 = b_Intercept + b_policy_me * .5 + b_kerry_me * .5 + `b_policy_me:kerry_me` * .5 * .5) With our post for fit5 in hand, we’ll follow the formulas at the top of page 298 to compute our \\(b_1\\) and \\(b_2\\) distributions. post %&gt;% transmute(b1 = ((Y_bar_4 - Y_bar_3) + (Y_bar_2 - Y_bar_1)) / 2, b2 = ((Y_bar_4 - Y_bar_2) + (Y_bar_3 - Y_bar_1)) / 2) %&gt;% pivot_longer(b1:b2) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 3 ## name mean sd ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 b1 -0.21 0.089 ## 2 b2 0.78 0.092 Hayes pointed out that the interaction effect, \\(b_3\\), is the same across models his OLS Models 1 and 2. This is largely true for our Bayesian HMC model8.5 and model8.6 models. fixef(model8.5)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.359 0.176 0.018 0.703 fixef(model8.6)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.365 0.178 0.013 0.729 However, the results aren’t exactly the same because of simulation error. If you were working on a project requiring high precision, increase the number of posterior iterations. To demonstrate, here we’ll increase each chain’s post-warmup iteration count by an order of magnitude, resulting in 80,000 post-warmup iterations rather than the default 4,000. model8.7 &lt;- update(model8.5, chains = 4, cores = 4, warmup = 1000, iter = 21000, file = &quot;fits/model08.07&quot;) model8.8 &lt;- update(model8.6, chains = 4, cores = 4, warmup = 1000, iter = 21000, file = &quot;fits/model08.08&quot;) Now they’re quite a bit closer. fixef(model8.7)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.361 0.179 0.011 0.714 fixef(model8.8)[4, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.360 0.179 0.010 0.711 And before you get fixate on how there are still differences after 80,000 iterations, each, consider comparing the two density plots. posterior_samples(model8.7) %&gt;% transmute(iteraction = `b_policy:kerry`) %&gt;% bind_rows( posterior_samples(model8.8) %&gt;% transmute(iteraction = `b_policy_me:kerry_me`) ) %&gt;% mutate(model = rep(str_c(&quot;8.&quot;, 7:8), times = n() / 2)) %&gt;% ggplot(aes(x = iteraction, fill = model)) + geom_density(size = 0, alpha = 1/2) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(3, 6)]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The interaction densities, by model&quot;, subtitle = &quot;Yes, they are indeed different. And yet that difference is so\\ntrivial that we&#39;d expect greater variability from measurement\\nerror than we still have from simulation error.&quot;, x = NULL) + theme_08 8.4.3 Conducting a \\(2 \\times 2\\) between-participants factorial ANOVA using PROCESS another regression model with brms. Since we’re square in single-level regression land with our brms approach, there’s no direct analogue for us, here. However, notice the post-ANOVA \\(t\\)-tests Hayes presented on page 300. If we just want to consider the \\(2 \\times 2\\) structure of our two dummy variables as indicative of four groups, we have one more coding system available for the job. With the handy str_c() function, we’ll concatenate the policy and kerry values into a nominal variable, policy_kerry. Here’s what that looks like: caskets &lt;- caskets %&gt;% mutate(policy_kerry = str_c(policy, kerry)) head(caskets) ## # A tibble: 6 x 8 ## policy interest age educ male conserv kerry policy_kerry ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; ## 1 1 4 39 3 1 4 1 11 ## 2 0 2 57 3 1 3 1 01 ## 3 1 3 63 2 0 6 1 11 ## 4 1 1 56 5 1 3 1 11 ## 5 1 1 50 3 0 3 1 11 ## 6 0 2 87 2 1 5 0 00 Now check out what happens if we reformat our formula to interest ~ 0 + policy_kerry. model8.9 &lt;- brm(data = caskets, family = gaussian, interest ~ 0 + policy_kerry, cores = 4, file = &quot;fits/model08.09&quot;) The brm() function recognized policy_kerry as a character vector and treated it as a nominal variable. The 0 + part of the function removed the model intercept. Here’s how that effects the output. print(model8.9) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: interest ~ 0 + policy_kerry ## Data: caskets (Number of observations: 541) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## policy_kerry00 1.78 0.09 1.60 1.96 1.00 5690 3226 ## policy_kerry01 2.38 0.09 2.21 2.56 1.00 5278 2946 ## policy_kerry10 1.40 0.09 1.21 1.58 1.00 5857 3076 ## policy_kerry11 2.36 0.09 2.19 2.53 1.00 5214 3359 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.04 0.03 0.98 1.10 1.00 4439 2872 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Without the typical intercept, brm() estimated the means for each of the four policy_kerry groups. It’s kinda like an intercept-only model, but with four intercepts. Here’s what their densities look like. post &lt;- posterior_samples(model8.9) post %&gt;% pivot_longer(b_policy_kerry00:b_policy_kerry11) %&gt;% mutate(name = str_remove(name, &quot;b_&quot;)) %&gt;% ggplot(aes(x = value, fill = name)) + geom_density(color = &quot;transparent&quot;, alpha = 2/3) + scale_fill_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Group means&quot;, x = NULL) + theme_08 Since each of the four primary vectors in our post object is of a group mean, it’s trivial to compute difference scores. To compute the difference score analogous to Hayes’s two \\(t\\)-tests, we’d do the following. post %&gt;% mutate(difference_1 = b_policy_kerry10 - b_policy_kerry00, difference_2 = b_policy_kerry11 - b_policy_kerry01) %&gt;% pivot_longer(starts_with(&quot;difference_&quot;)) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 difference_1 -0.384 -0.637 -0.137 0.95 median qi ## 2 difference_2 -0.026 -0.268 0.219 0.95 median qi Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 ochRe_1.0.0 ggthemes_4.2.4 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 ## [7] stringr_1.4.0 dplyr_1.0.6 purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ## [13] ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 ## [5] svUnit_1.0.3 sp_1.4-4 splines_4.0.4 crosstalk_1.1.0.1 ## [9] TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 digest_0.6.27 ## [13] htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 checkmate_2.0.0 ## [17] magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 ## [21] xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 ## [25] rvest_1.0.1 ggdist_3.0.0 haven_2.3.1 xfun_0.23 ## [29] callr_3.7.0 crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 ## [33] survival_3.2-10 zoo_1.8-8 glue_1.4.2 gtable_0.3.0 ## [37] emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [41] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 ## [45] DBI_1.1.0 miniUI_0.1.1.1 xtable_1.8-4 stats4_4.0.4 ## [49] StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 httr_1.4.2 ## [53] threejs_0.3.3 arrayhelpers_1.1-0 posterior_1.0.1 ellipsis_0.3.2 ## [57] farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 sass_0.3.1 ## [61] dbplyr_2.1.1 utf8_1.2.1 labeling_0.4.2 tidyselect_1.1.1 ## [65] rlang_0.4.11 reshape2_1.4.4 later_1.2.0 munsell_0.5.0 ## [69] cellranger_1.1.0 tools_4.0.4 cli_3.0.1 generics_0.1.0 ## [73] broom_0.7.6 ggridges_0.5.3 evaluate_0.14 fastmap_1.1.0 ## [77] processx_3.5.2 knitr_1.33 fs_1.5.0 nlme_3.1-152 ## [81] mime_0.10 projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 ## [85] bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 gamm4_0.2-6 ## [89] curl_4.3 reprex_2.0.0 statmod_1.4.35 bslib_0.2.4 ## [93] stringi_1.6.2 highr_0.9 ps_1.6.0 Brobdingnag_1.2-6 ## [97] lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 markdown_1.1 ## [101] tensorA_0.36.2 shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 ## [105] lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 estimability_1.3 ## [109] raster_3.4-5 httpuv_1.6.0 R6_2.5.0 bookdown_0.22 ## [113] promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 boot_1.3-26 ## [117] colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 assertthat_0.2.1 ## [121] withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 mgcv_1.8-33 ## [125] parallel_4.0.4 hms_1.1.0 grid_4.0.4 coda_0.19-4 ## [129] minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 ## [133] base64enc_0.1-3 dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 "],["some-myths-and-additional-extensions-of-moderation-analysis.html", "9 Some Myths and Additional Extensions of Moderation Analysis 9.1 Truths and myths about mean-centering 9.2 The estimation and interpretation of standardized regression coefficients in a moderation analysis 9.3 A caution on manual centering and standardization [because of missing data] 9.4 More than one moderator 9.5 Comparing conditional effects Session info", " 9 Some Myths and Additional Extensions of Moderation Analysis In this chapter, our Bayesian approach complicates some of Hayes’s flow. We’ll see how Bayesian HMC estimation can make us reconsider the value in mean centering and we’ll also slip in some missing data talk. 9.1 Truths and myths about mean-centering Mean-centering has been recommended in a few highly regarded books on regression analysis (e.g., Aiken &amp; West, 1991; Cohen et al., 2003), and several explanations have been offered for why mean-centering should be undertaken prior to computation of the product and model estimation. The explanation that seems to have resulted in the most misunderstanding is that \\(X\\) and \\(W\\) are likely to be highly correlated with \\(XW\\) and this will produce estimation problems caused by collinearity and result in poor or “strange” estimates of regression coefficients, large standard errors, and reduced power of the statistical test of the interaction. But this is, in large part, simply a myth. As I describe later, there are some reasons that mean- centering the focal antecedent or moderator variables can be a beneficial thing to do, which is why it has been recommended by some. However, it is incorrect to claim that it is necessary, that a failure to do so will lead one to incorrect inferences about moderation, or that the resulting regression coefficients are somehow strange or inherently uninterpretable. (Andrew F. Hayes, 2018, pp. 304–305, emphasis in the original) Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) ## Rows: 815 ## Columns: 7 ## $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1.0, 2… ## $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.67, 3.… ## $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.67, 2.… ## $ ideology &lt;dbl&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, 5, 4,… ## $ age &lt;dbl&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 38, 63… ## $ sex &lt;dbl&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0,… ## $ partyid &lt;dbl&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1,… Before we fit our models, we’ll go ahead and make our mean-centered predictors, negemot_c and age_c. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_c = negemot - mean(negemot), age_c = age - mean(age)) Now we’re ready to fit Models 1 and 2. But before we do, it’s worth repeating part of the text: Let’s load brms. library(brms) As we’ll see in just a bit, there are some important reasons for Bayesians using HMC to mean center that wouldn’t pop up within the OLS paradigm. First let’s fit model9.1 and model9.2. model9.1 follows the conventional moderation equation \\[Y = i_Y + b_1 X + b_2 W + b_3 XW + e_Y.\\] model9.2 is our mean-centered model, which we can express formally as \\[\\begin{align*} Y &amp; = i_Y + b_1 \\left (X - \\overline X \\right ) + b_2 \\left (W - \\overline W \\right ) + b_3 \\left (X - \\overline X \\right ) \\left (W - \\overline W \\right ) + e_Y, \\; \\text{or more simply} \\\\ &amp; = i_Y + b_1 X&#39; + b_2 W&#39; + b_3 X&#39;W&#39; + e_Y, \\end{align*}\\] where \\(X&#39; = \\left (X - \\overline X \\right)\\) and so on. model9.1 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + age + negemot:age, cores = 4, file = &quot;fits/model09.01&quot;) model9.2 &lt;- update(model9.1, newdata = glbwarm, govact ~ 1 + negemot_c + age_c + negemot_c:age_c, cores = 4, file = &quot;fits/model09.02&quot;) As with Hayes’s OLS models, our HMC models yield the same Bayesian \\(R^2\\) distributions, within simulation error. bayes_R2(model9.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.022 0.31 0.395 bayes_R2(model9.2) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.022 0.31 0.395 Our model summaries also correspond nicely with those at the top of Table 9.1. print(model9.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ 1 + negemot + age + negemot:age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.330 0.331 3.681 4.979 1.001 1587 1803 ## negemot 0.149 0.085 -0.014 0.321 1.001 1614 1942 ## age -0.031 0.006 -0.042 -0.019 1.001 1569 1951 ## negemot:age 0.007 0.002 0.004 0.010 1.001 1587 1935 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.097 0.026 1.046 1.148 1.004 2537 2319 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ negemot_c + age_c + negemot_c:age_c ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.597 0.040 4.517 4.676 1.002 3364 2390 ## negemot_c 0.501 0.025 0.451 0.552 1.002 3683 2546 ## age_c -0.005 0.002 -0.010 -0.001 1.002 5159 3161 ## negemot_c:age_c 0.007 0.002 0.004 0.010 1.000 5528 3166 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.098 0.028 1.045 1.155 1.000 3397 2642 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). However, notice the ‘Bulk_ESS’ and ‘Tail_ESS’ columns. The values for model9.2 were substantially larger than those for model9.1. These columns denote the number of effective samples (a.k.a. the effective sample size). Versions of brms before 2.10.0 returned a single effective sample size (ESS) value per parameter. We will cover where the change came from in a bit. But first, recall that we’ve been using brms defaults, which results in 4 HMC chains, each of which contains 2,000 draws (iterations), the first 1,000 of which are warmup values. After we discard the warmup values, that leaves 1,000 draws from each chain–4,000 total. As it turns out, Markov chains, and thus HMC chains, are typically autocorrelated, which means that each draw is partially dependent on the previous draw. Ideally, the autocorrelations are near zero. That’s often not the case. The bayesplot package offers a variety of diagnostic plots. Here we’ll use the mcmc_acf() function to make autocorrelation plots for all model parameters. Note that when we add add_chain = T to brms::posterior_samples(), we add an index to the data that allows us to keep track of which iteration comes from which chain. That index will come in handy for our mcmc_acf() plots. But before we get there, we’ll be using an xkcd-inspired theme with help from the xkcd package (Torres-Manzanera, 2018) for our plots in this chapter. # install.packages(&quot;xkcd&quot;, dependencies = T) library(xkcd) If you haven’t used the xkcd package, before, you might also need to take a few extra steps outlined in the paper by Torres-Manzanera (n.d.), xkcd: Plotting XKCD graphs, part of which requires help from the extrafont package (Chang, 2014). library(extrafont) download.file(&quot;http://simonsoftware.se/other/xkcd.ttf&quot;, dest = &quot;xkcd.ttf&quot;, mode = &quot;wb&quot;) system(&quot;mkdir ~/.fonts&quot;) system(&quot;cp xkcd.ttf ~/.fonts&quot;) # this line of code returned an error message # font_import(pattern = &quot;[X/x]kcd&quot;, prompt = FALSE) # this line from (https://stackoverflow.com/questions/49221040/error-in-font-import-while-installing-xkcd-font) fixed the problem font_import(path = &quot;~/.fonts&quot;, pattern = &quot;[X/x]kcd&quot;, prompt=FALSE) fonts() fonttable() if(.Platform$OS.type != &quot;unix&quot;) { ## Register fonts for Windows bitmap output loadfonts(device=&quot;win&quot;) } else { loadfonts() } After installing, I still experienced error messages, which were alleviated after I followed these steps outlined by Remi.b. You may or may not need them. But anyways, here are our mcmc_acf() plots. library(bayesplot) post1 &lt;- posterior_samples(model9.1, add_chain = T) mcmc_acf(post1, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot&quot;, &quot;b_age&quot;, &quot;b_negemot:age&quot;, &quot;sigma&quot;), lags = 4) + theme_xkcd() post2 &lt;- posterior_samples(model9.2, add_chain = T) mcmc_acf(post2, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot_c&quot;, &quot;b_age_c&quot;, &quot;b_negemot_c:age_c&quot;, &quot;sigma&quot;), lags = 4) + theme_xkcd() As it turns out, theme_xkcd() can’t handle special characters like \"_\", so it returns rectangles instead. So it goes… But again, high autocorrelations in the HMC chains have consequences for the effective sample size. In their (2020) vignette, Visual MCMC diagnostics using the bayesplot package, Gabry and Modrák wrote: The effective sample size is an estimate of the number of independent draws from the posterior distribution of the estimand of interest. Because the draws within a Markov chain are not independent if there is autocorrelation, the effective sample size, \\(n_{eff}\\), will be smaller than the total sample size, \\(N\\). The larger the ratio of \\(n_{eff}\\) to \\(N\\) the better. In that quote, they spoke as if there was only one measure of ESS. Though this has been the case for some time, times have changed. In a (2019) paper, Stan-team allstars Vehtari, Gelman, Simpson, Carpenter, and Bürkner proposed two measures of ESS: “bulk-ESS” and “tail-ESS.” From their paper, we read: if you plan to report quantile estimates or posterior intervals, we strongly suggest assessing the convergence of the chains for these quantiles. In Section 4.3 we show that convergence of Markov chains is not uniform across the parameter space and propose diagnostics and effective sample sizes specifically for extreme quantiles. This is different from the standard ESS estimate (which we refer to as the “bulk-ESS”), which mainly assesses how well the centre of the distribution is resolved. Instead, these “tail-ESS” measures allow the user to estimate the MCSE for interval estimates. (p. 5, emphasis in the original) You can read the paper for technical details. In short, the Bulk_ESS in the output of brms 2.10.0 and up is what was previously referred to as Eff.Sample, the effective sample size. This indexed the number of effective samples in “the centre of the” posterior distribution (i.e., the posterior mean or median). But since we also care about uncertainty in our models, we also care about how well we have characterized the tails of the posterior distribution in 95% intervals and such. The new Tail_ESS in brms output allows us to gauge the effective sample size for those intervals. The Bulk_ESS and Tail_ESS values were all well above 2,000 with model9.2 and the autocorrelations were very low, too. model9.1 had higher autocorrelations and lower ESS values. The upshot is that even though we have 4,000 samples for each parameter, those samples don’t necessarily give us the same quality of information fully independent samples would. Bulk_ESS and Tail_ESS values help you determine how concerned you should be. And, as it turns out, things like centering can help increase a models Bulk_ESS and Tail_ESS values. Wading in further, we can use the neff_ratio() function to collect the \\(n_{eff}\\) to \\(N\\) ratio for each model parameter and then use mcmc_neff() to make a visual diagnostic. Here we do so for model9.1 and model9.2. ratios_model9.1 &lt;- neff_ratio(model9.1, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot&quot;, &quot;b_age&quot;, &quot;b_negemot:age&quot;, &quot;sigma&quot;)) ratios_model9.2 &lt;- neff_ratio(model9.2, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot_c&quot;, &quot;b_age_c&quot;, &quot;b_negemot_c:age_c&quot;, &quot;sigma&quot;)) mcmc_neff(ratios_model9.1) + yaxis_text(hjust = 0) + theme_xkcd() mcmc_neff(ratios_model9.2) + yaxis_text(hjust = 0) + theme_xkcd() Although none of the \\(n_{eff}\\) to \\(N\\) ratios were in the shockingly-low range for either model, there were substantially higher for model9.2. In addition to autocorrelations and \\(n_{eff}\\) to \\(N\\) ratios, there is also the issue that the parameters in the model can themselves be correlated. If you like a visual approach, you can use brms::pairs() to retrieve histograms for each parameter along with scatter plots showing the shape of their correlations. Here we’ll use the off_diag_args argument to customize some of the plot settings. pairs(model9.1, off_diag_args = list(size = 1/10, alpha = 1/5)) pairs(model9.2, off_diag_args = list(size = 1/10, alpha = 1/5)) When fitting models with HMC, centering can make a difference for the parameter correlations. If you prefer a more numeric approach, vcov() will yield the variance/covariance matrix–or correlation matrix when using correlation = T–for the parameters in a model. vcov(model9.1, correlation = T) %&gt;% round(digits = 2) ## Intercept negemot age negemot:age ## Intercept 1.00 -0.93 -0.96 0.89 ## negemot -0.93 1.00 0.89 -0.96 ## age -0.96 0.89 1.00 -0.93 ## negemot:age 0.89 -0.96 -0.93 1.00 vcov(model9.2, correlation = T) %&gt;% round(digits = 2) ## Intercept negemot_c age_c negemot_c:age_c ## Intercept 1.00 0.02 0.02 0.05 ## negemot_c 0.02 1.00 0.04 -0.10 ## age_c 0.02 0.04 1.00 0.02 ## negemot_c:age_c 0.05 -0.10 0.02 1.00 And so wait, what does that even mean for a parameter to correlate with another parameter? you might ask. Fair enough. Let’s compute a parameter correlation step by step. The first step requires posterior_samples(). post &lt;- posterior_samples(model9.1) head(post) ## b_Intercept b_negemot b_age b_negemot:age sigma lp__ ## 1 4.204010 0.1395087 -0.03271575 0.008387642 1.126351 -1236.248 ## 2 4.022693 0.2058020 -0.02801013 0.007128736 1.119916 -1235.708 ## 3 4.344482 0.1919790 -0.02670543 0.005164702 1.108933 -1236.080 ## 4 4.083391 0.2073658 -0.02436273 0.005575253 1.102304 -1232.871 ## 5 3.934765 0.2173567 -0.02365274 0.006039011 1.111398 -1233.408 ## 6 4.225579 0.1693370 -0.02878213 0.006922315 1.118568 -1232.815 Now we’ve put our posterior iterations into a data object, post, we can make a scatter plot of two parameters. Here we’ll choose b_negemot and the interaction coefficient, b_negemot:age. post %&gt;% ggplot(aes(x = b_negemot, y = `b_negemot:age`)) + geom_point(size = 1/10, alpha = 1/5) + labs(subtitle = &quot;Each dot is the parameter pair\\nfrom a single iteration. Looking\\nacross the 4,000 total posterior\\niterations, it becomes clear the\\ntwo parameters are highly\\nnegatively correlated.&quot;) + theme_xkcd() And indeed, the Pearson’s correlation coefficient is strong. cor(post$b_negemot, post$`b_negemot:age`) ## [1] -0.9561894 And what was that part from the vcov() output, again? vcov(model9.1, correlation = T)[&quot;negemot&quot;, &quot;negemot:age&quot;] ## [1] -0.9561894 Boom! That’s where those correlations come from. This entire topic of HMC diagnostics can seem baffling, especially when compared to the simplicity of OLS. If this is your first introduction, you might want to watch lectures 10 and 11 from McElreath’s Statistical Rethinking Fall 2017 lecture series. Accordingly, you might check out Chapter 8 of his (2015) text, Chapter 9 of his (2020) text, and either of my ebooks translating his work into brms and tidyverse code (Kurz, 2021, 2020b). 9.1.1 The effect of mean-centering on multicollinearity and the standard error of \\(b_3\\). This can be difficult to keep track of, but what we just looked at were the correlations among model parameters. These are not the same as correlations among variables. As such, those correlations are not the same as those in Table 9.2. But we can get those, too. First we’ll have to do a little more data processing to get all the necessary mean-centered variables and standardized variables. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_x_age = negemot * age, negemot_c_x_age_c = negemot_c * age_c, negemot_z = (negemot - mean(negemot)) / sd(negemot), age_z = (age - mean(age) ) / sd(age)) %&gt;% mutate(negemot_z_x_age_z = negemot_z * age_z) And recall that to get our sweet Bayesian correlations, we use the multivariate mvbind() syntax to fit an intercepts-only model. Here we do that for all three of the Table 9.2 sections. model9.3 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot, age, negemot_x_age) ~ 1, cores = 4, file = &quot;fits/model09.03&quot;) model9.4 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot_c, age_c, negemot_c_x_age_c) ~ 1, cores = 4, file = &quot;fits/model09.04&quot;) model9.5 &lt;- brm(data = glbwarm, family = gaussian, mvbind(negemot_z, age_z, negemot_z_x_age_z) ~ 1, cores = 4, file = &quot;fits/model09.05&quot;) Here are their summaries. print(model9.3, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot ~ 1 ## age ~ 1 ## negemot_x_age ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemot_Intercept 3.559 0.052 3.455 3.663 1.000 3469 2851 ## age_Intercept 49.537 0.560 48.434 50.624 1.001 3714 2754 ## negemotxage_Intercept 174.886 3.339 168.262 181.347 1.000 3182 2753 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemot 1.530 0.038 1.457 1.605 1.002 3370 2706 ## sigma_age 16.356 0.392 15.603 17.143 1.000 3138 2980 ## sigma_negemotxage 97.456 2.411 92.871 102.218 1.001 2711 2347 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemot,age) -0.059 0.035 -0.125 0.009 1.001 3118 2775 ## rescor(negemot,negemotxage) 0.765 0.014 0.737 0.792 1.001 2726 2673 ## rescor(age,negemotxage) 0.547 0.024 0.499 0.593 1.001 3496 2692 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.4, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot_c ~ 1 ## age_c ~ 1 ## negemot_c_x_age_c ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemotc_Intercept 0.000 0.054 -0.106 0.105 1.001 6636 2853 ## agec_Intercept -0.004 0.578 -1.156 1.160 1.003 7940 2825 ## negemotcxagec_Intercept -1.432 0.850 -3.047 0.230 1.001 7685 3111 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemotc 1.532 0.038 1.460 1.609 1.001 8012 3014 ## sigma_agec 16.368 0.393 15.632 17.156 1.002 6283 3137 ## sigma_negemotcxagec 24.244 0.598 23.113 25.426 1.003 7169 2776 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemotc,agec) -0.056 0.035 -0.123 0.011 1.000 6991 2919 ## rescor(negemotc,negemotcxagec) 0.092 0.035 0.025 0.159 1.000 8046 3094 ## rescor(agec,negemotcxagec) -0.015 0.034 -0.082 0.052 1.000 7731 2990 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.5, digits = 3) ## Family: MV(gaussian, gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negemot_z ~ 1 ## age_z ~ 1 ## negemot_z_x_age_z ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negemotz_Intercept 0.000 0.036 -0.070 0.071 1.001 7483 3056 ## agez_Intercept 0.000 0.035 -0.068 0.068 1.001 7461 3072 ## negemotzxagez_Intercept -0.056 0.034 -0.124 0.010 1.001 7117 3106 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negemotz 1.002 0.025 0.955 1.052 1.008 8670 3322 ## sigma_agez 1.003 0.025 0.955 1.054 1.001 7666 2614 ## sigma_negemotzxagez 0.972 0.023 0.926 1.018 1.001 7455 3242 ## ## Residual Correlations: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## rescor(negemotz,agez) -0.057 0.034 -0.123 0.012 1.000 8085 3080 ## rescor(negemotz,negemotzxagez) 0.093 0.035 0.021 0.161 1.000 8273 2684 ## rescor(agez,negemotzxagez) -0.015 0.036 -0.085 0.056 1.002 7400 2550 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). A more condensed way to get that information might be with the brms::VarCorr() function. Just make sure to tack $residual__$cor onto the end. VarCorr(model9.3)$residual__$cor %&gt;% round(digits = 3) ## , , negemot ## ## Estimate Est.Error Q2.5 Q97.5 ## negemot 1.000 0.000 1.000 1.000 ## age -0.059 0.035 -0.125 0.009 ## negemotxage 0.765 0.014 0.737 0.792 ## ## , , age ## ## Estimate Est.Error Q2.5 Q97.5 ## negemot -0.059 0.035 -0.125 0.009 ## age 1.000 0.000 1.000 1.000 ## negemotxage 0.547 0.024 0.499 0.593 ## ## , , negemotxage ## ## Estimate Est.Error Q2.5 Q97.5 ## negemot 0.765 0.014 0.737 0.792 ## age 0.547 0.024 0.499 0.593 ## negemotxage 1.000 0.000 1.000 1.000 For the sake of space, I’ll let you check that out for model9.4 and model9.5. If you’re tricky with your VarCorr() indexing, you can also get the model-implied variances. VarCorr(model9.3)$residual__$cov[1, , &quot;negemot&quot;] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 2.342 0.117 2.123 2.577 VarCorr(model9.3)$residual__$cov[2, , &quot;age&quot;] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 267.685 12.848 243.455 293.891 VarCorr(model9.3)$residual__$cov[3, , &quot;negemotxage&quot;] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 9503.402 470.181 8624.944 10448.492 And if you’re like totally lost with all this indexing, you might execute VarCorr(correlations1) %&gt;% str() and spend a little time looking at what VarCorr() returns. On page 309, Hayes explained why the OLS variance for \\(b_3\\) is unaffected by mean centering. The story was similar for our HMC model, too. fixef(model9.1)[&quot;negemot:age&quot;, &quot;Est.Error&quot;] ## [1] 0.001599196 fixef(model9.2)[&quot;negemot_c:age_c&quot;, &quot;Est.Error&quot;] ## [1] 0.001600323 For more details, you might also see the Standardizing predictors and outputs subsection of Chapter 22 in the Stan user’s guide (Stan Development Team, 2021)–Stan, of course, being the computational engine underneath our brms hood. 9.1.2 The effect of mean-centering on \\(b_1\\), \\(b_2\\), and their standard errors posterior \\(SD\\)s. A second explanation given for why mean-centering is preferred is that it makes \\(b_1\\) and \\(b_2\\), the regression coefficients for \\(X\\) and \\(W\\), more meaningful. This is generally true and thus not a myth, although it is not necessarily true in all circumstances… . Mean-centering \\(X\\) and \\(W\\) prior to computation of the product and estimation of the model will produce \\(b_1\\) and \\(b_2\\) that are always meaningful, rather than meaningful only when \\(X\\) and/or \\(W\\) are meaningful when equal to zero… [After mean centering,] \\(b_1\\) estimates the difference in \\(Y\\) between two cases that differ by one unit on \\(X\\) among cases that are average on \\(W\\). Similarly, \\(b_2\\) estimates the difference in \\(Y\\) between two cases that differ by one unit on \\(W\\) among cases that are average on \\(X\\). These will always estimate conditional effects of \\(X\\) on \\(Y\\) within the range of the data, and they can always be interpreted. (p. 310. emphasis in the original) If you only care about posterior means, you can use model9.1 to reproduce the results at the bottom of page 310 like this. fixef(model9.1)[&quot;negemot&quot;, 1] + fixef(model9.1)[&quot;negemot:age&quot;, 1] * mean(glbwarm$age) ## [1] 0.5008785 Here’s the same computation using model9.2. fixef(model9.2)[&quot;negemot_c&quot;, 1] + fixef(model9.2)[&quot;negemot_c:age_c&quot;, 1] * mean(glbwarm$age_c) ## [1] 0.5007536 But we’re proper Bayesians and like a summary of the spread in the posterior. So we’ll evoke posterior_samples() and the other usual steps, this time just focusing on model9.1. post &lt;- posterior_samples(model9.1) post %&gt;% transmute(our_contidional_effect_given_W_bar = b_negemot + `b_negemot:age` * mean(glbwarm$age)) %&gt;% summarize(mean = mean(our_contidional_effect_given_W_bar), sd = sd(our_contidional_effect_given_W_bar)) %&gt;% round(digits = 3) ## mean sd ## 1 0.501 0.025 And note how the standard error Hayes computed at the top of page 311 corresponds nicely with the posterior \\(SD\\) we just computed. Hayes employed a fancy formula; we just used sd(). At any rate, the main message is centering did not effect our estimate of the conditional effect of \\(X\\). It turns out \\((\\theta_{X \\rightarrow Y} | W) = \\left (\\theta_{\\overline X \\rightarrow Y} | \\overline W \\right)\\). 9.1.3 The centering option in PROCESS. I’m not aware of a similar function in brms. You’ll have to use your data wrangling skills. 9.2 The estimation and interpretation of standardized regression coefficients in a moderation analysis Mean-centering does nothing to change the scaling of regression coefficients. Whether or not mean-centering is used when estimating a model of the form \\(\\hat Y = i_Y + b_1 X + b_2 W + b_3 XW\\), \\(b_1\\), \\(b_2\\), and \\(b_3\\) are interpreted with respect to the measured metrics of \\(X\\), \\(W\\), and \\(Y\\) (i.e., in unstandardized form). Although [Hayes] generally prefer[s] to report and interpret regression analyses based on unstandardized coefficients, it is possible to generate regression coefficients that are analogous to standardized regression coefficients in regression models without a product term as a predictor. However, one must be careful when doing so. (p. 313, emphasis in the original) 9.2.1 Variant 1. We’ve already computed standardized predictors. Now we just need to standardize the criterion, govact. glbwarm &lt;- glbwarm %&gt;% mutate(govact_z = (govact - mean(govact)) / sd(govact)) Fit the model. model9.6 &lt;- update(model9.1, newdata = glbwarm, govact_z ~ 1 + negemot_z + age_z + negemot_z:age_z, cores = 4, file = &quot;fits/model09.06&quot;) Check the Bayesian \\(R^2\\). bayes_R2(model9.6) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.021 0.311 0.395 Check the parameter summaries. print(model9.6, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z + age_z + negemot_z:age_z ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.008 0.029 -0.049 0.064 1.001 4866 3126 ## negemot_z 0.562 0.028 0.507 0.617 1.000 4471 3089 ## age_z -0.064 0.028 -0.118 -0.009 1.001 4991 3308 ## negemot_z:age_z 0.131 0.029 0.076 0.188 1.000 5436 3240 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.807 0.020 0.770 0.847 1.001 5141 3192 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). If you go all the way up back to Table 9.1, you’ll see our results are pretty similar to those in the text. 9.2.2 Variant 2. This time we need to standardize our interaction term, negemot_x_age_z, by hand. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_x_age_z = (negemot_x_age - mean(negemot_x_age)) / sd(negemot_x_age)) Now we’re ready to update(). model9.7 &lt;- update(model9.1, newdata = glbwarm, govact_z ~ 1 + negemot_z + age_z + negemot_x_age_z, cores = 4, file = &quot;fits/model09.07&quot;) bayes_R2(model9.7) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.354 0.021 0.31 0.394 print(model9.7, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z + age_z + negemot_x_age_z ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.000 0.028 -0.054 0.054 1.002 2801 2483 ## negemot_z 0.166 0.095 -0.015 0.355 1.005 1012 1387 ## age_z -0.367 0.072 -0.507 -0.225 1.006 1046 1335 ## negemot_x_age_z 0.510 0.113 0.284 0.729 1.005 1060 1308 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.807 0.020 0.770 0.848 1.002 2811 2268 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The results correspond nicely to those in Table 9.1, too. 9.3 A caution on manual centering and standardization [because of missing data] It’s worthwhile considering the issue of listwise deletion when data are partially missing. The brms default is to delete rows with missingness, NA in R, for the predictors. However, brms allows users to perform one-step Bayesian imputation for missing values using the mi() syntax. You can learn all the details in Bürkner’s (2021c) vignette, Handle missing values with brms. First we’ll fit see what happens when you fit a model in brms when some of the negemot_z values are missing, but without using the mi() syntax. And of course before we do that, we’ll make a negemot_z_missing variable, which is identical to negemot_z, but about 10% of the values are missing. set.seed(9) glbwarm &lt;- glbwarm %&gt;% mutate(missing = rbinom(n = n(), size = 1, prob = .1)) %&gt;% mutate(negemot_z_missing = ifelse(missing == 1, NA, negemot_z)) If you’ve never used rbinom() before, execute ?rbinom or look it up in your favorite web search engine. Here’s our listwise deletion model, which corresponds to what you’d get from a typical OLS-based program. model9.8 &lt;- update(model9.6, newdata = glbwarm, govact_z ~ 1 + negemot_z_missing + age_z + negemot_z_missing:age_z, cores = 4, file = &quot;fits/model09.08&quot;) Let’s compare the listwise deletion results with the model based on all the data. print(model9.6) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z + age_z + negemot_z:age_z ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.01 0.03 -0.05 0.06 1.00 4866 3126 ## negemot_z 0.56 0.03 0.51 0.62 1.00 4471 3089 ## age_z -0.06 0.03 -0.12 -0.01 1.00 4991 3308 ## negemot_z:age_z 0.13 0.03 0.08 0.19 1.00 5436 3240 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.81 0.02 0.77 0.85 1.00 5141 3192 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model9.8) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact_z ~ negemot_z_missing + age_z + negemot_z_missing:age_z ## Data: glbwarm (Number of observations: 731) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 0.00 0.03 -0.05 0.06 1.00 4880 3042 ## negemot_z_missing 0.57 0.03 0.51 0.63 1.00 4801 2924 ## age_z -0.05 0.03 -0.10 0.01 1.00 5129 3372 ## negemot_z_missing:age_z 0.12 0.03 0.06 0.18 1.00 4392 3052 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 0.81 0.02 0.77 0.85 1.00 5420 3168 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). In this case, the model results were similar to those based on all the data because we used rbinom() to delete the predictor values completely at random. With real data and real-live missing data mechanisms, the situation isn’t often so rosy. But anyway, the real story, here, is the Data: glbwarm (Number of observations: n) line at the top of the print() outputs. The number, \\(n\\), was 815 in the model using all the data and 731 for the one based on listwise deletion. That’s a lot of missing information. The mi() syntax will allow us to use all the rows in a model, even if one or more of the predictors contain missing values. The syntax makes the model a multivariate model in that now we’ll be modeling both govact_z and negemot_z_missing. As we’ve covered in prior chapters, there are multiple ways to write a multivariate model in brms (see Bürkner, 2021b). One nice way is to write the model for each criterion separately in a bf() statement. You combine the bf() statements together with the + operator. And for models like the ones in Hayes’s text, you’ll also want to tack on set_rescor(FALSE). You can do this within the brm() function, as usual. But I find that this clutters the code up more than I like. So another approach is to save the combination of bf() statements as an object. my_model &lt;- bf(govact_z ~ 1 + mi(negemot_z_missing) + age_z + mi(negemot_z_missing):age_z) + bf(negemot_z_missing | mi() ~ 1) + set_rescor(FALSE) With our multivariate formula saved as my_model, we’re ready to plug it into brm() and fit. model9.9 &lt;- brm(data = glbwarm, family = gaussian, my_model, cores = 4, file = &quot;fits/model09.09&quot;) Let’s see what we’ve done. print(model9.9) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: govact_z ~ 1 + mi(negemot_z_missing) + age_z + mi(negemot_z_missing):age_z ## negemot_z_missing | mi() ~ 1 ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## govactz_Intercept 0.01 0.03 -0.05 0.06 1.00 5485 3096 ## negemotzmissing_Intercept -0.00 0.04 -0.07 0.07 1.00 4977 3135 ## govactz_age_z -0.06 0.03 -0.12 -0.00 1.00 5341 3035 ## govactz_minegemot_z_missing 0.57 0.03 0.51 0.63 1.00 6042 2249 ## govactz_minegemot_z_missing:age_z 0.13 0.03 0.07 0.19 1.00 5485 3189 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_govactz 0.81 0.02 0.77 0.85 1.00 5655 3133 ## sigma_negemotzmissing 1.00 0.03 0.95 1.05 1.00 5181 2974 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). When using the multivariate mi() syntax, your print() output becomes more complicated. We got regression sub-models for both govact_z and negemot_z_missing. But look at the line at the top of the output that reads “Data: glbwarm (Number of observations: 815).” The multivariate mi() syntax used all the available data. No listwise deletion necessary. The print() output for our model obscured some of the results. To clarify what the mi() syntax did, let’s peek at the first columns returned by posterior_samples(). post &lt;- posterior_samples(model9.9) post[, 1:20] %&gt;% glimpse() ## Rows: 4,000 ## Columns: 20 ## $ b_govactz_Intercept &lt;dbl&gt; -0.0009375754, 0.0102454390, 0.0267679206, 0.0004908605… ## $ b_negemotzmissing_Intercept &lt;dbl&gt; 0.0421679586, 0.0028051301, -0.0258047227, 0.0319523969… ## $ b_govactz_age_z &lt;dbl&gt; 0.0038097886, 0.0055311310, 0.0101281349, -0.0306100074… ## $ bsp_govactz_minegemot_z_missing &lt;dbl&gt; 0.5438757, 0.5536677, 0.5578784, 0.6028770, 0.5446027, … ## $ `bsp_govactz_minegemot_z_missing:age_z` &lt;dbl&gt; 0.11819682, 0.14527529, 0.13840587, 0.18422013, 0.06941… ## $ sigma_govactz &lt;dbl&gt; 0.8580747, 0.8185694, 0.7947336, 0.7994697, 0.8124083, … ## $ sigma_negemotzmissing &lt;dbl&gt; 0.9785131, 0.9972329, 1.0021417, 1.0165915, 0.9822670, … ## $ `Ymi_negemotzmissing[10]` &lt;dbl&gt; -1.290512603, -1.043112362, -0.830640971, -0.873447449,… ## $ `Ymi_negemotzmissing[18]` &lt;dbl&gt; -0.98932629, -0.79446124, -1.61039075, -1.01502925, -0.… ## $ `Ymi_negemotzmissing[26]` &lt;dbl&gt; 0.334853667, 0.417298092, 0.588396261, 0.899239245, 0.0… ## $ `Ymi_negemotzmissing[29]` &lt;dbl&gt; 1.326713180, -0.460480411, -0.370049685, 1.001615849, -… ## $ `Ymi_negemotzmissing[32]` &lt;dbl&gt; -0.33018069, 0.18344865, -1.25270921, -1.82373863, 0.32… ## $ `Ymi_negemotzmissing[34]` &lt;dbl&gt; -0.46277395, -0.15870952, -1.82401414, 0.17684719, 0.35… ## $ `Ymi_negemotzmissing[38]` &lt;dbl&gt; -1.7951726, -1.0863270, -0.9174883, -1.1077899, -2.0922… ## $ `Ymi_negemotzmissing[41]` &lt;dbl&gt; 1.14102770, -0.68278622, 0.22707544, 1.48681521, 0.2399… ## $ `Ymi_negemotzmissing[50]` &lt;dbl&gt; 0.534109352, -1.669759946, -0.296342997, -0.685547859, … ## $ `Ymi_negemotzmissing[51]` &lt;dbl&gt; -0.46777446, 0.06965386, 0.34232446, -0.17051913, -0.62… ## $ `Ymi_negemotzmissing[56]` &lt;dbl&gt; 0.016301128, 0.665334352, 1.242373177, -1.088473074, 0.… ## $ `Ymi_negemotzmissing[78]` &lt;dbl&gt; -0.38659424, 0.76295879, 0.51827930, -0.18174219, 0.395… ## $ `Ymi_negemotzmissing[89]` &lt;dbl&gt; 1.02044743, 0.28167339, -0.61432986, -0.38829197, -0.32… Columns b_govactz_Intercept through sigma_negemotzmissing were business as usual. But notice all the Ymi_negemotzmissing[i] columns. In each of these we see 4,000 posterior draws for the missing negemot_z_missing values. The [i] part of the column names indexes which row number the iterations correspond to. Summarizing these columns might help us get a sense of the results. library(tidybayes) post %&gt;% pivot_longer(starts_with(&quot;Ymi&quot;), names_to = &quot;row&quot;) %&gt;% group_by(row) %&gt;% # yep, that&#39;s right, we&#39;re summarizing as usual mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 2) %&gt;% select(row:.upper) ## # A tibble: 84 x 4 ## row value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Ymi_negemotzmissing[10] -0.86 -2.43 0.62 ## 2 Ymi_negemotzmissing[101] 0.15 -1.51 1.82 ## 3 Ymi_negemotzmissing[117] -0.17 -1.85 1.53 ## 4 Ymi_negemotzmissing[135] 0.26 -1.29 1.8 ## 5 Ymi_negemotzmissing[139] -0.34 -1.92 1.22 ## 6 Ymi_negemotzmissing[148] -1.38 -2.81 0.06 ## 7 Ymi_negemotzmissing[150] -0.3 -1.75 1.12 ## 8 Ymi_negemotzmissing[152] 0 -1.57 1.62 ## 9 Ymi_negemotzmissing[153] -1.59 -3.12 -0.02 ## 10 Ymi_negemotzmissing[154] 0.57 -0.83 2.01 ## 11 Ymi_negemotzmissing[162] 0.09 -1.53 1.72 ## 12 Ymi_negemotzmissing[164] 0.39 -1.11 1.89 ## 13 Ymi_negemotzmissing[166] -0.06 -1.52 1.41 ## 14 Ymi_negemotzmissing[167] -0.15 -1.59 1.28 ## 15 Ymi_negemotzmissing[178] -0.51 -1.98 0.98 ## 16 Ymi_negemotzmissing[18] -0.88 -2.33 0.55 ## 17 Ymi_negemotzmissing[186] 0.12 -1.35 1.62 ## 18 Ymi_negemotzmissing[214] 0.95 -0.53 2.46 ## 19 Ymi_negemotzmissing[230] -0.17 -1.79 1.48 ## 20 Ymi_negemotzmissing[246] 0.6 -1.12 2.27 ## 21 Ymi_negemotzmissing[259] -0.98 -2.61 0.74 ## 22 Ymi_negemotzmissing[26] 0.59 -0.87 2.02 ## 23 Ymi_negemotzmissing[260] 0.49 -0.9 1.89 ## 24 Ymi_negemotzmissing[266] 0.23 -1.2 1.62 ## 25 Ymi_negemotzmissing[284] 0.17 -1.6 1.97 ## 26 Ymi_negemotzmissing[29] 0.27 -1.22 1.79 ## 27 Ymi_negemotzmissing[32] -0.48 -2.21 1.23 ## 28 Ymi_negemotzmissing[329] 0.22 -1.54 2 ## 29 Ymi_negemotzmissing[337] 0.25 -1.47 2 ## 30 Ymi_negemotzmissing[338] 0.16 -1.71 2 ## 31 Ymi_negemotzmissing[34] 0.26 -1.32 1.85 ## 32 Ymi_negemotzmissing[350] -0.92 -2.56 0.73 ## 33 Ymi_negemotzmissing[358] 0.96 -0.66 2.64 ## 34 Ymi_negemotzmissing[371] 0.16 -1.31 1.62 ## 35 Ymi_negemotzmissing[38] -1.56 -2.98 -0.1 ## 36 Ymi_negemotzmissing[383] 0.47 -1.1 2.07 ## 37 Ymi_negemotzmissing[394] 0.74 -0.76 2.33 ## 38 Ymi_negemotzmissing[397] 0.33 -1.41 2.03 ## 39 Ymi_negemotzmissing[398] 0.56 -1.07 2.25 ## 40 Ymi_negemotzmissing[401] -0.26 -1.99 1.52 ## 41 Ymi_negemotzmissing[406] 0.62 -0.98 2.21 ## 42 Ymi_negemotzmissing[41] 0.61 -0.97 2.2 ## 43 Ymi_negemotzmissing[424] 0.71 -0.97 2.38 ## 44 Ymi_negemotzmissing[435] -0.1 -1.91 1.69 ## 45 Ymi_negemotzmissing[440] 0.35 -1.16 1.87 ## 46 Ymi_negemotzmissing[447] -0.17 -1.75 1.45 ## 47 Ymi_negemotzmissing[469] -0.05 -1.85 1.77 ## 48 Ymi_negemotzmissing[472] 0.42 -1.02 1.91 ## 49 Ymi_negemotzmissing[476] 0.65 -0.82 2.16 ## 50 Ymi_negemotzmissing[484] -1.39 -2.9 0.11 ## 51 Ymi_negemotzmissing[50] -0.2 -1.57 1.15 ## 52 Ymi_negemotzmissing[507] -0.15 -1.72 1.44 ## 53 Ymi_negemotzmissing[51] -0.51 -2 1 ## 54 Ymi_negemotzmissing[515] 0.21 -1.27 1.65 ## 55 Ymi_negemotzmissing[519] -0.05 -1.54 1.5 ## 56 Ymi_negemotzmissing[524] -0.33 -1.81 1.22 ## 57 Ymi_negemotzmissing[540] 0.48 -1.18 2.17 ## 58 Ymi_negemotzmissing[555] 0.45 -1.09 2.03 ## 59 Ymi_negemotzmissing[56] 0 -1.61 1.61 ## 60 Ymi_negemotzmissing[585] 0.07 -1.36 1.5 ## 61 Ymi_negemotzmissing[593] 0.12 -1.67 1.85 ## 62 Ymi_negemotzmissing[602] -0.58 -2.06 0.93 ## 63 Ymi_negemotzmissing[605] 0.75 -0.89 2.38 ## 64 Ymi_negemotzmissing[612] 0.13 -1.5 1.69 ## 65 Ymi_negemotzmissing[613] 0.71 -0.88 2.36 ## 66 Ymi_negemotzmissing[621] -0.77 -2.25 0.73 ## 67 Ymi_negemotzmissing[629] 0.11 -1.4 1.6 ## 68 Ymi_negemotzmissing[630] 0.39 -1.07 1.88 ## 69 Ymi_negemotzmissing[643] 0.9 -0.75 2.58 ## 70 Ymi_negemotzmissing[653] -0.63 -2.32 1.08 ## 71 Ymi_negemotzmissing[679] -0.91 -2.59 0.78 ## 72 Ymi_negemotzmissing[701] -0.16 -1.72 1.32 ## 73 Ymi_negemotzmissing[742] 0.24 -1.42 1.9 ## 74 Ymi_negemotzmissing[751] 0.29 -1.36 1.96 ## 75 Ymi_negemotzmissing[752] -0.86 -2.25 0.58 ## 76 Ymi_negemotzmissing[760] 0.42 -1.17 2.05 ## 77 Ymi_negemotzmissing[774] 0.82 -0.95 2.6 ## 78 Ymi_negemotzmissing[779] -0.02 -1.77 1.71 ## 79 Ymi_negemotzmissing[78] 0.1 -1.56 1.8 ## 80 Ymi_negemotzmissing[792] -0.11 -2 1.67 ## 81 Ymi_negemotzmissing[794] 0.29 -1.39 1.97 ## 82 Ymi_negemotzmissing[799] -0.18 -1.89 1.53 ## 83 Ymi_negemotzmissing[89] -0.78 -2.28 0.79 ## 84 Ymi_negemotzmissing[94] 0.27 -1.29 1.76 That’s a lot of output. Here’s what those summaries look like in a coefficient plot. # summarize just like before post %&gt;% pivot_longer(starts_with(&quot;Ymi&quot;), names_to = &quot;row&quot;) %&gt;% group_by(row) %&gt;% mean_qi(value) %&gt;% # plot! ggplot(aes(x = row, y = value, ymin = .lower, ymax = .upper)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_pointinterval(size = 1/3) + scale_x_discrete(&quot;rank-ordered row number&quot;, breaks = NULL) + ylab(&quot;imputed value&quot;) + theme_xkcd() Each missing negemot_z value got an entire posterior distribution. And just as the model is uncertain about what those values might have been, that uncertainty was baked right into the primary submodel predicting govact_z. That’s a good thing. We want our Bayesian models to use as much information as they can and yield results with as much certainty as possible. But we don’t want our models to be more certain than the data–and priors–allow. When you use listwise deletion methods, you leave information on the table, which we don’t want. But when you use old fashioned ad hock methods like mean imputation, you underestimate the uncertainty in the model, which we also don’t want. We want the middle path. Here’s a focused look at two other important new parameters. posterior_summary(model9.9)[c(&quot;b_negemotzmissing_Intercept&quot;, &quot;sigma_negemotzmissing&quot;),] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## b_negemotzmissing_Intercept -0.001 0.036 -0.071 0.070 ## sigma_negemotzmissing 0.997 0.026 0.948 1.048 Our model has estimated the mean and standard deviations for our negemot_z_missing variable. Hopefully that isn’t a surprise. This is exactly what we asked brms to do with the negemot_z_missing | mi() ~ 1 part of the model formula. Since that submodel had no predictors, the intercept was just the mean. Correspondingly, the residual variance was the entire variance–but expressed in the usual \\(\\sigma\\) metric since we’re using brms. And since our negemot_z_missing variable is a subset of the standardized negemot_z variable, naturally the estimates for the mean and standard deviation are about 0 and 1, respectively. Another method we could have used is multiple imputation. With multiple imputation, you create a small number of alternative data sets, typically 5, into which you impute plausible values into the missing value slots. You then fit the model separately for each of the imputed data sets. Because the imputed values will vary across the data sets, that uncertainty will get appropriately transmitted to the model. I know this might sound crazy, but it typically leads to much lower model bias when compared to mean imputation or listwise deletion. But we didn’t quite use multiple imputation. With one-step Bayesian imputation using the mi() syntax, you get an entire posterior distribution for each missing value. And if you have variables in the data set that might help predict what those missing values are, you’d just plug that into the missing data submodel. Improving the imputation model can improve the subsequent substantive model. For more on the mi() approach, see Bürkner’s (2021c) vignette. McElreath lectured on this topic (here and here) within the context of his Statistical rethinking texts (McElreath, 2020, 2015), and you can find links to my translations of both of his texts here. For a more general introduction to missing data theory, check out van Burren’s (2018) book, Flexible imputation of missing data, or Enders’ great (2010) text, Applied missing data analysis. You can also find Enders lecturing on missing data here. The take home message is there is no need to ignore missing data or use outdated procedures like listwise deletion. Be a champion and model your missing data with brms. 9.4 More than one moderator None of this is a problem for brms. But instead of using the model=i syntax in Hayes’s PROCESS, you just have to specify your model formula in brm(). 9.4.1 Additive multiple moderation. It’s trivial to add sex, its interaction with negemot, and the two covariates (i.e., posemot and ideology) to the model. We can even do it within update(). model9.10 &lt;- update(model9.1, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex + negemot:age, cores = 4, file = &quot;fits/model09.10&quot;) Our output matches nicely with the formula at the bottom of page 232 and the PROCESS output in Figure 9.2. print(model9.10, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ negemot + sex + age + posemot + ideology + negemot:sex + negemot:age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.268 0.329 4.608 5.897 1.001 2565 2597 ## negemot 0.094 0.080 -0.062 0.253 1.002 2270 2435 ## sex -0.748 0.196 -1.136 -0.368 1.000 2116 2496 ## age -0.018 0.006 -0.030 -0.006 1.002 2145 2694 ## posemot -0.023 0.028 -0.077 0.031 1.001 3329 2699 ## ideology -0.207 0.027 -0.259 -0.156 1.000 4130 3007 ## negemot:sex 0.206 0.051 0.106 0.306 1.000 2082 2598 ## negemot:age 0.005 0.002 0.002 0.008 1.002 2120 2469 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.048 0.026 0.998 1.100 1.000 3829 2909 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). On page 325, Hayes discussed the unique variance each of the two moderation terms accounted for after controlling for the other covariates. In order to get our Bayesian version of these, we’ll have to fit two additional models, one after removing each of the interaction terms. model9.11 &lt;- update(model9.10, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex, cores = 4, file = &quot;fits/model09.11&quot;) model9.12 &lt;- update(model9.10, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:age, cores = 4, file = &quot;fits/model09.12&quot;) Here we’ll extract the bayes_R2() iterations for each of the three models, place them all in a single tibble, and then do a little arithmetic to get the difference scores. After all that data wrangling, we’ll summarize() as usual. r2 &lt;- tibble(r2_without_age_interaction = bayes_R2(model9.11, summary = F)[, 1], r2_without_sex_interaction = bayes_R2(model9.12, summary = F)[, 1], r2_with_both_interactions = bayes_R2(model9.10, summary = F)[, 1]) %&gt;% mutate(`delta R2 due to age interaction` = r2_with_both_interactions - r2_without_age_interaction, `delta R2 due to sex interaction` = r2_with_both_interactions - r2_without_sex_interaction) r2 %&gt;% pivot_longer(`delta R2 due to age interaction`:`delta R2 due to sex interaction`) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 delta R2 due to age interaction 0.007 -0.051 0.067 0.95 mean qi ## 2 delta R2 due to sex interaction 0.014 -0.044 0.069 0.95 mean qi Recall that \\(R^2\\) is in a 0-to-1 metric. It’s a proportion. If you want to convert that to a percentage, as in percent of variance explained, you’d just multiply by 100. To make it explicit, let’s do that. r2 %&gt;% pivot_longer(`delta R2 due to age interaction`:`delta R2 due to sex interaction`) %&gt;% group_by(name) %&gt;% mutate(percent = value * 100) %&gt;% mean_qi(percent) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 2 x 7 ## name percent .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 delta R2 due to age interaction 0.747 -5.08 6.73 0.95 mean qi ## 2 delta R2 due to sex interaction 1.37 -4.39 6.88 0.95 mean qi Hopefully it’s clear how our proportions turned percentages correspond to the numbers on page 325. However, note how our 95% credible intervals do not cohere with the \\(p\\)-values from Hayes’s \\(F\\)-tests. If we want to prep for our version of Figure 9.3, we’ll need to carefully specify the predictor values we’ll pass through the fitted() function. Here we do so and save them in nd. nd &lt;- crossing(negemot = seq(from = .5, to = 6.5, length.out = 30), sex = 0:1) %&gt;% expand(nesting(negemot, sex), age = c(30, 50, 70)) %&gt;% mutate(posemot = mean(glbwarm$posemot), ideology = mean(glbwarm$ideology)) str(nd) ## tibble [180 × 5] (S3: tbl_df/tbl/data.frame) ## $ negemot : num [1:180] 0.5 0.5 0.5 0.5 0.5 ... ## $ sex : int [1:180] 0 0 0 1 1 1 0 0 0 1 ... ## $ age : num [1:180] 30 50 70 30 50 70 30 50 70 30 ... ## $ posemot : num [1:180] 3.13 3.13 3.13 3.13 3.13 ... ## $ ideology: num [1:180] 4.08 4.08 4.08 4.08 4.08 ... With our nd values in hand, we’re ready to make our version of Figure 9.3. fitted(model9.10, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% # these lines will make the strip text match with those with Hayes&#39;s Figure mutate(sex = if_else(sex == 0, str_c(&quot;Females, W = &quot;, sex), str_c(&quot;Males, W = &quot;, sex)), age = str_c(&quot;Age, Z, = &quot;, age)) %&gt;% # finally, we plot! ggplot(aes(x = negemot, group = sex)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = sex), alpha = 1/3, color = &quot;transparent&quot;) + geom_line(aes(y = Estimate, color = sex), size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(3, 6)) + labs(x = expression(&quot;Negative Emotions about Climate Change, &quot;*italic(X)), y = expression(&quot;Support for Government Action to Mitigate Climate Change, &quot;*italic(Y))) + theme_xkcd() + theme(legend.position = &quot;top&quot;, legend.title = element_blank()) + facet_grid(age ~ .) Recall that the conditional effect of \\(X\\) for various values of \\(W\\) and \\(Z\\) is \\[\\theta_{X \\rightarrow Y} = b_1 + b_4 W + b_5 Z.\\] In the terms of model9.10 where sex = \\(W\\) and age = \\(Z\\), we can restate that as \\[ \\theta_{\\text{negemot} \\rightarrow \\text{govact}} = b_\\text{negemot} + b_{\\text{negemot} \\times \\text{sex}} \\text{sex} + b_{\\text{negemot} \\times \\text{age}} \\text{age}. \\] This is easiest to show with posterior_samples() and a little algebra. As in the middle of page 329, here we solve for both sexes and age == 50. post &lt;- posterior_samples(model9.10) post %&gt;% # algebra mutate(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 50, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 50) %&gt;% # more algebra mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% # this just orders the output mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.537 0.467 0.607 0.95 mean qi ## 2 women 0.331 0.259 0.401 0.95 mean qi ## 3 men - women 0.206 0.106 0.306 0.95 mean qi Switching our discussion to \\(b_5\\) (i.e., \\(b_{\\text{negemot} \\times \\text{age}}\\)), Hayes showed its value for two groups 10 years apart. Here it is for model9.10. post %&gt;% # algebra transmute(`10 * b_5` = `b_negemot:age` * 10) %&gt;% mean_qi() %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## `10 * b_5` .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.047 0.016 0.077 0.95 mean qi Further down on page 329, Hayes solved for the conditional effect of negemot for women at 50 versus 30. post %&gt;% mutate(women_50 = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 50, women_30 = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 30) %&gt;% mutate(`women_50 - women_30` = women_50 - women_30) %&gt;% pivot_longer(women_50:`women_50 - women_30`) %&gt;% mutate(name = factor(name, levels = c(&quot;women_50&quot;, &quot;women_30&quot;, &quot;women_50 - women_30&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 women_50 0.331 0.259 0.401 0.95 mean qi ## 2 women_30 0.236 0.15 0.323 0.95 mean qi ## 3 women_50 - women_30 0.095 0.032 0.154 0.95 mean qi Here it is for men. post %&gt;% mutate(men_50 = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 50, men_30 = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 30) %&gt;% mutate(`men_50 - men_30` = men_50 - men_30) %&gt;% pivot_longer(men_50:`men_50 - men_30`) %&gt;% mutate(name = factor(name, levels = c(&quot;men_50&quot;, &quot;men_30&quot;, &quot;men_50 - men_30&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men_50 0.537 0.467 0.607 0.95 mean qi ## 2 men_30 0.442 0.341 0.545 0.95 mean qi ## 3 men_50 - men_30 0.095 0.032 0.154 0.95 mean qi If you look closely, you’ll see women_50 - women_30 is the same as men_50 - men_30. 9.4.2 Moderated moderation. To fit the moderated moderation model in brms, just add to two new interaction terms to the formula. model9.13 &lt;- update(model9.10, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex + negemot:age + sex:age + negemot:sex:age, cores = 4, file = &quot;fits/model09.13&quot;) Check the summary. print(model9.13, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: govact ~ negemot + sex + age + posemot + ideology + negemot:sex + negemot:age + sex:age + negemot:sex:age ## Data: glbwarm (Number of observations: 815) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.569 0.488 3.599 5.544 1.004 1238 1734 ## negemot 0.270 0.119 0.039 0.506 1.004 1256 1608 ## sex 0.510 0.648 -0.773 1.767 1.004 1018 1387 ## age -0.004 0.010 -0.022 0.016 1.004 1183 1619 ## posemot -0.021 0.028 -0.077 0.034 1.001 3362 2689 ## ideology -0.205 0.027 -0.257 -0.155 1.001 3377 2708 ## negemot:sex -0.126 0.167 -0.459 0.208 1.004 1072 1447 ## negemot:age 0.001 0.002 -0.004 0.006 1.003 1279 1675 ## sex:age -0.025 0.012 -0.049 -0.000 1.004 974 1271 ## negemot:sex:age 0.007 0.003 0.000 0.013 1.003 1032 1266 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.047 0.025 0.999 1.097 1.001 3335 2894 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our print() output matches fairly well with the OLS results on pages 332 and 333. Here’s our new Bayesian \\(R^2\\). bayes_R2(model9.13) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.417 0.02 0.377 0.453 Because we haven’t changed the predictor variables in the model–just added interactions among them–there’s no need to redo our nd values. Rather, all we need to do is pass them through fitted() based on our new model9.13 and plot. Without further ado, here’s our Figure 9.6. fitted(model9.13, newdata = nd) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% # these lines will make the strip text match with those with Hayes&#39;s Figure mutate(sex = if_else(sex == 0, str_c(&quot;Females, W = &quot;, sex), str_c(&quot;Males, W = &quot;, sex)), age = str_c(&quot;Age, Z, = &quot;, age)) %&gt;% # behold, Figure 9.6! ggplot(aes(x = negemot, group = sex)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = sex), alpha = 1/3, color = &quot;transparent&quot;) + geom_line(aes(y = Estimate, color = sex), size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(3, 6)) + labs(x = expression(&quot;Negative Emotions about Climate Change, &quot;*italic(X)), y = expression(&quot;Support for Government Action to Mitigate Climate Change, &quot;*italic(Y))) + theme_xkcd() + theme(legend.position = &quot;top&quot;, legend.title = element_blank()) + facet_grid(age ~ .) For the pick-a-point values Hayes covered on page 338, recall that when using posterior_sample(), our \\(b_4\\) is b_negemot:sex and our \\(b_7\\) is b_negemot:sex:age. post &lt;- posterior_samples(model9.13) post %&gt;% mutate(`age = 30` = `b_negemot:sex` + `b_negemot:sex:age` * 30, `age = 50` = `b_negemot:sex` + `b_negemot:sex:age` * 50, `age = 70` = `b_negemot:sex` + `b_negemot:sex:age` * 70) %&gt;% pivot_longer(contains(&quot;=&quot;), names_to = &quot;theta_XW_on_Y_given&quot;) %&gt;% group_by(theta_XW_on_Y_given) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## theta_XW_on_Y_given value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 age = 30 0.072 -0.087 0.235 0.95 mean qi ## 2 age = 50 0.204 0.105 0.301 0.95 mean qi ## 3 age = 70 0.335 0.171 0.494 0.95 mean qi Our method for making a JN technique plot with fitted() way back in Chapter 7 isn’t going to work, here. At least not as far as I can see. Rather, we’re going to have to skillfully manipulate our post object. For those new to R, this might be a little confusing at first. So I’m going to make a crude attempt first and then get more sophisticated. Crude attempt: post %&gt;% mutate(`age = 30` = `b_negemot:sex` + `b_negemot:sex:age` * 30, `age = 50` = `b_negemot:sex` + `b_negemot:sex:age` * 50, `age = 70` = `b_negemot:sex` + `b_negemot:sex:age` * 70) %&gt;% pivot_longer(contains(&quot;=&quot;), names_to = &quot;theta_XW_on_Y_given&quot;) %&gt;% mutate(`theta XW on Y given` = str_extract(theta_XW_on_Y_given, &quot;\\\\d+&quot;) %&gt;% as.double()) %&gt;% group_by(`theta XW on Y given`) %&gt;% mean_qi(value) %&gt;% # the plot ggplot(aes(x = `theta XW on Y given`)) + geom_hline(yintercept = 0) + geom_vline(xintercept = 38.114) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 1/2) + geom_line(aes(y = value), size = 1) + coord_cartesian(xlim = c(20, 85), ylim = c(-.25, .75)) + theme_xkcd() Notice how we just took the code from our pick-a-point analysis and dumped it into a plot. So one obvious approach would be to pick like 30 or 50 age values to plug into transmute() and just do the same thing. If you’re super afraid of coding, that’d be one intuitive but extremely verbose attempt. I have done stuff like that earlier in my R career. There’s no shame in being extremely verbose and redundant if that’s what makes sense. Another way is to think in terms of functions. When we made age = 30 within transmute(), we took a specific age value (i.e., 30) and plugged it into the formula b_negemot:sex + b_negemot:sex:age * i where \\(i\\) = 30. And when we made age = 50 we did exactly the same thing but switched out the 30 for a 50. So what we need is a function that will take a range of values for \\(i\\), plug them into our b_negemot:sex + b_negemot:sex:age * i formula, and then neatly return the output. A nice base R function for that is sapply(). sapply(15:90, function(i) { post$`b_negemot:sex` + post$`b_negemot:sex:age` * i } ) %&gt;% data.frame() %&gt;% str() ## &#39;data.frame&#39;: 4000 obs. of 76 variables: ## $ X1 : num -0.3971 -0.3357 -0.0531 -0.112 -0.0531 ... ## $ X2 : num -0.384 -0.3219 -0.0448 -0.1036 -0.0439 ... ## $ X3 : num -0.371 -0.3081 -0.0365 -0.0953 -0.0348 ... ## $ X4 : num -0.3579 -0.2944 -0.0281 -0.0869 -0.0257 ... ## $ X5 : num -0.3449 -0.2806 -0.0198 -0.0786 -0.0166 ... ## $ X6 : num -0.33184 -0.26682 -0.01148 -0.07023 -0.00745 ... ## $ X7 : num -0.31879 -0.25306 -0.00316 -0.06187 0.00167 ... ## $ X8 : num -0.30575 -0.23929 0.00517 -0.05352 0.01079 ... ## $ X9 : num -0.2927 -0.2255 0.0135 -0.0452 0.0199 ... ## $ X10: num -0.2797 -0.2118 0.0218 -0.0368 0.029 ... ## $ X11: num -0.2666 -0.198 0.0301 -0.0285 0.0382 ... ## $ X12: num -0.2536 -0.1842 0.0385 -0.0201 0.0473 ... ## $ X13: num -0.2405 -0.1705 0.0468 -0.0118 0.0564 ... ## $ X14: num -0.22748 -0.1567 0.05511 -0.00341 0.06552 ... ## $ X15: num -0.21443 -0.14293 0.06344 0.00494 0.07464 ... ## $ X16: num -0.2014 -0.1292 0.0718 0.0133 0.0838 ... ## $ X17: num -0.1883 -0.1154 0.0801 0.0216 0.0929 ... ## $ X18: num -0.1753 -0.1016 0.0884 0.03 0.102 ... ## $ X19: num -0.1623 -0.0879 0.0967 0.0384 0.1111 ... ## $ X20: num -0.1492 -0.0741 0.1051 0.0467 0.1202 ... ## $ X21: num -0.1362 -0.0603 0.1134 0.0551 0.1294 ... ## $ X22: num -0.1231 -0.0466 0.1217 0.0634 0.1385 ... ## $ X23: num -0.1101 -0.0328 0.13 0.0718 0.1476 ... ## $ X24: num -0.097 -0.019 0.1384 0.0801 0.1567 ... ## $ X25: num -0.08399 -0.00528 0.14668 0.08847 0.16585 ... ## $ X26: num -0.07094 0.00849 0.15501 0.09682 0.17497 ... ## $ X27: num -0.0579 0.0223 0.1633 0.1052 0.1841 ... ## $ X28: num -0.0449 0.036 0.1717 0.1135 0.1932 ... ## $ X29: num -0.0318 0.0498 0.18 0.1219 0.2023 ... ## $ X30: num -0.0188 0.0636 0.1883 0.1302 0.2115 ... ## $ X31: num -0.00572 0.07732 0.19663 0.13858 0.22057 ... ## $ X32: num 0.00733 0.09108 0.20495 0.14693 0.22969 ... ## $ X33: num 0.0204 0.1048 0.2133 0.1553 0.2388 ... ## $ X34: num 0.0334 0.1186 0.2216 0.1636 0.2479 ... ## $ X35: num 0.0465 0.1324 0.2299 0.172 0.2571 ... ## $ X36: num 0.0595 0.1461 0.2383 0.1803 0.2662 ... ## $ X37: num 0.0726 0.1599 0.2466 0.1887 0.2753 ... ## $ X38: num 0.0856 0.1737 0.2549 0.197 0.2844 ... ## $ X39: num 0.0986 0.1874 0.2632 0.2054 0.2935 ... ## $ X40: num 0.112 0.201 0.272 0.214 0.303 ... ## $ X41: num 0.125 0.215 0.28 0.222 0.312 ... ## $ X42: num 0.138 0.229 0.288 0.23 0.321 ... ## $ X43: num 0.151 0.243 0.297 0.239 0.33 ... ## $ X44: num 0.164 0.256 0.305 0.247 0.339 ... ## $ X45: num 0.177 0.27 0.313 0.256 0.348 ... ## $ X46: num 0.19 0.284 0.321 0.264 0.357 ... ## $ X47: num 0.203 0.298 0.33 0.272 0.367 ... ## $ X48: num 0.216 0.311 0.338 0.281 0.376 ... ## $ X49: num 0.229 0.325 0.346 0.289 0.385 ... ## $ X50: num 0.242 0.339 0.355 0.297 0.394 ... ## $ X51: num 0.255 0.353 0.363 0.306 0.403 ... ## $ X52: num 0.268 0.366 0.371 0.314 0.412 ... ## $ X53: num 0.281 0.38 0.38 0.322 0.421 ... ## $ X54: num 0.294 0.394 0.388 0.331 0.43 ... ## $ X55: num 0.307 0.408 0.396 0.339 0.439 ... ## $ X56: num 0.32 0.421 0.405 0.347 0.449 ... ## $ X57: num 0.333 0.435 0.413 0.356 0.458 ... ## $ X58: num 0.346 0.449 0.421 0.364 0.467 ... ## $ X59: num 0.36 0.463 0.43 0.372 0.476 ... ## $ X60: num 0.373 0.477 0.438 0.381 0.485 ... ## $ X61: num 0.386 0.49 0.446 0.389 0.494 ... ## $ X62: num 0.399 0.504 0.455 0.397 0.503 ... ## $ X63: num 0.412 0.518 0.463 0.406 0.512 ... ## $ X64: num 0.425 0.532 0.471 0.414 0.522 ... ## $ X65: num 0.438 0.545 0.48 0.423 0.531 ... ## $ X66: num 0.451 0.559 0.488 0.431 0.54 ... ## $ X67: num 0.464 0.573 0.496 0.439 0.549 ... ## $ X68: num 0.477 0.587 0.505 0.448 0.558 ... ## $ X69: num 0.49 0.6 0.513 0.456 0.567 ... ## $ X70: num 0.503 0.614 0.521 0.464 0.576 ... ## $ X71: num 0.516 0.628 0.53 0.473 0.585 ... ## $ X72: num 0.529 0.642 0.538 0.481 0.595 ... ## $ X73: num 0.542 0.655 0.546 0.489 0.604 ... ## $ X74: num 0.555 0.669 0.555 0.498 0.613 ... ## $ X75: num 0.568 0.683 0.563 0.506 0.622 ... ## $ X76: num 0.581 0.697 0.571 0.514 0.631 ... Okay, so that looks a little monstrous. What we did in the first argument was tell sapply() which values we’d like to use in some function. We chose each integer ranging from 15 to 90–which, if you do the math, is 76 values. We then told sapply() to plug those values into a custom function, which we defined as function(i) {post$b_negemot:sex + post$b_negemot:sex:age * i}. In our custom function, i was a placeholder for each of those 76 integers. But remember that post has 4,000 rows, each one corresponding to one of the 4,000 posterior iterations. Thus, for each of our 76 i-values, we got 4,000 results. After all that sapply() returned a matrix. Since we like to work within the tidyverse and use ggplot2, we just went ahead and put those results in a tibble. With our sapply() output in hand, all we need to do is a little more indexing and summarizing and we’re ready to plot. The result is our very own version of Figure 9.7. sapply(15:90, function(i) post$`b_negemot:sex` + post$`b_negemot:sex:age` * i) %&gt;% data.frame() %&gt;% set_names(15:90) %&gt;% pivot_longer(everything()) %&gt;% mutate(age = as.double(name)) %&gt;% group_by(age) %&gt;% mean_qi(value) %&gt;% ggplot(aes(x = age)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_vline(xintercept = 38.114, color = &quot;grey75&quot;) + geom_ribbon(aes(ymin = .lower, ymax = .upper), alpha = 1/2) + geom_line(aes(y = value), size = 1) + coord_cartesian(xlim = c(20, 85), ylim = c(-.25, .75)) + labs(x = expression(paste(&quot;Age, &quot;, italic(Z))), y = &quot;Conditional Two-way Interaction Between\\nNegative Emotions and Sex&quot;) + theme_xkcd() Or for kicks and giggles, another way to get a clearer sense of how our data informed the shape of the plot, here we replace our geom_ribbon() + geom_line() code with geom_pointrange(). sapply(15:90, function(i) { post$`b_negemot:sex` + post$`b_negemot:sex:age` * i }) %&gt;% data.frame() %&gt;% set_names(15:90) %&gt;% pivot_longer(everything()) %&gt;% mutate(age = as.double(name)) %&gt;% group_by(age) %&gt;% mean_qi(value) %&gt;% ggplot(aes(x = age)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_vline(xintercept = 38.114, color = &quot;grey75&quot;) + geom_pointrange(aes(y = value, ymin = .lower, ymax = .upper), shape = 16, size = 1/3) + coord_cartesian(xlim = c(20, 85), ylim = c(-.25, .75)) + labs(x = expression(&quot;Age, &quot;*italic(Z)), y = &quot;Conditional Two-way Interaction Between\\nNegative Emotions and Sex&quot;) + theme_xkcd() Although I probably wouldn’t try to use a plot like this in a manuscript, I hope it makes clear how the way we’ve been implementing the JN technique is just the pick-a-point approach in bulk. No magic, here. For all you tidyverse fanatics out there, don’t worry. There are more tidyverse-centric ways to get the plot values than with sapply(). We’ll get to them soon enough. It’s advantageous to have good old base R sapply() up your sleeve, too. And new R users, it’s helpful to know that sapply() is one part of the apply() family of base R functions, which you might learn more about here or here or here. Now the conditional effect of \\(X\\) on \\(Y\\) given \\(W\\) and \\(Z\\) is \\[\\theta_{X \\rightarrow Y} = b_1 + b_4 W + b_5 Z + b_7 WZ.\\] In the terms of model9.13 where sex = \\(W\\) and age = \\(Z\\), we can restate that as \\[ \\theta_{\\text{negemot} \\rightarrow \\text{govact}} = b_\\text{negemot} + b_{\\text{negemot} \\times \\text{sex}} \\text{sex} + b_{\\text{negemot} \\times \\text{age}} \\text{age} + b_{\\text{negemot} \\times \\text{sex} \\times \\text{age}} \\text{sex} \\times \\text{age}. \\] Following Hayes at the bottom of page 341, here is the difference in the effect of negative emotions between men and women among 30 year olds, \\(\\theta_{XW \\rightarrow Y} | (Z = 30)\\). post %&gt;% # algebra mutate(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 30 + `b_negemot:sex:age` * 1 * 30, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 30 + `b_negemot:sex:age` * 0 * 30) %&gt;% # more algebra mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% # this just orders the output mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.371 0.253 0.492 0.95 mean qi ## 2 women 0.299 0.195 0.405 0.95 mean qi ## 3 men - women 0.072 -0.087 0.235 0.95 mean qi In contrast, here is \\(\\theta_{XW \\rightarrow Y} | (Z = 50)\\). post %&gt;% mutate(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 50 + `b_negemot:sex:age` * 1 * 50, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 50 + `b_negemot:sex:age` * 0 * 50) %&gt;% mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.522 0.454 0.592 0.95 mean qi ## 2 women 0.319 0.243 0.393 0.95 mean qi ## 3 men - women 0.204 0.105 0.301 0.95 mean qi Finally, here we compute \\(\\theta_{XW \\rightarrow Y} | (Z = 70)\\). post %&gt;% transmute(men = b_negemot + `b_negemot:sex` * 1 + `b_negemot:age` * 70 + `b_negemot:sex:age` * 1 * 70, women = b_negemot + `b_negemot:sex` * 0 + `b_negemot:age` * 70 + `b_negemot:sex:age` * 0 * 70) %&gt;% mutate(`men - women` = men - women) %&gt;% pivot_longer(men:`men - women`) %&gt;% mutate(name = factor(name, levels = c(&quot;men&quot;, &quot;women&quot;, &quot;men - women&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 men 0.674 0.581 0.766 0.95 mean qi ## 2 women 0.338 0.202 0.475 0.95 mean qi ## 3 men - women 0.335 0.171 0.494 0.95 mean qi 9.5 Comparing conditional effects In this section, [Hayes discussed] a test of the difference between two conditional effects in a moderation model. The method [Hayes described] is called a “slope difference test” by Dawson (Dawson, 2014; Dawson &amp; Richter, 2006), who offers some guidelines on how to conduct this test for the moderated moderation model. (p. 342) As usual, we will follow along, but with alternative methods to the statistical testing paradigm. We will steadfastly continue summarizing and plotting the posterior distribution from various vantage points. 9.5.1 Comparing conditional effects in the additive multiple moderation model. When we’re interested in estimating the difference in the conditional effect of \\(X\\) on \\(Y\\) (i.e., \\(\\theta_{X \\rightarrow Y}\\)) for \\(W = w_1\\) and \\(Z = z_1\\) versus when \\(W = w_2\\) and \\(Z = z_2\\), that follows the formula \\[\\begin{align*} \\Delta \\theta_{X \\rightarrow Y} &amp; = (b_1 + b_4 w_1 + b_5 z_1) - (b_1 + b_4 w_2 + b_5 z_2) \\\\ &amp; = b_4 (w_1 - w_2) + b_5 (z_1 - z_2). \\end{align*}\\] As in other cases, we don’t have to worry about special considerations for computing the standard errors for out Bayesian models. All we need to do is follow the simple algebraic manipulations of the posterior distribution. Because of the correlation structure within the parameters, the uncertainty in the conditional distribution will work itself out. 9.5.2 Comparing conditional effects in the moderated moderation model. We’ll update our formula from last section to \\[\\begin{align*} \\Delta \\theta_{X \\rightarrow Y} &amp; = (b_1 + b_4 w_1 + b_5 z_1 + b_7 w_1 z_1) - (b_1 + b_4 w_2 + b_5 z_2 + b_7 w_2 z_2) \\\\ &amp; = b_4 (w_1 - w_2) + b_5 (z_1 - z_2) + b_7 (w_1 z_1 - w_2 z_2). \\end{align*}\\] 9.5.3 Implementation in PROCESS brms. Since we don’t have the contrast feature automated like in PROCESS, we’ll have to carefully follow the equations above to specify the values properly in R. Here we’ll use the equation in the first line, \\[\\Delta \\theta_{X \\rightarrow Y} = (b_1 + b_4 w_1 + b_5 z_1 + b_7 w_1 z_1) - (b_1 + b_4 w_2 + b_5 z_2 + b_7 w_2 z_2).\\] w1 &lt;- 1 z1 &lt;- 30 w2 &lt;- 0 z2 &lt;- 50 post %&gt;% mutate(`30-year-old men` = b_negemot + `b_negemot:sex` * w1 + `b_negemot:age` * z1 + `b_negemot:sex:age` * w1 * z1, `50-year-old women` = b_negemot + `b_negemot:sex` * w2 + `b_negemot:age` * z2 + `b_negemot:sex:age` * w2 * z2) %&gt;% mutate(contrast = `30-year-old men` - `50-year-old women`) %&gt;% pivot_longer(`30-year-old men`:contrast) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, .025), ul = quantile(value, .975)) %&gt;% mutate_if(is.double, round, digits = 4) ## # A tibble: 3 x 5 ## name mean sd ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 30-year-old men 0.371 0.0607 0.253 0.492 ## 2 50-year-old women 0.319 0.0375 0.243 0.393 ## 3 contrast 0.0523 0.07 -0.0832 0.188 Notice how our posterior \\(SD\\) corresponded nicely to the standard error in Hayes’s contrast test. And we didn’t even have to worry about using the frightening Formula 9.21 on page 345. That information was contained in the posterior distribution all along. All we had to do was combine the parameter iterations with a little algebra and then summarize(). For good measure, we’ll compute using the equation in the second line, \\[\\Delta \\theta_{X \\rightarrow Y} = b_4 (w_1 - w_2) + b_5 (z_1 - z_2) + b_7 (w_1 z_1 - w_2 z_2).\\] post %&gt;% mutate(contrast = `b_negemot:sex` * (w1 - w2) + `b_negemot:age` * (z1 - z2) + `b_negemot:sex:age` * (w1 * z1 - w2 * z2)) %&gt;% pivot_longer(contrast) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, .025), ul = quantile(value, .975)) %&gt;% mutate_if(is.double, round, digits = 4) ## # A tibble: 1 x 5 ## name mean sd ll ul ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 contrast 0.0523 0.07 -0.0832 0.188 Same results. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 bayesplot_1.8.0 xkcd_0.0.6 extrafont_0.17 brms_2.15.0 Rcpp_1.0.6 ## [7] forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 ## [13] tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 Hmisc_4.4-2 plyr_1.8.6 ## [5] igraph_1.2.6 svUnit_1.0.3 sp_1.4-4 splines_4.0.4 ## [9] crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 ## [13] digest_0.6.27 htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 ## [17] checkmate_2.0.0 magrittr_2.0.1 cluster_2.1.0 modelr_0.1.8 ## [21] RcppParallel_5.0.2 matrixStats_0.57.0 extrafontdb_1.0 xts_0.12.1 ## [25] sandwich_3.0-0 prettyunits_1.1.1 jpeg_0.1-8.1 colorspace_2.0-0 ## [29] rvest_1.0.1 ggdist_3.0.0 haven_2.3.1 xfun_0.23 ## [33] callr_3.7.0 crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 ## [37] survival_3.2-10 zoo_1.8-8 glue_1.4.2 gtable_0.3.0 ## [41] emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [45] Rttf2pt1_1.3.8 rstan_2.21.2 abind_1.4-5 scales_1.1.1 ## [49] mvtnorm_1.1-1 DBI_1.1.0 miniUI_0.1.1.1 htmlTable_2.1.0 ## [53] xtable_1.8-4 foreign_0.8-81 Formula_1.2-4 stats4_4.0.4 ## [57] StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 httr_1.4.2 ## [61] threejs_0.3.3 arrayhelpers_1.1-0 RColorBrewer_1.1-2 posterior_1.0.1 ## [65] ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 ## [69] nnet_7.3-15 sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 ## [73] labeling_0.4.2 tidyselect_1.1.1 rlang_0.4.11 reshape2_1.4.4 ## [77] later_1.2.0 munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 ## [81] cli_3.0.1 generics_0.1.0 broom_0.7.6 ggridges_0.5.3 ## [85] evaluate_0.14 fastmap_1.1.0 processx_3.5.2 knitr_1.33 ## [89] fs_1.5.0 nlme_3.1-152 mime_0.10 projpred_2.0.2 ## [93] xml2_1.3.2 compiler_4.0.4 shinythemes_1.1.2 rstudioapi_0.13 ## [97] png_0.1-7 gamm4_0.2-6 curl_4.3 reprex_2.0.0 ## [101] statmod_1.4.35 bslib_0.2.4 stringi_1.6.2 highr_0.9 ## [105] ps_1.6.0 Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 ## [109] nloptr_1.2.2.2 markdown_1.1 tensorA_0.36.2 shinyjs_2.0.0 ## [113] vctrs_0.3.8 pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 ## [117] bridgesampling_1.0-0 estimability_1.3 data.table_1.14.0 raster_3.4-5 ## [121] httpuv_1.6.0 latticeExtra_0.6-29 R6_2.5.0 bookdown_0.22 ## [125] promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 boot_1.3-26 ## [129] colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 assertthat_0.2.1 ## [133] withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 mgcv_1.8-33 ## [137] parallel_4.0.4 hms_1.1.0 rpart_4.1-15 grid_4.0.4 ## [141] coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 ## [145] lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 References Aiken, L. S., &amp; West, S. G. (1991). Multiple regression: Testing and interpreting interactions. SAGE. Bürkner, P.-C. (2021b). Estimating multivariate models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html Bürkner, P.-C. (2021c). Handle missing values with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_missings.html Chang, W. (2014). Extrafont: Tools for using fonts. https://cran.r-project.org/package=extrafont/ Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). Applied multiple regression/correlation analysis for the behavioral sciences (3rd edition). Lawrence Erlbaum Associates. https://doi.org/10.4324/9780203774441 Dawson, J. F. (2014). Moderation in management research: What, why, when, and how. Journal of Business and Psychology, 29(1), 1–19. https://doi.org/10.1007/s10869-013-9308-7 Dawson, J. F., &amp; Richter, A. W. (2006). Probing three-way interactions in moderated multiple regression: Development and application of a slope difference test. Journal of Applied Psychology, 91(4), 917–926. https://doi.org/10.1037/0021-9010.91.4.917 Enders, C. K. (2010). Applied missing data analysis. Guilford press. http://www.appliedmissingdata.com/ Gabry, J., &amp; Modrák, M. (2020). Visual MCMC diagnostics using the bayesplot package. https://CRAN.R-project.org/package=bayesplot/vignettes/visual-mcmc-diagnostics.html Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Kurz, A. S. (2021). Statistical rethinking with brms, ggplot2, and the tidyverse: Second Edition (version 0.2.0). https://bookdown.org/content/4857/ Kurz, A. S. (2020b). Statistical rethinking with brms, ggplot2, and the tidyverse (version 1.2.0). https://doi.org/10.5281/zenodo.3693202 McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/ McElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. https://xcelab.net/rm/statistical-rethinking/ Stan Development Team. (2021). Stan user’s guide, Version 2.26. https://mc-stan.org/docs/2_26/stan-users-guide/index.html Torres-Manzanera, E. (n.d.). Xkcd: Plotting XKCD graphs. Journal of Statistical Software, 12. https://cran.r-project.org/package=xkcd/vignettes/xkcd-intro.pdf Torres-Manzanera, E. (2018). Xkcd: Plotting ggplot2 graphics in an XKCD style. https://CRAN.R-project.org/package=xkcd van Buuren, S. (2018). Flexible imputation of missing data (Second Edition). CRC Press. https://stefvanbuuren.name/fimd/ Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; Bürkner, P.-C. (2019). Rank-normalization, folding, and localization: An improved \\(\\widehat R\\) for assessing convergence of MCMC. arXiv Preprint arXiv:1903.08008. https://arxiv.org/abs/1903.08008? "],["multicategorical-focal-antecedents-and-moderators.html", "10 Multicategorical Focal Antecedents and Moderators 10.1 Moderation of the effect of a multicategorical antecedent variable 10.2 An example from the sex disrimination in the workplace study 10.3 Visualizing the model 10.4 Probing the interaction 10.5 When the moderator is multicategorical Session info", " 10 Multicategorical Focal Antecedents and Moderators In this chapter, [Hayes] extend[ed] the principles of moderation analysis described in Chapters 7 and 8 to testing interaction involving a multicategorical focal antecedent variable or moderator. As you will see, the principles discussed in those chapters generalize quite readily, although the model necessarily requires more than one product to capture an interaction between two variables. This makes the formulas a bit more complex, and the visualizing and probing process a bit more involved. But with comfort with the fundamentals described so far, you should not find it difficult to master this extension of multiple regression analysis. (Andrew F. Hayes, 2018, p. 350) 10.1 Moderation of the effect of a multicategorical antecedent variable Take the case of a continuous or dichotomous moderator \\(W\\) and a multicategorical \\(X\\) “with \\(g\\) groups, include \\(g − 1\\) variables coding membership in the groups, the moderator variable \\(W\\), and \\(g − 1\\) products between the \\(g − 1\\) group codes and moderator \\(W\\) in a regression model” (p. 351) following the form \\[ Y = i_Y + \\sum_{i = 1}^{g - 1} b_i D_i + b_g W + \\sum_{j = g + 1}^{2g - 1} b_j D_{j - g} W + e_Y, \\] where \\(D_i\\) denotes the \\(i\\)th dummy variable. Given the case where \\(g = 4\\), that formula can be re-expressed as \\[\\begin{align*} Y &amp; = i_Y + b_1 D_1 + b_2 D_2 + b_3 D_3 + b_4 W + b_5 D_1 W + b_6 D_2 W + b_7 D_3 W + e_Y, \\;\\;\\;\\text{or} \\\\ &amp; = i_Y + (b_1 + b_5 W) D_1 + (b_2 + b_6 W) D_2 + (b_3 + b_7 W) D_3 + b_4 W + e_Y. \\end{align*}\\] 10.2 An example from the sex disrimination in the workplace study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) ## Rows: 129 ## Columns: 6 ## $ subnum &lt;dbl&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, 1… ## $ protest &lt;dbl&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, … ## $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.8… ## $ angry &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1, … ## $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.5… ## $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.2… With a little if_else(), computing the dummies d1 and d2 is easy enough. protest &lt;- protest %&gt;% mutate(d1 = if_else(protest == 1, 1, 0), d2 = if_else(protest == 2, 1, 0)) Load brms. library(brms) With model10.1 and model10.2 we fit the multicategorical multivariable model and the multicategorical moderation models, respectively. model10.1 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + d1 + d2 + sexism, cores = 4, file = &quot;fits/model10.01&quot;) model10.2 &lt;- update(model10.1, newdata = protest, liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism, cores = 4, file = &quot;fits/model10.02&quot;) Behold the \\(R^2\\) summaries. r2 &lt;- tibble(`Model 10.1` = bayes_R2(model10.1, summary = F)[, 1], `Model 10.2` = bayes_R2(model10.2, summary = F)[, 1]) %&gt;% mutate(`The R2 difference` = `Model 10.2` - `Model 10.1`) r2 %&gt;% pivot_longer(everything()) %&gt;% # this line isn&#39;t necessary, but it sets the order the summaries appear in mutate(name = factor(name, levels = c(&quot;Model 10.1&quot;, &quot;Model 10.2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(name) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 5 ## name mean median ll ul ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Model 10.1 0.071 0.066 0.012 0.156 ## 2 Model 10.2 0.156 0.154 0.065 0.26 ## 3 The R2 difference 0.085 0.086 -0.033 0.21 Interestingly, even though our posterior means and medians for the model-specific \\(R^2\\) values differed some from the OLS estimates in the text, their difference corresponded quite nicely to the one in the text. Let’s take a look at their distributions. r2 %&gt;% pivot_longer(everything()) %&gt;% ggplot(aes(x = value)) + geom_density(size = 0, fill = &quot;grey33&quot;) + scale_y_continuous(NULL, breaks = NULL) + facet_wrap(~ name, scales = &quot;free_y&quot;) + theme_minimal() The model coefficient summaries cohere well with those in Table 10.1. print(model10.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ 1 + d1 + d2 + sexism ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.771 0.616 3.589 6.010 1.002 5284 3301 ## d1 0.500 0.233 0.057 0.969 1.000 3991 3092 ## d2 0.450 0.226 0.009 0.891 1.000 4294 3079 ## sexism 0.106 0.117 -0.127 0.333 1.001 5157 3186 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.043 0.066 0.923 1.175 1.001 4272 3009 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). print(model10.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ d1 + d2 + sexism + d1:sexism + d2:sexism ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 7.694 1.070 5.638 9.815 1.000 1499 1833 ## d1 -4.091 1.530 -7.090 -1.051 1.000 1467 1701 ## d2 -3.477 1.408 -6.179 -0.709 1.000 1451 1949 ## sexism -0.470 0.208 -0.883 -0.072 1.000 1492 1809 ## d1:sexism 0.894 0.294 0.316 1.477 1.000 1454 1764 ## d2:sexism 0.776 0.275 0.248 1.309 1.000 1460 1870 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.006 0.066 0.888 1.151 1.000 2613 2471 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 10.3 Visualizing the model To get our version of the values in Table 10.2, we’ll first recreate columns for \\(d_1\\) through \\(W\\) (SEXISM) and save then as a tibble, nd. ( nd &lt;- tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1)) %&gt;% expand(nesting(d1, d2), sexism = quantile(protest$sexism, probs = c(.16, .5, .84))) ) ## # A tibble: 9 x 3 ## d1 d2 sexism ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0 0 4.31 ## 2 0 0 5.12 ## 3 0 0 5.87 ## 4 0 1 4.31 ## 5 0 1 5.12 ## 6 0 1 5.87 ## 7 1 0 4.31 ## 8 1 0 5.12 ## 9 1 0 5.87 With nd in hand, we’ll feed the predictor values into fitted() for the typical posterior summaries. fitted(model10.2, newdata = nd) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 5.671 0.225 5.225 6.104 ## [2,] 5.290 0.156 4.988 5.601 ## [3,] 4.938 0.226 4.489 5.391 ## [4,] 5.537 0.203 5.133 5.930 ## [5,] 5.785 0.152 5.486 6.091 ## [6,] 6.015 0.219 5.578 6.445 ## [7,] 5.432 0.249 4.940 5.928 ## [8,] 5.776 0.160 5.459 6.088 ## [9,] 6.095 0.203 5.697 6.492 The values in our Estimate column correspond to those in the \\(\\hat Y\\) column in the table. We, of course, add summaries of uncertainty to the point estimates. If we want to make a decent line plot for our version of Figure 10.3, we’ll need many more values for sexism, which will appear on the \\(x\\)-axis. nd &lt;- tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1)) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) This time we’ll save the results from fitted() as a tlbble and wrangle a bit to get ready for the plot. f &lt;- fitted(model10.2, newdata = nd, probs = c(.025, .25, .75, .975)) %&gt;% data.frame() %&gt;% bind_cols(nd) %&gt;% mutate(condition = if_else(d1 == 1, &quot;Individual Protest&quot;, if_else(d2 == 1, &quot;Collective Protest&quot;, &quot;No Protest&quot;))) %&gt;% # this line is not necessary, but it will help order the facets of the plot mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) glimpse(f) ## Rows: 90 ## Columns: 10 ## $ Estimate &lt;dbl&gt; 6.050493, 6.001914, 5.953336, 5.904758, 5.856180, 5.807601, 5.759023, 5.710445, … ## $ Est.Error &lt;dbl&gt; 0.3653449, 0.3460231, 0.3269753, 0.3082520, 0.2899163, 0.2720464, 0.2547406, 0.2… ## $ Q2.5 &lt;dbl&gt; 5.328209, 5.324293, 5.314224, 5.300169, 5.284162, 5.264836, 5.250654, 5.240870, … ## $ Q25 &lt;dbl&gt; 5.798930, 5.762295, 5.726087, 5.689122, 5.653504, 5.618733, 5.581046, 5.546334, … ## $ Q75 &lt;dbl&gt; 6.302794, 6.238915, 6.179077, 6.116206, 6.054327, 5.992865, 5.930719, 5.872689, … ## $ Q97.5 &lt;dbl&gt; 6.769590, 6.683770, 6.596054, 6.504766, 6.422166, 6.338107, 6.256257, 6.169473, … ## $ d1 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ d2 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,… ## $ sexism &lt;dbl&gt; 3.500000, 3.603448, 3.706897, 3.810345, 3.913793, 4.017241, 4.120690, 4.224138, … ## $ condition &lt;fct&gt; No Protest, No Protest, No Protest, No Protest, No Protest, No Protest, No Prote… For Figure 10.3 and many to follow for this chapter, we’ll superimpose 50% intervals on top of 95% intervals. # this will help us add the original data points to the plot protest &lt;- protest %&gt;% mutate(condition = ifelse(protest == 0, &quot;No Protest&quot;, ifelse(protest == 1, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # this will help us with the x-axis breaks &lt;- tibble(values = quantile(protest$sexism, probs = c(.16, .5, .84))) %&gt;% mutate(labels = values %&gt;% round(digits = 2) %&gt;% as.character()) # Here we plot f %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/3) + geom_ribbon(aes(ymin = Q25, ymax = Q75), alpha = 1/3) + geom_line(aes(y = Estimate)) + geom_point(data = protest, aes(y = liking), size = 2/3) + scale_x_continuous(breaks = breaks$values, labels = breaks$labels) + coord_cartesian(xlim = c(4, 6), ylim = c(2.5, 7.2)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + theme_minimal() + facet_wrap(~ condition) By adding the data to the plots, they are both more informative and now serve as a posterior predictive check. 10.4 Probing the interaction These will involve both omnibus tests and pairwise comparisons. 10.4.1 The pick-a-point approach. “The pick-a-point approach requires you to choose values of the moderator \\(W\\) and then estimate the conditional effect of \\(X\\) on \\(Y\\) at those values and conduct an inferential test” [evaluate the posterior distribution] (p. 368). 10.4.1.1 Omnibus inference. Hayes used the omnibus testing framework to assess how important coefficients \\(b_1\\) and \\(b_2\\) were to our interaction model, model1. Before fitting the models, he discussed why he preferred to fit models after centering sexism (i.e., \\(W\\)) to 4.25. Here we’ll call our centered variable sexism_p, where _p stands in for “prime.” protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 4.25) From here on, model10.3 is the moderation model without the lower-order d1 and d2 terms; model10.4 is the full moderation model. But we’re going to be fitting both these models three different ways, based on how we centersexism. So for this first set where we centered sexism on 4.25, we’ll give them the suffix a. # the model without d1 + d2 model10.3a &lt;- update(model10.2, newdata = protest, liking ~ 1 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4, file = &quot;fits/model10.03a&quot;) # the full model with d1 + d2 model10.4a &lt;- update(model10.2, newdata = protest, liking ~ 1 + d1 + d2 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4, file = &quot;fits/model10.04a&quot;) The coefficient summaries for model10.4a correspond to the top section of Table 10.3 (p. 373). fixef(model10.4a) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.706 0.237 5.243 6.164 ## d1 -0.301 0.345 -0.988 0.366 ## d2 -0.191 0.315 -0.822 0.424 ## sexism_p -0.481 0.208 -0.892 -0.059 ## d1:sexism_p 0.907 0.295 0.341 1.485 ## d2:sexism_p 0.787 0.277 0.240 1.310 We can compare their Bayesian \\(R^2\\) distributions like we usually do. library(tidybayes) r2 &lt;- tibble(`Model without d1 + d2` = bayes_R2(model10.3a, summary = F)[, 1], `Model with d1 + d2` = bayes_R2(model10.4a, summary = F)[, 1]) %&gt;% mutate(`The R2 difference` = `Model with d1 + d2` - `Model without d1 + d2`) r2 %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(key) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## key value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Model without d1 + d2 0.141 0.049 0.24 0.95 median qi ## 2 Model with d1 + d2 0.156 0.063 0.258 0.95 median qi ## 3 The R2 difference 0.015 -0.127 0.152 0.95 median qi Our results differ a bit from those in the text (p. 370), but the substantive interpretation is the same. The d1 and d2 parameters added little predictive power to the model in terms of \\(R^2\\). We can also use information criteria to compare the models. Here are the results from using the LOO-CV. model10.3a &lt;- add_criterion(model10.3a, &quot;loo&quot;) model10.4a &lt;- add_criterion(model10.4a, &quot;loo&quot;) loo_compare(model10.3a, model10.4a) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model10.3a 0.0 0.0 -185.9 11.0 6.5 1.9 371.9 22.0 ## model10.4a -1.5 0.8 -187.4 10.9 8.0 2.0 374.8 21.8 The LOO-CV difference between the two models was pretty small. Thus, the LOO-CV gives the same general message as the \\(R^2\\). The d1 and d2 parameters were sufficiently small and uncertain enough that constraining them to zero did little in terms of reducing the explanatory power of the statistical model. Here’s the same thing all over again, but this time after centering sexism on 5.120. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 5.120) Now fit the models. # the model without d1 + d2 model10.3b &lt;- update(model10.2, newdata = protest, liking ~ 1 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4, file = &quot;fits/model10.03b&quot;) # the full model with d1 + d2 model10.4b &lt;- update(model10.2, newdata = protest, liking ~ 1 + d1 + d2 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4, file = &quot;fits/model10.04b&quot;) These coefficient summaries correspond to the middle section of Table 10.3 (p. 373). fixef(model10.4b) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 5.286 0.156 4.974 5.592 ## d1 0.486 0.220 0.055 0.926 ## d2 0.495 0.222 0.060 0.934 ## sexism_p -0.470 0.202 -0.867 -0.082 ## d1:sexism_p 0.898 0.289 0.340 1.456 ## d2:sexism_p 0.777 0.269 0.246 1.290 Here are the Bayesian \\(R^2\\) summaries and the summary for their difference. r2 &lt;- tibble(`Model without d1 + d2` = bayes_R2(model10.3b, summary = F)[, 1], `Model with d1 + d2` = bayes_R2(model10.4b, summary = F)[, 1]) %&gt;% mutate(`The R2 difference` = `Model with d1 + d2` - `Model without d1 + d2`) r2 %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Model without d1 + d2 0.1 0.028 0.194 0.95 median qi ## 2 Model with d1 + d2 0.155 0.065 0.253 0.95 median qi ## 3 The R2 difference 0.055 -0.078 0.178 0.95 median qi This time, our \\(\\Delta R^2\\) distribution was more similar to the results Hayes reported in the text (p. 370, toward the bottom). Here’s the updated LOO-CV. model10.3b &lt;- add_criterion(model10.3b, &quot;loo&quot;) model10.4b &lt;- add_criterion(model10.4b, &quot;loo&quot;) loo_compare(model10.3b, model10.4b) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model10.4b 0.0 0.0 -187.2 10.9 7.7 1.9 374.3 21.7 ## model10.3b -1.6 3.1 -188.8 11.9 6.2 2.0 377.6 23.9 Here again our Bayesian \\(R^2\\) and loo() results cohere, both suggesting the d1 and d2 parameters were of little predictive utility. Note how this differs a little from the second \\(F\\)-test on page 370. Here’s what happens when we center sexism on 5.896. First center. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 5.896) Fit the models. # the model without d1 + d2 model10.3c &lt;- update(model10.2, newdata = protest, liking ~ 1 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4, file = &quot;fits/model10.03c&quot;) # the full model with d1 + d2 model10.4c &lt;- update(model10.2, newdata = protest, liking ~ 1 + d1 + d2 + sexism_p + d1:sexism_p + d2:sexism_p, cores = 4, file = &quot;fits/model10.04c&quot;) These coefficient summaries correspond to the lower section of Table 10.3 (p. 373). fixef(model10.4c) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## Intercept 4.917 0.231 4.469 5.374 ## d1 1.188 0.307 0.593 1.781 ## d2 1.104 0.317 0.492 1.736 ## sexism_p -0.479 0.208 -0.892 -0.076 ## d1:sexism_p 0.908 0.292 0.323 1.490 ## d2:sexism_p 0.787 0.278 0.262 1.365 Again, compute the \\(R^2\\) distributions and their difference-score distribution. r2 &lt;- tibble(`Model without d1 + d2` = bayes_R2(model10.3c, summary = F)[, 1], `Model with d1 + d2` = bayes_R2(model10.4c, summary = F)[, 1]) %&gt;% mutate(`The R2 difference` = `Model with d1 + d2` - `Model without d1 + d2`) r2 %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;Model without d1 + d2&quot;, &quot;Model with d1 + d2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(name) %&gt;% median_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Model without d1 + d2 0.027 0.002 0.094 0.95 median qi ## 2 Model with d1 + d2 0.156 0.064 0.257 0.95 median qi ## 3 The R2 difference 0.125 0.013 0.231 0.95 median qi That \\(\\Delta R^2\\) distribution matches up nicely with the one Hayes reported at the bottom of page 370. Now compare the models with the LOO. model10.3c &lt;- add_criterion(model10.3c, &quot;loo&quot;) model10.4c &lt;- add_criterion(model10.4c, &quot;loo&quot;) loo_compare(model10.3c, model10.4c) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model10.4c 0.0 0.0 -187.3 10.9 7.9 1.9 374.7 21.8 ## model10.3c -6.5 5.6 -193.8 13.4 5.8 1.9 387.6 26.7 Although our Bayesian \\(R^2\\) difference is now predominantly positive, the LOO-CV difference for the two models remains uncertain. Here’s a look at the two parameters in question using a handmade coefficient plot. posterior_samples(model10.4c) %&gt;% pivot_longer(b_d1:b_d2) %&gt;% mutate(name = str_remove(name, &quot;b_&quot;)) %&gt;% ggplot(aes(x = value, y = name)) + stat_summary(fun = median, fun.min = function(i) quantile(i, probs = .025), fun.max = function(i) quantile(i, probs = .975), color = &quot;grey33&quot;) + stat_summary(geom = &quot;linerange&quot;, fun.min = function(i) quantile(i, probs = .25), fun.max = function(i) quantile(i, probs = .75), color = &quot;grey33&quot;, size = 1.25) + ylab(NULL) + coord_cartesian(xlim = c(0, 2)) + theme_minimal() For Figure 10.4, we’ll drop our faceting approach and just make one big plot. Heads up: I’m going to drop the 50% intervals from this plot. They’d just make it too busy. f %&gt;% ggplot(aes(x = sexism, y = Estimate, ymin = Q2.5, ymax = Q97.5, alpha = condition)) + geom_ribbon() + geom_line() + scale_alpha_manual(values = c(.2, .5, .8)) + scale_x_continuous(breaks = breaks$values, labels = breaks$labels) + coord_cartesian(xlim = c(4, 6), ylim = c(4.5, 6.7)) + labs(x = expression(&quot;Perceived Pervasiveness of Sex Discrimination in Society &quot;*(italic(W))), y = &quot;Evaluation of the Attorney&quot;) + theme_minimal() + theme(legend.direction = &quot;vertical&quot;, legend.position = &quot;top&quot;, legend.title = element_blank()) 10.4.1.2 Pairwise inference. Hayes continues to reference Table 10.3. In the last subsection, we reproduced those results one model at a time. Why not practice doing it altogether? There are a lot of ways you could do this. A good first try is to extend the fixef() approach from before with a little help from bind_rows(). bind_rows( # start with `model4a` fixef(model10.4a) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;), # add `model4b` fixef(model10.4b) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;), # add `model4c` fixef(model10.4c) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;) ) %&gt;% # wrangle a bit mutate(`w&#39;` = str_c(&quot;w - &quot;, c(4.25, 5.12, 5.896)) %&gt;% rep(., each = 6)) %&gt;% select(`w&#39;`, everything()) %&gt;% mutate_if(is.double, round, digits = 3) ## w&#39; parameter Estimate Est.Error Q2.5 Q97.5 ## 1 w - 4.25 Intercept 5.706 0.237 5.243 6.164 ## 2 w - 4.25 d1 -0.301 0.345 -0.988 0.366 ## 3 w - 4.25 d2 -0.191 0.315 -0.822 0.424 ## 4 w - 4.25 sexism_p -0.481 0.208 -0.892 -0.059 ## 5 w - 4.25 d1:sexism_p 0.907 0.295 0.341 1.485 ## 6 w - 4.25 d2:sexism_p 0.787 0.277 0.240 1.310 ## 7 w - 5.12 Intercept 5.286 0.156 4.974 5.592 ## 8 w - 5.12 d1 0.486 0.220 0.055 0.926 ## 9 w - 5.12 d2 0.495 0.222 0.060 0.934 ## 10 w - 5.12 sexism_p -0.470 0.202 -0.867 -0.082 ## 11 w - 5.12 d1:sexism_p 0.898 0.289 0.340 1.456 ## 12 w - 5.12 d2:sexism_p 0.777 0.269 0.246 1.290 ## 13 w - 5.896 Intercept 4.917 0.231 4.469 5.374 ## 14 w - 5.896 d1 1.188 0.307 0.593 1.781 ## 15 w - 5.896 d2 1.104 0.317 0.492 1.736 ## 16 w - 5.896 sexism_p -0.479 0.208 -0.892 -0.076 ## 17 w - 5.896 d1:sexism_p 0.908 0.292 0.323 1.490 ## 18 w - 5.896 d2:sexism_p 0.787 0.278 0.262 1.365 This code works okay, but it’s redundant. Here’s a streamlined approach where we use a combination of nested tibbles and the purrr::map() function to work with our three model fits–model10.4a, model10.4b, and model10.4c–in bulk. t &lt;- tibble(`w&#39;` = str_c(&quot;w - &quot;, c(4.25, 5.12, 5.896)), name = str_c(&quot;model10.4&quot;, letters[1:3])) %&gt;% mutate(fit = map(name, get)) %&gt;% mutate(s = map(fit, ~fixef(.) %&gt;% data.frame() %&gt;% rownames_to_column(&quot;parameter&quot;))) %&gt;% unnest(s) %&gt;% select(`w&#39;`, parameter:Q97.5) t %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 18 x 6 ## `w&#39;` parameter Estimate Est.Error Q2.5 Q97.5 ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 w - 4.25 Intercept 5.71 0.237 5.24 6.16 ## 2 w - 4.25 d1 -0.301 0.345 -0.988 0.366 ## 3 w - 4.25 d2 -0.191 0.315 -0.822 0.424 ## 4 w - 4.25 sexism_p -0.481 0.208 -0.892 -0.059 ## 5 w - 4.25 d1:sexism_p 0.907 0.295 0.341 1.48 ## 6 w - 4.25 d2:sexism_p 0.787 0.277 0.24 1.31 ## 7 w - 5.12 Intercept 5.29 0.156 4.97 5.59 ## 8 w - 5.12 d1 0.486 0.22 0.055 0.926 ## 9 w - 5.12 d2 0.495 0.222 0.06 0.934 ## 10 w - 5.12 sexism_p -0.47 0.202 -0.867 -0.082 ## 11 w - 5.12 d1:sexism_p 0.898 0.289 0.34 1.46 ## 12 w - 5.12 d2:sexism_p 0.777 0.269 0.246 1.29 ## 13 w - 5.896 Intercept 4.92 0.231 4.47 5.37 ## 14 w - 5.896 d1 1.19 0.307 0.593 1.78 ## 15 w - 5.896 d2 1.10 0.317 0.492 1.74 ## 16 w - 5.896 sexism_p -0.479 0.208 -0.892 -0.076 ## 17 w - 5.896 d1:sexism_p 0.908 0.292 0.323 1.49 ## 18 w - 5.896 d2:sexism_p 0.787 0.278 0.262 1.36 Summary tables like this are precise and very common in the literature. But you can get lost in all those numbers. A coefficient plot can be better. This first version is pretty close to the Table 10.3 format. t %&gt;% # this will help us order our y-axis mutate(parameter = factor(parameter, levels = c(&quot;d2:sexism_p&quot;, &quot;d1:sexism_p&quot;, &quot;sexism_p&quot;, &quot;d2&quot;, &quot;d1&quot;, &quot;Intercept&quot;)), # this is just for aesthetics `w&#39;` = str_c(&quot;w&#39; = &quot;, `w&#39;`)) %&gt;% # plot! ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = parameter)) + geom_pointrange() + labs(x = NULL, y = NULL) + theme_minimal() + theme(axis.text.y = element_text(hjust = 0)) + facet_wrap(~ `w&#39;`, nrow = 1) Notice how this arrangement makes it easiest to compare coefficients within models. If we wanted to make it easier to compare coefficients across models, we might arrange the plot like so. t %&gt;% # this will help us order our y-axis mutate(parameter = factor(parameter, levels = c(&quot;Intercept&quot;, &quot;d1&quot;, &quot;d2&quot;, &quot;sexism_p&quot;, &quot;d1:sexism_p&quot;, &quot;d2:sexism_p&quot;))) %&gt;% # plot! ggplot(aes(x = Estimate, xmin = Q2.5, xmax = Q97.5, y = `w&#39;`)) + geom_pointrange() + labs(x = NULL, y = NULL) + theme_minimal() + theme(axis.text.y = element_text(hjust = 0)) + facet_wrap(~ parameter, ncol = 1) Oh man–with sweet plots like these, who needs tables! This makes it much easier to see what happened as we changed values we centered sexism on. In the middle paragraph on page 374, Hayes pointed out “that \\(b_1\\) and \\(b_2\\) differ in these analyses, but \\(b_3\\), \\(b_4\\), and \\(b_5\\) are unaffected by the centering.” Our coefficient plot clarified that in a way I don’t think a table ever could. But before we move on, let’s back up a little in the text. “To make this more concrete, consider the effect of Catherine’s behavior on how she is perceived among people who are relatively high in their perceptions of the pervasiveness of sex discrimination in society” (p. 372). For this, Hayes defined “relatively high” as \\(W = 5.896\\). To get those estimates for each condition, we’ll use fitted(). Since the number of unique predictor values is small for this example, we’ll just plug them directly into the newdata argument rather than first saving them as a nd object. fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 5.896)) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## [1,] 4.925 0.230 4.472 5.387 ## [2,] 6.106 0.206 5.704 6.513 ## [3,] 6.023 0.223 5.580 6.462 Those posterior summaries match up nicely with the point estimates Hayes presented at the bottom of page 372. Hayes further expounded: So by using the regression centering strategy described earlier in the context of an omnibus test of equality of values of \\(\\hat Y\\), the regression coefficients \\(b_1\\) and \\(b_2\\) provide pairwise inferences consistent with the coding system used to represent the three groups, conditioned on the value that \\(W\\) is centered around. In the next few sentences, he focused on what happened when \\(W = 4.250\\) (i.e., in model4a). Recall that the two coefficients in question, \\(b_1\\) and \\(b_2\\), are named d1 and d2 when we pull their summaries with fixef(). fixef(model10.4a)[c(&quot;d1&quot;, &quot;d2&quot;), ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## d1 -0.301 0.345 -0.988 0.366 ## d2 -0.191 0.315 -0.822 0.424 Hayes then clarified that in this model \\[\\begin{align*} b_1 &amp; = \\theta_{D_1 \\rightarrow Y} | (W = 4.250) = 5.400 - 5.698 = -0.299 \\;\\;\\; \\text{ and} \\\\ b_2 &amp; = \\theta_{D_2 \\rightarrow Y} | (W = 4.250) = 5.513 - 5.698 = -0.185. \\end{align*}\\] That is, it is the same as a difference score of each of the experimental conditions minus the “No protest” condition. To further show the difference-score quality of these coefficients, we can continue using fitted() in conjunction with the original model10.2 to get the group comparisons for when \\(W = 4.250\\). Since these involve computing difference scores, we’ll have to use summary = F and do some wrangling. fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 4.25), summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 5 x 4 ## name value .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No Protest 5.70 5.23 6.15 ## 2 Individual Protest 5.41 4.89 5.92 ## 3 Collective Protest 5.52 5.10 5.93 ## 4 difference_a -0.291 -0.96 0.39 ## 5 difference_b -0.179 -0.795 0.454 Within simulation variance, difference_a is the same as \\(b_{1 | \\text{model10.4a}}\\) and difference_b is the same as \\(b_{2 | \\text{model10.4a}}\\). Here’s the same thing for when \\(W = 5.120\\). fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 5.120), summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 5 x 4 ## name value .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No Protest 5.29 4.99 5.60 ## 2 Individual Protest 5.78 5.46 6.09 ## 3 Collective Protest 5.78 5.49 6.09 ## 4 difference_a 0.487 0.034 0.919 ## 5 difference_b 0.496 0.058 0.932 Finally, here it is for when \\(W = 5.986\\). fitted(model10.2, newdata = tibble(d1 = c(0, 1, 0), d2 = c(0, 0, 1), sexism = 5.986), summary = F) %&gt;% data.frame() %&gt;% set_names(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% select(name:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 5 x 4 ## name value .lower .upper ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 No Protest 4.88 4.4 5.37 ## 2 Individual Protest 6.14 5.72 6.58 ## 3 Collective Protest 6.05 5.58 6.52 ## 4 difference_a 1.26 0.625 1.93 ## 5 difference_b 1.17 0.522 1.84 10.4.2 The Johnson-Neyman technique. As discussed in section 7.4, a problem with the pick-a-point approach to probing an interaction is having to choose values of the moderator. When the moderator is a continuum, you may not have any basis for choosing some values rather than others, and the choice you make will certainly influence the results of the probing exercise to some extent… Actively choosing a different system or con- vention, such as using the sample mean of \\(W\\), a standard deviation below the mean, and a standard deviation above the mean also does not eliminate the problem. But the Johnson–Neyman (JN) technique avoids this problem entirely. (p. 376) 10.4.2.1 Omnibus inference. Consider the first sentence of the section: Applied to probing an interaction between a multicategorical \\(X\\) and a continuous \\(W\\), an omnibus version of the JM technique involves finding the value or values of \\(W\\) where their \\(F\\)-ratio comparing the \\(g\\) estimated values of \\(Y\\) is just statistically significant. (p. 376) Since we’re not using \\(F\\)-tests with our approach to Bayesian modeling, the closest we might have is a series of \\(R^2\\) difference tests, which would require refitting the model multiple times over many ways of centering the \\(W\\)-variable, sexism. I suppose you could do this if you wanted, but it just seems silly, to me. I’ll leave this one up to the interested reader. 10.4.2.2 Pairwise inference. Hayes didn’t make plots for this section, but if you’re careful constructing your nd and with the subsequent wrangling, you can make the usual plots. Since we have two conditions we’d like to compare with No Protest, we’ll make two plots. Here’s the comparison using Individual Protest, first. nd &lt;- tibble(d1 = 0:1, d2 = 0) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) # the transition value Hayes identified in the text Hayes_value &lt;- 5.065 # we need some new data nd &lt;- tibble(d1 = 0:1, d2 = 0) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) # plug those data into `fitted()` fitted(model10.2, newdata = nd, summary = F) %&gt;% # wrangle data.frame() %&gt;% gather(key, estimate) %&gt;% bind_cols( nd %&gt;% expand(nesting(d1, d2, sexism), iter = 1:4000) ) %&gt;% mutate(condition = if_else(d1 == 0, &quot;No Protest&quot;, &quot;Individual Protest&quot;)) %&gt;% select(-c(key, d1:d2)) %&gt;% spread(key = condition, value = estimate) %&gt;% mutate(difference = `Individual Protest` - `No Protest`) %&gt;% # plot! ggplot(aes(x = sexism, y = difference)) + stat_summary(geom = &quot;ribbon&quot;, fun.min = function(i) quantile(i, probs = .025), fun.max = function(i) quantile(i, probs = .975), alpha = 1/3) + stat_summary(geom = &quot;ribbon&quot;, fun.min = function(i) quantile(i, probs = .25), fun.max = function(i) quantile(i, probs = .75), alpha = 1/3) + stat_summary(geom = &quot;line&quot;, fun = median) + scale_x_continuous(breaks = c(4, Hayes_value, 6), labels = c(&quot;4&quot;, Hayes_value, &quot;6&quot;)) + coord_cartesian(xlim = c(4, 6)) + labs(subtitle = expression(&quot;Our JN-technique plot for &quot;*italic(Individual~Protest)*&quot; compared with &quot;*italic(No~Protest))) + theme_minimal() Now we’re ready to compare No Protest to Collective Protest. The main data difference is which values we assigned to the d1 and d2 columns in nd. For kicks, we should practice another way to get the median line and interval ribbons. The stat_summary() approach from above works great, but it’s verbose. The tidybayes::stat_lineribbon() function will give us the same results with fewer lines of code. # the transition value Hayes identified in the text Hayes_value &lt;- 5.036 # new data nd &lt;- tibble(d1 = 0, d2 = 0:1) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) # this part is the same as before fitted(model10.2, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% mutate(name = str_remove(name, &quot;X&quot;) %&gt;% as.double()) %&gt;% arrange(name, iter) %&gt;% bind_cols(expand(nd, nesting(d1, d2, sexism), iter = 1:4000)) %&gt;% # there are some mild differences, here mutate(condition = if_else(d2 == 0, &quot;No Protest&quot;, &quot;Collective Protest&quot;)) %&gt;% select(-c(name, d1:d2)) %&gt;% pivot_wider(names_from = condition, values_from = value) %&gt;% mutate(difference = `Collective Protest` - `No Protest`) %&gt;% # plot! ggplot(aes(x = sexism, y = difference)) + # look how compact this is! stat_lineribbon(.width = c(0.5, 0.95), alpha = 1/3, fill = &quot;black&quot;) + scale_x_continuous(breaks = c(4, Hayes_value, 6), labels = c(&quot;4&quot;, Hayes_value, &quot;6&quot;)) + coord_cartesian(xlim = c(4, 6)) + labs(subtitle = expression(&quot;Our JN-technique plot for &quot;*italic(Collective~Protest)*&quot; compared with &quot;*italic(No~Protest))) + theme_minimal() And here we do it one last time between the two active protest conditions. For good measure, we will continue experimenting with different ways of plotting the results. This time well first summarize the posterior median and intervals with tidybayes::median_qi() before plotting. We’ll then feed those results into our plot with the aid of tidybayes::geom_lineribbon() and a follow-up scale_fill_manual() line. nd &lt;- tibble(d1 = 1:0, d2 = 0:1) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) fitted(model10.2, newdata = nd, summary = F) %&gt;% data.frame() %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% mutate(name = str_remove(name, &quot;X&quot;) %&gt;% as.double()) %&gt;% arrange(name, iter) %&gt;% bind_cols(expand(nd, nesting(d1, d2, sexism), iter = 1:4000)) %&gt;% # there are some mild differences, here mutate(condition = if_else(d1 == 0, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;)) %&gt;% select(-c(name, d1:d2)) %&gt;% pivot_wider(names_from = condition, values_from = value) %&gt;% mutate(difference = `Collective Protest` - `Individual Protest`) %&gt;% # group and summarise, here group_by(sexism) %&gt;% median_qi(difference, .width = c(.5, .95)) %&gt;% # plot! ggplot(aes(x = sexism, y = difference, ymin = .lower, ymax = .upper)) + # look how simple these two lines are geom_lineribbon(show.legend = F) + scale_fill_manual(values = c(&quot;grey75&quot;, &quot;grey50&quot;)) + coord_cartesian(xlim = c(4, 6)) + labs(subtitle = expression(&quot;Our JN-technique plot for &quot;*italic(Collective~Protest)*&quot; compared with &quot;*italic(Individual~Protest))) + theme_minimal() Little difference between those conditions. 10.5 When the moderator is multicategorical From a substantive standpoint the combination of a multicategorical variable \\(X\\) and a dichotomous or continuous moderator \\(W\\) versus a dichotomous or continuous variable \\(X\\) and a multicategorical moderator \\(W\\) might seem different. From a modeling perspective, the difference is trivial. As Hayes pointed out, “when we claim from a statistical test of moderation that \\(X\\)’s effect is moderated by \\(W\\), then it is also true that \\(W\\)’s effect is moderated by \\(X\\). This is the symmetry property of interactions” (p. 381). This symmetry holds when we’re not using the hypothesis-testing framework, too. 10.5.1 An example. Just as a refresher, here’s the print() output for model2. print(model10.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: liking ~ d1 + d2 + sexism + d1:sexism + d2:sexism ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 7.694 1.070 5.638 9.815 1.000 1499 1833 ## d1 -4.091 1.530 -7.090 -1.051 1.000 1467 1701 ## d2 -3.477 1.408 -6.179 -0.709 1.000 1451 1949 ## sexism -0.470 0.208 -0.883 -0.072 1.000 1492 1809 ## d1:sexism 0.894 0.294 0.316 1.477 1.000 1454 1764 ## d2:sexism 0.776 0.275 0.248 1.309 1.000 1460 1870 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.006 0.066 0.888 1.151 1.000 2613 2471 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). The Bayesian \\(R^2\\): bayes_R2(model10.2) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2 0.156 0.05 0.065 0.26 And the \\(R^2\\) difference between this and the model excluding the interaction terms: tibble(`Model 10.1` = bayes_R2(model10.1, summary = F)[, 1], `Model 10.2` = bayes_R2(model10.2, summary = F)[, 1]) %&gt;% transmute(difference = `Model 10.2` - `Model 10.1`) %&gt;% mean_qi(difference) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## difference .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 0.085 -0.033 0.21 0.95 mean qi Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3. # this will help us with the `geom_text()` annotation slopes &lt;- tibble(slope = c(fixef(model10.2)[&quot;sexism&quot;, &quot;Estimate&quot;] + fixef(model10.2)[&quot;d1:sexism&quot;, &quot;Estimate&quot;], fixef(model10.2)[&quot;sexism&quot;, &quot;Estimate&quot;] + fixef(model10.2)[&quot;d2:sexism&quot;, &quot;Estimate&quot;], fixef(model10.2)[&quot;sexism&quot;, &quot;Estimate&quot;]), x = c(4.8, 4.6, 5), y = c(6.37, 6.25, 4.5), condition = factor(c(&quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;No Protest&quot;), levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(label = str_c(&quot;This slope is about &quot;, slope %&gt;% round(digits = 3))) # now we plot f %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/3) + geom_ribbon(aes(ymin = Q25, ymax = Q75), alpha = 1/3) + geom_line(aes(y = Estimate)) + geom_text(data = slopes, aes(x = x, y = y, label = label)) + coord_cartesian(xlim = c(4, 6)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(X), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + facet_wrap(~ condition) + theme_minimal() 10.5.2 Probing the interaction and interpreting the regression coefficients. We computed the posterior means for the slopes when prepping for the figure, above. Here’s how we might get more complete posterior summaries. Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3. post &lt;- posterior_samples(model10.2) %&gt;% transmute(`No Protest` = b_sexism + `b_d1:sexism` * 0 + `b_d2:sexism` * 0, `Individual Protest` = b_sexism + `b_d1:sexism` * 1 + `b_d2:sexism` * 0, `Collective Protest` = b_sexism + `b_d1:sexism` * 0 + `b_d2:sexism` * 1) post %&gt;% pivot_longer(everything()) %&gt;% mutate(name = factor(name, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 No Protest -0.47 -0.883 -0.072 0.95 mean qi ## 2 Individual Protest 0.425 0.028 0.846 0.95 mean qi ## 3 Collective Protest 0.306 -0.072 0.674 0.95 mean qi Here are the differences among the three protest groups. post %&gt;% transmute(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Individual Protest - Collective Protest` = `Individual Protest` - `Collective Protest`) %&gt;% pivot_longer(everything()) %&gt;% # again, not necessary, but useful for reordering the summaries mutate(name = factor(name, levels = c(&quot;Individual Protest - No Protest&quot;, &quot;Collective Protest - No Protest&quot;, &quot;Individual Protest - Collective Protest&quot;))) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Individual Protest - No Protest 0.894 0.316 1.48 0.95 mean qi ## 2 Collective Protest - No Protest 0.776 0.248 1.31 0.95 mean qi ## 3 Individual Protest - Collective Protest 0.118 -0.419 0.661 0.95 mean qi Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 ## [5] svUnit_1.0.3 sp_1.4-4 splines_4.0.4 crosstalk_1.1.0.1 ## [9] TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 digest_0.6.27 ## [13] htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 checkmate_2.0.0 ## [17] magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 ## [21] xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 ## [25] rvest_1.0.1 ggdist_3.0.0 haven_2.3.1 xfun_0.23 ## [29] callr_3.7.0 crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 ## [33] survival_3.2-10 zoo_1.8-8 glue_1.4.2 gtable_0.3.0 ## [37] emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [41] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 ## [45] DBI_1.1.0 miniUI_0.1.1.1 viridisLite_0.4.0 xtable_1.8-4 ## [49] stats4_4.0.4 StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 ## [53] httr_1.4.2 threejs_0.3.3 arrayhelpers_1.1-0 posterior_1.0.1 ## [57] ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 ## [61] sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 tidyselect_1.1.1 ## [65] labeling_0.4.2 rlang_0.4.11 reshape2_1.4.4 later_1.2.0 ## [69] munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 cli_3.0.1 ## [73] generics_0.1.0 broom_0.7.6 ggridges_0.5.3 evaluate_0.14 ## [77] fastmap_1.1.0 processx_3.5.2 knitr_1.33 fs_1.5.0 ## [81] nlme_3.1-152 mime_0.10 projpred_2.0.2 xml2_1.3.2 ## [85] compiler_4.0.4 bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 ## [89] gamm4_0.2-6 curl_4.3 reprex_2.0.0 statmod_1.4.35 ## [93] bslib_0.2.4 stringi_1.6.2 highr_0.9 ps_1.6.0 ## [97] Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 ## [101] markdown_1.1 tensorA_0.36.2 shinyjs_2.0.0 vctrs_0.3.8 ## [105] pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 ## [109] estimability_1.3 raster_3.4-5 httpuv_1.6.0 R6_2.5.0 ## [113] bookdown_0.22 promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 ## [117] boot_1.3-26 colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 ## [121] assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 ## [125] mgcv_1.8-33 parallel_4.0.4 hms_1.1.0 grid_4.0.4 ## [129] coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 ## [133] lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 "],["fundamentals-of-conditional-process-analysis.html", "11 Fundamentals of Conditional Process Analysis 11.1 Examples of conditional process models in the literature 11.2 Conditional direct and indirect effects 11.3 Example: Hiding your feelings from your work team 11.4 Estimation of a conditional process model using PROCESS 11.5 Quantifying and visualizing (conditional) indirect and direct effects. 11.6 Statistical inference Session info", " 11 Fundamentals of Conditional Process Analysis Thus far in this book, mediation and moderation have been treated as distinct, separate, and independent concepts with different analytical procedures and interpretations. Yet processes modeled with mediation analysis likely are contingent and hence moderated, in that they operate differently for different people or in different contexts or circumstances. A more complete analysis, therefore, should attempt to model the mechanisms at work linking \\(X\\) to \\(Y\\) while simultaneously allowing those effects to be contingent on context, circumstance, or individual differences. (Andrew F. Hayes, 2018, p. 395) 11.1 Examples of conditional process models in the literature You can look up the various examples in the literature on your own. The main point is moderation can be combined with mediation in a number of different ways. But these examples [we skipped for the sake of brevity] only scratch the surface of what is possible. Think about the number of possibilities when you increase the number of mediators, distinguish between moderation of paths in a parallel versus serial multiple mediator model, or allow for multiple moderators of different paths or the same path, and so forth. The possibilities are nearly endless. But regardless of the configuration of moderated paths or complexity of the model, conditional process analysis involves the estimation and interpretation of direct and indirect effects, just as in a simple mediation analysis. However, when causal effects in a mediation model are moderated, they will be conditional on those moderators. Thus, an understanding of the concepts of the conditional direct effect and the conditional indirect effect is required before one should attempt to undertake a conditional process analysis. (p. 401, emphasis in the original) 11.2 Conditional direct and indirect effects When a direct or indirect effect is conditional, analysis and interpretation of the results of the modeling process should be based on a formal estimate of and inference about conditional direct and/or conditional in- direct effects. In this section, [Hayes illustrated] the computation of conditional direct and indirect effects for example models that combine moderation and mediation. (p. 403) 11.3 Example: Hiding your feelings from your work team Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) teams &lt;- read_csv(&quot;data/teams/teams.csv&quot;) glimpse(teams) ## Rows: 60 ## Columns: 4 ## $ dysfunc &lt;dbl&gt; -0.23, -0.13, 0.00, -0.33, 0.39, 1.02, -0.35, -0.23, 0.39, -0.08, -0.23, 0.09, -0.29, -0.06,… ## $ negtone &lt;dbl&gt; -0.51, 0.22, -0.08, -0.11, -0.48, 0.72, -0.18, -0.13, 0.52, -0.26, 1.08, 0.53, -0.19, 0.15, … ## $ negexp &lt;dbl&gt; -0.49, -0.49, 0.84, 0.84, 0.17, -0.82, -0.66, -0.16, -0.16, -0.16, -0.16, 0.50, 0.84, 0.50, … ## $ perform &lt;dbl&gt; 0.12, 0.52, -0.08, -0.08, 0.12, 1.12, -0.28, 0.32, -1.08, -0.28, -1.08, -0.28, -0.28, -0.88,… Load the brms package. library(brms) Recall that we fit mediation models with brms using multivariate syntax. In previous attempts, we’ve defined and saved the model components outside of the brm() function and then plugged then into brm() using their identifier. Just to shake things up a bit, we’ll just do all the steps right in brm(), this time. model11.1 &lt;- brm(data = teams, family = gaussian, bf(negtone ~ 1 + dysfunc) + bf(perform ~ 1 + dysfunc + negtone + negexp + negtone:negexp) + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model11.01&quot;) Check the model summary. print(model11.1, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: negtone ~ 1 + dysfunc ## perform ~ 1 + dysfunc + negtone + negexp + negtone:negexp ## Data: teams (Number of observations: 60) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## negtone_Intercept 0.026 0.064 -0.098 0.153 1.001 7013 2793 ## perform_Intercept -0.011 0.059 -0.129 0.105 1.000 7375 3089 ## negtone_dysfunc 0.620 0.171 0.285 0.953 1.006 7462 3022 ## perform_dysfunc 0.362 0.185 -0.001 0.718 1.001 5560 3232 ## perform_negtone -0.434 0.136 -0.694 -0.166 1.000 5335 3117 ## perform_negexp -0.020 0.124 -0.259 0.225 1.000 6662 3159 ## perform_negtone:negexp -0.514 0.246 -1.006 -0.037 1.000 4799 3216 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_negtone 0.487 0.048 0.409 0.589 1.001 5627 3135 ## sigma_perform 0.459 0.043 0.383 0.550 1.001 5628 3051 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Our model summary coheres nicely with Table 11.1 and the formulas on page 409. Here are the \\(R^2\\) distribution summaries. bayes_R2(model11.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2negtone 0.193 0.079 0.045 0.345 ## R2perform 0.319 0.078 0.157 0.458 On page 410 Hayes reported two sample means. Compute them like so. mean(teams$negexp) %&gt;% round(digits = 3) # w_bar ## [1] -0.008 mean(teams$perform) %&gt;% round(digits = 3) # m_bar ## [1] -0.032 For our Figure 11.4 and other similar figures in this chapter, we’ll use spaghetti plots. Recall that with a spaghetti plots for linear models, we only need two values for the variable on the \\(x\\)-axis, rather than the typical 30+. nd &lt;- crossing(negtone = c(-.8, .8), negexp = quantile(teams$negexp, probs = c(.16, .50, .84))) %&gt;% mutate(dysfunc = mean(teams$dysfunc)) Here’s our Figure 11.4, which uses only the first 40 HMC iterations for the spaghetti-plot lines. # `fitted()` fitted(model11.1, newdata = nd, resp = &quot;perform&quot;, summary = F) %&gt;% # wrangle as_tibble() %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% arrange(name, iter) %&gt;% select(-iter) %&gt;% bind_cols(expand(nd, nesting(negtone, negexp), iter = 1:4000)) %&gt;% mutate(negexp = factor(str_c(&quot;expresivity = &quot;, negexp), levels = c(&quot;expresivity = -0.49&quot;, &quot;expresivity = -0.06&quot;, &quot;expresivity = 0.6&quot;))) %&gt;% filter(iter &lt; 41) %&gt;% # plot ggplot(aes(x = negtone, y = value, group = iter)) + geom_line(color = &quot;skyblue3&quot;, size = 1/4) + coord_cartesian(xlim = c(-.5, .5), ylim = c(-.6, .6)) + labs(x = expression(paste(&quot;Negative Tone of the Work Climate (&quot;, italic(M), &quot;)&quot;)), y = &quot;Team Performance&quot;) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;)) + facet_wrap(~ negexp) Also, the plot theme in this chapter is a nod to the style John Kruschke frequently uses in his papers and texts (e.g., Kruschke, 2015). Using Hayes’s notation from the top of page 412, we can express \\(M\\)’s conditional effect on \\(Y\\) as \\[\\theta_{M \\rightarrow Y} = b_1 + b_3 W,\\] where \\(M\\) is negtone, \\(Y\\) is perform, and \\(W\\) is negexp. We can extract our posterior summaries for \\(b_1\\) and \\(b_3\\) like so. fixef(model11.1)[c(&quot;perform_negtone&quot;, &quot;perform_negtone:negexp&quot;), ] ## Estimate Est.Error Q2.5 Q97.5 ## perform_negtone -0.4335440 0.1357573 -0.6944009 -0.16598288 ## perform_negtone:negexp -0.5141659 0.2458267 -1.0064484 -0.03698026 11.4 Estimation of a conditional process model using PROCESS We just fit the model in the last section. No need to repeat. 11.5 Quantifying and visualizing (conditional) indirect and direct effects. The analysis presented thus far has been piecemeal, in that [Hayes] addressed how to estimate the regression coefficients for each equation in this conditional process model and how to interpret them using standard principles of regression analysis, moderation analysis, and so forth. But a complete analysis goes further by integrating the estimates of each of the effects in the model (i.e., \\(X \\rightarrow M, \\theta_{M \\rightarrow Y}\\)) to yield the direct and indirect effects of \\(X\\) on \\(Y\\). That is, the individual effects as quantified with the regression coefficients (conditional or otherwise) in equations 11.10 and 11.11 are not necessarily of immediate interest or relevance. Estimating them is a means to an end. What matters is the estimation of the direct and indirect effects, for they convey information about how \\(X\\) influences \\(Y\\) directly or through a mediator and how those effects are contingent on a moderator. (pp. 417–418) 11.5.0.1 The conditional indirect effect of \\(X\\). One way to make a version of Table 11.2 is to work with the posterior_samples(), simply summarizing the distributions with means. post &lt;- posterior_samples(model11.1) post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(conditional_effect = b1 + b3 * w, conditional_indirect_effect = a * (b1 + b3 * w)) %&gt;% select(-(b1:b3)) %&gt;% pivot_longer(-w) %&gt;% group_by(w, name) %&gt;% summarise(mean = mean(value) %&gt;% round(digits = 3)) %&gt;% pivot_wider(names_from = name, values_from = mean) ## # A tibble: 3 x 4 ## # Groups: w [3] ## w a conditional_effect conditional_indirect_effect ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.531 0.62 -0.161 -0.1 ## 2 -0.006 0.62 -0.431 -0.267 ## 3 0.6 0.62 -0.742 -0.46 That kind of summary isn’t the most Bayesian of us. Why not plot, instead? post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(conditional_effect = b1 + b3 * w, conditional_indirect_effect = a * (b1 + b3 * w)) %&gt;% select(-(b1:b3)) %&gt;% pivot_longer(-w) %&gt;% mutate(label = str_c(&quot;W = &quot;, w), w = fct_reorder(label, w)) %&gt;% ggplot(aes(x = value)) + geom_vline(xintercept = 0, color = &quot;grey50&quot;, linetype = 2) + geom_histogram(color = &quot;white&quot;, fill = &quot;skyblue3&quot;) + scale_y_continuous(NULL, breaks = NULL) + xlab(&quot;posterior&quot;) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;)) + facet_grid(w ~ name) Now the posterior distribution for each is on full display. 11.5.0.2 The direct effect. The direct effect of \\(X\\) on \\(Y\\) (i.e., dysfunc on perform) for this model is b_perform_dysfunc in brms. Here’s how to get its summary values from posterior_summary(). posterior_summary(model11.1)[&quot;b_perform_dysfunc&quot;, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## 0.362 0.185 -0.001 0.718 11.5.1 Visualizing the direct and indirect effects. For Figure 11.7 we’ll use the first 400 HMC iterations. post &lt;- post %&gt;% mutate(`-0.7` = b_negtone_dysfunc * (b_perform_negtone + `b_perform_negtone:negexp` * -0.7), `0.7` = b_negtone_dysfunc * (b_perform_negtone + `b_perform_negtone:negexp` * 0.7)) post %&gt;% select(b_perform_dysfunc, `-0.7`:`0.7`) %&gt;% pivot_longer(-b_perform_dysfunc) %&gt;% mutate(negexp = name %&gt;% as.double(), iter = rep(1:4000, times = 2)) %&gt;% filter(iter &lt; 401) %&gt;% ggplot(aes(x = negexp, group = iter)) + geom_hline(aes(yintercept = b_perform_dysfunc), color = &quot;skyblue3&quot;, size = .3, alpha = .3) + geom_line(aes(y = value), color = &quot;skyblue3&quot;, size = .3, alpha = .3) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(paste(&quot;Nonverbal Negative Expressivity (&quot;, italic(W), &quot;)&quot;)), y = &quot;Effect of Dysfunctional Behavior on Team Performance&quot;) + theme_bw() + theme(panel.grid = element_blank()) Since the b_perform_dysfunc values are constant across \\(W\\), the individual HMC iterations end up perfectly parallel in the spaghetti plot. This is an example of a visualization I’d avoid making with a spaghetti plot for a professional presentation. But hopefully it has some pedagogical value, here. 11.6 Statistical inference 11.6.1 Inference about the direct effect. We’ve already been expressing uncertainty in terms of percentile-based 95% intervals and histograms. Here’s a plot of the direct effect, b_perform_dysfunc. library(tidybayes) # breaks breaks &lt;- mode_hdi(post$b_perform_dysfunc, .width = .95) %&gt;% pivot_longer(starts_with(&quot;y&quot;)) %&gt;% pull(value) post %&gt;% ggplot(aes(x = b_perform_dysfunc)) + geom_histogram(binwidth = .025, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointinterval(aes(y = 0), point_interval = mode_hdi, .width = .95) + scale_x_continuous(&quot;The direct effect (i.e., b_perform_dysfunc)&quot;, breaks = breaks, labels = round(breaks, digits = 3)) + scale_y_continuous(NULL, breaks = NULL) + theme_bw() + theme(axis.line.x = element_line(size = 1/4), panel.border = element_blank(), panel.grid = element_blank()) Since we’re plotting in a style similar to Kruschke, we switched from emphasizing the posterior mean or median to marking off the posterior mode, which is Kruschkes’ preferred measure of central tendency. We also ditched our typical percentile-based 95% intervals for highest posterior density intervals. The stat_pointinterval() function from the Matthew Kay’s tidybayes package made it easy to compute those values with the point_interval = mode_hdi argument. Note how we also used tidybayes::mode_hdi() to compute those values and plug them into scale_x_continuous(). 11.6.2 Inference about the indirect effect. Much like above, we can make a plot of the conditional indirect effect \\(ab_3\\). post &lt;- post %&gt;% mutate(ab_3 = b_negtone_dysfunc * `b_perform_negtone:negexp`) # breaks breaks &lt;- mode_hdi(post$ab_3, .width = .95) %&gt;% pivot_longer(starts_with(&quot;y&quot;)) %&gt;% pull(value) post %&gt;% ggplot(aes(x = ab_3)) + geom_histogram(binwidth = .025, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointinterval(aes(y = 0), point_interval = mode_hdi, .width = .95) + scale_x_continuous(expression(paste(&quot;The indirect effect, &quot;, italic(ab)[3])), breaks = breaks, labels = round(breaks, digits = 3)) + scale_y_continuous(NULL, breaks = NULL) + theme_bw() + theme(axis.line.x = element_line(size = 1/4), panel.border = element_blank(), panel.grid = element_blank()) 11.6.3 Probing moderation of mediation. One of the contributions of Preacher et al. (2007) to the literature on moderated mediation analysis was their discussion of inference for conditional indirect effects. They suggested two approaches, one a normal theory-based approach that is an analogue of the Sobel test in unmoderated mediation analysis, and another based on bootstrapping. (p. 426) One of the contributions of this project is moving away from NHST in favor of Bayesian modeling. Since we’ve already been referencing him with our plot themes, you might check out Kruschke’s (2015) textbook for more discussion on Bayes versus NHST. 11.6.3.1 Normal theory approach. As we’re square within the Bayesian modeling paradigm, we have no need to appeal to normal theory for the posterior \\(SD\\)s or 95% intervals. 11.6.3.2 Bootstrap confidence intervals Two types of Bayesian credible intervals. We produced the posterior means corresponding to those in Table 11.3 some time ago. Here they are, again, with percentile-based 95% intervals via tidybayes::mean_qi(). post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(`a(b1 + b3w)` = a * (b1 + b3 * w)) %&gt;% group_by(w) %&gt;% mean_qi(`a(b1 + b3w)`) %&gt;% select(w:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 4 ## w `a(b1 + b3w)` .lower .upper ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.531 -0.1 -0.408 0.171 ## 2 -0.006 -0.267 -0.525 -0.073 ## 3 0.6 -0.46 -0.813 -0.177 If we wanted to summarize those same effects with posterior modes and 95% highest posterior density intervals, instead, we’d replace our mean_qi() lnie with mode_hdi(). post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(`a(b1 + b3w)` = a * (b1 + b3 * w)) %&gt;% group_by(w) %&gt;% mode_hdi(`a(b1 + b3w)`) %&gt;% select(w:.upper) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 4 ## w `a(b1 + b3w)` .lower .upper ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 -0.531 -0.056 -0.397 0.177 ## 2 -0.006 -0.229 -0.495 -0.054 ## 3 0.6 -0.421 -0.792 -0.158 And we might plot these with something like this. post %&gt;% mutate(a = b_negtone_dysfunc, b1 = b_perform_negtone, b3 = `b_perform_negtone:negexp`) %&gt;% expand(nesting(a, b1, b3), w = c(-0.531, -0.006, 0.600)) %&gt;% mutate(`a(b1 + b3w)` = a * (b1 + b3 * w)) %&gt;% select(w:`a(b1 + b3w)`) %&gt;% mutate(label = str_c(&quot;W = &quot;, w), w = fct_reorder(label, w)) %&gt;% ggplot(aes(y = `a(b1 + b3w)`)) + geom_hline(yintercept = 0, color = &quot;grey50&quot;, linetype = 2) + geom_histogram(binwidth = .05, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointinterval(aes(x = 0), point_interval = mode_hdi, .width = .95) + scale_x_continuous(NULL, breaks = NULL) + scale_y_continuous(&quot;The conditional indirect effect&quot;, limits = c(-1.25, .75)) + theme_bw() + theme(axis.line.y = element_line(size = 1/4), panel.border = element_blank(), panel.grid = element_blank(), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;), strip.text = element_text(hjust = 0)) + facet_wrap(~ w, nrow = 1) This, of course, leads us right into the next section. 11.6.3.3 A Johnson-Neyman approach. On page 429, Hayes discussed how Preacher et al. (2007)’s attempt to apply the JN technique in this context presumed the sampling distribution of the conditional indirect effect is normal. Given that the sampling distribution of the conditional indirect effect is not normal, the approach they describe yields, at best, an approximate solution. To [Hayes’s] knowledge, no one has ever proposed a bootstrapping-based analogue of the Johnson-Neyman method for probing the moderation of an indirect effect. However, our Bayesian HMC approach makes no such assumption. All we need to do is manipulate the posterior as usual. Here it is, this time using all 4,000 iterations. post %&gt;% transmute(iter = 1:n(), `-0.8` = b_perform_negtone + `b_perform_negtone:negexp` * -0.8, `0.8` = b_perform_negtone + `b_perform_negtone:negexp` * 0.8) %&gt;% pivot_longer(-iter) %&gt;% mutate(name = name %&gt;% as.double()) %&gt;% ggplot(aes(x = name, y = value, group = iter)) + geom_line(color = &quot;skyblue3&quot;, size = 1/6, alpha = 1/15) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(italic(W)), y = &quot;The conditional indirect effect&quot;) + theme_bw() + theme(panel.grid = element_blank()) Glorious. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 svUnit_1.0.3 ## [6] sp_1.4-4 splines_4.0.4 crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 ## [11] inline_0.3.17 digest_0.6.27 htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 ## [16] checkmate_2.0.0 magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 ## [21] xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 rvest_1.0.1 ## [26] ggdist_3.0.0 haven_2.3.1 xfun_0.23 callr_3.7.0 crayon_1.4.1 ## [31] jsonlite_1.7.2 lme4_1.1-25 survival_3.2-10 zoo_1.8-8 glue_1.4.2 ## [36] gtable_0.3.0 emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [41] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 ## [46] miniUI_0.1.1.1 xtable_1.8-4 HDInterval_0.2.2 stats4_4.0.4 StanHeaders_2.21.0-7 ## [51] DT_0.16 htmlwidgets_1.5.3 httr_1.4.2 threejs_0.3.3 arrayhelpers_1.1-0 ## [56] posterior_1.0.1 ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 ## [61] sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 tidyselect_1.1.1 labeling_0.4.2 ## [66] rlang_0.4.11 reshape2_1.4.4 later_1.2.0 munsell_0.5.0 cellranger_1.1.0 ## [71] tools_4.0.4 cli_3.0.1 generics_0.1.0 broom_0.7.6 ggridges_0.5.3 ## [76] evaluate_0.14 fastmap_1.1.0 processx_3.5.2 knitr_1.33 fs_1.5.0 ## [81] nlme_3.1-152 mime_0.10 projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 ## [86] bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 gamm4_0.2-6 curl_4.3 ## [91] reprex_2.0.0 statmod_1.4.35 bslib_0.2.4 stringi_1.6.2 highr_0.9 ## [96] ps_1.6.0 Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 ## [101] markdown_1.1 tensorA_0.36.2 shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 ## [106] lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 estimability_1.3 raster_3.4-5 ## [111] httpuv_1.6.0 R6_2.5.0 bookdown_0.22 promises_1.2.0.1 gridExtra_2.3 ## [116] codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 ## [121] assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 mgcv_1.8-33 ## [126] parallel_4.0.4 hms_1.1.0 grid_4.0.4 coda_0.19-4 minqa_1.2.4 ## [131] rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Kruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/ Preacher, K. J., Rucker, D. D., &amp; Hayes, A. F. (2007). Addressing moderated mediation hypotheses: Theory, methods, and prescriptions. Multivariate Behavioral Research, 42(1), 185–227. https://doi.org/10.1080/00273170701341316 "],["further-examples-of-conditional-process-analysis.html", "12 Further Examples of Conditional Process Analysis 12.1 Revisiting the disaster framing study 12.2 Moderation of the direct and indirect effects in a conditional process model 12.3 Statistical inference 12.4 Mediated moderation Session info", " 12 Further Examples of Conditional Process Analysis In this chapter [Hayes built] on the foundation laid by stepping through an analysis of a more complicated conditional process model that include[d] moderation of both the indirect effects in a simple mediation model. [He did] so by first using a piecemeal approach that focuse[d] on each pathway in the model. With some understanding gained by this examination of the components in the process, [he brought] the pieces together into an integrated conditional process analysis… When an indirect effect of \\(X\\) on \\(Y\\) through \\(M\\) is moderated, we call this phenomenon moderated mediation. In such a scenario, the mechanism represented by the \\(X \\rightarrow M \\rightarrow Y\\) chain of events operates to varying degrees (or not at all) for certain people or in certain contexts. A similar-sounding phenomenon is mediated moderation, which refers to the scenario in which an interaction between X and some moderator \\(W\\) on \\(Y\\) is carried through a mediator \\(M\\). [We’ll see] in this chapter that a mediated moderation analysis is really nothing other than a mediation analysis with the product of two variables serving as the causal agent of focus. (Andrew F. Hayes, 2018, p. 432) 12.1 Revisiting the disaster framing study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) ## Rows: 211 ## Columns: 5 ## $ id &lt;dbl&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 2… ## $ frame &lt;dbl&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0,… ## $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5.4, 3.4, 7.… ## $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.65, 3.15, 2.… ## $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1.0, 6.4, 3.… Load brms. library(brms) At the top of page 433, Hayes fit a simple univariable model \\[Y = b_0 + b_1 X + e_Y,\\] where the \\(X\\) is frame the \\(Y\\) is donate. Here’s the model. model12.1 &lt;- brm(data = disaster, family = gaussian, donate ~ 1 + frame, chains = 4, cores = 4, file = &quot;fits/model12.01&quot;) Check the summary. print(model12.1, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: donate ~ 1 + frame ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 4.561 0.125 4.317 4.809 1.001 5175 3173 ## frame 0.088 0.187 -0.278 0.459 1.001 4815 3077 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.328 0.067 1.207 1.466 1.000 3697 2849 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Hayes interpreted the coefficient for frame through the lens of a \\(t\\) statistic and accompanying \\(p\\)-value. We’ll just plot the posterior. For the figures in this chapter, we’ll take theme cues from the vignettes from Matthew Kay’s tidybayes package. library(tidybayes) theme_set(theme_tidybayes() + cowplot::panel_border()) posterior_samples(model12.1) %&gt;% ggplot(aes(x = b_frame, y = 0)) + stat_halfeye() + geom_vline(xintercept = 0, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) Now we fit the moderation model \\[Y = b_0 + b_1 X + b_2 W + b_3 XW + e_Y,\\] where skeptic is the \\(W\\) variable. model12.2 &lt;- brm(data = disaster, family = gaussian, donate ~ 1 + frame + skeptic + frame:skeptic, chains = 4, cores = 4, file = &quot;fits/model12.02&quot;) Our model12.2 summary matches nicely with the text. print(model12.2, digits = 3) ## Family: gaussian ## Links: mu = identity; sigma = identity ## Formula: donate ~ 1 + frame + skeptic + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## Intercept 5.026 0.222 4.598 5.472 1.003 2316 2709 ## frame 0.681 0.332 0.027 1.324 1.001 2032 2692 ## skeptic -0.139 0.057 -0.248 -0.028 1.001 2189 2751 ## frame:skeptic -0.170 0.084 -0.333 -0.005 1.000 1835 2232 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma 1.243 0.061 1.130 1.369 1.000 3409 2635 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Here’s our Figure 12.2. nd &lt;- crossing(frame = 0:1, skeptic = seq(from = 0, to = 7, length.out = 30)) fitted(model12.2, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(frame = ifelse(frame == 0, str_c(&quot;Natural causes (X = &quot;, frame, &quot;)&quot;), str_c(&quot;Climate change (X = &quot;, frame, &quot;)&quot;))) %&gt;% mutate(frame = factor(frame, levels = c(&quot;Natural causes (X = 0)&quot;, &quot;Climate change (X = 1)&quot;))) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(color = frame)) + scale_fill_brewer(palette = &quot;Set2&quot;) + scale_color_brewer(palette = &quot;Set2&quot;) + coord_cartesian(xlim = c(1, 6), ylim = c(3.5, 5.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Willingness to Donate to Victims&quot;) + theme(legend.direction = &quot;horizontal&quot;, legend.position = &quot;top&quot;, legend.title = element_blank()) In Hayes’s Figure 12.2, he emphasized the differences at the three levels of skeptic. If you want the full difference score distributions in a pick-a-point-approach sort of way, you might plot the densities with tidybayes::stat_halfeye(), which places coefficient plots at the base of the densities. In this case, we show the posterior medians with the dots, the 50% intervals with the thick horizontal lines, and the 95% intervals with the thinner horizontal lines. nd &lt;- crossing(frame = 0:1, skeptic = quantile(disaster$skeptic, probs = c(.16, .5, .86))) fitted(model12.2, summary = F, newdata = nd) %&gt;% as_tibble() %&gt;% set_names(mutate(nd, label = str_c(frame, &quot;_&quot;, skeptic)) %&gt;% pull(label)) %&gt;% mutate(iter = 1:n()) %&gt;% pivot_longer(-iter) %&gt;% separate(name, into = c(&quot;frame&quot;, &quot;skeptic&quot;), sep = &quot;_&quot;, convert = T) %&gt;% pivot_wider(names_from = frame, values_from = value) %&gt;% mutate(difference = `1` - `0`) %&gt;% ggplot(aes(x = difference, y = skeptic, fill = skeptic %&gt;% as.character())) + stat_halfeye(point_interval = median_qi, .width = c(0.95, 0.5)) + scale_fill_brewer() + scale_y_continuous(breaks = quantile(disaster$skeptic, probs = c(.16, .5, .86)), labels = quantile(disaster$skeptic, probs = c(.16, .5, .86)) %&gt;% round(2)) + theme(legend.position = &quot;none&quot;) Here’s our simple mediation model, model12.3, using the multivariate syntax right in the brm() function. model12.3 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame) + bf(donate ~ 1 + frame + justify) + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model12.03&quot;) print(model12.3, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame ## donate ~ 1 + frame + justify ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.803 0.091 2.624 2.979 1.001 5717 2773 ## donate_Intercept 7.237 0.232 6.785 7.695 1.001 6962 2824 ## justify_frame 0.135 0.130 -0.116 0.397 1.001 5889 2747 ## donate_frame 0.214 0.139 -0.054 0.492 1.000 6815 2978 ## donate_justify -0.954 0.075 -1.104 -0.809 1.001 6780 2728 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.936 0.046 0.853 1.030 1.000 6263 3297 ## sigma_donate 0.986 0.048 0.900 1.083 1.000 6631 3225 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Consider the Bayesian \\(R^2\\) summaries. bayes_R2(model12.3) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2justify 0.01 0.012 0.000 0.043 ## R2donate 0.45 0.038 0.369 0.519 If you want the indirect effect with its intervals, you use posterior_samples() and data wrangle, as usual. posterior_samples(model12.3) %&gt;% mutate(ab = b_justify_frame * b_donate_justify) %&gt;% mean_qi(ab) ## # A tibble: 1 x 6 ## ab .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.129 -0.381 0.112 0.95 mean qi 12.2 Moderation of the direct and indirect effects in a conditional process model Our conditional process model follows the form \\[\\begin{align*} M &amp; = i_M + a_1 X + a_2 W + a_3 XW + e_M \\\\ Y &amp; = i_Y + c_1&#39; X + c_2&#39; W + c_3&#39; XW + b M + e_Y. \\end{align*}\\] We don’t need to do anything particularly special to fit a model like this with brms. It just requires we do a careful job specifying the formulas in our bf() arguments. If you find this syntax a little too cumbersome, you can always specify the formulas outside of brm(), save them as one or multiple objects, and plug those objects into brm(). model12.4 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame + skeptic + frame:skeptic) + bf(donate ~ 1 + frame + justify + skeptic + frame:skeptic) + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model12.04&quot;) Check the model summary. print(model12.4, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame + skeptic + frame:skeptic ## donate ~ 1 + frame + justify + skeptic + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.447 0.150 2.160 2.745 1.000 3956 3352 ## donate_Intercept 7.286 0.280 6.747 7.826 1.000 4162 2876 ## justify_frame -0.557 0.223 -0.980 -0.104 1.000 3525 3009 ## justify_skeptic 0.106 0.038 0.034 0.181 1.001 3702 3090 ## justify_frame:skeptic 0.200 0.057 0.085 0.307 1.000 3168 2893 ## donate_frame 0.168 0.270 -0.379 0.712 1.000 3188 2643 ## donate_justify -0.922 0.086 -1.090 -0.752 1.000 5319 2789 ## donate_skeptic -0.042 0.047 -0.135 0.052 1.000 3636 3050 ## donate_frame:skeptic 0.013 0.070 -0.123 0.151 1.001 3094 2861 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.817 0.040 0.746 0.898 1.001 5516 2974 ## sigma_donate 0.989 0.051 0.895 1.095 1.001 5520 2638 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Here are the Bayesian \\(R^2\\) summaries. bayes_R2(model12.4) ## Estimate Est.Error Q2.5 Q97.5 ## R2justify 0.2488686 0.04278815 0.1637038 0.3285313 ## R2donate 0.4522253 0.03772236 0.3730654 0.5195589 12.2.1 Estimation using PROCESS. We just fit that model. Next! 12.2.2 Quantifying direct and indirect effects. Here are summaries for \\(a_1\\) through \\(a_3\\). fixef(model12.4)[c(3:5), ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## justify_frame -0.557 0.223 -0.980 -0.104 ## justify_skeptic 0.106 0.038 0.034 0.181 ## justify_frame:skeptic 0.200 0.057 0.085 0.307 This is \\(b\\). fixef(model12.4)[&quot;donate_justify&quot;, ] %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## -0.922 0.086 -1.090 -0.752 We’ll need to employ posterior_samples() to compute \\((a_1 + a_3 W)b\\), as shown in Table 12.2. post &lt;- posterior_samples(model12.4) %&gt;% mutate(`indirect effect when W is 1.592` = (b_justify_frame + `b_justify_frame:skeptic` * 1.592) * b_donate_justify, `indirect effect when W is 2.800` = (b_justify_frame + `b_justify_frame:skeptic` * 2.800) * b_donate_justify, `indirect effect when W is 5.200` = (b_justify_frame + `b_justify_frame:skeptic` * 5.200) * b_donate_justify) post %&gt;% pivot_longer(starts_with(&quot;indirect&quot;)) %&gt;% group_by(name) %&gt;% median_qi(value, .prob = .95) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 3 x 7 ## name value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 indirect effect when W is 1.592 0.219 -0.056 0.511 0.95 median qi ## 2 indirect effect when W is 2.800 -0.001 -0.218 0.218 0.95 median qi ## 3 indirect effect when W is 5.200 -0.439 -0.754 -0.165 0.95 median qi And if you really want that full-on Table 12.2 layout, try this. post %&gt;% mutate(a1 = b_justify_frame, a3 = `b_justify_frame:skeptic`, b = b_donate_justify, c1 = b_donate_frame, c3 = `b_donate_frame:skeptic`) %&gt;% expand(nesting(a1, a3, b, c1, c3), w = c(1.592, 2.800, 5.200)) %&gt;% mutate(`a1 + a3w` = a1 + a3 * w, `(a1 + a3w)b` = (a1 + a3 * w) * b, `direct effect` = c1 + c3 * w) %&gt;% select(-(a1:a3), -(c1:c3)) %&gt;% pivot_longer(-w) %&gt;% group_by(w, name) %&gt;% summarise(mean = mean(value) %&gt;% round(digits = 3)) %&gt;% pivot_wider(names_from = name, values_from = mean) %&gt;% select(w, `a1 + a3w`, b, everything()) ## # A tibble: 3 x 5 ## # Groups: w [3] ## w `a1 + a3w` b `(a1 + a3w)b` `direct effect` ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 1.59 -0.239 -0.922 0.221 0.188 ## 2 2.8 0.002 -0.922 -0.002 0.203 ## 3 5.2 0.481 -0.922 -0.444 0.233 12.2.2.1 The conditional direct effect of \\(X\\). We already computed this in the last code block, above. But since we just focused on the posterior means, here’s a summary of their medians and 95% intervals. post &lt;- post %&gt;% mutate(`direct effect when W is 1.592` = b_donate_frame + `b_donate_frame:skeptic` * 1.592, `direct effect when W is 2.800` = b_donate_frame + `b_donate_frame:skeptic` * 2.800, `direct effect when W is 5.200` = b_donate_frame + `b_donate_frame:skeptic` * 5.200) post %&gt;% pivot_longer(starts_with(&quot;direct&quot;)) %&gt;% group_by(name) %&gt;% median_qi(value, .width = .95) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) ## # A tibble: 3 x 4 ## name value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 direct effect when W is 1.592 0.184 -0.174 0.553 ## 2 direct effect when W is 2.800 0.201 -0.072 0.485 ## 3 direct effect when W is 5.200 0.234 -0.136 0.599 We can always plot, too. w &lt;- c(1.592, 2.800, 5.200) post %&gt;% expand(nesting(b_donate_frame, `b_donate_frame:skeptic`), w = w) %&gt;% mutate(`conditional direct effect` = b_donate_frame + `b_donate_frame:skeptic` * w) %&gt;% ggplot(aes(x = `conditional direct effect`, y = w, fill = w %&gt;% as.character())) + stat_halfeye(point_interval = median_qi, .width = c(0.95, 0.5)) + scale_y_continuous(breaks = w) + scale_fill_brewer() + theme(legend.position = &quot;none&quot;) 12.2.3 Visualizing the direct and indirect effects. We’ll need to do some post wrangling before we’re ready to make our Figure 12.7. We’ll save the results as effects. effects &lt;- post %&gt;% expand(nesting(b_justify_frame, `b_justify_frame:skeptic`, b_donate_justify, b_donate_frame, `b_donate_frame:skeptic`), w = seq(from = 0, to = 6, length.out = 30)) %&gt;% mutate(`direct effect` = b_donate_frame + `b_donate_frame:skeptic` * w, `indirect effect` = (b_justify_frame + `b_justify_frame:skeptic` * w) * b_donate_justify) %&gt;% pivot_longer(c(`direct effect`, `indirect effect`)) %&gt;% mutate(name = factor(name, levels = c(&quot;direct effect&quot;, &quot;indirect effect&quot;))) %&gt;% select(w:value) head(effects) ## # A tibble: 6 x 3 ## w name value ## &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; ## 1 0 direct effect 0.158 ## 2 0 indirect effect 1.37 ## 3 0.207 direct effect 0.163 ## 4 0.207 indirect effect 1.30 ## 5 0.414 direct effect 0.167 ## 6 0.414 indirect effect 1.22 Now we plot. # we&#39;ll need this for `geom_text()` text &lt;- tibble(x = c(4.2, 4.7), y = c(.28, -.28), angle = c(3.6, 335), name = factor(c(&quot;direct effect&quot;, &quot;indirect effect&quot;), levels = c(&quot;direct effect&quot;, &quot;indirect effect&quot;))) # plot! effects %&gt;% ggplot(aes(x = w, color = name, fill = name)) + stat_lineribbon(aes(y = value), .width = .95, alpha = 1/3) + geom_text(data = text, aes(x = x, y = y, angle = angle, label = name), size = 5) + scale_fill_brewer(type = &quot;qual&quot;) + scale_color_brewer(type = &quot;qual&quot;) + coord_cartesian(xlim = c(1, 5.5), ylim = c(-.6, .4)) + labs(x = expression(Climate~Change~Skepticism~(italic(W))), y = &quot;Effects of Disaster Frame on Willingness to Donate&quot;) + theme(legend.position = &quot;none&quot;) Note how wide those 95% intervals are relative to the scale of the \\(y\\)-axis, which I specifically kept within the same range as Figure 12.7 in the text. To me the message is clear: include credible-interval ribbons in your regression slope plots. They help depict how uncertain the posterior is in a way a simple line slopes just don’t. 12.3 Statistical inference 12.3.1 Inference about the direct effect. We’ve already computed the 95% intervals for the direct effect, \\(\\theta_{X \\rightarrow Y}\\), conditional on the three levels of \\(W\\). Here’s a different look at those intervals, superimposed on the 80% and 50% intervals, using the tidybayes::stat_interval() function. post %&gt;% pivot_longer(starts_with(&quot;direct&quot;)) %&gt;% mutate(name = str_remove(name, &quot;direct effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = name, y = value, group = name)) + stat_interval(.width = c(.95, .80, .5)) + scale_color_brewer(&quot;Interval&quot;) + coord_cartesian(xlim = c(1, 5.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Conditional Direct Effect of Disaster Frame on\\nWillingness to Donate&quot;) 12.3.2 Inference about the indirect effect. 12.3.2.1 A statistical test of moderated mediation. To get a sense of \\(a_3 b\\), we just: post &lt;- post %&gt;% mutate(a3b = `b_justify_frame:skeptic` * b_donate_justify) post %&gt;% select(a3b) %&gt;% median_qi(a3b) %&gt;% mutate_if(is.double, round, digits = 3) ## # A tibble: 1 x 6 ## a3b .lower .upper .width .point .interval ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 -0.183 -0.301 -0.076 0.95 median qi Here we’ll combine stat_intervalh() and stat_pointintervalh() to visualize \\(a_3 b\\) with a coefficient plot. post %&gt;% ggplot(aes(x = a3b, y = 1)) + stat_interval(.width = c(.95, .8, .5)) + stat_pointinterval(point_interval = median_qi, .width = c(.95, .8, .5), position = position_nudge(y = -.75)) + scale_color_brewer(&quot;Interval&quot;) + scale_y_discrete(NULL, breaks = NULL) + coord_cartesian(xlim = c(-.5, 0)) + labs(title = expression(paste(&quot;Coefficient plot for &quot;, italic(a)[3], italic(b), &quot; (i.e., the index of moderated mediation)&quot;)), x = NULL) + theme(legend.position = &quot;none&quot;) 12.3.2.2 Probing moderation of mediation. As we discussed in Chapter 11, our Bayesian version of the JN technique should be fine because HMC does not impose the normality assumption on the parameter posteriors. In this instance, I’ll leave the JN technique plot as an exercise for the interested reader. Here we’ll just follow along with the text and pick a few points. We computed and inspected these 95% intervals, above. Here’s another way we might stat_halfeye() to look at their entire densities. post %&gt;% pivot_longer(starts_with(&quot;indirect&quot;)) %&gt;% rename(`conditional indirect effect` = value) %&gt;% mutate(W = str_remove(name, &quot;indirect effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = W, y = `conditional indirect effect`, fill = W %&gt;% as.character())) + geom_hline(yintercept = 0, linetype = 2) + stat_halfeye(point_interval = median_qi, .width = 0.95) + scale_fill_brewer() + scale_x_continuous(breaks = c(1.592, 2.8, 5.2), labels = c(1.6, 2.8, 5.2)) + coord_cartesian(ylim = c(-1, 1)) + theme(legend.position = &quot;none&quot;, panel.grid.minor.y = element_blank()) 12.3.3 Pruning the model. Fitting the model without the interaction term is just a small change to one of our formula arguments. model12.5 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame + skeptic + frame:skeptic) + bf(donate ~ 1 + frame + justify + skeptic) + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model12.05&quot;) Here are the results. print(model12.5, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame + skeptic + frame:skeptic ## donate ~ 1 + frame + justify + skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.452 0.152 2.154 2.751 1.000 3011 3020 ## donate_Intercept 7.260 0.223 6.819 7.687 1.001 5343 3003 ## justify_frame -0.563 0.219 -0.992 -0.141 1.001 2829 2791 ## justify_skeptic 0.105 0.039 0.026 0.182 1.000 3021 2964 ## justify_frame:skeptic 0.201 0.055 0.092 0.313 1.000 2740 2724 ## donate_frame 0.211 0.129 -0.044 0.461 1.001 4524 3203 ## donate_justify -0.919 0.081 -1.075 -0.756 1.001 4244 3245 ## donate_skeptic -0.037 0.037 -0.111 0.035 1.000 4714 3044 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.818 0.042 0.742 0.907 1.001 4651 2751 ## sigma_donate 0.985 0.048 0.894 1.086 1.000 4531 2657 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Since we’re altering the model, we may as well use information criteria to compare the two versions. model12.4 &lt;- add_criterion(model12.4, &quot;loo&quot;) model12.5 &lt;- add_criterion(model12.5, &quot;loo&quot;) loo_compare(model12.4, model12.5) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model12.5 0.0 0.0 -557.6 16.6 10.8 1.3 1115.1 33.1 ## model12.4 -1.2 0.2 -558.8 16.6 12.1 1.5 1117.6 33.3 The difference in LOO-CV values for the two models was modest. There’s little predictive reason to choose one over the other. You could argue in favor of model12.5 because it’s simpler than model12.4. Since we’ve got a complex model either way, one might also consider which one was of primary theoretical interest. 12.4 Mediated moderation Mediation is moderated if the indirect effect of \\(X\\) on \\(Y\\) through one or more mediators is contingent on a moderator. With evidence of moderated mediation, one can claim that the \\(X \\rightarrow M \\rightarrow Y\\) chain of events functions differently or to varying degrees for different people, in different contexts or conditions, or whatever the moderator variable represents. Although similar in name and pronunciation to moderated mediation, the term mediated moderation refers to the phenomenon in which an interaction between \\(X\\) and a moderator \\(W\\) in a model of \\(Y\\) is carried through a mediator. (p. 459, emphasis in the original) Hayes later opined: Although there is an abundance of published examples of mediated moderation analysis, their frequency of occurrence in the literature should not be confused with meaningfulness of the procedure itself. I will argue toward the end of this section that rarely is the phenomenon of mediated moderation interesting when interpreted as such. It is almost always substantively more meaningful to conceptualize a mediated moderation process in terms of moderated mediation. But before doing this, I will describe how a mediated moderation analysis is undertaken. (p. 460) 12.4.1 Mediated moderation as the indirect effect of a product. Hayes explains this in the next subsection, but we’ve already fit this model presented in this subsection. We called it model12.4. Here’s the summary. print(model12.4, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: justify ~ 1 + frame + skeptic + frame:skeptic ## donate ~ 1 + frame + justify + skeptic + frame:skeptic ## Data: disaster (Number of observations: 211) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## justify_Intercept 2.447 0.150 2.160 2.745 1.000 3956 3352 ## donate_Intercept 7.286 0.280 6.747 7.826 1.000 4162 2876 ## justify_frame -0.557 0.223 -0.980 -0.104 1.000 3525 3009 ## justify_skeptic 0.106 0.038 0.034 0.181 1.001 3702 3090 ## justify_frame:skeptic 0.200 0.057 0.085 0.307 1.000 3168 2893 ## donate_frame 0.168 0.270 -0.379 0.712 1.000 3188 2643 ## donate_justify -0.922 0.086 -1.090 -0.752 1.000 5319 2789 ## donate_skeptic -0.042 0.047 -0.135 0.052 1.000 3636 3050 ## donate_frame:skeptic 0.013 0.070 -0.123 0.151 1.001 3094 2861 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_justify 0.817 0.040 0.746 0.898 1.001 5516 2974 ## sigma_donate 0.989 0.051 0.895 1.095 1.001 5520 2638 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). 12.4.2 Why mediated moderation is neither interesting nor meaningful. Mediated moderation and moderated mediation are statistically the same. The only difference between them is how they are interpreted, and on what part of the model your attention is focused. Moderated mediation focuses on the conditional nature of an indirect effect–how an indirect effect is moderated. If you think of the terms “mediation” and “indirect effect” as essentially synonymous conceptually, then moderated mediation means a moderated indirect effect. Interpretive focus in a moderated mediation analysis is directed at estimating the indirect effect and how that effect varies as a function of a moderator. Mediated moderation, by contrast, asks about the mechanism through which an interaction between \\(X\\) and a moderator \\(W\\) operates, where the product of \\(X\\) and \\(W\\) is construed as the causal agent sending its effect to \\(Y\\) through \\(M\\). Focus in mediated moderation is the estimation of the indirect effect of the product of \\(X\\) and \\(W\\). (p. 465) Hayes later concluded that we should avoid the articulation of hypotheses or research questions in terms of the mediation of the effect of a product, abandoning the term mediated moderation entirely, and instead [reframe] such hypotheses and research questions in terms of the contingencies of an indirect effect–moderated mediation. (p. 467, emphasis in the original) Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 dplyr_1.0.6 ## [7] purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 svUnit_1.0.3 ## [6] sp_1.4-4 splines_4.0.4 crosstalk_1.1.0.1 TH.data_1.0-10 rstantools_2.1.1 ## [11] inline_0.3.17 digest_0.6.27 htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 ## [16] checkmate_2.0.0 magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 ## [21] xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 rvest_1.0.1 ## [26] ggdist_3.0.0 haven_2.3.1 xfun_0.23 callr_3.7.0 crayon_1.4.1 ## [31] jsonlite_1.7.2 lme4_1.1-25 survival_3.2-10 zoo_1.8-8 glue_1.4.2 ## [36] gtable_0.3.0 emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [41] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 DBI_1.1.0 ## [46] miniUI_0.1.1.1 xtable_1.8-4 stats4_4.0.4 StanHeaders_2.21.0-7 DT_0.16 ## [51] htmlwidgets_1.5.3 httr_1.4.2 threejs_0.3.3 RColorBrewer_1.1-2 arrayhelpers_1.1-0 ## [56] posterior_1.0.1 ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 ## [61] sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 labeling_0.4.2 tidyselect_1.1.1 ## [66] rlang_0.4.11 reshape2_1.4.4 later_1.2.0 munsell_0.5.0 cellranger_1.1.0 ## [71] tools_4.0.4 cli_3.0.1 generics_0.1.0 broom_0.7.6 ggridges_0.5.3 ## [76] evaluate_0.14 fastmap_1.1.0 processx_3.5.2 knitr_1.33 fs_1.5.0 ## [81] nlme_3.1-152 mime_0.10 projpred_2.0.2 xml2_1.3.2 compiler_4.0.4 ## [86] bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 gamm4_0.2-6 curl_4.3 ## [91] reprex_2.0.0 statmod_1.4.35 bslib_0.2.4 stringi_1.6.2 highr_0.9 ## [96] ps_1.6.0 Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 ## [101] markdown_1.1 tensorA_0.36.2 shinyjs_2.0.0 vctrs_0.3.8 pillar_1.6.1 ## [106] lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 estimability_1.3 cowplot_1.1.1 ## [111] raster_3.4-5 httpuv_1.6.0 R6_2.5.0 bookdown_0.22 promises_1.2.0.1 ## [116] gridExtra_2.3 codetools_0.2-18 boot_1.3-26 colourpicker_1.1.0 MASS_7.3-53 ## [121] gtools_3.8.2 assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 ## [126] mgcv_1.8-33 parallel_4.0.4 hms_1.1.0 grid_4.0.4 coda_0.19-4 ## [131] minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 lubridate_1.7.10 base64enc_0.1-3 ## [136] dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 "],["conditional-process-analysis-with-a-multicategorical-antecedent.html", "13 Conditional Process Analysis with a Multicategorical Antecedent 13.1 Revisiting sexual discrimination in the workplace 13.2 Looking at the components of the indirect effect of \\(X\\) 13.3 Relative conditional indirect effects 13.4 Testing and probing moderation of mediation 13.5 Relative conditional direct effects Session info", " 13 Conditional Process Analysis with a Multicategorical Antecedent With his opening lines, Hayes prepared us: At the end of any great fireworks show is the grand finale, where the pyrotechnicians throw everything remaining in their arsenal at you at once, leaving you amazed, dazed, and perhaps temporarily a little hard of hearing. Although this is not the final chapter of this book, I am now going to throw everything at you at once with an example of the most complicated conditional process model I will cover in this book. (Andrew F. Hayes, 2018, p. 469) Enjoy the fireworks. 🎆 13.1 Revisiting sexual discrimination in the workplace Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) ## Rows: 129 ## Columns: 6 ## $ subnum &lt;dbl&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, 1… ## $ protest &lt;dbl&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, … ## $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.8… ## $ angry &lt;dbl&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1, … ## $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.5… ## $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.2… With a little ifelse(), we can make the d1 and d2 contrast-coded dummies. protest &lt;- protest %&gt;% mutate(d1 = ifelse(protest == 0, -2/3, 1/3), d2 = ifelse(protest == 0, 0, ifelse(protest == 1, -1/2, 1/2))) Now load brms. library(brms) Our statistical model follows two primary equations, \\[\\begin{align*} M &amp; = i_M + a_1 D_1 + a_2 D_2 + a_3 W + a_4 D_1 W + a_5 D_2 W + e_M \\\\ Y &amp; = i_Y + c_1&#39; D_1 + c_2&#39; D_2 + c_3&#39; W + c_4&#39; D_1 W + c_5&#39; D_2 W + b M + e_Y. \\end{align*}\\] Here’s how we might specify the sub-model formulas with bf(). m_model &lt;- bf(respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism) y_model &lt;- bf(liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism + respappr) Now we’re ready to fit our primary model, the conditional process model with a multicategorical antecedent. model13.1 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model13.01&quot;) Here’s the model summary, which coheres reasonably well with the output in Table 13.1. print(model13.1, digits = 3) ## Family: MV(gaussian, gaussian) ## Links: mu = identity; sigma = identity ## mu = identity; sigma = identity ## Formula: respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism ## liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism + respappr ## Data: protest (Number of observations: 129) ## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; ## total post-warmup samples = 4000 ## ## Population-Level Effects: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## respappr_Intercept 4.616 0.665 3.306 5.905 1.000 5481 3303 ## liking_Intercept 3.475 0.640 2.252 4.736 1.000 4894 3307 ## respappr_d1 -2.941 1.500 -5.804 0.090 1.001 2613 2287 ## respappr_d2 1.711 1.645 -1.439 4.969 1.002 3068 2677 ## respappr_sexism 0.039 0.129 -0.211 0.287 1.000 5611 3334 ## respappr_d1:sexism 0.856 0.290 0.269 1.404 1.001 2621 2258 ## respappr_d2:sexism -0.250 0.316 -0.870 0.353 1.001 3078 2564 ## liking_d1 -2.719 1.198 -5.112 -0.443 1.001 3374 2991 ## liking_d2 0.021 1.305 -2.532 2.688 1.001 2959 2647 ## liking_sexism 0.073 0.107 -0.136 0.280 1.001 4656 2895 ## liking_respappr 0.367 0.071 0.228 0.510 1.000 4932 3331 ## liking_d1:sexism 0.524 0.235 0.082 0.997 1.001 3339 2766 ## liking_d2:sexism -0.033 0.251 -0.539 0.452 1.001 3033 2776 ## ## Family Specific Parameters: ## Estimate Est.Error l-95% CI u-95% CI Rhat Bulk_ESS Tail_ESS ## sigma_respappr 1.147 0.074 1.012 1.298 1.000 4290 3036 ## sigma_liking 0.916 0.060 0.810 1.043 1.002 5095 2833 ## ## Samples were drawn using sampling(NUTS). For each parameter, Bulk_ESS ## and Tail_ESS are effective sample size measures, and Rhat is the potential ## scale reduction factor on split chains (at convergence, Rhat = 1). Instead of the table format of Hayes’s Table 3 (p. 475), why not display the parameter summaries in a coefficient plot? library(ggdark) library(tidybayes) post &lt;- posterior_samples(model13.1) post %&gt;% pivot_longer(starts_with(&quot;b_&quot;)) %&gt;% mutate(name = str_remove(name, &quot;b_&quot;)) %&gt;% separate(name, into = c(&quot;criterion&quot;, &quot;predictor&quot;), sep = &quot;_&quot;) %&gt;% mutate(criterion = factor(criterion, levels = c(&quot;respappr&quot;, &quot;liking&quot;)), predictor = factor(predictor, levels = c(&quot;Intercept&quot;, &quot;respappr&quot;, &quot;d2:sexism&quot;, &quot;d1:sexism&quot;, &quot;sexism&quot;, &quot;d2&quot;, &quot;d1&quot;))) %&gt;% ggplot(aes(x = value, y = predictor, group = predictor)) + stat_halfeye(.width = .95, normalize = &quot;xy&quot;, color = &quot;white&quot;, size = 1/3) + coord_cartesian(xlim = c(-7, 6)) + labs(x = NULL, y = NULL) + dark_theme_bw() + theme(axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank(), panel.grid.major = element_line(color = &quot;grey20&quot;), panel.grid.minor = element_blank()) + facet_wrap(~ criterion) Note our use of dark_theme_bw() from the ggdark package. The Bayesian \\(R^2\\) distributions are reasonably close to the estimates in the text. bayes_R2(model13.1) %&gt;% round(digits = 3) ## Estimate Est.Error Q2.5 Q97.5 ## R2respappr 0.321 0.054 0.211 0.420 ## R2liking 0.297 0.054 0.191 0.399 13.2 Looking at the components of the indirect effect of \\(X\\) A mediation process contains at least two “stages.” The first stage is the effect of the presumed causal antecedent variable \\(X\\) on the proposed mediator \\(M\\), and the second stage is the effect of the mediator \\(M\\) on the final consequent variable \\(Y\\). More complex models, such as the serial mediation model, will contain more stages. In a model such as the one that is the focus of this chapter with only a single mediator, the indirect effect of \\(X\\) on \\(Y\\) through \\(M\\) is quantified as the product of the effects in these two stages. When one or both of the stages of a mediation process is moderated, making sense of the indirect effect requires getting intimate with each of the stages, so that when they are integrated or multiplied together, you can better understand how differences or changes in \\(X\\) map on to differences in \\(Y\\) through a mediator differently depending on the value of a moderator. (p. 480) 13.2.1 Examining the first stage of the mediation process. When making a newdata object to feed into fitted() with more complicated models, it can be useful to review the model formula like so. model13.1$formula ## respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism ## liking ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism + respappr Now we’ll prep for and make our version of Figure 13.3. nd &lt;- tibble(d1 = c(1/3, -2/3, 1/3), d2 = c(1/2, 0, -1/2)) %&gt;% expand(nesting(d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) f1 &lt;- fitted(model13.1, newdata = nd, resp = &quot;respappr&quot;) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(condition = ifelse(d2 == 0, &quot;No Protest&quot;, ifelse(d2 == -1/2, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) protest &lt;- protest %&gt;% mutate(condition = ifelse(protest == 0, &quot;No Protest&quot;, ifelse(protest == 1, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) f1 %&gt;% ggplot(aes(x = sexism, group = condition)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), linetype = 3, color = &quot;white&quot;, fill = &quot;transparent&quot;) + geom_line(aes(y = Estimate), color = &quot;white&quot;) + geom_point(data = protest, aes(x = sexism, y = respappr), color = &quot;red&quot;, size = 2/3) + coord_cartesian(xlim = c(4, 6)) + labs(x = expression(Perceived~Pervasiveness~of~Sex~Discrimination~&quot;in&quot;~Society~(italic(W))), y = expression(Perceived~Appropriateness~of~Response~(italic(M)))) + dark_theme_bw() + theme(panel.grid = element_blank()) + facet_wrap(~condition) In order to get the \\(\\Delta R^2\\) distribution analogous to the change in \\(R^2\\) \\(F\\)-test Hayes discussed on page 482, we’ll have to first refit the model without the interaction for the \\(M\\) criterion. Here are the sub-models. m_model &lt;- bf(respappr ~ 1 + d1 + d2 + sexism) y_model &lt;- bf(liking ~ 1 + d1 + d2 + respappr + sexism + d1:sexism + d2:sexism) Now we fit model13.2. model13.2 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model13.02&quot;) With model13.2 in hand, we’re ready to compare \\(R^2\\) distributions. # extract the R2 draws and wrangle r2 &lt;- tibble(model13.1 = bayes_R2(model13.1, resp = &quot;respappr&quot;, summary = F)[, 1], model13.2 = bayes_R2(model13.2, resp = &quot;respappr&quot;, summary = F)[, 1]) %&gt;% mutate(difference = model13.1 - model13.2) # breaks breaks &lt;- median_qi(r2$difference, .width = .95) %&gt;% pivot_longer(starts_with(&quot;y&quot;)) %&gt;% pull(value) # plot! r2 %&gt;% ggplot(aes(x = difference, y = 0)) + stat_halfeye(fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .width = 0.95) + scale_x_continuous(expression(Delta*italic(R)^2), breaks = breaks, labels = round(breaks, digits = 2)) + scale_y_continuous(NULL, breaks = NULL) + dark_theme_bw() + theme(panel.grid = element_blank()) And we might also compare the models by their information criteria. model13.1 &lt;- add_criterion(model13.1, c(&quot;waic&quot;, &quot;loo&quot;)) model13.2 &lt;- add_criterion(model13.2, c(&quot;waic&quot;, &quot;loo&quot;)) loo_compare(model13.1, model13.2, criterion = &quot;loo&quot;) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_loo se_elpd_loo p_loo se_p_loo looic se_looic ## model13.1 0.0 0.0 -380.3 14.8 16.4 2.8 760.6 29.7 ## model13.2 -2.2 4.1 -382.5 14.8 13.8 2.4 765.0 29.7 loo_compare(model13.1, model13.2, criterion = &quot;waic&quot;) %&gt;% print(simplify = F) ## elpd_diff se_diff elpd_waic se_elpd_waic p_waic se_p_waic waic se_waic ## model13.1 0.0 0.0 -380.2 14.8 16.3 2.8 760.4 29.6 ## model13.2 -2.2 4.1 -382.4 14.8 13.7 2.4 764.8 29.7 The Bayesian \\(R^2\\), the LOO-CV, and the WAIC all suggest there’s little difference between the two models with respect to their predictive utility. In such a case, I’d lean on theory to choose between them. If inclined, one could also do Bayesian model averaging. Within our Bayesian modeling paradigm, we don’t have a direct analogue to the \\(F\\)-tests Hayes presented on page 483. We can just extract the fitted draws and wrangle to get the difference scores. # we need new `nd` data nd &lt;- protest %&gt;% distinct(d1, d2, condition) %&gt;% expand(nesting(condition, d1, d2), sexism = c(4.250, 5.120, 5.896)) # extract the fitted draws f1 &lt;- add_epred_draws(model13.1, newdata = nd, resp = &quot;respappr&quot;) %&gt;% ungroup() %&gt;% select(sexism, condition, .epred, .draw) %&gt;% pivot_wider(names_from = condition, values_from = .epred) %&gt;% mutate(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Collective Protest - Individual Protest` = `Collective Protest` - `Individual Protest`) # a tiny bit more wrangling and we&#39;re ready f1 %&gt;% pivot_longer(cols = contains(&quot;-&quot;)) %&gt;% # plot the difference distributions! ggplot(aes(x = value, y = 0)) + stat_halfeye(point_interval = median_qi, .width = .95, fill = &quot;grey50&quot;, color = &quot;white&quot;) + geom_vline(xintercept = 0, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + facet_grid(sexism ~ name) + dark_theme_bw() + theme(panel.grid = element_blank()) Did you notice our use of the add_epred_draws() function? add_epred_draws() is a convenience function from tidybayes, that works in a similar way to brms::fitted(). The advantage of the add_epred_draws() approach is it returns the output in a tidy tibble format and, if you use the newdata argument, it will automatically add those predictor values to the output. To learn more about add_epred_draws() and other similar functions, check out Kay’s (2020a) tutorial, Extracting and visualizing tidy draws from brms models. Now we have f1, it’s easy to get the typical numeric summaries for all of the differences. f1 %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% pivot_longer(-sexism) %&gt;% group_by(name, sexism) %&gt;% mean_qi() %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value) ## # A tibble: 9 x 5 ## name sexism mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Collective Protest - Individual Protest 4.25 0.649 -0.074 1.41 ## 2 Collective Protest - Individual Protest 5.12 0.432 -0.051 0.916 ## 3 Collective Protest - Individual Protest 5.90 0.238 -0.436 0.877 ## 4 Collective Protest - No Protest 4.25 1.02 0.318 1.73 ## 5 Collective Protest - No Protest 5.12 1.66 1.18 2.14 ## 6 Collective Protest - No Protest 5.90 2.22 1.52 2.94 ## 7 Individual Protest - No Protest 4.25 0.373 -0.425 1.17 ## 8 Individual Protest - No Protest 5.12 1.23 0.744 1.72 ## 9 Individual Protest - No Protest 5.90 1.99 1.28 2.68 The three levels of Collective Protest - Individual Protest correspond nicely with some of the analyses Hayes presented on pages 484–486. For example, consider this snip from page 485: “the difference in perceived appropriateness between those told she collectively protested and those told she individually protested is not quite statistically significant, \\(\\theta_{D_{2}\\rightarrow M} | (W = 4.250) = 0.634,\\) \\(t(123) = 1.705,\\) \\(p = .091,\\) \\(95\\%\\ \\text{CI} = -0.102\\) to \\(1.370\\).” That corresponds very nicely to the top row of our last bit of output. However, these don’t get at the differences Hayes expressed as \\(\\theta_{D_{1}\\rightarrow M}\\) on pages 484–486. For those, we’ll have to work directly with the posterior_samples(). post &lt;- posterior_samples(model13.1) post %&gt;% transmute(`4.250` = b_respappr_d1 + `b_respappr_d1:sexism` * 4.250, `5.210` = b_respappr_d1 + `b_respappr_d1:sexism` * 5.120, `5.896` = b_respappr_d1 + `b_respappr_d1:sexism` * 5.896) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value, `Difference in Catherine&#39;s perceived behavior between being told she protested or not when W` = name) ## # A tibble: 3 x 4 ## `Difference in Catherine&#39;s perceived behavior between being told she proteste… mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.250 0.697 0.043 1.36 ## 2 5.210 1.44 1.03 1.88 ## 3 5.896 2.11 1.48 2.71 In the same way, here are the corresponding posterior summaries for the various combinations of \\(\\theta_{D_{2}\\rightarrow M}\\) conditional on three levels of \\(W\\). post %&gt;% transmute(`4.250` = b_respappr_d2 + `b_respappr_d2:sexism` * 4.250, `5.210` = b_respappr_d2 + `b_respappr_d2:sexism` * 5.120, `5.896` = b_respappr_d2 + `b_respappr_d2:sexism` * 5.896) %&gt;% pivot_longer(everything()) %&gt;% group_by(name) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value, `Difference in Catherine&#39;s perceived behavior between being told she protested or not when W` = name) ## # A tibble: 3 x 4 ## `Difference in Catherine&#39;s perceived behavior between being told she proteste… mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.250 0.649 -0.074 1.41 ## 2 5.210 0.432 -0.051 0.916 ## 3 5.896 0.238 -0.436 0.877 At the end of the subsection, Hayes highlighted \\(a_5\\). Here it is. post %&gt;% ggplot(aes(x = `b_respappr_d2:sexism`, y = 0)) + stat_halfeye(point_interval = median_qi, .width = 0.95, fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = c(-1, 1)) + xlab(expression(&quot;b_respappr_d2:sexism (i.e., &quot;*italic(a)[5]*&quot;)&quot;)) + dark_theme_bw() + theme(panel.grid = element_blank()) Turns out \\(a_5\\) has a wide posterior. 13.2.2 Estimating the second stage of the mediation process. Now here’s \\(b\\). post %&gt;% ggplot(aes(x = b_liking_respappr, y = 0)) + stat_halfeye(point_interval = median_qi, .width = 0.95, fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_x_continuous(expression(&quot;b_liking_respappr (i.e., &quot;*italic(b)*&quot;)&quot;), breaks = c(-1, median(post$b_liking_respappr), 1), labels = c(-1, median(post$b_liking_respappr) %&gt;% round(3), 1)) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = c(-1, 1)) + dark_theme_bw() + theme(panel.grid = element_blank()) Note how we plotted \\(b\\) on the same range of the \\(x\\)-axis as we did \\(a_5\\), above. This posterior is much more narrow. 13.3 Relative conditional indirect effects When \\(X\\) is a multicategorical variable representing \\(g = 3\\) groups, there are two indirect effects, which we called relative indirect effects in Chapter 10. But these relative indirect effects are still products of effects. In this example, because one of these effects is a function, then the relative indirect effects become a function as well. (p. 487, emphasis in the original) Before we use Hayes’s formulas at the top of page 488 to re-express the posterior in terms of the relative conditional indirect effects, we might want to clarify which of the post columns correspond to the relevant parameters. \\(a_1\\) = b_respappr_d1 \\(a_2\\) = b_respappr_d2 \\(a_4\\) = b_respappr_d1:sexism \\(a_5\\) = b_respappr_d2:sexism \\(b\\) = b_liking_respappr To get our posterior transformations, we’ll use the expand()-based approach from Chapter 12. Here’s the preparatory data wrangling. indirect &lt;- post %&gt;% expand(nesting(b_respappr_d1, b_respappr_d2, `b_respappr_d1:sexism`, `b_respappr_d2:sexism`, b_liking_respappr), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% mutate(`Protest vs. No Protest` = (b_respappr_d1 + `b_respappr_d1:sexism` * sexism) * b_liking_respappr, `Collective vs. Individual Protest` = (b_respappr_d2 + `b_respappr_d2:sexism` * sexism) * b_liking_respappr) %&gt;% pivot_longer(contains(&quot;Protest&quot;)) %&gt;% select(sexism:value) %&gt;% group_by(name, sexism) %&gt;% median_qi(value) head(indirect) ## # A tibble: 6 x 8 ## name sexism value .lower .upper .width .point .interval ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;chr&gt; ## 1 Collective vs. Individual Protest 3.5 0.294 -0.0966 0.787 0.95 median qi ## 2 Collective vs. Individual Protest 3.60 0.285 -0.0845 0.753 0.95 median qi ## 3 Collective vs. Individual Protest 3.71 0.275 -0.0760 0.723 0.95 median qi ## 4 Collective vs. Individual Protest 3.81 0.266 -0.0633 0.692 0.95 median qi ## 5 Collective vs. Individual Protest 3.91 0.257 -0.0532 0.663 0.95 median qi ## 6 Collective vs. Individual Protest 4.02 0.249 -0.0420 0.632 0.95 median qi Now we’ve saved our results in indirect, we just need to plug them into ggplot() to make our version of Figure 13.4. indirect %&gt;% ggplot(aes(x = sexism, y = value, ymin = .lower, ymax = .upper, group = name)) + geom_ribbon(color = &quot;white&quot;, fill = &quot;transparent&quot;, linetype = 3) + geom_line(color = &quot;white&quot;) + coord_cartesian(xlim = c(4, 6), ylim = c(-.6, .8)) + labs(title = &quot;These are just the conditional indirect effects&quot;, x = expression(Perceived~Pervasiveness~of~Sex~Discrimination~&#39;in&#39;~Society~(italic(W))), y = &quot;Relative Conditional Effect on Liking&quot;) + dark_theme_bw() + theme(legend.position = &quot;none&quot;, panel.grid = element_blank()) + facet_grid(~ name) Do not that unlike the figure in the text, we’re only displaying the conditional indirect effects. Once you include the 95% intervals, things get too cluttered to add in other effects. Here’s how we might make our version of Table 13.2 based on posterior means. post %&gt;% expand(nesting(b_respappr_d1, b_respappr_d2, `b_respappr_d1:sexism`, `b_respappr_d2:sexism`, b_liking_respappr), w = c(4.250, 5.125, 5.896)) %&gt;% rename(b = b_liking_respappr) %&gt;% mutate(`relative effect of d1` = (b_respappr_d1 + `b_respappr_d1:sexism` * w), `relative effect of d2` = (b_respappr_d2 + `b_respappr_d2:sexism` * w)) %&gt;% mutate(`conditional indirect effect of d1` = `relative effect of d1` * b, `conditional indirect effect of d2` = `relative effect of d2` * b) %&gt;% pivot_longer(cols = c(contains(&quot;of d&quot;), b)) %&gt;% group_by(w, name) %&gt;% summarise(mean = mean(value) %&gt;% round(digits = 3)) %&gt;% pivot_wider(names_from = name, values_from = mean) %&gt;% select(w, `relative effect of d1`, `relative effect of d2`, everything()) ## # A tibble: 3 x 6 ## # Groups: w [3] ## w `relative effect o… `relative effect o… b `conditional indirect … `conditional indirect… ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 4.25 0.697 0.649 0.367 0.256 0.238 ## 2 5.12 1.45 0.43 0.367 0.531 0.158 ## 3 5.90 2.11 0.238 0.367 0.773 0.087 13.4 Testing and probing moderation of mediation Surely by now you knew we weren’t going to be satisfied with summarizing the model with a bunch of posterior means. 13.4.1 A test of moderation of the relative indirect effect. In this section Hayes referred to \\(a_4 b\\) and \\(a_5b\\) as the indexes of moderated mediation of the indirect effects of Protest vs. No Protest and Collective vs. Individual Protest, respectively. To express their uncertainty we’ll just work directly with the posterior_samples(), which we’ve saved as post. post &lt;- post %&gt;% mutate(a4b = `b_respappr_d1:sexism` * b_liking_respappr, a5b = `b_respappr_d2:sexism` * b_liking_respappr) post %&gt;% pivot_longer(a4b:a5b, names_to = &quot;parameter&quot;) %&gt;% group_by(parameter) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(parameter:.upper) ## # A tibble: 2 x 4 ## parameter value .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 a4b 0.314 0.088 0.571 ## 2 a5b -0.092 -0.336 0.134 Here they are in a stat_halfeye() plot. post %&gt;% pivot_longer(a4b:a5b, names_to = &quot;parameter&quot;) %&gt;% ggplot(aes(x = value, y = parameter)) + stat_halfeye(point_interval = median_qi, .width = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_y_discrete(NULL, expand = c(.1, .1)) + xlab(NULL) + dark_theme_bw() + theme(axis.ticks.y = element_blank(), panel.grid.major.y = element_blank(), panel.grid.minor.y = element_blank()) 13.4.2 Probing moderation of mediation. We already computed the relevant 95% credible intervals at the end of Section 13.3. We could inspect those in a stat_halfeye() plot, too. # we did this all before post %&gt;% expand(nesting(b_respappr_d1, b_respappr_d2, `b_respappr_d1:sexism`, `b_respappr_d2:sexism`, b_liking_respappr), w = c(4.250, 5.125, 5.896)) %&gt;% rename(b = b_liking_respappr) %&gt;% mutate(`relative effect of d1` = (b_respappr_d1 + `b_respappr_d1:sexism` * w), `relative effect of d2` = (b_respappr_d2 + `b_respappr_d2:sexism` * w)) %&gt;% mutate(`conditional indirect effect of d1` = `relative effect of d1` * b, `conditional indirect effect of d2` = `relative effect of d2` * b) %&gt;% pivot_longer(contains(&quot;conditional&quot;)) %&gt;% # now plot instead of summarizing ggplot(aes(x = w, y = value)) + stat_halfeye(point_interval = median_qi, .width = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + labs(x = &quot;Sexism&quot;, y = &quot;Relative Conditional Effect on Liking&quot;) + dark_theme_bw() + theme(panel.grid.minor.x = element_blank(), panel.grid.major.x = element_blank()) + facet_wrap(~ name) 13.5 Relative conditional direct effects In order to get the \\(R^2\\) difference distribution analogous to the change in \\(R^2\\) \\(F\\)-test Hayes discussed on pages 495–496, we’ll have to first refit the model without the interaction for the \\(Y\\) criterion, liking. m_model &lt;- bf(respappr ~ 1 + d1 + d2 + sexism + d1:sexism + d2:sexism) y_model &lt;- bf(liking ~ 1 + d1 + d2 + respappr + sexism) model13.3 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4, file = &quot;fits/model13.03&quot;) Here’s the \\(\\Delta R^2\\) density for our \\(Y\\), liking. # wrangle tibble(model13.1 = bayes_R2(model13.1, resp = &quot;liking&quot;, summary = F)[, 1], model13.3 = bayes_R2(model13.3, resp = &quot;liking&quot;, summary = F)[, 1]) %&gt;% mutate(difference = model13.1 - model13.3) %&gt;% # plot ggplot(aes(x = difference, y = 0)) + stat_halfeye(point_interval = median_qi, .width = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = c(-.5, .5)) + xlab(expression(Delta*italic(R)^2)) + dark_theme_bw() + theme(panel.grid = element_blank()) We’ll also compare the models by their information criteria. model13.3 &lt;- add_criterion(model13.3, c(&quot;waic&quot;, &quot;loo&quot;)) loo_compare(model13.1, model13.3, criterion = &quot;loo&quot;) ## elpd_diff se_diff ## model13.1 0.0 0.0 ## model13.3 -0.6 2.8 loo_compare(model13.1, model13.3, criterion = &quot;waic&quot;) ## elpd_diff se_diff ## model13.1 0.0 0.0 ## model13.3 -0.6 2.8 As when we went through these steps for resp = \"respappr\", above, the Bayesian \\(R^2\\), the LOO-CV, and the WAIC all suggest there’s little difference between the two models with respect to predictive utility. In such a case, I’d lean on theory to choose between them. If inclined, one could also do Bayesian model averaging. Our approach to plotting the relative conditional direct effects will mirror what we did for the relative conditional indirect effects, above. Here are the brm() parameters that correspond to the parameter names of Hayes’s notation. \\(c_1\\) = b_liking_d1 \\(c_2\\) = b_liking_d2 \\(c_4\\) = b_liking_d1:sexism \\(c_5\\) = b_liking_d2:sexism With all clear, we’re ready to make our version of Figure 13.4 with respect to the conditional direct effects. # wrangle post %&gt;% expand(nesting(b_liking_d1, b_liking_d2, `b_liking_d1:sexism`, `b_liking_d2:sexism`), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% mutate(`Protest vs. No Protest` = b_liking_d1 + `b_liking_d1:sexism` * sexism, `Collective vs. Individual Protest` = b_liking_d2 + `b_liking_d2:sexism` * sexism) %&gt;% pivot_longer(contains(&quot;Protest&quot;)) %&gt;% group_by(name, sexism) %&gt;% median_qi(value) %&gt;% # plot ggplot(aes(x = sexism, y = value, ymin = .lower, ymax = .upper)) + geom_ribbon(color = &quot;white&quot;, fill = &quot;transparent&quot;, linetype = 3) + geom_line() + coord_cartesian(xlim = c(4, 6), ylim = c(-.6, .8)) + labs(title = &quot;These are just the conditional direct effects&quot;, x = expression(&quot;Perceived Pervasiveness of Sex Discrimination in Society &quot;*(italic(W))), y = &quot;Relative Conditional Effect on Liking&quot;) + dark_theme_bw() + theme(legend.position = &quot;none&quot;, panel.grid = element_blank()) + facet_grid(~ name) Holy smokes, them are some wide 95% CIs! No wonder the information criteria and \\(R^2\\) comparisons were so uninspiring. Notice that the \\(y\\)-axis is on the parameter space. When Hayes made his Figure 13.5, he put the \\(y\\)-axis on the liking space, instead. When we want things in the parameter space, we work with the output of posterior_samples(); when we want them in the criterion space, we typically use fitted(). This time, however, we’ll practice again with tidbayes::add_epred_draws(). # we need new `nd` data nd &lt;- protest %&gt;% distinct(d1, d2, condition) %&gt;% expand(nesting(condition, d1, d2), sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% mutate(respappr = mean(protest$respappr)) # feed `nd` into `add_epred_draws()` and then summarize with `median_qi()` f &lt;- add_epred_draws(model13.1, newdata = nd, resp = &quot;liking&quot;) %&gt;% median_qi(.epred) # plot! f %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = .lower, ymax = .upper), linetype = 3, color = &quot;white&quot;, fill = &quot;transparent&quot;) + geom_line(aes(y = .epred)) + geom_point(data = protest, aes(y = liking), color = &quot;red&quot;, size = 2/3) + coord_cartesian(xlim = c(4, 6), ylim = c(4, 7)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = expression(paste(&quot;Evaluation of the Attorney (&quot;, italic(Y), &quot;)&quot;))) + dark_theme_bw() + theme(panel.grid = element_blank()) + facet_wrap(~ condition) Relative to the text, we expanded the range of the \\(y\\)-axis a bit to show more of that data (and there’s even more data outside of our expanded range). Also note how after doing so and after including the 95% CI bands, the crossing regression line effect in Hayes’s Figure 13.5 isn’t as impressive looking any more. On pages 497 and 498, Hayes discussed more omnibus \\(F\\)-tests. Much like with the \\(M\\) criterion, we won’t come up with Bayesian \\(F\\)-tests, but we might go ahead and make pairwise comparisons at the three percentiles Hayes prefers. # we need new `nd` data nd &lt;- protest %&gt;% distinct(d1, d2, condition) %&gt;% expand(nesting(condition, d1, d2), sexism = c(4.250, 5.120, 5.896)) %&gt;% mutate(respappr = mean(protest$respappr)) # define f f &lt;- add_epred_draws(model13.1, newdata = nd, resp = &quot;liking&quot;) %&gt;% ungroup() %&gt;% select(condition, sexism, .draw, .epred) %&gt;% pivot_wider(names_from = condition, values_from = .epred) %&gt;% mutate(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Collective Protest - Individual Protest` = `Collective Protest` - `Individual Protest`) # a tiny bit more wrangling and we&#39;re ready to plot the difference distributions f %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% pivot_longer(-sexism) %&gt;% mutate(sexism = str_c(&quot;W = &quot;, sexism)) %&gt;% ggplot(aes(x = value, y = 0)) + stat_halfeye(point_interval = median_qi, .width = .95, color = &quot;white&quot;) + geom_vline(xintercept = 0, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + dark_theme_bw() + theme(panel.grid = element_blank()) + facet_grid(sexism ~ name) Now we have f, it’s easy to get the typical numeric summaries for the differences. f %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% pivot_longer(-sexism) %&gt;% group_by(name, sexism) %&gt;% mean_qi(value) %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(name:.upper) %&gt;% rename(mean = value) ## # A tibble: 9 x 5 ## name sexism mean .lower .upper ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 Collective Protest - Individual Protest 4.25 -0.118 -0.709 0.472 ## 2 Collective Protest - Individual Protest 5.12 -0.146 -0.518 0.247 ## 3 Collective Protest - Individual Protest 5.90 -0.172 -0.707 0.357 ## 4 Collective Protest - No Protest 4.25 -0.552 -1.14 0.052 ## 5 Collective Protest - No Protest 5.12 -0.11 -0.562 0.333 ## 6 Collective Protest - No Protest 5.90 0.283 -0.359 0.92 ## 7 Individual Protest - No Protest 4.25 -0.434 -1.04 0.188 ## 8 Individual Protest - No Protest 5.12 0.036 -0.391 0.469 ## 9 Individual Protest - No Protest 5.90 0.455 -0.142 1.07 We don’t have \\(p\\)-values, but who needs them? All the differences are small in magnitude and have wide 95% intervals straddling zero. To get the difference scores Hayes presented on pages 498–500, one might execute something like this. post %&gt;% transmute(d1_4.250 = b_liking_d1 + `b_liking_d1:sexism` * 4.250, d1_5.120 = b_liking_d1 + `b_liking_d1:sexism` * 5.120, d1_5.896 = b_liking_d1 + `b_liking_d1:sexism` * 5.896, d2_4.250 = b_liking_d2 + `b_liking_d2:sexism` * 4.250, d2_5.120 = b_liking_d2 + `b_liking_d2:sexism` * 5.120, d2_5.896 = b_liking_d2 + `b_liking_d2:sexism` * 5.896) %&gt;% pivot_longer(everything(), names_sep = &quot;_&quot;, names_to = c(&quot;protest dummy&quot;, &quot;sexism&quot;)) %&gt;% group_by(`protest dummy`, sexism) %&gt;% mean_qi() %&gt;% mutate_if(is.double, round, digits = 3) %&gt;% select(`protest dummy`:.upper) %&gt;% rename(mean = value) ## # A tibble: 6 x 5 ## `protest dummy` sexism mean .lower .upper ## &lt;chr&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 d1 4.250 -0.493 -1.02 0.018 ## 2 d1 5.120 -0.037 -0.444 0.356 ## 3 d1 5.896 0.369 -0.194 0.942 ## 4 d2 4.250 -0.118 -0.709 0.472 ## 5 d2 5.120 -0.146 -0.518 0.247 ## 6 d2 5.896 -0.172 -0.707 0.357 Each of those was our Bayesian version of an iteration of what you might call \\(\\theta_{D_i \\rightarrow Y} | W\\). Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## other attached packages: ## [1] tidybayes_3.0.0 ggdark_0.2.1 brms_2.15.0 Rcpp_1.0.6 forcats_0.5.1 stringr_1.4.0 ## [7] dplyr_1.0.6 purrr_0.3.4 readr_1.4.0 tidyr_1.1.3 tibble_3.1.2 ggplot2_3.3.5 ## [13] tidyverse_1.3.1 ## ## loaded via a namespace (and not attached): ## [1] readxl_1.3.1 backports_1.2.1 plyr_1.8.6 igraph_1.2.6 ## [5] svUnit_1.0.3 sp_1.4-4 splines_4.0.4 crosstalk_1.1.0.1 ## [9] TH.data_1.0-10 rstantools_2.1.1 inline_0.3.17 digest_0.6.27 ## [13] htmltools_0.5.1.1 rsconnect_0.8.16 fansi_0.4.2 checkmate_2.0.0 ## [17] magrittr_2.0.1 modelr_0.1.8 RcppParallel_5.0.2 matrixStats_0.57.0 ## [21] xts_0.12.1 sandwich_3.0-0 prettyunits_1.1.1 colorspace_2.0-0 ## [25] rvest_1.0.1 ggdist_3.0.0 haven_2.3.1 xfun_0.23 ## [29] callr_3.7.0 crayon_1.4.1 jsonlite_1.7.2 lme4_1.1-25 ## [33] survival_3.2-10 zoo_1.8-8 glue_1.4.2 gtable_0.3.0 ## [37] emmeans_1.5.2-1 V8_3.4.0 distributional_0.2.2 pkgbuild_1.2.0 ## [41] rstan_2.21.2 abind_1.4-5 scales_1.1.1 mvtnorm_1.1-1 ## [45] emo_0.0.0.9000 DBI_1.1.0 miniUI_0.1.1.1 xtable_1.8-4 ## [49] stats4_4.0.4 StanHeaders_2.21.0-7 DT_0.16 htmlwidgets_1.5.3 ## [53] httr_1.4.2 threejs_0.3.3 arrayhelpers_1.1-0 posterior_1.0.1 ## [57] ellipsis_0.3.2 farver_2.1.0 pkgconfig_2.0.3 loo_2.4.1 ## [61] sass_0.3.1 dbplyr_2.1.1 utf8_1.2.1 labeling_0.4.2 ## [65] tidyselect_1.1.1 rlang_0.4.11 reshape2_1.4.4 later_1.2.0 ## [69] munsell_0.5.0 cellranger_1.1.0 tools_4.0.4 cli_3.0.1 ## [73] generics_0.1.0 broom_0.7.6 ggridges_0.5.3 evaluate_0.14 ## [77] fastmap_1.1.0 processx_3.5.2 knitr_1.33 fs_1.5.0 ## [81] nlme_3.1-152 mime_0.10 projpred_2.0.2 xml2_1.3.2 ## [85] compiler_4.0.4 bayesplot_1.8.0 shinythemes_1.1.2 rstudioapi_0.13 ## [89] gamm4_0.2-6 curl_4.3 reprex_2.0.0 statmod_1.4.35 ## [93] bslib_0.2.4 stringi_1.6.2 highr_0.9 ps_1.6.0 ## [97] Brobdingnag_1.2-6 lattice_0.20-41 Matrix_1.3-2 nloptr_1.2.2.2 ## [101] markdown_1.1 tensorA_0.36.2 shinyjs_2.0.0 vctrs_0.3.8 ## [105] pillar_1.6.1 lifecycle_1.0.0 jquerylib_0.1.4 bridgesampling_1.0-0 ## [109] estimability_1.3 raster_3.4-5 httpuv_1.6.0 R6_2.5.0 ## [113] bookdown_0.22 promises_1.2.0.1 gridExtra_2.3 codetools_0.2-18 ## [117] boot_1.3-26 colourpicker_1.1.0 MASS_7.3-53 gtools_3.8.2 ## [121] assertthat_0.2.1 withr_2.4.2 shinystan_2.5.0 multcomp_1.4-16 ## [125] mgcv_1.8-33 parallel_4.0.4 hms_1.1.0 grid_4.0.4 ## [129] coda_0.19-4 minqa_1.2.4 rmarkdown_2.8 shiny_1.6.0 ## [133] lubridate_1.7.10 base64enc_0.1-3 dygraphs_1.1.1.6 References Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Kay, M. (2020a). Extracting and visualizing tidy draws from brms models. https://mjskay.github.io/tidybayes/articles/tidy-brms.html "],["miscellaneous-topics-and-some-frequently-asked-questions.html", "14 Miscellaneous Topics and Some Frequently Asked Questions 14.1 A strategy for approaching a conditional process analysis 14.2 How do I write about this? 14.3 Should I use structural equation modeling instead of regression analysis? 14.4 The pitfalls of subgroups analysis 14.5 Can a variable simultaneously mediate and moderate another variable’s effect? 14.6 Interaction between \\(X\\) and \\(M\\) in mediation analysis? 14.7 Repeated measures designs 14.8 Dichotomous, ordinal, count, and survival outcomes Session info", " 14 Miscellaneous Topics and Some Frequently Asked Questions The vast majority of scientists would probably argue that when push comes to shove, the theoretical horse should pull the statistical cart. Statistical methods are mathematical tools, some of them quite amazing in what they do, which can help us to discern order amid the apparent chaos in a batch of data. But ultimately, the stories that statistical methods help us tell are told by our brains, not by the mathematics, and our brains are good at making sense of things–of coming up with stories to explain what we perceive. The problem is that the same pattern of results can be interpreted in many different ways, especially if the pattern is found after an extensive round of exploratory data analysis. Without a theoretical orientation to guide our attempts at making sense of our data or, better still, to guide our research design and data collection efforts, our awesome storytelling ability can lead us astray by invoking explanations for findings that may sound good but that are mere conjecture even if we can find a theoretical hook on which to hang them post hoc. I won’t argue against this perspective, as I believe it is for the most part right on the money. But I also believe that statistical methods can play an important role in theory development as well–that the statistical cart need not always, should not always, and often does not follow the theoretical horse. When we learn something new analytically, this can change the way we think of things theoretically and how we then go about testing the ideas that our newfound awareness of an analytical method inspired (cf. Andrew F. Hayes et al., 2008, p. 2). (Andrew F. Hayes, 2018, pp. 507–508) 14.1 A strategy for approaching a conditional process analysis Things don’t always turn out as we expected and articulated in hypotheses 1, 2, and 3. And sometimes after looking at the data, our thinking about the process at work changes and new hypotheses come to mind that are worth testing. Scientists routinely switch back and forth between the context of justification and the context of discovery, testing hypotheses conceived before the data were analyzed while also exploring one’s data to see what else can be learned from patterns observed but not anticipated. In the next paragraph, we see Hayes anticipated criticism at this paragraph and some of the subsections to follow. My two cents are that problems arise when we approach statistics from a \\(p\\)-value-based hypothesis-testing perspective, when we pose exploratory research as confirmatory, when we engage in closed science practices, and when we only present the analyses that “worked.” For some engaging thoughts on iterative Bayesian workflows, you might check out Navarro’s blog series, Paths in strange spaces; here’s part 1. 14.1.1 Step 1: Construct your conceptual diagram of the process. Build up your model slowly and with the aid of visuals. 14.1.2 Step 2: Translate the conceptual model into a statistical model. We don’t estimate the conceptual model. [Presuming mediation,] a conceptual model must be translated into a statistical model in the form of at least two equations, depending on the number of proposed mediators in the model. With an understanding of the principles of moderation and mediation analysis described in this book, you should be able to do this without too much difficulty. (p. 510) 14.1.3 Step 3: Estimate the statistical model. Hayes used OLS-based procedures throughout the text. We have been using Bayesian software. Though I prefer brms, you might also check out blavaan or rstanarm. As a group, these will allow you to fit many more kinds of regression models than available through the OLS paradigm. 14.1.4 Step 4: Determine whether expected moderation exists. I’m not a fan of this “whether [x] exists” talk. First, it seems way to black and white. For more thoughts along those lines, check out Gelman’s (2015) paper, The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Second, it places too much faith in the analysis of a single data set. For more on those lines, consider what Hayes wrote in the middle of this subsection: Just because an interaction is not significant, that doesn’t mean your proposed moderator does not moderate the path you proposed it moderates. Parsimony might dictate that your model should be cleansed of this interaction, but null hypotheses tests are fallible, and sometimes real effects are so weak that we don’t have the power to detect them given the limitations of our resources or other things out of our control. (p. 511) This is all posed in the language of NHST, but the basic points still hold for other paradigms. If you have a theory-informed model, I recommend showing the results for that model regardless of the sizes of the parameters. I have concerns about the next subsection. 14.1.4.1 Step 4A. If you have decided to prune your model of nonsignificant interactions, then go back to step 1 and start fresh by redrawing your conceptual diagram in light of the evidence you now have and proceed through these steps again. A certain moral or ethical logic might dictate that you not pretend when describing your analysis that this is where you started in the first place. Yet Bem (1987) makes the argument that spending lots of time talking about ideas that turned out to be “wrongheaded” isn’t going to produce a particularly interesting paper. You’ll have to sort out for yourself where you stand on this continuum of scientific ethics. (p. 512) Hayes is quite right: “You’ll have to sort out for yourself where you stand on this continuum of scientific ethics.” At this point in the social-psychology replication crisis–a crisis of which Bem’s shoddy work has played no small part (Earp &amp; Trafimow, 2015; Galak et al., 2012; see Nelson et al., 2018; Pashler &amp; Wagenmakers, 2012; Yong, 2012)–, it’s shocking to read Hayes endorsing this advice. At a bare minimum, I recommend presenting your failed theory-based models in supplemental materials. You can upload them to the Open Science Framework at https://osf.io/ for free. 14.1.5 Step 5: Probe and interpret interactions involving components of the indirect effect. At this stage, probe any interactions involving components of the indirect effect of \\(X\\) so that you will have some understanding of the contingencies of the various effects that are the components of the larger conditional process model you are estimating. This exercise will help inform and clarify your interpretation of the conditional indirect effect(s) of \\(X\\) later on. (p. 512) 14.1.6 Step 6: Quantify and test conditional indirect effects (if relevant). Within the paradigm I have introduces throughout this text, “testing” effects is never relevant. However, one can and should think in terms of the magnitudes of the parameters in the model. Think in terms of effect sizes. For a frequentist introduction to effect-size thinking, Geoff Cumming’s work is a fine place to start, such as his (2014) article, The new statistics: Why and how. For a Bayesian alternative, check out Kruschke and Liddell’s (2018) article, The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. 14.1.7 Step 7: Quantify and test conditional direct effects (if relevant). “If your model includes moderation of the direct effect of \\(X\\), you will want to probe this interaction by estimating the conditional direct effects” (p. 513). 14.1.8 Step 8: Tell your story. Real science does not proceed in the manner described in re- search methods and statistics textbooks. Rather, we routinely straddle the fence between the hypothetico-deductive approach and a more discovery-oriented or inquisitive mindset that is open to any story the data may inform. Sometimes the story we originally conceived prior to data analysis is simply wrong and we know it after analyzing the data. No one wants to read (as Daryl Bem once put it rather bluntly) “a personal history about your stillborn thoughts” (Bem, 1987, p. 173). Sometimes our data speak to us in ways that change the story we thought we were going to tell into something much more interesting, and hopefully more accurate. (p. 514) I largely agree, though I still recommend against following Bem’s recommendations. Yes, we need to present out work compellingly. But do resist the urge to un-transparently reinvent your research hypotheses for the sake of flashy rhetoric. If you have evidence against one of the theoretical models in your field, let them know! For an example of scientists embracing the failure of theory, check out Klein and colleagues’ (2019) Many Labs 4: Failure to replicate mortality salience effect with and without original author involvement. Of course, there is always the danger of capitalizing on chance when you let your explorations of the data influence the story you tell. We are great at explaining patterns we see. Our brains are wired to do it. So replication is important, and it may be the only way of establishing the generality of our findings and claims in the end. (p. 514) Yes indeed. So please stop following the poor examples of Bem and others. Present your research honestly and transparently. 14.2 How do I write about this? I have become convinced that the ability to communicate in writing is at least as if not more important than the ability to manipulate numbers and think in abstractions. You don’t have to be a good data analyst to be a good scientist, but your future on the front lines of science is limited if you can’t write effectively. (p. 515) Agreed. On page 518, Hayes gave an example of how to write up the results of a mediation analysis in a narrative style. Here’s a more Bayesian version: From a simple [Bayesian] mediation analysis conducted using [Hamiltonian Monte Carlo], article location indirectly influenced intentions to buy sugar through its effect on beliefs about how others would be influenced. As can be seen in Figure 3.3 and Table 3.2, participants told that the article would be published on the front page believed others would be more influenced to buy sugar than those told that the article would appear in an economic supplement (\\(a\\) = 0.477[, 95% CI [0.277, 0.677]]), and participants who believed others would be more influenced by the story expressed a stronger intention to go buy sugar themselves (\\(b\\) = 0.506[, 95% CI [0.306, 0.706]]). [The credible interval] for the indirect effect (\\(ab\\) = 0.241) based on 5,000 bootstrap samples was entirely above zero (0.007 to 0.526). [The evidence suggested] that article location [had little influence on] intention to buy sugar independent of its effect on presumed media influence (\\(c&#39;\\) = 0.254[, 95% CI [-0.154, 0.554]]). In addition to throwing in talk about Bayes, I added 95% credible interval information for all point estimates (i.e., posterior means or medians) and shifted the language away from a dichotomous NHST style to emphasize the magnitude and uncertainty of the conditional direct effect (\\(c&#39;\\)). A little further down we read: Third, throughout this book, I emphasize estimation and interpretation of effects in their unstandardized metric, and I report unstandardized effects when I report the results in my own research. There is a widespread belief that standardized effects are best reported, because the measurement scales used in most sciences are arbitrary and not inherently meaningful, or that standardized effects are more comparable across studies or investigators using different methods. But standardization simply changes one arbitrary measurement scale into another arbitrary scale, and because standardized effects are scaled in terms of variability in the sample, they are not comparable across studies conducted by different investigators regardless of whether the same measurement scales are used. (p. 519) To my mind, this leads directly to thoughts about effect sizes. I recommend you ponder long and hard on how to interpret your results in terms of effect sizes. If your research is anything like mine, it’s not always clear what the best approach might be. To get your juices flowing, you might check out Kelley and Preacher’s (2012) On effect size. 14.2.1 Reporting a mediation analysis. Mediation is a causal phenomenon. You will find some people skeptical of the use of mediation analysis in studies based on data that are purely correlational in nature and involve no experimental manipulation or measurement over time. Some people are quite fanatical about this, and if you are unlucky enough to get such an extreme reviewer when trying to publish your work, there may not be much you can to do to convince him or her otherwise. (p. 520) In recent years, I’ve shifted more and more in the direction of the ‘fanatics.’ That might seem odd given I’ve poured all this time and effort into translating a book highlighting and endorsing cross-sectional mediation. I think cross-sectional mediation is a fine teaching tool; it’s a good place for budding data analysts to start. But please do not stop there. Do not stop with this book. Mediation is causal process and causal processes are necessarily longitudinal. A fine place to dip your toes into those waters are the works of Maxwell, Cole, and Mitchell (Maxwell et al., 2011; e.g., Maxwell &amp; Cole, 2007; Mitchell &amp; Maxwell, 2013). If you care about the causal process under your study, please collect longitudinal data. If you learn best by snarky twitter discussions, go here. 14.2.2 Reporting a moderation analysis. Some of the more interesting studies you will find show that what is commonly assumed turns out to be true only sometimes, or that a well-known manipulation only works for some types of people. When writing about moderation, you have the opportunity to tell the scientific world that things aren’t as simple as perhaps they have seemed or been assumed to be, and that there are conditions that must be placed on our understanding of the world. (p. 522) I don’t care for the NHST framing in many of the paragraphs to follow. If you find it a struggle to move beyond this way of thinking, I recommend soaking in Gelman’s (2015) editorial commentary, The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Later we read: The interpretation of the regression coefficients for \\(X\\) and \\(W\\) in a model that includes \\(XW\\) are highly dependent on the scaling of \\(X\\) and \\(W\\). If you have centered a variable, say so. If one or both of these variables is dichotomous, tell the reader what numerical codes were used to represent the two groups. Preferably, choose codes for the two groups that differ by one unit. The more information you give to the reader about how your variables are scaled or coded, the more the reader will be able to look at your results in the text, tables, or figures, discern their meaning, and interpret them correctly. (0. 524) Agreed. And if you’re working under tight word-limit constraints, just give all these details–and others such as centering, standardizing, priors, formal model formulas, HMC chain diagnostic checks, posterior-predictive checks–in supplemental material posted to a stable online repository, such as the Open Science Framework. Other than that, please consider plotting your interactions. Hayes gave some examples of that in the text, but I think his approach was inadequate. Include measures of uncertainty (e.g., 95% credible intervals) in your visualizations. For examples of this beyond those I reported in this text, check out this nice (2018) tutorial by McCabe, Kim, and King. For visualization ideas specific to the brms-tidybayes framework, check out Kay’s (2020a) Extracting and visualizing tidy draws from brms models. 14.2.3 Reporting a conditional process analysis. One of the challenges you are likely to face when writing about a conditional process analysis is staying within the page allowance that most journal editors provide. A well-written analysis will usually contain multiple tables, perhaps a figure or two to depict the conceptual model and perhaps an interaction or two, and enough text to describe what was found in substantive terms while also providing sufficient detail about the analysis for the reader to understand what was done. Many reviewers, editors, and readers will not be familiar with this approach and may need to be educated within the text, further lengthening the manuscript. Yet I am also amazed how much I am able to cut from my own writing with sufficient editing, so don’t be wedded to every word you write, and don’t be afraid to delete that sentence or two you spent much time pondering, crafting, and fine-tuning but that upon third or fourth reading really isn’t necessary to convey what needs to be conveyed. That said, I would err on the side of presenting more information rather than less whenever space allows it. (p. 526) As recommended just above, you can also cover all this with online supplemental material posted to a stable online repository, such as the Open Science Framework. I can’t recommend this enough. 14.3 Should I use structural equation modeling instead of regression analysis? First to clarify, one can do structural equation modeling (SEM) as a Bayesian. At the time of this writing, brms is only capable of limited forms of SEM. In fact, all the multivariate models we have fit this far can be thought of as special cases of Bayesian SEM (see here). However, it appears brms will offer expanded SEM capabilities sometime in the future. To keep up with the Bürkner’s progress, you might intermittently check in to issue #303 on the brms GitHub page. And of course, you can always check out the blavaan package. 14.4 The pitfalls of subgroups analysis If at all possible, just don’t do this. Hayes covered the following reasons why: “First, the subgroups approach may not accurately reflect the process purportedly at work” (p. 531). “Second, a direct or indirect effect may be descriptively different in the two groups but may not actually be different when subjected to a formal statistical test of differences” (pp. 531–532). For more on this point, check out Gelman and Stern’s (2006) The difference between “significant” and “not significant” is not itself statistically significant. “Third, the subgroups approach conflates statistical significance with sample size” (p. 532). “Finally, this approach requires that the proposed moderator be categorical” (p. 532). 14.5 Can a variable simultaneously mediate and moderate another variable’s effect? “Just because something is mathematically possible doesn’t mean that it is sensible theoretically or substantively interpretable when it happens” (p. 540). I suspect part of this issue has to do with confusion around the longitudinal nature of mediation al processes and a confounding of state versus trait (i.e., within- and between-case variation). See the Cole, Maxwell and Mitchell papers referenced, above, to start thinking about mediation within the context of longitudinal data. The issue of within- versus between-case variation is huge and IMO under-appreciated in the mediation literature. If you’re ready to blow your mind a little, I can think of no better place to start learning about this than Ellen Hamaker’s engaging (2012) chapter, Why researchers should think “within-person”: A paradigmatic rationale. 14.6 Interaction between \\(X\\) and \\(M\\) in mediation analysis? The mathematics of this approach relies on the counterfactual or potential outcomes approach to causal analysis that is popular in statistics, less widely known in the social science research community, and, to many, a little harder to digest. For discussions of this approach, see Imai, Keele, and Tingley (2010), Muthé́n and Asparouhov (2015), Valeri and VanderWeele (2013), and VanderWeele (2015). 14.7 Repeated measures designs In all examples throughout this book, cases were measured on mediator(s) \\(M\\) and outcome \\(Y\\) only once. In nonexperimental studies, they were measured once on the causal antecedent \\(X\\), whereas in experimental studies they were assigned to one of two or three experimental conditions used as \\(X\\) in the model. Although such research designs are common, also common are “repeated measures” designs that involve measuring cases more than once on the variables in a mediation model. There are several forms such designs take, and there are approaches to mediation and conditional process analysis that can be used depending on the form of the design. (p. 541) On the next page, Hayes introduced the multilevel approach to mediation. For more on this topic, check out the great (2018) paper from Vuorre and Bolger, Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience which introduced a package for Bayesian multilevel mediation models called bmlm (Vuorre, 2017, 2019). Yes, you can do this in brms. Hayes also discussed the cross-lag panel model for longitudinal mediation (e.g., Valente &amp; MacKinnon, 2017). I have not tried it, but I believe you could do this with current versions of brms. Here’s a thread on the Stan forums discussing how from a multilevel perspective. For a more detailed discussion of mediation in panel designs like this, see Cole and Maxwell (2003), Little, Preacher, Selig, and Card (2007), and Selig and Preacher (2009). Another analytical option is available when \\(M\\) and \\(Y\\) are measured at least three times, regardless of the number of measurements of \\(X\\). Parallel process latent growth modeling allows for \\(X\\) (either in a single measurement or manipulation, or its change over time) to influence the trajectory in change in the mediator, which in turn can influence the trajectory in the change in \\(Y\\) over time. [Yes, brms can do this]. See Cheong et al. Cheong et al. (2003) and Selig and Preacher (2009) for discussions of the mathematics of mediation analysis in a latent growth context. (p. 545, emphasis in the original) 14.8 Dichotomous, ordinal, count, and survival outcomes [Our version of] this book is focused squarely and exclusively on linear regression analysis using the [single-level Gaussian likelihood] as the computational backbone of mediation, moderation, and conditional process analysis. In all examples that included a mediation component, all mediator(s) \\(M\\) and final consequent variable \\(Y\\) were always treated as continuous dimensions with at least interval level measurement properties. But no doubt you will find yourself in a situation where \\(M\\) and/or \\(Y\\) is dichotomous, or an ordinal scale with only a few scale points, or perhaps a count variable. Although such variables can be modeled with [the Gaussian likelihood], doing so is controversial because there are better methods that respect the special statistical considerations that come up when such variables are on the left sides of equations. (p. 545) Going beyond the Gaussian likelihood is often framed in terms of the generalized linear model (GLM). To wade into the GLM from within a Bayesian framework, I recommend Kruschke’s (2015) text, Doing Bayesian data analysis, Second Edition: A tutorial with R, JAGS, and Stan, or either edition of McElreath’s text, Statistical rethinking: A Bayesian course with examples in R and Stan (2020, 2015). I have free ebooks of all three wherein I have translated their code into a tidyverse and brms framework (Kurz, 2021, 2020a, 2020b). Liberate yourself from the tyranny of the Gauss. Embrace the GLM. Session info sessionInfo() ## R version 4.0.4 (2021-02-15) ## Platform: x86_64-apple-darwin17.0 (64-bit) ## Running under: macOS Catalina 10.15.7 ## ## Matrix products: default ## BLAS: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRblas.dylib ## LAPACK: /Library/Frameworks/R.framework/Versions/4.0/Resources/lib/libRlapack.dylib ## ## locale: ## [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 ## ## attached base packages: ## [1] stats graphics grDevices utils datasets methods base ## ## loaded via a namespace (and not attached): ## [1] bookdown_0.22 digest_0.6.27 R6_2.5.0 jsonlite_1.7.2 magrittr_2.0.1 ## [6] evaluate_0.14 rlang_0.4.11 stringi_1.6.2 jquerylib_0.1.4 bslib_0.2.4 ## [11] rmarkdown_2.8 tools_4.0.4 stringr_1.4.0 xfun_0.23 compiler_4.0.4 ## [16] htmltools_0.5.1.1 knitr_1.33 sass_0.3.1 References Bem, D. J. (1987). Writing the empirical journal article. In M. P. Zanna &amp; J. M. Darley (Eds.), The complete academic: A practical guide for the beginning social scientist (pp. 171–201). Lawrence Erlbaum Associates. Cheong, J., MacKinnon, D. P., &amp; Khoo, S. T. (2003). Investigation of mediational processes using parallel process latent growth curve modeling. Structural Equation Modeling : A Multidisciplinary Journal, 10(2), 238. https://doi.org/10.1207/S15328007SEM1002_5 Cole, D. A., &amp; Maxwell, S. E. (2003). Testing mediational models with longitudinal data: Questions and tips in the use of structural equation modeling. Journal of Abnormal Psychology, 112(4), 558–577. https://doi.org/10.1037/0021-843X.112.4.558 Cumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7–29. https://doi.org/10.1177/0956797613504966 Earp, B. D., &amp; Trafimow, D. (2015). Replication, falsification, and the crisis of confidence in social psychology. Frontiers in Psychology, 6. https://doi.org/10.3389/fpsyg.2015.00621 Galak, J., LeBoeuf, R. A., Nelson, L. D., &amp; Simmons, J. P. (2012). Correcting the past: Failures to replicate psi. Journal of Personality and Social Psychology, 103(6), 933–948. https://doi.org/10.1037/a0029709 Gelman, A. (2015). The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Journal of Management, 41(2), 632–643. https://doi.org/10.1177/0149206314525208 Gelman, A., &amp; Stern, H. (2006). The difference between “significant” and “not significant” is not itself statistically significant. The American Statistician, 60(4), 328–331. https://doi.org/10.1198/000313006X152649 Hamaker, E. L. (2012). Why researchers should think \"within-person\": A paradigmatic rationale. In Handbook of research methods for studying daily life (pp. 43–61). The Guilford Press. https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055 Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Hayes, Andrew F., Slater, M. D., &amp; Snyder, L. B. (2008). The SAGE sourcebook of advanced data analysis methods for communication research. https://us.sagepub.com/en-us/nam/the-sage-sourcebook-of-advanced-data-analysis-methods-for-communication-research/book228339 Imai, K., Keele, L., &amp; Tingley, D. (2010). A general approach to causal mediation analysis. Psychological Methods, 15(4), 309–334. https://doi.org/10.1037/a0020761 Kay, M. (2020a). Extracting and visualizing tidy draws from brms models. https://mjskay.github.io/tidybayes/articles/tidy-brms.html Kelley, K., &amp; Preacher, K. J. (2012). On effect size. Psychological Methods, 17(2), 137. https://doi.org/10.1037/a0028086 Klein, R. A., Cook, C. L., Ebersole, C. R., Vitiello, C., Nosek, B. A., Chartier, C. R., Christopherson, C. D., Clay, S., Collisson, B., Crawford, J., Cromar, R., Vidamuerte, D., Gardiner, G., Gosnell, C., Grahe, J., Hall, C., Joy-Gaba, J., Legg, A. M., Levitan, C., … Ratliff, K. (2019). Many Labs 4: Failure to replicate mortality salience effect with and without original author involvement. PsyArXiv. https://doi.org/10.31234/osf.io/vef2c Kruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/ Kruschke, J. K., &amp; Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin &amp; Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4 Kurz, A. S. (2021). Statistical rethinking with brms, ggplot2, and the tidyverse: Second Edition (version 0.2.0). https://bookdown.org/content/4857/ Kurz, A. S. (2020a). Doing Bayesian data analysis in brms and the tidyverse (version 0.4.0). https://bookdown.org/content/3686/ Kurz, A. S. (2020b). Statistical rethinking with brms, ggplot2, and the tidyverse (version 1.2.0). https://doi.org/10.5281/zenodo.3693202 Little, T. D., Preacher, K. J., Selig, J. P., &amp; Card, N. A. (2007). New developments in latent variable panel analyses of longitudinal data. International Journal of Behavioral Development, 31(4), 357–365. https://doi.org/10.1177/0165025407077757 Maxwell, S. E., &amp; Cole, D. A. (2007). Bias in cross-sectional analyses of longitudinal mediation. Psychological Methods, 12(1), 23–44. https://doi.org/10.1037/1082-989X.12.1.23 Maxwell, S. E., Cole, D. A., &amp; Mitchell, M. A. (2011). Bias in cross-sectional analyses of longitudinal mediation: Partial and complete mediation under an autoregressive model. Multivariate Behavioral Research, 46(5), 816–841. https://doi.org/10.1080/00273171.2011.606716 McCabe, C. J., Kim, D. S., &amp; King, K. M. (2018). Improving present practices in the visual display of interactions. Advances in Methods and Practices in Psychological Science, 1(2), 147–165. https://doi.org/10.1177/2515245917746792 McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/ McElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. https://xcelab.net/rm/statistical-rethinking/ Mitchell, M. A., &amp; Maxwell, S. E. (2013). A comparison of the cross-sectional and sequential designs when assessing longitudinal mediation. Multivariate Behavioral Research, 48(3), 301–339. https://doi.org/10.1080/00273171.2013.784696 Muthén, B., &amp; Asparouhov, T. (2015). Causal effects in mediation modeling: An introduction with applications to latent variables. Structural Equation Modeling: A Multidisciplinary Journal, 22(1), 12–23. https://doi.org/10.1080/10705511.2014.935843 Nelson, L. D., Simmons, J., &amp; Simonsohn, U. (2018). Psychology’s renaissance. Annual Review of Psychology, 69(1), 511–534. https://doi.org/10.1146/annurev-psych-122216-011836 Pashler, H., &amp; Wagenmakers, E. (2012). Editors’ introduction to the special section on replicability in psychological science: A crisis of confidence? Perspectives on Psychological Science, 7(6), 528–530. https://doi.org/10.1177/1745691612465253 Selig, J. P., &amp; Preacher, K. J. (2009). Mediation models for longitudinal data in developmental research. Research in Human Development, 6(2-3), 144–164. https://doi.org/10.1080/15427600902911247 Valente, M. J., &amp; MacKinnon, D. P. (2017). Comparing models of change to estimate the mediated effect in the pretest-posttest control group design. Structural Equation Modeling : A Multidisciplinary Journal, 24(3), 428–450. https://doi.org/10.1080/10705511.2016.1274657 Valeri, L., &amp; VanderWeele, T. J. (2013). Mediation analysis allowing for exposuremediator interactions and causal interpretation: Theoretical assumptions and implementation with SAS and SPSS macros. Psychological Methods, 18(2), 137. https://doi.org/10.1037/a0031034 VanderWeele, T. (2015). Explanation in causal inference: Methods for mediation and interaction (1st edition). Oxford University Press. Vuorre, M. (2017). bmlm: Bayesian multilevel mediation [Manual]. https://cran.r-project.org/package=bmlm Vuorre, M. (2019). bmlm: Bayesian multilevel mediation [Manual]. https://github.com/mvuorre/bmlm/ Vuorre, M., &amp; Bolger, N. (2018). Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience. Behavior Research Methods, 50(5), 2125–2143. https://doi.org/10.3758/s13428-017-0980-9 Yong, E. (2012). Replication studies: Bad copy. Nature News, 485(7398), 298. https://doi.org/10.1038/485298a "],["references.html", "References", " References Aiken, L. S., &amp; West, S. G. (1991). Multiple regression: Testing and interpreting interactions. SAGE. Allan, A., Cook, D., Gayler, R., Kirk, H., Peng, R., &amp; Saber, E. (2017). ochRe: Australia-themed colour palettes [Manual]. https://github.com/ropenscilabs/ochRe Arnold, J. B. (2021). ggthemes: Extra themes, scales and geoms for ’ggplot2’. https://CRAN.R-project.org/package=ggthemes Baron, R. M., &amp; Kenny, D. A. (1986). The moderatormediator variable distinction in social psychological research: Conceptual, strategic, and statistical considerations. Journal of Personality and Social Psychology, 51(6), 1173–1182. https://doi.org/10.1037/0022-3514.51.6.1173 Bauer, D. J., &amp; Curran, P. J. (2005). Probing interactions in fixed and multilevel regression: Inferential and graphical techniques. Multivariate Behavioral Research, 40(3), 373–400. https://doi.org/10.1207/s15327906mbr4003_5 Bem, D. J. (1987). Writing the empirical journal article. In M. P. Zanna &amp; J. M. Darley (Eds.), The complete academic: A practical guide for the beginning social scientist (pp. 171–201). Lawrence Erlbaum Associates. BibTeX. (2020). http://www.bibtex.org/ Bolger, N., Zee, K. S., Rossignac-Milon, M., &amp; Hassin, R. R. (2019). Causal processes in psychology are heterogeneous. Journal of Experimental Psychology: General, 148(4), 601–618. https://doi.org/10.1037/xge0000558 Brilleman, S., Crowther, M., Moreno-Betancur, M., Buros Novik, J., &amp; Wolfe, R. (2018). Joint longitudinal and time-to-event models via Stan. https://github.com/stan-dev/stancon_talks/ Bürkner, P.-C. (2021a). Estimating distributional models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_distreg.html Bürkner, P.-C. (2021b). Estimating multivariate models with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_multivariate.html Bürkner, P.-C. (2021c). Handle missing values with brms. https://CRAN.R-project.org/package=brms/vignettes/brms_missings.html Bürkner, P.-C. (2021d). Parameterization of response distributions in brms. https://CRAN.R-project.org/package=brms/vignettes/brms_families.html Bürkner, P.-C. (2017). brms: An R package for Bayesian multilevel models using Stan. Journal of Statistical Software, 80(1), 1–28. https://doi.org/10.18637/jss.v080.i01 Bürkner, P.-C. (2018). Advanced Bayesian multilevel modeling with the R package brms. The R Journal, 10(1), 395–411. https://doi.org/10.32614/RJ-2018-017 Bürkner, P.-C. (2020). brms: Bayesian regression models using ’Stan’. https://CRAN.R-project.org/package=brms Bürkner, P.-C. (2021e). brms reference manual, Version 2.15.0. https://CRAN.R-project.org/package=brms/brms.pdf Chang, W. (2014). Extrafont: Tools for using fonts. https://cran.r-project.org/package=extrafont/ Chapman, D. A., &amp; Lickel, B. (2016). Climate change and disasters: How framing affects justifications for giving or withholding aid to disaster victims. Social Psychological and Personality Science, 7(1), 13–20. https://doi.org/10.1177/1948550615590448 Cheong, J., MacKinnon, D. P., &amp; Khoo, S. T. (2003). Investigation of mediational processes using parallel process latent growth curve modeling. Structural Equation Modeling : A Multidisciplinary Journal, 10(2), 238. https://doi.org/10.1207/S15328007SEM1002_5 Cohen, J. (1968). Multiple regression as a general data-analytic system. Psychological Bulletin, 70(6, Pt.1), 426–443. https://doi.org/10.1037/h0026714 Cohen, J., Cohen, P., West, S. G., &amp; Aiken, L. S. (2003). Applied multiple regression/correlation analysis for the behavioral sciences (3rd edition). Lawrence Erlbaum Associates. https://doi.org/10.4324/9780203774441 Cole, D. A., &amp; Maxwell, S. E. (2003). Testing mediational models with longitudinal data: Questions and tips in the use of structural equation modeling. Journal of Abnormal Psychology, 112(4), 558–577. https://doi.org/10.1037/0021-843X.112.4.558 Cumming, G. (2014). The new statistics: Why and how. Psychological Science, 25(1), 7–29. https://doi.org/10.1177/0956797613504966 Darlington, R. B., &amp; Hayes, A. F. (2017). Regression analysis and linear models: Concepts, applications, and implementation. Guilford Press. https://www.guilford.com/books/Regression-Analysis-and-Linear-Models/Darlington-Hayes/9781462521135/reviews Dawson, J. F. (2014). Moderation in management research: What, why, when, and how. Journal of Business and Psychology, 29(1), 1–19. https://doi.org/10.1007/s10869-013-9308-7 Dawson, J. F., &amp; Richter, A. W. (2006). Probing three-way interactions in moderated multiple regression: Development and application of a slope difference test. Journal of Applied Psychology, 91(4), 917–926. https://doi.org/10.1037/0021-9010.91.4.917 Earp, B. D., &amp; Trafimow, D. (2015). Replication, falsification, and the crisis of confidence in social psychology. Frontiers in Psychology, 6. https://doi.org/10.3389/fpsyg.2015.00621 Enders, C. K. (2010). Applied missing data analysis. Guilford press. http://www.appliedmissingdata.com/ Gabry, J. (2019). Graphical posterior predictive checks using the bayesplot package. https://CRAN.R-project.org/package=bayesplot/vignettes/graphical-ppcs.html Gabry, J. (2020). loo reference manual, Version 2.4.1. https://CRAN.R-project.org/package=loo/loo.pdf Gabry, J., &amp; Goodrich, B. (2020). rstanarm: Bayesian applied regression modeling via stan [Manual]. https://CRAN.R-project.org/package=rstanarm Gabry, J., &amp; Mahr, T. (2021). bayesplot: Plotting for Bayesian models. https://CRAN.R-project.org/package=bayesplot Gabry, J., &amp; Modrák, M. (2020). Visual MCMC diagnostics using the bayesplot package. https://CRAN.R-project.org/package=bayesplot/vignettes/visual-mcmc-diagnostics.html Gabry, J., Simpson, D., Vehtari, A., Betancourt, M., &amp; Gelman, A. (2019). Visualization in Bayesian workflow. Journal of the Royal Statistical Society: Series A (Statistics in Society), 182(2), 389–402. https://doi.org/10.1111/rssa.12378 Galak, J., LeBoeuf, R. A., Nelson, L. D., &amp; Simmons, J. P. (2012). Correcting the past: Failures to replicate psi. Journal of Personality and Social Psychology, 103(6), 933–948. https://doi.org/10.1037/a0029709 Garnier, S. (2021). viridis: Default color maps from ’matplotlib’ [Manual]. https://CRAN.R-project.org/package=viridis Gelman, A. (2015). The connection between varying treatment effects and the crisis of unreplicable research: A Bayesian perspective. Journal of Management, 41(2), 632–643. https://doi.org/10.1177/0149206314525208 Gelman, A., &amp; Carlin, J. (2014). Beyond power calculations: Assessing type S (sign) and type M (magnitude) errors. Perspectives on Psychological Science, 9(6), 641–651. https://doi.org/10.1177/1745691614551642 Gelman, A., Goodrich, B., Gabry, J., &amp; Vehtari, A. (2019). R-squared for Bayesian regression models. The American Statistician, 73(3), 307–309. https://doi.org/10.1080/00031305.2018.1549100 Gelman, A., &amp; Hill, J. (2006). Data analysis using regression and multilevel/hierarchical models. Cambridge University Press. https://doi.org/10.1017/CBO9780511790942 Gelman, A., &amp; Stern, H. (2006). The difference between “significant” and “not significant” is not itself statistically significant. The American Statistician, 60(4), 328–331. https://doi.org/10.1198/000313006X152649 Grantham, N. (2019). ggdark: Dark mode for ’ggplot2’ themes [Manual]. https://CRAN.R-project.org/package=ggdark Grolemund, G., &amp; Wickham, H. (2017). R for data science. O’Reilly. https://r4ds.had.co.nz Hamaker, E. L. (2012). Why researchers should think \"within-person\": A paradigmatic rationale. In Handbook of research methods for studying daily life (pp. 43–61). The Guilford Press. https://www.guilford.com/books/Handbook-of-Research-Methods-for-Studying-Daily-Life/Mehl-Conner/9781462513055 Hayes, Andrew F. (2015). An index and test of linear moderated mediation. Multivariate Behavioral Research, 50(1), 1–22. https://doi.org/10.1080/00273171.2014.962683 Hayes, Andrew F. (2005). Statistical methods for communication science. Routledge. https://doi.org/10.4324/9781410613707 Hayes, Andrew F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach (Second edition). The Guilford Press. https://www.guilford.com/books/Introduction-to-Mediation-Moderation-and-Conditional-Process-Analysis/Andrew-Hayes/9781462534654 Hayes, Andrew F., Slater, M. D., &amp; Snyder, L. B. (2008). The SAGE sourcebook of advanced data analysis methods for communication research. https://us.sagepub.com/en-us/nam/the-sage-sourcebook-of-advanced-data-analysis-methods-for-communication-research/book228339 Healy, K. (2018). Data visualization: A practical introduction. Princeton University Press. https://socviz.co/ Heyns, E. (2020). Better BibTeX for zotero. https://retorque.re/zotero-better-bibtex/ Hocking, T. D. (2021). Directlabels: Direct labels for multicolor plots [Manual]. https://CRAN.R-project.org/package=directlabels IBM Corporation. (2020). IBM SPSS Statistics for Windows. https://www.ibm.com/products/spss-statistics Imai, K., Keele, L., &amp; Tingley, D. (2010). A general approach to causal mediation analysis. Psychological Methods, 15(4), 309–334. https://doi.org/10.1037/a0020761 Jaccard, J., &amp; Turrisi, R. (2003). Interaction effects in multiple regression (2nd edition). Sage Publications. https://dx.doi.org/10.4135/9781412984522 Kay, M. (2020a). Extracting and visualizing tidy draws from brms models. https://mjskay.github.io/tidybayes/articles/tidy-brms.html Kay, M. (2020b). tidybayes: Tidy data and ’geoms’ for Bayesian models. https://mjskay.github.io/tidybayes/ Kelley, K., &amp; Preacher, K. J. (2012). On effect size. Psychological Methods, 17(2), 137. https://doi.org/10.1037/a0028086 Klein, R. A., Cook, C. L., Ebersole, C. R., Vitiello, C., Nosek, B. A., Chartier, C. R., Christopherson, C. D., Clay, S., Collisson, B., Crawford, J., Cromar, R., Vidamuerte, D., Gardiner, G., Gosnell, C., Grahe, J., Hall, C., Joy-Gaba, J., Legg, A. M., Levitan, C., … Ratliff, K. (2019). Many Labs 4: Failure to replicate mortality salience effect with and without original author involvement. PsyArXiv. https://doi.org/10.31234/osf.io/vef2c Kruschke, J. K. (2015). Doing Bayesian data analysis: A tutorial with R, JAGS, and Stan. Academic Press. https://sites.google.com/site/doingbayesiandataanalysis/ Kruschke, J. K., &amp; Liddell, T. M. (2018). The Bayesian New Statistics: Hypothesis testing, estimation, meta-analysis, and power analysis from a Bayesian perspective. Psychonomic Bulletin &amp; Review, 25(1), 178–206. https://doi.org/10.3758/s13423-016-1221-4 Kurz, A. S. (2021). Statistical rethinking with brms, ggplot2, and the tidyverse: Second Edition (version 0.2.0). https://bookdown.org/content/4857/ Kurz, A. S. (2020a). Doing Bayesian data analysis in brms and the tidyverse (version 0.4.0). https://bookdown.org/content/3686/ Kurz, A. S. (2020b). Statistical rethinking with brms, ggplot2, and the tidyverse (version 1.2.0). https://doi.org/10.5281/zenodo.3693202 Legler, J., &amp; Roback, P. (2019). Broadening your statistical horizons: Generalized linear models and multilevel models. https://bookdown.org/roback/bookdown-bysh/ Little, T. D., Preacher, K. J., Selig, J. P., &amp; Card, N. A. (2007). New developments in latent variable panel analyses of longitudinal data. International Journal of Behavioral Development, 31(4), 357–365. https://doi.org/10.1177/0165025407077757 Lucas, T. (2016). palettetown: Use Pokemon inspired colour palettes [Manual]. https://CRAN.R-project.org/package=palettetown Maxwell, S. E., &amp; Cole, D. A. (2007). Bias in cross-sectional analyses of longitudinal mediation. Psychological Methods, 12(1), 23–44. https://doi.org/10.1037/1082-989X.12.1.23 Maxwell, S. E., Cole, D. A., &amp; Mitchell, M. A. (2011). Bias in cross-sectional analyses of longitudinal mediation: Partial and complete mediation under an autoregressive model. Multivariate Behavioral Research, 46(5), 816–841. https://doi.org/10.1080/00273171.2011.606716 McCabe, C. J., Kim, D. S., &amp; King, K. M. (2018). Improving present practices in the visual display of interactions. Advances in Methods and Practices in Psychological Science, 1(2), 147–165. https://doi.org/10.1177/2515245917746792 McElreath, R. (2020). Statistical rethinking: A Bayesian course with examples in R and Stan (Second Edition). CRC Press. https://xcelab.net/rm/statistical-rethinking/ McElreath, R. (2015). Statistical rethinking: A Bayesian course with examples in R and Stan. CRC press. https://xcelab.net/rm/statistical-rethinking/ Meredith, M., &amp; Kruschke, J. (2018). HDInterval: Highest (posterior) density intervals [Manual]. https://CRAN.R-project.org/package=HDInterval Merkle, E. C., &amp; Rosseel, Y. (2018). blavaan: Bayesian structural equation models via parameter expansion. Journal of Statistical Software, 85(4), 1–30. https://doi.org/10.18637/jss.v085.i04 Merkle, E. C., Rosseel, Y., &amp; Goodrich, B. (2020). blavaan: Bayesian latent variable analysis. https://CRAN.R-project.org/package=blavaan Miočević, M., MacKinnon, D. P., &amp; Levy, R. (2017). Power in Bayesian mediation analysis for small sample research. Structural Equation Modeling: A Multidisciplinary Journal, 24(5), 666–683. https://doi.org/10.1080/10705511.2017.1312407 Mitchell, M. A., &amp; Maxwell, S. E. (2013). A comparison of the cross-sectional and sequential designs when assessing longitudinal mediation. Multivariate Behavioral Research, 48(3), 301–339. https://doi.org/10.1080/00273171.2013.784696 Muthén, B., &amp; Asparouhov, T. (2015). Causal effects in mediation modeling: An introduction with applications to latent variables. Structural Equation Modeling: A Multidisciplinary Journal, 22(1), 12–23. https://doi.org/10.1080/10705511.2014.935843 Navarro, D. (2019). Learning statistics with R. https://learningstatisticswithr.com Nelson, L. D., Simmons, J., &amp; Simonsohn, U. (2018). Psychology’s renaissance. Annual Review of Psychology, 69(1), 511–534. https://doi.org/10.1146/annurev-psych-122216-011836 Pashler, H., &amp; Wagenmakers, E. (2012). Editors’ introduction to the special section on replicability in psychological science: A crisis of confidence? Perspectives on Psychological Science, 7(6), 528–530. https://doi.org/10.1177/1745691612465253 Peng, R. D. (2019). R programming for data science. https://bookdown.org/rdpeng/rprogdatascience/ Peng, R. D., Kross, S., &amp; Anderson, B. (2017). Mastering software development in {}R{}. https://github.com/rdpeng/RProgDA Preacher, K. J., &amp; Kelley, K. (2011). Effect size measures for mediation models: Quantitative strategies for communicating indirect effects. Psychological Methods, 16(2), 93–115. https://doi.org/10.1037/a0022658 Preacher, K. J., Rucker, D. D., &amp; Hayes, A. F. (2007). Addressing moderated mediation hypotheses: Theory, methods, and prescriptions. Multivariate Behavioral Research, 42(1), 185–227. https://doi.org/10.1080/00273170701341316 R Core Team. (2020). R: A language and environment for statistical computing. R Foundation for Statistical Computing. https://www.R-project.org/ Revelle, W. (2021). psych: Procedures for psychological, psychometric, and personality research. https://CRAN.R-project.org/package=psych Ripley, B. (2019). MASS: Support functions and datasets for venables and ripley’s MASS. https://CRAN.R-project.org/package=MASS Rogosa, D. (1980). Comparing nonparallel regression lines. Psychological Bulletin, 88(2), 307–321. https://doi.org/10.1037/0033-2909.88.2.307 Rosseel, Y., &amp; Jorgensen, T. D. (2019). lavaan: Latent variable analysis [Manual]. https://lavaan.org Roy Rosenzweig Center for History and New Media. (2020). Zotero. https://www.zotero.org/ SAS/IML software. (2020). https://www.sas.com/ Selig, J. P., &amp; Preacher, K. J. (2009). Mediation models for longitudinal data in developmental research. Research in Human Development, 6(2-3), 144–164. https://doi.org/10.1080/15427600902911247 Spiller, S. A., Fitzsimons, G. J., Lynch, J. G., &amp; Mcclelland, G. H. (2013). Spotlights, floodlights, and the magic number zero: Simple effects tests in moderated regression. Journal of Marketing Research, 50(2), 277–288. https://doi.org/10.1509/jmr.12.0420 Stan Development Team. (2020). RStan: The R interface to Stan. https://cran.r-project.org/web/packages/rstan/vignettes/rstan.html Stan Development Team. (2021). Stan user’s guide, Version 2.26. https://mc-stan.org/docs/2_26/stan-users-guide/index.html Thoen, E. (2019). dutchmasters [Manual]. https://github.com/EdwinTh/dutchmasters Torres-Manzanera, E. (n.d.). Xkcd: Plotting XKCD graphs. Journal of Statistical Software, 12. https://cran.r-project.org/package=xkcd/vignettes/xkcd-intro.pdf Torres-Manzanera, E. (2018). Xkcd: Plotting ggplot2 graphics in an XKCD style. https://CRAN.R-project.org/package=xkcd Tufte, E. R. (2001). The visual display of quantitative information (Second Edition). Graphics Press. https://www.edwardtufte.com/tufte/books_vdqi Valente, M. J., &amp; MacKinnon, D. P. (2017). Comparing models of change to estimate the mediated effect in the pretest-posttest control group design. Structural Equation Modeling : A Multidisciplinary Journal, 24(3), 428–450. https://doi.org/10.1080/10705511.2016.1274657 Valeri, L., &amp; VanderWeele, T. J. (2013). Mediation analysis allowing for exposuremediator interactions and causal interpretation: Theoretical assumptions and implementation with SAS and SPSS macros. Psychological Methods, 18(2), 137. https://doi.org/10.1037/a0031034 van Buuren, S. (2018). Flexible imputation of missing data (Second Edition). CRC Press. https://stefvanbuuren.name/fimd/ VanderWeele, T. (2015). Explanation in causal inference: Methods for mediation and interaction (1st edition). Oxford University Press. Vehtari, A., &amp; Gabry, J. (2020). Using the loo package (version \\(&gt;\\)= 2.0.0). https://CRAN.R-project.org/package=loo/vignettes/loo2-example.html Vehtari, A., &amp; Gabry, J. (2019). Bayesian stacking and pseudo-BMA weights using the loo package. https://CRAN.R-project.org/package=loo/vignettes/loo2-weights.html Vehtari, A., Gabry, J., Magnusson, M., Yao, Y., &amp; Gelman, A. (2019). loo: Efficient leave-one-out cross-validation and WAIC for bayesian models. https://CRAN.R-project.org/package=loo/ Vehtari, A., Gelman, A., &amp; Gabry, J. (2017). Practical Bayesian model evaluation using leave-one-out cross-validation and WAIC. Statistics and Computing, 27(5), 1413–1432. https://doi.org/10.1007/s11222-016-9696-4 Vehtari, A., Gelman, A., Simpson, D., Carpenter, B., &amp; Bürkner, P.-C. (2019). Rank-normalization, folding, and localization: An improved \\(\\widehat R\\) for assessing convergence of MCMC. arXiv Preprint arXiv:1903.08008. https://arxiv.org/abs/1903.08008? Vermeer, J. (1657). The little street. Vuorre, M. (2017). bmlm: Bayesian multilevel mediation [Manual]. https://cran.r-project.org/package=bmlm Vuorre, M. (2019). bmlm: Bayesian multilevel mediation [Manual]. https://github.com/mvuorre/bmlm/ Vuorre, M., &amp; Bolger, N. (2018). Within-subject mediation analysis for experimental data in cognitive psychology and neuroscience. Behavior Research Methods, 50(5), 2125–2143. https://doi.org/10.3758/s13428-017-0980-9 Wickham, H. (2016). ggplot2: Elegant graphics for data analysis. Springer-Verlag New York. https://ggplot2-book.org/ Wickham, H. (2019). tidyverse: Easily install and load the ’tidyverse’. https://CRAN.R-project.org/package=tidyverse Wickham, H., Averick, M., Bryan, J., Chang, W., McGowan, L. D., François, R., Grolemund, G., Hayes, A., Henry, L., Hester, J., Kuhn, M., Pedersen, T. L., Miller, E., Bache, S. M., Müller, K., Ooms, J., Robinson, D., Seidel, D. P., Spinu, V., … Yutani, H. (2019). Welcome to the tidyverse. Journal of Open Source Software, 4(43), 1686. https://doi.org/10.21105/joss.01686 Xie, Y. (2016). bookdown: Authoring books and technical documents with R markdown. Chapman and Hall/CRC. https://bookdown.org/yihui/bookdown/ Xie, Y. (2020). bookdown: Authoring books and technical documents with R Markdown. https://CRAN.R-project.org/package=bookdown Xie, Y., Allaire, J. J., &amp; Grolemund, G. (2020). R markdown: The definitive guide. Chapman and Hall/CRC. https://bookdown.org/yihui/rmarkdown/ Yao, Y., Vehtari, A., Simpson, D., &amp; Gelman, A. (2018). Using stacking to average Bayesian predictive distributions (with discussion). Bayesian Analysis, 13(3), 917–1007. https://doi.org/10.1214/17-BA1091 Yong, E. (2012). Replication studies: Bad copy. Nature News, 485(7398), 298. https://doi.org/10.1038/485298a Yuan, Y., &amp; MacKinnon, D. P. (2009). Bayesian mediation analysis. Psychological Methods, 14(4), 301–322. https://doi.org/10.1037/a0016972 "]]
