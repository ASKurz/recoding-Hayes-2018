[
["index.html", "recoding Introduction to Mediation, Moderation, and Conditional Process Analysis Welcome", " recoding Introduction to Mediation, Moderation, and Conditional Process Analysis A Solomon Kurz 2018-07-14 Welcome Andrew Hayes’s Introduction to Mediation, Moderation, and Conditional Process Analysis text, the second edition of which just came out, has become a staple in social science graduate education. Both editions of his text have been from a frequentist OLS perspective. This project is an effort to connect his work with the Bayesian paradigm. Herein I refit his models with my favorite R package for Bayesian regression, Bürkner’s brms. I also prefer plotting with Wickham’s ggplot2, and recently converted to using tidyverse-style syntax (which you might learn about here or here). But to be clear, this project is not meant to stand alone. It’s a supplement to the textbook. Disclaimer: brms is a rapidly-evolving package. To get a sense, see how frequently Bürkner has updated some of the most recent versions. I also have a lot to learn as a Bayesian and as an R user. So some of the code may appear dated or inelegant. Which is all to say, suggestions on how to improve my code are welcome. If you’re totally new to Bayesian regression and HMC estimation, you might want to look at this paper, watch a few of these, or even start with my other repo. That said, you do not need to be totally fluent in Bayes or brms. Otherwise why would you need this project, anyway? IMO, the most important things are curiosity, a willingness to try, and persistent tinkering. I love this stuff. Hopefully you will, too. Happy modeling! The source code of the project is available here. This project is powered by Yihui Xie’s bookdown package which makes it easy to turn R markdown files into HTML, PDF, and EPUB. You can learn more here. "],
["introduction.html", "1 Introduction References Session info", " 1 Introduction Since there’s no code or data plots in this chapter, there’s nothing to translate. Enjoy an old video of Hayes promoting conditional process analysis, instead. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] compiler_3.5.1 backports_1.1.2 bookdown_0.7 magrittr_1.5 #&gt; [5] rprojroot_1.3-2 tools_3.5.1 htmltools_0.3.6 yaml_2.1.19 #&gt; [9] Rcpp_0.12.17 stringi_1.2.3 rmarkdown_1.10 knitr_1.20 #&gt; [13] xfun_0.3 stringr_1.3.1 digest_0.6.15 evaluate_0.10.1 "],
["fundamentals-of-linear-regression.html", "2 Fundamentals of Linear Regression 2.1 Correlation and prediction 2.2 The simple linear regression model 2.3 Alternative explanations for association 2.4 Multiple linear regression 2.5 Measures of model fit 2.6 Statistical inference 2.7 Multicategorical antecedent variables 2.8 Assumptions for interpretation and statistical inference Reference Session info", " 2 Fundamentals of Linear Regression 2.1 Correlation and prediction Here we load a couple necessary packages, load the data, and take a peek. library(tidyverse) glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) #&gt; Observations: 815 #&gt; Variables: 7 #&gt; $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1.0, 2.6... #&gt; $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.67, 3.00... #&gt; $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.67, 2.00... #&gt; $ ideology &lt;int&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, 5, 4, 5... #&gt; $ age &lt;int&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 38, 63, ... #&gt; $ sex &lt;int&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1... #&gt; $ partyid &lt;int&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 3, 1, 1... If you are new to tidyverse-style syntax, possibly the oddest component is the pipe (i.e., %&gt;%). I’m not going to explain the %&gt;% in this project, but you might learn more about in this brief clip, starting around minute 21:25 in this talk by Wickham, or in section 5.6.1 from Grolemund and Wickham’s R for Data Science. Really, all of chapter 5 of R4DS is great for new R and new tidyverse users, and their chapter 3 is a nice introduction to plotting with ggplot2. Here is our version of Figure 2.1. glbwarm %&gt;% group_by(negemot, govact) %&gt;% count() %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_point(aes(size = n)) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + theme_bw() + theme(legend.position = &quot;none&quot;) There are other ways to handle the overplotting issue, such as jittering. glbwarm %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + theme_bw() Here’s the simple Pearson’s correlation coefficient. cor(glbwarm$negemot, glbwarm$govact) #&gt; [1] 0.578 If you want more plentiful output, the cor.test() function provides a \\(t\\)-value, the degrees of freedom, the corresponding \\(p\\)-value and the 95% confidence intervals, in addition to the Pearson’s correlation coefficient. cor.test(glbwarm$negemot, glbwarm$govact) #&gt; #&gt; Pearson&#39;s product-moment correlation #&gt; #&gt; data: glbwarm$negemot and glbwarm$govact #&gt; t = 20, df = 800, p-value &lt;2e-16 #&gt; alternative hypothesis: true correlation is not equal to 0 #&gt; 95 percent confidence interval: #&gt; 0.530 0.622 #&gt; sample estimates: #&gt; cor #&gt; 0.578 To get the Bayesian version, we’ll open our focal statistical package, Bürkner’s brms. [And I’ll briefly note that you could also do many of these analyses with other packages, such as blavaan. I just prefer brms.] library(brms) We’ll start simple and just use the default priors and settings, but with the addition of parallel sampling via cores = 4. model1 &lt;- brm(data = glbwarm, family = gaussian, cbind(negemot, govact) ~ 1, chains = 4, cores = 4) print(model1) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: negemot ~ 1 #&gt; govact ~ 1 #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; negemot_Intercept 3.56 0.05 3.45 3.67 3633 1.00 #&gt; govact_Intercept 4.59 0.05 4.50 4.68 3647 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_negemot 1.53 0.04 1.46 1.61 3603 1.00 #&gt; sigma_govact 1.36 0.03 1.30 1.43 3558 1.00 #&gt; rescor(negemot,govact) 0.58 0.02 0.53 0.62 3800 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Within the brms framework, \\(\\sigma\\) of the Gaussian likelihood is considered a family-specific parameter (e.g., there is no \\(\\sigma\\) for the Poisson distribution). When you have an intercept-only regression model with multiple variables, the covariance among their \\(\\sigma\\) parameters, rescor(negemot,govact) in this case, is a correlation. To learn more about the multivariate syntax in brms, click here or code vignette(&quot;brms_multivariate&quot;). But to clarify the output: ‘Estimate’ = the posterior mean, analogous to the frequentist point estimate ‘Est.Error’ = the posterior \\(SD\\), analogous to the frequentist standard error ‘l-95% CI’ = the lower-level of the percentile-based 95% Bayesian credible interval ‘u-95% CI’ = the upper-level of the same 2.2 The simple linear regression model Here is how one might get the simple OLS coefficients in base R with the lm() function. (model2 &lt;- lm(data = glbwarm, govact ~ 1 + negemot)) #&gt; #&gt; Call: #&gt; lm(formula = govact ~ 1 + negemot, data = glbwarm) #&gt; #&gt; Coefficients: #&gt; (Intercept) negemot #&gt; 2.757 0.514 For more detailed output, put the model object model2 into the summary() function. summary(model2) #&gt; #&gt; Call: #&gt; lm(formula = govact ~ 1 + negemot, data = glbwarm) #&gt; #&gt; Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -4.329 -0.673 0.102 0.755 3.214 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error t value Pr(&gt;|t|) #&gt; (Intercept) 2.7573 0.0987 27.9 &lt;2e-16 *** #&gt; negemot 0.5142 0.0255 20.2 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Residual standard error: 1.11 on 813 degrees of freedom #&gt; Multiple R-squared: 0.334, Adjusted R-squared: 0.333 #&gt; F-statistic: 407 on 1 and 813 DF, p-value: &lt;2e-16 Here’s the Bayesian model in brms. model2 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot, chains = 4, cores = 4) There are several ways to get a brms model summary. A go-to is with the print() function. print(model2) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ 1 + negemot #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 2.76 0.10 2.56 2.96 4000 1.00 #&gt; negemot 0.51 0.03 0.46 0.57 3803 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.11 0.03 1.06 1.17 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The summary() function works very much the same way. To get a more focused look, you can use the posterior_summary() function: posterior_summary(model2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; b_Intercept 2.758 0.1021 2.556 2.956 #&gt; b_negemot 0.514 0.0261 0.462 0.565 #&gt; sigma 1.112 0.0275 1.060 1.167 #&gt; lp__ -1248.621 1.2617 -1251.883 -1247.216 That also yields the log posterior, lp__, which you can learn more about here or here. We won’t focus on the lp__ directly in this project. But anyways, the Q2.5 and Q97.5, are the lower- and upper-levels of the 95% credible intervals. The Q prefix stands for quantile (see this thread). In this case, these are a renamed version of the l-95% CI and u-95% CI columns from our print() output. To make a quick plot of the regression line, one can use the convenient brms function, marginal_effects(). marginal_effects(model2) If you want to customize that output, you might nest it in plot(). plot(marginal_effects(model2), points = T, point_args = c(height = .05, width = .05, alpha = 1/2, size = 1/3)) It’s also useful to be able to work with the output of a brms model directly. For our first step, we’ll put our HMC draws into a data frame. post &lt;- posterior_samples(model2) head(post) #&gt; b_Intercept b_negemot sigma lp__ #&gt; 1 2.73 0.525 1.05 -1250 #&gt; 2 2.86 0.505 1.11 -1249 #&gt; 3 2.76 0.520 1.11 -1247 #&gt; 4 2.98 0.446 1.12 -1251 #&gt; 5 2.91 0.462 1.08 -1250 #&gt; 6 2.77 0.512 1.12 -1247 Next, we’ll use the fitted() function to simulate model-implied summaries for the expected govact value, given particular predictor values. Our first model only has negemot as a predictor, and we’ll ask for the expected govact values for negemot ranging from 0 to 7. nd &lt;- tibble(negemot = seq(from = 0, to = 7, length.out = 30)) f_model2 &lt;- fitted(model2, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) f_model2 #&gt; # A tibble: 30 x 5 #&gt; Estimate Est.Error Q2.5 Q97.5 negemot #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 2.76 0.102 2.56 2.96 0 #&gt; 2 2.88 0.0963 2.69 3.07 0.241 #&gt; 3 3.01 0.0906 2.83 3.18 0.483 #&gt; 4 3.13 0.0849 2.96 3.29 0.724 #&gt; 5 3.25 0.0794 3.10 3.41 0.966 #&gt; 6 3.38 0.0739 3.23 3.52 1.21 #&gt; # ... with 24 more rows The first two columns should look familiar to the output from print(model2), above. The next two columns, Q2.5 and Q97.5, are the lower- and upper-levels of the 95% credible intervals, like we got from posterior_samples(). We got the final column with the bind_cols(nd) code. Here’s our bespoke version of Figure 2.4. glbwarm %&gt;% group_by(negemot, govact) %&gt;% count() %&gt;% ggplot(aes(x = negemot)) + geom_point(aes(y = govact, size = n)) + geom_ribbon(data = f_model2, aes(ymin = Q2.5, ymax = Q97.5), fill = &quot;grey75&quot;, alpha = 3/4) + geom_line(data = f_model2, aes(y = Estimate)) + annotate(&quot;text&quot;, x = 2.2, y = 7.5, label = &quot;Cases with positive residuals&quot;, color = &quot;red3&quot;) + annotate(&quot;text&quot;, x = 4.75, y = .8, label = &quot;Cases with negative residuals&quot;, color = &quot;blue3&quot;) + labs(x = expression(paste(&quot;NEGEMOT: Negative emotions about climate change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = expression(paste(&quot;GOVACT: Support for governmentaction (&quot;, italic(&quot;Y&quot;), &quot;)&quot;))) + coord_cartesian(xlim = range(glbwarm$negemot)) + theme_bw() + theme(legend.position = &quot;none&quot;) 2.2.1 Interpretation of the constant and regression coefficient Nothing to recode, here. 2.2.2 The standardized regression model 2.2.3 Simple linear regression with a dichotomous antecedent variable. Here we add sex to the model. model3 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + sex, chains = 4, cores = 4) print(model3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ 1 + sex #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 4.72 0.07 4.58 4.85 3872 1.00 #&gt; sex -0.27 0.10 -0.45 -0.07 3960 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.36 0.03 1.29 1.42 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Our model output is very close to that in the text. If you just wanted the coefficients, you might use the fixef() function. fixef(model3) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 4.716 0.068 4.58 4.850 #&gt; sex -0.265 0.097 -0.45 -0.073 Though not necessary, we used the round() function to reduce the number of significant digits in the output. You can get a little more information with the posterior_summary() function. But since Bayesian estimation yields an entire posterior distribution, you can visualize that distribution in any number of ways. Because we’ll be using ggplot2, we’ll need to put the posterior draws into a data frame before plotting. post &lt;- posterior_samples(model3) We could summarize the posterior with boxplots: post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% select(male, female) %&gt;% gather() %&gt;% ggplot(aes(x = key, y = value)) + geom_boxplot(aes(fill = key)) + theme_bw() + theme(legend.position = &quot;none&quot;) Or with overlapping density plots: post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% select(male, female) %&gt;% gather() %&gt;% ggplot(aes(x = value, group = key, fill = key)) + geom_density(color = &quot;transparent&quot;, alpha = 3/4) + theme_bw() Or even with violin plots with superimposed posterior medians and 95% intervals: post %&gt;% rename(female = b_Intercept) %&gt;% mutate(male = female + b_sex) %&gt;% select(male, female) %&gt;% gather() %&gt;% ggplot(aes(x = key, y = value)) + geom_violin(aes(fill = key), color = &quot;transparent&quot;, alpha = 3/4) + stat_summary(fun.y = median, fun.ymin = function(i){quantile(i, probs = .025)}, fun.ymax = function(i){quantile(i, probs = .975)}) + theme_bw() + theme(legend.position = &quot;none&quot;) For even more ideas, see Matthew Kay’s tidybayes package. You can also get a sense of the model estimates for women and men with a little addition. Here we continue to use the round() function to simplify the output. # for women round(fixef(model3)[1, ], digits = 2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 4.72 0.07 4.58 4.85 # for men round(fixef(model3)[1, ] + fixef(model3)[2, ], digits = 2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 4.45 0.17 4.13 4.78 Here’s the partially-standardized model, first with lm(). glbwarm &lt;- glbwarm %&gt;% mutate(govact_z = (govact - mean(govact))/sd(govact)) lm(data = glbwarm, govact_z ~ 1 + sex) #&gt; #&gt; Call: #&gt; lm(formula = govact_z ~ 1 + sex, data = glbwarm) #&gt; #&gt; Coefficients: #&gt; (Intercept) sex #&gt; 0.0963 -0.1972 Now we’ll use Bayes. model3_p_z &lt;- brm(data = glbwarm, family = gaussian, govact_z ~ 1 + sex, chains = 4, cores = 4) fixef(model3_p_z) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 0.0979 0.0477 0.00333 0.1916 #&gt; sex -0.1996 0.0688 -0.33517 -0.0664 2.3 Alternative explanations for association On page 46, Hayes produced a couple correlations. Here’s how to get them from base R. cor(glbwarm$sex, glbwarm$negemot) #&gt; [1] -0.117 cor(glbwarm$sex, glbwarm$govact) #&gt; [1] -0.0986 Again, if we wanted to get full Bayesian estimates, we’d fit an intercept-only multivariate model. brm(data = glbwarm, family = gaussian, cbind(negemot, govact, sex) ~ 1, chains = 4, cores = 4) %&gt;% print(digits = 3) #&gt; Family: MV(gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: negemot ~ 1 #&gt; govact ~ 1 #&gt; sex ~ 1 #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; negemot_Intercept 3.558 0.054 3.453 3.660 4000 1.000 #&gt; govact_Intercept 4.587 0.048 4.490 4.678 4000 1.000 #&gt; sex_Intercept 0.489 0.018 0.454 0.522 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_negemot 1.532 0.038 1.459 1.607 4000 1.000 #&gt; sigma_govact 1.363 0.033 1.300 1.428 4000 1.000 #&gt; sigma_sex 0.502 0.013 0.477 0.528 4000 1.000 #&gt; rescor(negemot,govact) 0.576 0.023 0.530 0.620 4000 1.000 #&gt; rescor(negemot,sex) -0.117 0.034 -0.185 -0.046 4000 0.999 #&gt; rescor(govact,sex) -0.097 0.035 -0.166 -0.027 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). For our purposes, the action is in the ‘rescor(\\(i\\), \\(j\\))’ portions of the ‘Family Specific Parameters’ section. Anyway, if you wanted to get all the Pearson’s correlations among the glbwarm variables, rather than piecewise cor() approach, you could use the lowerCor() function from the psych package. psych::lowerCor(glbwarm[, 1:7], digits = 3) #&gt; govact posemt negemt idelgy age sex partyd #&gt; govact 1.000 #&gt; posemot 0.043 1.000 #&gt; negemot 0.578 0.128 1.000 #&gt; ideology -0.418 -0.029 -0.349 1.000 #&gt; age -0.097 0.042 -0.057 0.212 1.000 #&gt; sex -0.099 0.074 -0.117 0.133 0.166 1.000 #&gt; partyid -0.360 -0.036 -0.324 0.619 0.154 0.109 1.000 2.4 Multiple linear regression model4 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + posemot + ideology + sex + age, chains = 4, cores = 4) print(model4) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ 1 + negemot + posemot + ideology + sex + age #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 4.06 0.20 3.66 4.45 4000 1.00 #&gt; negemot 0.44 0.03 0.39 0.49 4000 1.00 #&gt; posemot -0.03 0.03 -0.08 0.03 4000 1.00 #&gt; ideology -0.22 0.03 -0.27 -0.16 4000 1.00 #&gt; sex -0.01 0.08 -0.16 0.14 4000 1.00 #&gt; age -0.00 0.00 -0.01 0.00 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.07 0.03 1.02 1.12 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Here is the posterior mean, what you might call the Bayesian point estimate, for someone with: negative emotions = 3, positive emotions = 4, ideology = 2, is male (i.e., sex = 1), and is 30 years of age fixef(model4)[1] + fixef(model4)[2]*3 + fixef(model4)[3]*4 + fixef(model4)[4]*2 + fixef(model4)[5]*1 + fixef(model4)[6]*30 #&gt; [1] 4.79 Here’s the same deal for a man of the same profile, but with one point higher on negemot. fixef(model4)[1] + fixef(model4)[2]*4 + fixef(model4)[3]*4 + fixef(model4)[4]*2 + fixef(model4)[5]*1 + fixef(model4)[6]*30 #&gt; [1] 5.23 If you want a full expression of the model uncertaintly in terms of the shape of the posterior distribution and the 95% intervals, you’ll probably just want to use posterior_samples() and do a little data processing. post &lt;- posterior_samples(model4) post &lt;- post %&gt;% mutate(our_posterior = b_Intercept + b_negemot*4 + b_posemot*4 + b_ideology*2 + b_sex*1 + b_age*30) # This intermediary step will make it easier to specify the break points and their labels for the x-axis post_summary &lt;- quantile(post$our_posterior, probs = c(.025, .5, .975)) %&gt;% as_tibble() %&gt;% mutate(labels = value %&gt;% round(digits = 3) %&gt;% as.character()) ggplot(data = post, aes(x = our_posterior)) + geom_density(fill = &quot;black&quot;) + geom_vline(xintercept = post_summary$value, size = c(.5, .75, .5), linetype = c(2, 1, 2), color = &quot;white&quot;) + scale_x_continuous(NULL, breaks = post_summary$value, labels = post_summary$labels) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The expected govact score for a 30-year-old man for whom\\nnegemot and posemot both equal 4 and ideology equals 2.\\nThe solid and dashed white vertical lines are the posterior\\nmedian and 95% intervals, respectively.&quot;) + theme_bw() In the text, Hayes showed that individuals based on these two profiles would be expected to differ by 0.441 (i.e., 5.244 - 4.803 = 0.441). That’s fine if you’re only working with OLS point estimates. But a proper Bayesian approach would express the difference in terms of an entire poster distribution, or at least a point estimate accompanied by some sort of intervals. Here we’ll just work with the posterior to create a difference distribution. You could do that with a little deft posterior_samples() wrangling. Here we’ll employ fitted(). nd &lt;- tibble(negemot = c(3, 4), posemot = 4, ideology = 2, sex = 1, age = 30) fitted(model4, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% rename(condition_a = V1, contition_b = V2) %&gt;% mutate(difference = contition_b - condition_a) %&gt;% ggplot(aes(x = difference)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + ggtitle(&quot;The posterior density for the difference between\\nthe two conditions.&quot;) + theme_bw() 2.4.1 The standardized regression model. Since brms doesn’t automatically give us the standardized coefficients the way OLS output often does, we’ll have to be proactive. One solution is just to standardized the data themselves and then re-fit the model with those standardized variables. That leads us to the issue of how one standardized variables to begin with. Recall that standardizing entails subtracting the mean of a variable from that variable and then dividing that value by the standard deviation. We don’t want to do that by hand. So one handy way is to make a custom function to do that work for us. sandardize &lt;- function(x){ (x - mean(x))/sd(x) } Go here to learn more about making custom functions in R. Here we’ll employ our custom standardize() function to make standardized versions of our variables. glbwarm &lt;- glbwarm %&gt;% mutate(posemot_z = sandardize(posemot), negemot_z = sandardize(negemot), ideology_z = sandardize(ideology), sex_z = sandardize(sex), age_z = sandardize(age)) Now we’ve got us our standardized variables, let’s fit a standardized model. model4_z &lt;- brm(data = glbwarm, family = gaussian, govact_z ~ 1 + negemot_z + posemot_z + ideology_z + sex_z + age_z, chains = 4, cores = 4) Here are the newly standardized coefficient summaries, minus the Intercept. fixef(model4_z)[-1, ] %&gt;% round(3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; negemot_z 0.495 0.030 0.435 0.553 #&gt; posemot_z -0.027 0.028 -0.082 0.025 #&gt; ideology_z -0.243 0.031 -0.304 -0.182 #&gt; sex_z -0.003 0.028 -0.059 0.051 #&gt; age_z -0.016 0.029 -0.073 0.041 Our coefficients match up nicely with those in the text. Just as with Hayes’s OLS estimates, we should not attempt to interpret the standardized sex_z coefficient from our Bayesian model. Here’s how we’d fit a partially-standardized model–a model in which all variables except for sex are standardized. model4_z_p &lt;- update(model4_z, newdata = glbwarm, formula = govact_z ~ 1 + negemot_z + posemot_z + ideology_z + sex + age_z, chains = 4, cores = 4) And here are the coefficient summaries, including the Intercept, for the partially-standardized model. fixef(model4_z_p) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 0.003 0.040 -0.075 0.081 #&gt; negemot_z 0.494 0.029 0.438 0.550 #&gt; posemot_z -0.027 0.028 -0.082 0.027 #&gt; ideology_z -0.243 0.030 -0.302 -0.184 #&gt; sex -0.006 0.055 -0.114 0.101 #&gt; age_z -0.015 0.028 -0.069 0.038 As Hayes wrote, now sex = -0.006 has a sensible interpretation. “We can say that men and women differ by [-0.006] standard deviations in their support for government action when all other variables in the model are held constant (p. 53).” On page 54, Hayes gave us the equation to transform unstandardized coefficients to standardized ones: \\[\\tilde{b}_{i} = b_{i}\\left(\\frac{SD_{X_{i}}}{SD_{Y}}\\right)\\] Let’s give it a whirl with negemot. # Here&#39;s the coefficient for `negemot` from the standardized model, `model4_z` fixef(model4_z)[&quot;negemot_z&quot;, &quot;Estimate&quot;] #&gt; [1] 0.495 # Here&#39;s the coefficient for `negemot` from the unstandardized model, `model4` fixef(model4)[&quot;negemot&quot;, &quot;Estimate&quot;] #&gt; [1] 0.441 # And here we use Hayes&#39;s formula to standardize the unstandardized coefficient fixef(model4)[&quot;negemot&quot;, &quot;Estimate&quot;]*(sd(glbwarm$negemot)/sd(glbwarm$govact)) #&gt; [1] 0.495 Looks like we got it within rounding error–pretty good! However, that was just the posterior mean, the Bayesian point estimate. If we want to more fully express the uncertainty around the mean–and we do–, we’ll need to work with the posterior draws. # the posterior draws from the unstandardized model posterior_samples(model4) %&gt;% # using Hayes&#39;s formula to standardize `b_negemot` mutate(`hand-made b_negemot_z` = b_negemot*(sd(glbwarm$negemot)/sd(glbwarm$govact))) %&gt;% # taking on the `b_negemot_z` column from the standardized `model4_z` models posterior draws bind_cols(posterior_samples(model4_z) %&gt;% select(b_negemot_z)) %&gt;% # isolating those two columns select(`hand-made b_negemot_z`, b_negemot_z) %&gt;% # converting the data to the long format and grouping by `key` gather() %&gt;% group_by(key) %&gt;% # here we summarize the results summarise(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 5 #&gt; key mean sd ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 b_negemot_z 0.495 0.03 0.435 0.553 #&gt; 2 hand-made b_negemot_z 0.495 0.029 0.437 0.552 So our summary confirms that we can apply Hayes’s formula to a posterior_samples() column in order to get fuller summary statistics for a hand-converted standardized coefficient. This would be in full compliance with, say, APA recommendations to include 95% intervals with all effect sizes–the standardized regression coefficient being the effect size, here. 2.5 Measures of model fit In the Bayesian world, we don’t tend to appeal to the \\(SS_{residual}\\), the \\(MS_{residual}\\), or the standard error of estimate. We do sometimes, however, appeal to the \\(R^2\\). I’m not going to go into the technical details here, but you should be aware that the Bayesian \\(R^2\\) is not calculated the same as the OLS \\(R^2\\) is. If you want to dive in, check out the paper by Gelman, Goodrich, Gabry, and Ali. Here’s how to get it in brms. bayes_R2(model4, summary = T) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.389 0.02 0.347 0.427 Happily, it comes with 95% intervals, which will make the editors at APA journals happy. If you want to go beyond summary statistics and take a look at the full posterior, just set summary = F and data wrangle and plot as usual. bayes_R2(model4, summary = F) %&gt;% as_tibble() %&gt;% ggplot(aes(x = R2)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Behold: The Bayesian &quot;, italic(&quot;R&quot;)^{2}, &quot; distribution for model 4&quot;)), x = NULL) + coord_cartesian(xlim = 0:1) + theme_bw() Another way we examine model fit is with graphical posterior predictive checks. Posterior predictive checking is a very general approach, which you might learn more about here or with a few keyword searches in on Gelman’s blog. One basic way is to use the model in order to simulate data and then compare those data with the original data–the basic idea being that good fitting models should produce data similar to the original data. Recall how we’ve used fitted() to make regression lines and expected values? We’ll, now we’ll use predict() to simulate data based on our models. predict(model4, summary = F, nsamples = 3) %&gt;% t() %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(key = str_replace(key, &quot;V&quot;, &quot;simulation &quot;)) %&gt;% rename(govact = value) %&gt;% bind_cols( bind_rows( glbwarm %&gt;% select(-govact), glbwarm %&gt;% select(-govact), glbwarm %&gt;% select(-govact)) ) %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + coord_cartesian(ylim = 0:9) + theme_bw() + facet_wrap(~key, ncol = 3) The question is, do these simulated data sets look like the original data? Let’s see. glbwarm %&gt;% ggplot(aes(x = negemot, y = govact)) + geom_jitter(height = .05, width = .05, alpha = 1/2, size = 1/3) + coord_cartesian(ylim = 0:9) + theme_bw() Overall, the simulations aren’t bad. But in all three govact tends to veer above 7.5, which is where the original data appear to be bounded. But otherwise the overall shape is pretty close, at least with respect to negemot. There’s nothing special about three simulations. Three is just more than one and gives you a sense of the variance across simulations. Also, we only examined the model fit with respect to negemot. Since there are other variables in the model, we might also assess the model based on them. Another method is with the brms::pp_check() function, which allows users to access a variety of convenience functions from the bayesplot package. Here we’ll use the default settings and just tack on theme_bw() for aesthetics. pp_check(model4) + theme_bw() #&gt; Using 10 posterior samples for ppc type &#39;dens_overlay&#39; by default. What we did was simulate 10 data sets worth of govact values, plot their densities (i.e., the thin blue lines) and compare them with the density of the original govact values. What we want is for the thin blue lines to largely align with the thick blue line. Though not perfect, the simulations from our model4 did a pretty okay job of reproducing the original govact distribution. For more ideas on this method, see the brms reference manual and this vignette for the bayesplot package. 2.6 Statistical inference Here’s a tidyverse way to do Hayes’s simulation. We’re just using OLS regression with the lm() function. You could do this with Bayesian HMC estimation, but man would it take a while. # first, we&#39;ll need two custom functions # this first one will use the `sample_n()` function to randomly sample from `glbwarm` make_sample &lt;- function(i){ set.seed(i) sample_n(glbwarm, 50, replace = F) } # this second function will fit our model, the same one from `model4`, to each of our subsamples glbwarm_model &lt;- function(df) { lm(govact ~ 1 + negemot + posemot + ideology + sex + age, data = df) } # we need an iteration index, which will double as the values we set our seed with in our `make_sample()` function tibble(iter = 1:1e4) %&gt;% group_by(iter) %&gt;% # inserting our subsamples mutate(sample = map(iter, make_sample)) %&gt;% # fitting our models mutate(model = map(sample, glbwarm_model)) %&gt;% # taking those model results and tidying them with the broom package mutate(broom = map(model, broom::tidy)) %&gt;% # unnesting allows us to access our model results unnest(broom) %&gt;% # we&#39;re only going to focus on the estimates for `negemot` filter(term == &quot;negemot&quot;) %&gt;% # Here it is, Figure 2.7 ggplot(aes(x = estimate)) + geom_histogram(binwidth = .025, boundary = 0) + labs(x = &quot;Unstandardized regression coefficient for negemot&quot;, y = &quot;Frequency in 1e4 samples of size 50&quot;) + theme_bw() To learn more about this approach to simulations, see this section of R4DS. 2.6.1 Testing a null hypothesis. As Bayesians, we don’t need to wed ourselves to the null hypothesis. We’re not interested in the probability of the data given the null hypothesis. Rather, we’re interested in the probability of the parameters given the data. posterior_samples(model4) %&gt;% ggplot(aes(x = b_negemot)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + geom_vline(xintercept = posterior_interval(model4)[&quot;b_negemot&quot;, ], color = &quot;white&quot;, linetype = 2) + scale_x_continuous(breaks = posterior_interval(model4)[&quot;b_negemot&quot;, ] %&gt;% as.double(), labels = posterior_interval(model4)[&quot;b_negemot&quot;, ] %&gt;% as.double() %&gt;% round(digits = 2) %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The most probable values for our b_negemot parameter are the ones around the peak\\nof the density. For convenience, the dashed lines denote the 95% credible intervals.\\nSure, you could ask yourself, &#39;Is zero within those intervals?&#39; But with such rich output,\\nthat seems like an impoverished question to ask.&quot;) + theme_bw() 2.6.2 Interval estimation. Within the Bayesian paradigm, we don’t use 95% intervals based on the typical frequentist formula. With the brms package, we typically use percentile-based intervals. Take the 95% credible intervals for the negemot coefficient from model model4: posterior_interval(model4)[&quot;b_negemot&quot;, ] #&gt; 2.5% 97.5% #&gt; 0.389 0.491 We can actually get those intervals with the simple use of the base R quantile() function. posterior_samples(model4) %&gt;% summarize(the_2.5_percentile = quantile(b_negemot, probs = .025), the_97.5_percentile = quantile(b_negemot, probs = .975)) #&gt; the_2.5_percentile the_97.5_percentile #&gt; 1 0.389 0.491 The consequence of this is that our Bayesian credible intervals aren’t necessarily symmetric. Which is fine because the posterior distribution for a given parameter isn’t always symmetric. But not all Bayesian intervals are percentile based. John Kruschke, for example, often recommends highest posterior density intervals in his work. The brms package doesn’t have a convenience function for these, but you can compute them with help from the HDInterval package. library(HDInterval) hdi(posterior_samples(model4)[ , &quot;b_negemot&quot;], credMass = .95) #&gt; lower upper #&gt; 0.388 0.488 #&gt; attr(,&quot;credMass&quot;) #&gt; [1] 0.95 Finally, because Bayesians aren’t bound to the NHST paradigm, we aren’t bound to 95% intervals, either. For example, in both his excellent text and as a default in its accompanying rethinking package, Richard McElreath often uses 89% intervals. Alternatively, Andrew Gelman has publically advocated for 50% intervals. The most important thing is to express the uncertainty in the posterior in a clearly-specified way. If you’d like, say, 80% intervals in your model summary, you can insert a prob argument into either print() or summary(). print(model4, prob = .8) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ 1 + negemot + posemot + ideology + sex + age #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-80% CI u-80% CI Eff.Sample Rhat #&gt; Intercept 4.06 0.20 3.80 4.31 4000 1.00 #&gt; negemot 0.44 0.03 0.41 0.47 4000 1.00 #&gt; posemot -0.03 0.03 -0.06 0.01 4000 1.00 #&gt; ideology -0.22 0.03 -0.25 -0.18 4000 1.00 #&gt; sex -0.01 0.08 -0.11 0.09 4000 1.00 #&gt; age -0.00 0.00 -0.00 0.00 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-80% CI u-80% CI Eff.Sample Rhat #&gt; sigma 1.07 0.03 1.04 1.10 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Note how two of our columns changed to ‘l-80% CI’ and ‘u-80% CI’. You can specify custom percentile levels with posterior_summary(): posterior_summary(model4, probs = c(.9, .8, .7, .6, .4, .3, .2, .1)) %&gt;% round(digits = 2) #&gt; Estimate Est.Error Q90 Q80 Q70 Q60 Q40 Q30 Q20 Q10 #&gt; b_Intercept 4.06 0.20 4.31 4.23 4.17 4.11 4.01 3.96 3.89 3.80 #&gt; b_negemot 0.44 0.03 0.47 0.46 0.45 0.45 0.43 0.43 0.42 0.41 #&gt; b_posemot -0.03 0.03 0.01 0.00 -0.01 -0.02 -0.03 -0.04 -0.05 -0.06 #&gt; b_ideology -0.22 0.03 -0.18 -0.20 -0.20 -0.21 -0.22 -0.23 -0.24 -0.25 #&gt; b_sex -0.01 0.08 0.09 0.05 0.03 0.01 -0.03 -0.05 -0.08 -0.11 #&gt; b_age 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 0.00 #&gt; sigma 1.07 0.03 1.10 1.09 1.08 1.07 1.06 1.06 1.05 1.04 #&gt; lp__ -1215.77 1.83 -1213.73 -1214.24 -1214.63 -1215.03 -1215.93 -1216.45 -1217.15 -1218.26 And of course, you can use multiple interval summaries when you summarize() the output from posterior_samples(). E.g., posterior_samples(model4) %&gt;% select(b_Intercept:b_age) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(`l-95% CI` = quantile(value, probs = .025), `u-95% CI` = quantile(value, probs = .975), `l-50% CI` = quantile(value, probs = .25), `u-50% CI` = quantile(value, probs = .75)) %&gt;% mutate_if(is.double, round, digits = 2) #&gt; # A tibble: 6 x 5 #&gt; key `l-95% CI` `u-95% CI` `l-50% CI` `u-50% CI` #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 b_age -0.01 0 0 0 #&gt; 2 b_ideology -0.27 -0.16 -0.24 -0.2 #&gt; 3 b_Intercept 3.66 4.45 3.92 4.2 #&gt; 4 b_negemot 0.39 0.49 0.42 0.46 #&gt; 5 b_posemot -0.08 0.03 -0.05 -0.01 #&gt; 6 b_sex -0.16 0.14 -0.06 0.04 Throughout this project, I’m going to be lazy and default to conventional 95% intervals, with occasional appearances of 50% intervals. 2.6.3 Testing a hypothesis about a set of antecedent variables. Here we’ll make use of the update() function to hastily fit our reduced model, model5. model5 &lt;- update(model4, govact ~ 1 + ideology + sex + age, chains = 4, cores = 4) We can get a look at the \\(R^2\\) summaries for our competing models like this. bayes_R2(model4) %&gt;% round(digits = 2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.39 0.02 0.35 0.43 bayes_R2(model5) %&gt;% round(digits = 2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.18 0.02 0.14 0.22 So far, it looks like our fuller model, model4, explains more variation in the data. If we wanted to look at their distributions, we’d set summary = F in the bayes_R2() function and convert the results to a data frame or tibble. Here we use bind_cols() to put the \\(R^2\\) results for both in the same tibble. R2s &lt;- bayes_R2(model4, summary = F) %&gt;% as_tibble() %&gt;% rename(R2_model4 = R2) %&gt;% bind_cols( bayes_R2(model5, summary = F) %&gt;% as_tibble() %&gt;% rename(R2_model5 = R2) ) head(R2s) #&gt; # A tibble: 6 x 2 #&gt; R2_model4 R2_model5 #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.374 0.177 #&gt; 2 0.402 0.239 #&gt; 3 0.383 0.174 #&gt; 4 0.397 0.181 #&gt; 5 0.372 0.178 #&gt; 6 0.404 0.184 With our R2s tibble in hand, we’re ready to plot. R2s %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + theme_bw() Yep, the \\(R^2\\) distribution for model4, the one including the emotion variables, is clearly larger than that for the more parsimonious model5. And it’d just take a little more data wrangling to get a formal \\(R^2\\) difference score. R2s %&gt;% mutate(difference = R2_model5 - R2_model4) %&gt;% ggplot(aes(x = difference)) + geom_density(fill = &quot;black&quot;, color = &quot;transparent&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = -1:0) + labs(title = expression(paste(Delta, italic(&quot;R&quot;)^{2})), subtitle = expression(paste(&quot;This is the amount the &quot;, italic(&quot;R&quot;)^{2}, &quot; dropped after we pruned the emotion variables from the model.&quot;)), x = NULL) + theme_bw() The \\(R^2\\) approach is popular within the social sciences. But it has its limitations, the first of which is that it doesn’t correct for model complexity. The second is it’s not applicable to a range of models, such as those that do not use the Gaussian likelihood (e.g., logistic regression) or to multilevel models. Happily, information criteria offer a more general framework. The AIC is the most popular information criteria among frequentists. Within the Bayesian world, we have the DIC, the WAIC, and the LOO. The DIC is quickly falling out of favor and is not immediately available with the brms package. However, we can use the WAIC and the LOO, both of which are computed in brms via the loo package. In brms, you can get the WAIC or LOO values with waic() or loo(), respectively. Here we use loo() and save the output as objects. l_model4 &lt;- loo(model4) l_model5 &lt;- loo(model5) Here’s the main loo-summary output for model4. l_model4 #&gt; #&gt; Computed from 4000 by 815 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -1213.7 22.7 #&gt; p_loo 7.5 0.6 #&gt; looic 2427.5 45.5 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. You get a wealth of output, more of which can be seen with str(l_model4). For now, notice the “All pareto k estimates are good (k &lt; 0.5).” Pareto \\(k\\) values can be used for diagnostics. Each case in the data gets its own \\(k\\) value and we like it when those \\(k\\)s are low. The makers of the loo package get worried when those \\(k\\)s exceed 0.7 and as a result, loo() spits out a warning message when they do. Happily, we have no such warning messages in this example. If you want to work with the \\(k\\) values directly, you can extract them and place them into a tibble like so: l_model4$diagnostics %&gt;% as_tibble() #&gt; # A tibble: 815 x 2 #&gt; pareto_k n_eff #&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.120 3973. #&gt; 2 -0.143 3992. #&gt; 3 0.0169 3890. #&gt; 4 0.311 2405. #&gt; 5 -0.0462 3997. #&gt; 6 -0.126 3966. #&gt; # ... with 809 more rows The pareto_k values can be used to examine cases that are overly-influential on the model parameters, something akin to a Cook’s \\(D_{i}\\). See, for example this discussion on stackoverflow.com in which several members of the Stan team weighed in. The issue is also discussed in this paper and in this lecture by Aki Vehtari. But anyway, we’re getting ahead of ourselves. Back to the LOO. Like other information criteria, the LOO values aren’t of interest in and of themselves. However, the values of one model’s LOO relative to that of another is of great interest. We generally prefer models with lower information criteria. With compare_ic(), we can compute a formal difference score between multiple loo objects. compare_ic(l_model4, l_model5) #&gt; LOOIC SE #&gt; model4 2427 45.5 #&gt; model5 2666 41.1 #&gt; model4 - model5 -238 31.8 We also get a standard error. Here it looks like model4 was substantially better, in terms of LOO-values, than model5. For more on the LOO, see the loo reference manual, this handy vignette, or the scholarly papers referenced therein. Also, although McElreath doesn’t discuss the LOO, he does cover the topic in general in his text and in his online lectures on the topic. 2.7 Multicategorical antecedent variables partyid is coded 1 = Democrat 2 = Independent 3 = Repuclican. You can get a count of the cases within a give partyid like this: glbwarm %&gt;% group_by(partyid) %&gt;% count() #&gt; # A tibble: 3 x 2 #&gt; # Groups: partyid [3] #&gt; partyid n #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 1 359 #&gt; 2 2 192 #&gt; 3 3 264 We can get grouped means for govact like this: glbwarm %&gt;% group_by(partyid) %&gt;% summarize(mean_support_for_governmental_action = mean(govact)) #&gt; # A tibble: 3 x 2 #&gt; partyid mean_support_for_governmental_action #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 1 5.06 #&gt; 2 2 4.61 #&gt; 3 3 3.92 We can make dummies with the ifelse() function. We’ll just go ahead and do that right within the brm() function. model6 &lt;- brm(data = glbwarm %&gt;% mutate(Democrat = ifelse(partyid == 1, 1, 0), Republican = ifelse(partyid == 3, 1, 0)), family = gaussian, govact ~ 1 + Democrat + Republican, chains = 4, cores = 4) fixef(model6) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 4.607 0.0929 4.426 4.786 #&gt; Democrat 0.458 0.1140 0.232 0.683 #&gt; Republican -0.684 0.1224 -0.913 -0.436 The intercept is the stand-in for Independents and the other two coefficients are difference scores. The \\(R^2\\) is okay: bayes_R2(model6) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.133 0.021 0.093 0.175 There’s no need to compute an \\(F\\)-test on our \\(R^2\\). The posterior mean and it’s 95% intervals are well away from zero. But you could use your bayes_R2(model6, summary = F) plotting skills from above to more fully inspect the posterior if you’d like. We could also use information criteria. One method would be to compare the WAIC or LOO value of model6 with an intercept-only model. First, we’ll need to fit that model. model7 &lt;- update(model6, govact ~ 1, chains = 4, cores = 4) If we just put both models into waic(), we can side step the need to save their outputs as objects which we then put into compare_ic(). waic(model6, model7) #&gt; WAIC SE #&gt; model6 2707 40.1 #&gt; model7 2818 42.7 #&gt; model6 - model7 -110 20.8 The WAIC comparison suggests model6, the one with the partyid dummies, is an improvement over the simple intercept-only model. Another way to compare the information criteria is with AIC-type weighting. The brms package offers a variety of weighting methods via the model_weights() function. MWs &lt;- model_weights(model6, model7, weights = &quot;waic&quot;) MWs #&gt; model6 model7 #&gt; 1.00e+00 1.14e-24 If you’re not a fan of scientific notation, you can put the results in a tibble and look at them on a plot. MWs %&gt;% as.data.frame() %&gt;% rownames_to_column() %&gt;% ggplot(aes(x = ., y = rowname)) + geom_point() + labs(subtitle = &quot;The weights should sum to 1. In this case virtually all the weight is placed\\nin model6. Recall, that these are RELATIVE weights. Add another\\nmodel fit into the mix and the weights might well change.&quot;, x = &quot;WAIC weight&quot;, y = NULL) + theme_bw() + theme(axis.ticks.y = element_blank()) You could, of course, do all this with the LOO. 2.8 Assumptions for interpretation and statistical inference 2.8.1 Linearity. I have nothing to add, here. 2.8.2 Normality. The brms package is quite general and allows users to fit models from a variety of likelihoods other than the Gaussian. For example, users can accommodate outliers/extreme values with Student’s t regression. You can do count regression with the Poisson or the negative binomial… For more, see McElreath’s lecture introducing the generalized linear model or Bürkner’s vignette, Parameterization of Response Distributions in brms 2.8.3 Homoscedasticity. The brms package can also accommodate homoscedasticity with distributional modeling. In short, one simply models \\(\\sigma\\) in addition to the mean, \\(\\mu\\). See Bürkner’s handy vignette on the topic. 2.8.4 Independence. And the issue of independence is where the multilevel model comes on. See any relevant text, such as Statistical Rethinking or Data Analysis Using Regression and Multilevel/Hierarchical Models. Reference Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] HDInterval_0.2.0 bindrcpp_0.2.2 brms_2.3.4 Rcpp_0.12.17 forcats_0.3.0 stringr_1.3.1 #&gt; [7] dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 #&gt; [13] tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 threejs_0.3.1 #&gt; [6] httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 tools_3.5.1 backports_1.1.2 #&gt; [11] utf8_1.1.4 R6_2.2.2 DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 #&gt; [16] withr_2.1.2 tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 xml2_1.2.0 #&gt; [26] labeling_0.3 colourpicker_1.0 bookdown_0.7 scales_0.5.0 dygraphs_1.1.1.5 #&gt; [31] mvtnorm_1.0-8 psych_1.8.4 ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 #&gt; [36] foreign_0.8-70 rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 shiny_1.1.0 #&gt; [46] bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 gtools_3.8.1 crosstalk_1.0.0 #&gt; [51] inline_0.3.15 magrittr_1.5 loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 #&gt; [56] munsell_0.5.0 abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 miniUI_0.1.1.1 #&gt; [66] lattice_0.20-35 haven_1.1.2 hms_0.4.2 knitr_1.20 pillar_1.2.3 #&gt; [71] igraph_1.2.1 markdown_0.8 shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 #&gt; [76] stats4_3.5.1 rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 xfun_0.3 #&gt; [86] mime_0.5 xtable_1.8-2 broom_0.4.5 coda_0.19-1 later_0.7.3 #&gt; [91] rsconnect_0.8.8 shinythemes_1.1.1 bridgesampling_0.4-0 "],
["the-simple-mediation-model.html", "3 The Simple Mediation Model 3.1 Estimation of the direce, indirect, and total effects of \\(X\\) 3.2 Example with dichotomous \\(X\\): The influence of presumed media influence 3.3 Statistical inference 3.4 An example with continuous \\(X\\): Economic stress among small-business owners Reference Session info", " 3 The Simple Mediation Model 3.1 Estimation of the direce, indirect, and total effects of \\(X\\) 3.2 Example with dichotomous \\(X\\): The influence of presumed media influence Here we load a couple necessary packages, load the data, and take a peek at them. library(tidyverse) pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) glimpse(pmi) #&gt; Observations: 123 #&gt; Variables: 6 #&gt; $ cond &lt;int&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0... #&gt; $ pmi &lt;dbl&gt; 7.0, 6.0, 5.5, 6.5, 6.0, 5.5, 3.5, 6.0, 4.5, 7.0, 1.0, 6.0, 5.0, 7.0, 7.0, 7.0, 4.5, 3.5... #&gt; $ import &lt;int&gt; 6, 1, 6, 6, 5, 1, 1, 6, 6, 6, 3, 3, 4, 7, 1, 6, 3, 3, 2, 4, 4, 6, 7, 4, 5, 4, 6, 5, 5, 7... #&gt; $ reaction &lt;dbl&gt; 5.25, 1.25, 5.00, 2.75, 2.50, 1.25, 1.50, 4.75, 4.25, 6.25, 1.25, 2.75, 3.75, 5.00, 4.00... #&gt; $ gender &lt;int&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1... #&gt; $ age &lt;dbl&gt; 51.0, 40.0, 26.0, 21.0, 27.0, 25.0, 23.0, 25.0, 22.0, 24.0, 22.0, 21.0, 23.0, 21.0, 22.0... You can get the male/female split like so: pmi %&gt;% group_by(gender) %&gt;% count() #&gt; # A tibble: 2 x 2 #&gt; # Groups: gender [2] #&gt; gender n #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 0 80 #&gt; 2 1 43 Here is the split by condition: pmi %&gt;% group_by(cond) %&gt;% count() #&gt; # A tibble: 2 x 2 #&gt; # Groups: cond [2] #&gt; cond n #&gt; &lt;int&gt; &lt;int&gt; #&gt; 1 0 65 #&gt; 2 1 58 Here is how to get the ungrouped mean and SD values for reaction and pmi, as presented in Table 3.1, pmi %&gt;% select(reaction, pmi) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 pmi 5.60 1.32 #&gt; 2 reaction 3.48 1.55 You might get the mean and SD values for reaction and pmi grouped by cond like this: pmi %&gt;% select(reaction, pmi, cond) %&gt;% gather(key, value, -cond) %&gt;% group_by(cond, key) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 4 x 4 #&gt; # Groups: cond [2] #&gt; cond key mean sd #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 pmi 5.38 1.34 #&gt; 2 0 reaction 3.25 1.61 #&gt; 3 1 pmi 5.85 1.27 #&gt; 4 1 reaction 3.75 1.45 Let’s load our primary statistical package. library(brms) Before we begin, I should acknowledge that I greatly benefited by this great blog post on path analysis in brms by Jarrett Byrnes. In brms, we handle mediation models using the multivariate syntax. There are a few ways to do this. Let’s start simple. If you look at the path model in Figure 3.3, you’ll note that reaction is predicted by pmi and cond. pmi, in turn, is predicted solely by cond. So we have two regression models, which is just the kind of thing the brms multivariate syntax is for. So first let’s specify both models, which we’ll nest in bf() functions and save as objects. y_model &lt;- bf(reaction ~ 1 + pmi + cond) m_model &lt;- bf(pmi ~ 1 + cond) Now we have our bf() objects in hand, we’ll combine them with the + operator within the brm() function. We’ll also specify set_rescor(FALSE)–we’re not interested in adding a residual correlation between reaction and pmi. model1 &lt;- brm(data = pmi, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) Here are our results. print(model1) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: reaction ~ 1 + pmi + cond #&gt; pmi ~ 1 + cond #&gt; Data: pmi (Number of observations: 123) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; reaction_Intercept 0.52 0.55 -0.53 1.58 4000 1.00 #&gt; pmi_Intercept 5.38 0.17 5.05 5.71 4000 1.00 #&gt; reaction_pmi 0.51 0.10 0.32 0.69 4000 1.00 #&gt; reaction_cond 0.25 0.26 -0.25 0.75 4000 1.00 #&gt; pmi_cond 0.48 0.24 0.01 0.96 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_reaction 1.41 0.09 1.24 1.61 4000 1.00 #&gt; sigma_pmi 1.32 0.09 1.17 1.50 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). If you compare our model summary with the coefficients in the path model in Figure 3.3, you’ll see our coefficients are the same. The brms summary also includes intercepts and residual variances, which are typically omitted in path diagrams even though they’re still part of the model. If you’re getting lost in all the model output, try this. fixef(model1)[3:5, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; reaction_pmi 0.508 0.096 0.322 0.694 #&gt; reaction_cond 0.253 0.259 -0.250 0.748 #&gt; pmi_cond 0.477 0.244 0.007 0.957 Also note that Hayes tends to refer to the intercepts as constants. In his Table 3.2, Hayes included the \\(R^2\\) values. Here are ours. bayes_R2(model1) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2_reaction 0.210 0.056 0.102 0.316 #&gt; R2_pmi 0.039 0.032 0.000 0.116 It’s worth it to actually plot the \\(R^2\\) distributions. # we&#39;ll get our color palette from ggthemes library(ggthemes) bayes_R2(model1, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;, alpha = 2/3) + scale_fill_colorblind() + # we got this color palette from the ggthemes package coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for fit0&quot;)), x = NULL) + theme_classic() We went through the trouble of plotting the \\(R^2\\) distributions because it’s useful to understand that they won’t often be symmetric when they’re near their logical boundaries (i.e., 0 and 1). This is where asymmetric Bayesian credible intervals can really shine. Let’s get down to business and examine the indirect effect, the \\(ab\\) pathway. In our model: \\(a\\) = pmi_cond \\(b\\) = reaction_pmi You can isolate them with fixef()[i]. fixef(model1)[5 , ] #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.47668 0.24440 0.00721 0.95700 fixef(model1)[3 , ] #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.5077 0.0959 0.3223 0.6941 So the naive approach would be to just multiply them. (fixef(model1)[5 , ] * fixef(model1)[3 , ]) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.242 0.023 0.002 0.664 Now, this does get us the correct ‘Estimate’ (i.e., posterior mean). However, the posterior SD and 95% intervals are off. If you want to do this properly, you need to work with the poster samples themselves. Here they are: post &lt;- posterior_samples(model1) glimpse(post) #&gt; Observations: 4,000 #&gt; Variables: 8 #&gt; $ b_reaction_Intercept &lt;dbl&gt; -0.0751, 0.6081, 1.2556, 0.1603, 0.5602, 0.9165, 0.6553, 1.6509, -0.2385, -0... #&gt; $ b_pmi_Intercept &lt;dbl&gt; 5.42, 5.39, 5.34, 5.22, 5.31, 5.18, 5.51, 5.37, 5.50, 5.67, 5.09, 5.62, 5.17... #&gt; $ b_reaction_pmi &lt;dbl&gt; 0.620, 0.478, 0.426, 0.548, 0.516, 0.442, 0.440, 0.293, 0.636, 0.601, 0.412,... #&gt; $ b_reaction_cond &lt;dbl&gt; 0.3907, 0.2704, -0.0605, 0.1839, 0.3621, 0.3386, 0.4139, 0.0900, 0.6226, 0.7... #&gt; $ b_pmi_cond &lt;dbl&gt; 0.4195, 0.6181, 0.3631, 0.7494, 0.3181, 0.7329, 0.1759, 0.7270, 0.0878, 0.24... #&gt; $ sigma_reaction &lt;dbl&gt; 1.41, 1.39, 1.49, 1.29, 1.38, 1.48, 1.45, 1.47, 1.37, 1.51, 1.34, 1.47, 1.35... #&gt; $ sigma_pmi &lt;dbl&gt; 1.24, 1.43, 1.21, 1.41, 1.33, 1.25, 1.28, 1.47, 1.18, 1.30, 1.30, 1.36, 1.35... #&gt; $ lp__ &lt;dbl&gt; -433, -433, -435, -434, -433, -433, -434, -438, -437, -436, -435, -435, -435... Here we compute the indirect effect, ab. post &lt;- post %&gt;% mutate(ab = b_pmi_cond*b_reaction_pmi) Now we have ab as a properly computed vector, we can summarize it with the quantile() function. quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) #&gt; 50% 2.5% 97.5% #&gt; 0.235 0.004 0.522 And we can even visualize it as a density. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(3)[3]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Our indirect effect, the &quot;, italic(&quot;ab&quot;), &quot; pathway&quot;)), x = NULL) + theme_classic() It’s also worth pointing out that as the indirect effect isn’t perfectly symmetric, its mean and median aren’t quite the same. post %&gt;% summarize(mean = mean(ab), median = median(ab)) %&gt;% round(digits = 3) #&gt; mean median #&gt; 1 0.242 0.235 Their magnitudes are similar, but this asymmetry will be a source of contrast to our estimates and those in the text. This is also something to consider when reporting on central tendency. When the indirect effect–or any other parameter, for that matter–is quite asymmetric, you might prefer reporting the median rather than the mean. On page 90, Hayes computed the adjusted means for \\(Y\\). For both cond == 1 and cond == 0, he computed the expected values for reaction when pmi was at its mean. A natural way to do that in brms is with fitted(). First we’ll put our input values for cond and pmi in a tibble, which we’ll call nd. Then we’ll feed nd into the newdata argument within the fitted() function. nd &lt;- tibble(cond = 1:0, pmi = mean(pmi$pmi)) fitted(model1, newdata = nd) #&gt; , , reaction #&gt; #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 3.62 0.190 3.25 4.00 #&gt; [2,] 3.37 0.176 3.03 3.72 #&gt; #&gt; , , pmi #&gt; #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 5.86 0.182 5.50 6.21 #&gt; [2,] 5.38 0.169 5.05 5.71 Because model1 is a multivariate model, fitted() returns the model-implied summaries for both reaction and pmi. If you just want the adjusted means for reaction, you can use the resp argument within fitted(). fitted(model1, newdata = nd, resp = &quot;reaction&quot;) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 3.62 0.190 3.25 4.00 #&gt; [2,] 3.37 0.176 3.03 3.72 Note how this is where the two values in the \\(Y\\) adjusted column in Table 3.1 came from. However, if we want to reproduce how Hayes computed the total effect (i.e. \\(c&#39;\\) + \\(ab\\)), we’ll need to work with the posterior itself, post. Recall, we’ve already saved the indirect effect as a vector, ab. The direct effect, \\(c&#39;\\), is labeled b_reaction_cond within post. in order to get the total effect, \\(c\\), all we need to is add those vectors together. post &lt;- post %&gt;% mutate(total_effect = b_reaction_cond + ab) Here’s the posterior mean with its 95% intervals post %&gt;% summarize(mean = mean(total_effect), ll = quantile(total_effect, prob = .025), ul = quantile(total_effect, prob = .975)) #&gt; mean ll ul #&gt; 1 0.495 -0.0704 1.08 3.2.1 Estimation of the model in PROCESS for SPSS and SAS. Nothing new for us, here. 3.3 Statistical inference 3.3.1 Inference about the total effect of \\(X\\) on \\(Y\\). 3.3.2 Inference about the direct effect of \\(X\\) on \\(Y\\). In this section, Hayes provides a \\(t\\)-test and corresponding \\(p\\)-value for the direct effect (i.e., \\(c&#39;\\), b_reaction_cond). Instead of the \\(t\\)-test, we can just look at the posterior distribution. post %&gt;% ggplot(aes(x = b_reaction_cond)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(4)[4]) + geom_vline(xintercept = 0, color = &quot;white&quot;, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Yep, 0 is a credible value for &quot;, italic(&quot;c&quot;), &quot;.&quot;)), x = NULL) + theme_classic() If you wanted to quantify what proportion of the density was less than 0, you could do: post %&gt;% summarize(proportion_below_zero = filter(., b_reaction_cond &lt; 0) %&gt;% nrow()/nrow(.)) #&gt; proportion_below_zero #&gt; 1 0.17 This is something like a Bayesian \\(p\\)-value. But of course, you could always just look at the posterior intervals. posterior_interval(model1)[&quot;b_reaction_cond&quot;, ] #&gt; 2.5% 97.5% #&gt; -0.250 0.748 3.3.3 Inference about the indirect of \\(X\\) on \\(Y\\) through \\(M\\). 3.3.3.1 The normal theory approach. This is not our approach. 3.3.3.2 Bootstrap confidence interval. This is not our approach. However, Markov chain Monte Carlo (MCMC) methods are iterative and share some characteristics with boostrapping. On page 98, Hayes outlined 6 steps for constructing the \\(ab\\) bootstrap confidence interval. Here are our responses to those steps w/r/t Bayes with MCMC–or in our case HMC (i.e., Hamiltonian Monte Carlo). If HMC or MCMC, in general, are new to you, you might check out this lecture or the Stan reference manual if you’re more technically oriented. Anyway, Hayes’s 6 steps: 3.3.3.2.1 Step 1. With HMC we do not take random samples of the data themselves. Rather, we take random draws from the posterior distribution. The posterior distribution is the joint probability distribution of our model. 3.3.3.2.2 Step 2. After we fit our model with the brm() function and save our posterior draws in a data frame (i.e., post &lt;- posterior_samples(my_model_fit)), we then make a new column (a.k.a. vector, variable) that is the product of our coefficients for the \\(a\\) and \\(b\\) pathways. In the example above, this looked like post %&gt;% mutate(ab = b_pmi_cond*b_reaction_pmi). Let’s take a look at those columns. post %&gt;% select(b_pmi_cond, b_reaction_pmi, ab) %&gt;% slice(1:10) #&gt; b_pmi_cond b_reaction_pmi ab #&gt; 1 0.4195 0.620 0.2602 #&gt; 2 0.6181 0.478 0.2954 #&gt; 3 0.3631 0.426 0.1546 #&gt; 4 0.7494 0.548 0.4107 #&gt; 5 0.3181 0.516 0.1643 #&gt; 6 0.7329 0.442 0.3238 #&gt; 7 0.1759 0.440 0.0774 #&gt; 8 0.7270 0.293 0.2131 #&gt; 9 0.0878 0.636 0.0558 #&gt; 10 0.2452 0.601 0.1473 Our data frame, post, has 4000 rows. Why 4000? By default, brms runs 4 HMC chains. Each chain has 2000 iterations, 1000 of which are warmups, which we always discard. As such, there are 1000 good iterations left in each chain and \\(1000\\times4 = 4000\\). We can change these defaults as needed. At this point in the project, the default settings have been fine. Each row in post contains the parameter values based on one of those draws. And again, these are draws from the posterior distribution. They are not draws from the data. 3.3.3.2.3 Step 3. We don’t refit the model \\(k\\) times based on the samples from the data. We take a number of draws from the posterior distribution. Hayes likes to take 5000 samples when he bootstraps. Happily, that number is quite similar to our 4000 HMC draws. Whether 5000, 4000 or 10,000, these are all large enough numbers that the distributions become fairly stable. With HMC, however, you might want to increase the number of iterations if the effective sample size, ‘Eff.Sample’ in the print() output, is substantially smaller than the number of iterations. 3.3.3.2.4 Step 4. When we use the quantile() function to compute our Bayesian credible intervals, we’ve sorted. Conceptually, we’ve done this: post %&gt;% select(ab) %&gt;% arrange(ab) %&gt;% slice(1:10) #&gt; ab #&gt; 1 -0.1366 #&gt; 2 -0.1217 #&gt; 3 -0.1179 #&gt; 4 -0.1068 #&gt; 5 -0.1068 #&gt; 6 -0.1056 #&gt; 7 -0.1042 #&gt; 8 -0.1027 #&gt; 9 -0.0994 #&gt; 10 -0.0974 3.3.3.2.5 Step 5. Yes, this is what we do, too. ci &lt;- 95 .5*(100 - ci) #&gt; [1] 2.5 3.3.3.2.6 Step 6. This is also what we do. ci &lt;- 95 (100 - .5*(100 - ci)) #&gt; [1] 97.5 Also, notice the headers in the rightmost two columns in our posterior_summary() output: posterior_summary(model1) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; b_reaction_Intercept 0.524 0.5487 -5.28e-01 1.581 #&gt; b_pmi_Intercept 5.379 0.1687 5.05e+00 5.715 #&gt; b_reaction_pmi 0.508 0.0959 3.22e-01 0.694 #&gt; b_reaction_cond 0.253 0.2594 -2.50e-01 0.748 #&gt; b_pmi_cond 0.477 0.2444 7.21e-03 0.957 #&gt; sigma_reaction 1.409 0.0915 1.24e+00 1.605 #&gt; sigma_pmi 1.320 0.0851 1.17e+00 1.501 #&gt; lp__ -434.914 1.9037 -4.39e+02 -432.185 Those .025 and .975 quantiles from above are just what brms is giving us in our 95% Bayesian credible intervals. Here’s our version of Figure 3.5 # these will come in handy in the subtitle ll &lt;- quantile(post$ab, probs = .025) %&gt;% round(digits = 3) ul &lt;- quantile(post$ab, probs = .975) %&gt;% round(digits = 3) post %&gt;% ggplot(aes(x = ab)) + geom_histogram(color = &quot;white&quot;, size = .25, fill = colorblind_pal()(5)[5], binwidth = .025, boundary = 0) + geom_vline(xintercept = quantile(post$ab, probs = c(.025, .975)), linetype = 3, color = colorblind_pal()(6)[6]) + labs(x = expression(paste(&quot;Indirect effect (&quot;, italic(&quot;ab&quot;), &quot;)&quot;)), y = &quot;Frequency in 4,000 HMC posterior draws&quot;, subtitle = paste(&quot;95% of the posterior draws are between&quot;, ll, &quot;and&quot;, ul)) + theme_classic() Again, as Hayes discussed how to specify different types of intervals in PROCESS on page 102, you can ask for different kinds of intervals in your print() or summary() output with the probs argument, just as you can with quantile() when working directly with the posterior draws. Hayes discussed setting the seed in PROCESS on page 104. You can do this with the seed argument in the brm() function, too. 3.3.3.3 Alternative “asymmetric” confidence interval approaches. This section does not quite refer to us. I’m a little surprised Hayes didn’t at least dedicate a paragraph or two mentioning Bayesian estimation. Sure, he mentioned Monte Carlo, but not within the context of Bayes. So it goes… 3.4 An example with continuous \\(X\\): Economic stress among small-business owners Here’s the estress data. estress &lt;- read_csv(&quot;data/estress/estress.csv&quot;) glimpse(estress) #&gt; Observations: 262 #&gt; Variables: 7 #&gt; $ tenure &lt;dbl&gt; 1.67, 0.58, 0.58, 2.00, 5.00, 9.00, 0.00, 2.50, 0.50, 0.58, 9.00, 1.92, 2.00, 1.42, 0.92... #&gt; $ estress &lt;dbl&gt; 6.0, 5.0, 5.5, 3.0, 4.5, 6.0, 5.5, 3.0, 5.5, 6.0, 5.5, 4.0, 3.0, 2.5, 3.5, 6.0, 4.0, 6.0... #&gt; $ affect &lt;dbl&gt; 2.60, 1.00, 2.40, 1.16, 1.00, 1.50, 1.00, 1.16, 1.33, 3.00, 3.00, 2.00, 1.83, 1.16, 1.16... #&gt; $ withdraw &lt;dbl&gt; 3.00, 1.00, 3.66, 4.66, 4.33, 3.00, 1.00, 1.00, 2.00, 4.00, 4.33, 1.00, 5.00, 1.66, 4.00... #&gt; $ sex &lt;int&gt; 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1... #&gt; $ age &lt;int&gt; 51, 45, 42, 50, 48, 48, 51, 47, 40, 43, 57, 36, 33, 29, 33, 48, 40, 45, 37, 42, 54, 57, ... #&gt; $ ese &lt;dbl&gt; 5.33, 6.05, 5.26, 4.35, 4.86, 5.05, 3.66, 6.13, 5.26, 4.00, 2.53, 6.60, 5.20, 5.66, 5.66... The model set up is just like before. There are no complications switching from a binary \\(X\\) variable to a continuous one. y_model &lt;- bf(withdraw ~ 1 + estress + affect) m_model &lt;- bf(affect ~ 1 + estress) With our y_model and m_model defined, we’re ready to fit. model2 &lt;- brm(data = estress, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) Let’s take a look. print(model2, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: withdraw ~ 1 + estress + affect #&gt; affect ~ 1 + estress #&gt; Data: estress (Number of observations: 262) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; withdraw_Intercept 1.446 0.256 0.954 1.949 4000 1.000 #&gt; affect_Intercept 0.801 0.146 0.520 1.088 4000 1.000 #&gt; withdraw_estress -0.077 0.052 -0.178 0.025 4000 0.999 #&gt; withdraw_affect 0.771 0.104 0.564 0.972 4000 1.000 #&gt; affect_estress 0.173 0.030 0.114 0.231 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_withdraw 1.138 0.051 1.043 1.246 4000 0.999 #&gt; sigma_affect 0.685 0.030 0.630 0.747 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The ‘Eff.Sample’ and ‘Rhat’ values look great. Happily, the values in our summary cohere well with those Hayes reported in Table 3.5. Here are our \\(R^2\\) values. bayes_R2(model2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2_withdraw 0.183 0.0386 0.1080 0.258 #&gt; R2_affect 0.117 0.0350 0.0535 0.187 These are also quite similar to those in the text. Here’s our indirect effect. # putting the posterior draws into a data frame post &lt;- posterior_samples(model2) # computing the ab coefficient with multiplication post &lt;- post %&gt;% mutate(ab = b_affect_estress*b_withdraw_affect) # getting the posterior median and 95% intervals with `quantile()` quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) #&gt; 50% 2.5% 97.5% #&gt; 0.131 0.081 0.194 We can visualize its shape, median, and 95% intervals in a density plot. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = colorblind_pal()(7)[7]) + geom_vline(xintercept = quantile(post$ab, probs = c(.025, .5, .975)), color = &quot;white&quot;, linetype = c(2, 1, 2), size = c(.5, .8, .5)) + scale_x_continuous(breaks = quantile(post$ab, probs = c(.025, .5, .975)), labels = quantile(post$ab, probs = c(.025, .5, .975)) %&gt;% round(2) %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;Behold our &quot;, italic(&quot;ab&quot;), &quot;!&quot;)), x = NULL) + theme_classic() Here’s \\(c&#39;\\), the direct effect of esterss predicting withdraw. posterior_summary(model2)[&quot;b_withdraw_estress&quot;, ] #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; -0.0771 0.0523 -0.1783 0.0247 It has wide flapping intervals which do straddle zero. A little addition will give us the direct effect, \\(c\\). post &lt;- post %&gt;% mutate(c = b_withdraw_estress + ab) quantile(post$c, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) #&gt; 50% 2.5% 97.5% #&gt; 0.056 -0.050 0.162 Reference Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] ggthemes_3.5.0 brms_2.3.4 Rcpp_0.12.17 bindrcpp_0.2.2 forcats_0.3.0 stringr_1.3.1 #&gt; [7] dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 #&gt; [13] tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 threejs_0.3.1 #&gt; [6] httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 tools_3.5.1 backports_1.1.2 #&gt; [11] utf8_1.1.4 R6_2.2.2 DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 #&gt; [16] withr_2.1.2 tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 xml2_1.2.0 #&gt; [26] labeling_0.3 colourpicker_1.0 bookdown_0.7 scales_0.5.0 dygraphs_1.1.1.5 #&gt; [31] mvtnorm_1.0-8 psych_1.8.4 ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 #&gt; [36] foreign_0.8-70 rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 shiny_1.1.0 #&gt; [46] bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 gtools_3.8.1 crosstalk_1.0.0 #&gt; [51] inline_0.3.15 magrittr_1.5 loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 #&gt; [56] munsell_0.5.0 abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 miniUI_0.1.1.1 #&gt; [66] lattice_0.20-35 haven_1.1.2 hms_0.4.2 knitr_1.20 pillar_1.2.3 #&gt; [71] igraph_1.2.1 markdown_0.8 shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 #&gt; [76] stats4_3.5.1 rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 xfun_0.3 #&gt; [86] mime_0.5 xtable_1.8-2 broom_0.4.5 coda_0.19-1 later_0.7.3 #&gt; [91] rsconnect_0.8.8 shinythemes_1.1.1 bridgesampling_0.4-0 "],
["causal-steps-confounding-and-causal-order.html", "4 Causal Steps, Confounding, and Causal Order 4.1 What about Barron and Kenny? 4.2 Confounding and causal order 4.3 Effect size 4.4 Statistical power 4.5 Multiple \\(X\\)s or \\(Y\\)s: Analyze separately or simultaneously? References Session info", " 4 Causal Steps, Confounding, and Causal Order 4.1 What about Barron and Kenny? On page 121 of the text, Hayes opined: Complete and partial mediation are concepts that are deeply ingrained in the thinking of social and behavioral scientists. But I just don’t see what they offer our understanding of a phenomenon. They are too sample-size-dependent and the distinction between them has no substantive or theoretical meaning or value of any consequence. I recommend avoiding expressing hypotheses about mediation or results of a mediation analysis using these terms. 4.2 Confounding and causal order 4.2.1 Accounting for confounding and epiphenomenal association. Here we load a couple necessary packages, load the data, and take a peek at them. library(tidyverse) estress &lt;- read_csv(&quot;data/estress/estress.csv&quot;) glimpse(estress) #&gt; Observations: 262 #&gt; Variables: 7 #&gt; $ tenure &lt;dbl&gt; 1.67, 0.58, 0.58, 2.00, 5.00, 9.00, 0.00, 2.50, 0.50, 0.58, 9.00, 1.92, 2.00, 1.42, 0.92... #&gt; $ estress &lt;dbl&gt; 6.0, 5.0, 5.5, 3.0, 4.5, 6.0, 5.5, 3.0, 5.5, 6.0, 5.5, 4.0, 3.0, 2.5, 3.5, 6.0, 4.0, 6.0... #&gt; $ affect &lt;dbl&gt; 2.60, 1.00, 2.40, 1.16, 1.00, 1.50, 1.00, 1.16, 1.33, 3.00, 3.00, 2.00, 1.83, 1.16, 1.16... #&gt; $ withdraw &lt;dbl&gt; 3.00, 1.00, 3.66, 4.66, 4.33, 3.00, 1.00, 1.00, 2.00, 4.00, 4.33, 1.00, 5.00, 1.66, 4.00... #&gt; $ sex &lt;int&gt; 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1... #&gt; $ age &lt;int&gt; 51, 45, 42, 50, 48, 48, 51, 47, 40, 43, 57, 36, 33, 29, 33, 48, 40, 45, 37, 42, 54, 57, ... #&gt; $ ese &lt;dbl&gt; 5.33, 6.05, 5.26, 4.35, 4.86, 5.05, 3.66, 6.13, 5.26, 4.00, 2.53, 6.60, 5.20, 5.66, 5.66... Here are the Pearson’s correlations. psych::lowerCor(estress, digits = 3) #&gt; tenure estrss affect wthdrw sex age ese #&gt; tenure 1.000 #&gt; estress 0.068 1.000 #&gt; affect -0.065 0.340 1.000 #&gt; withdraw -0.035 0.064 0.417 1.000 #&gt; sex -0.003 0.133 0.046 0.050 1.000 #&gt; age 0.266 0.066 -0.018 -0.035 0.083 1.000 #&gt; ese -0.060 -0.158 -0.246 -0.243 0.028 -0.083 1.000 Let’s open brms. library(brms) Recall that if you want the correlations with Bayesian estimation and those sweet Bayesian credible intervals, you set up an intercept-only multivariate model. model1 &lt;- brm(data = estress, family = gaussian, cbind(ese, estress, affect, withdraw) ~ 1, chains = 4, cores = 4) The summary: print(model1, digits = 3) #&gt; Family: MV(gaussian, gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: ese ~ 1 #&gt; estress ~ 1 #&gt; affect ~ 1 #&gt; withdraw ~ 1 #&gt; Data: estress (Number of observations: 262) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; ese_Intercept 5.607 0.060 5.491 5.726 4000 0.999 #&gt; estress_Intercept 4.621 0.090 4.445 4.797 4000 0.999 #&gt; affect_Intercept 1.598 0.046 1.511 1.690 4000 1.000 #&gt; withdraw_Intercept 2.322 0.078 2.167 2.473 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_ese 0.954 0.043 0.873 1.042 4000 1.000 #&gt; sigma_estress 1.437 0.063 1.321 1.568 4000 0.999 #&gt; sigma_affect 0.730 0.032 0.670 0.796 4000 1.000 #&gt; sigma_withdraw 1.258 0.054 1.158 1.372 4000 1.000 #&gt; rescor(ese,estress) -0.154 0.061 -0.270 -0.034 4000 0.999 #&gt; rescor(ese,affect) -0.239 0.057 -0.349 -0.127 4000 0.999 #&gt; rescor(estress,affect) 0.335 0.055 0.225 0.437 4000 1.000 #&gt; rescor(ese,withdraw) -0.238 0.059 -0.349 -0.119 4000 0.999 #&gt; rescor(estress,withdraw) 0.061 0.062 -0.061 0.183 4000 1.000 #&gt; rescor(affect,withdraw) 0.410 0.054 0.303 0.510 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Since we have posteriors for the correlations, why not plot them? Here we use the theme_black() from brms and a color scheme from the viridis package. library(viridis) posterior_samples(model1) %&gt;% select(rescor__ese__estress, rescor__ese__affect, rescor__estress__withdraw) %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(alpha = .85, color = &quot;transparent&quot;) + scale_fill_viridis(discrete = T, option = &quot;D&quot;, direction = -1, labels = c(expression(paste(rho[&quot;ese, affect&quot;])), expression(paste(rho[&quot;ese, estress&quot;])), expression(paste(rho[&quot;estress, withdraw&quot;]))), guide = guide_legend(label.hjust = 0, label.theme = element_text(size = 15, angle = 0, color = &quot;white&quot;), title.theme = element_blank())) + coord_cartesian(xlim = c(-1, 1)) + labs(title = &quot;Our correlation density plot&quot;, x = NULL) + theme_black() + theme(panel.grid = element_blank(), axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank()) Before we fit our mediation model with brm(), we’ll specify the sub-models, here. y_model &lt;- bf(withdraw ~ 1 + estress + affect + ese + sex + tenure) m_model &lt;- bf(affect ~ 1 + estress + ese + sex + tenure) With y_model and m_model defined, we’re ready to fit. model2 &lt;- brm(data = estress, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) Here’s the summary: print(model2, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: withdraw ~ 1 + estress + affect + ese + sex + tenure #&gt; affect ~ 1 + estress + ese + sex + tenure #&gt; Data: estress (Number of observations: 262) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; withdraw_Intercept 2.748 0.540 1.708 3.798 4000 0.999 #&gt; affect_Intercept 1.783 0.317 1.160 2.413 4000 0.999 #&gt; withdraw_estress -0.094 0.053 -0.194 0.008 4000 0.999 #&gt; withdraw_affect 0.707 0.103 0.503 0.907 4000 0.999 #&gt; withdraw_ese -0.212 0.074 -0.354 -0.066 4000 0.999 #&gt; withdraw_sex 0.128 0.148 -0.163 0.422 4000 1.000 #&gt; withdraw_tenure -0.002 0.011 -0.023 0.018 4000 1.000 #&gt; affect_estress 0.160 0.030 0.102 0.218 4000 0.999 #&gt; affect_ese -0.155 0.046 -0.247 -0.063 4000 0.999 #&gt; affect_sex 0.016 0.086 -0.153 0.182 4000 1.000 #&gt; affect_tenure -0.011 0.006 -0.023 0.001 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_withdraw 1.127 0.049 1.035 1.228 4000 0.999 #&gt; sigma_affect 0.671 0.030 0.615 0.731 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). In the printout, notice how first within intercepts and then with covariates and sigma, the coefficients are presented as for withdraw first and then affect. Also notice how the coefficients for the covariates are presented in the same order for each criterions. Hopefully that’ll make it easier to sift through the printout. Happily, our coefficients are quite similar to those in Table 4.1 Here are the \\(R^2\\) values. bayes_R2(model2) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2_withdraw 0.213 0.038 0.139 0.287 #&gt; R2_affect 0.171 0.038 0.097 0.244 These are also in the same ballpark, but a little higher. Why not glance at their densities? bayes_R2(model2, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;, alpha = .85) + scale_fill_manual(values = c(viridis_pal(option = &quot;A&quot;)(7)[c(7, 3)]), labels = c(&quot;affect&quot;, &quot;withdraw&quot;), guide = guide_legend(title.theme = element_blank())) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for model2&quot;)), x = NULL) + theme_black() + theme(panel.grid = element_blank()) Here we retrieve the posterior samples, compute the indirect effect, and summarize the indirect effect with quantile(). post &lt;- posterior_samples(model2) %&gt;% mutate(ab = b_affect_estress*b_withdraw_affect) quantile(post$ab, probs = c(.5, .025, .975)) %&gt;% round(digits = 3) #&gt; 50% 2.5% 97.5% #&gt; 0.111 0.066 0.171 The results are similar to those in the text (p. 127). Here’s what it looks like. post %&gt;% ggplot(aes(x = ab)) + geom_density(color = &quot;transparent&quot;, fill = viridis_pal(option = &quot;A&quot;)(7)[5]) + geom_vline(xintercept = quantile(post$ab, probs = c(.5, .025, .975)), color = &quot;black&quot;, linetype = c(1, 3, 3)) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(italic(&quot;ab&quot;))) + theme_black() + theme(panel.grid = element_blank()) Once again, those sweet Bayesian credible intervals get the job done. Here’s a way to get both the direct effect, \\(c&#39;\\) (i.e., b_withdraw_estress), and the total effect, \\(c\\) (i.e., \\(c&#39;\\) + \\(ab\\)) of estress on withdraw. post %&gt;% mutate(c = b_withdraw_estress + ab) %&gt;% rename(c_prime = b_withdraw_estress) %&gt;% select(c_prime, c) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 2 x 4 #&gt; key mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 c 0.019 -0.085 0.125 #&gt; 2 c_prime -0.094 -0.194 0.008 Both appear pretty small. Which leads us to the next section… 4.3 Effect size 4.3.1 The partially standardized effect. We get \\(SD\\)s using the sd() function. Here’s the \\(SD\\) for our \\(Y\\) variable, withdraw. sd(estress$withdraw) #&gt; [1] 1.25 Here we compute the partially standardized effect sizes for \\(c&#39;\\) and \\(ab\\) by dividing those vectors in our post object by sd(estress$withdraw), which we saved as SD_y. SD_y &lt;- sd(estress$withdraw) post %&gt;% mutate(c_prime_ps = b_withdraw_estress/SD_y, ab_ps = ab/SD_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% select(c_prime_ps, ab_ps, c_ps) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ab_ps 0.091 0.089 0.053 0.137 #&gt; 2 c_prime_ps -0.075 -0.076 -0.156 0.007 #&gt; 3 c_ps 0.015 0.015 -0.068 0.101 The results are similar, though not identical, to those in the text. Here we have both rounding error and estimation differences at play. The plots: post %&gt;% mutate(c_prime_ps = b_withdraw_estress/SD_y, ab_ps = ab/SD_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% select(c_prime_ps, ab_ps, c_ps) %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(alpha = .85, color = &quot;transparent&quot;) + scale_fill_viridis(discrete = T, option = &quot;D&quot;) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Partially-standardized coefficients&quot;, x = NULL) + theme_black() + theme(panel.grid = element_blank(), legend.position = &quot;none&quot;) + facet_wrap(~key, ncol = 3) On page 135, Hayes revisited the model from section 3.3. We’ll have to reload the data and refit that model to follow along. pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) y_model &lt;- bf(reaction ~ 1 + pmi + cond) m_model &lt;- bf(pmi ~ 1 + cond) model3 &lt;- brm(data = pmi, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) The partially-standardized parameters require some posterior_samples() wrangling. post &lt;- posterior_samples(model3) SD_y &lt;- sd(pmi$reaction) post %&gt;% mutate(ab = b_pmi_cond * b_reaction_pmi, c_prime = b_reaction_cond) %&gt;% mutate(ab_ps = ab/SD_y, c_prime_ps = c_prime/SD_y) %&gt;% mutate(c_ps = c_prime_ps + ab_ps) %&gt;% select(c_prime_ps, ab_ps, c_ps) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ab_ps 0.156 0.152 0.004 0.341 #&gt; 2 c_prime_ps 0.163 0.164 -0.165 0.493 #&gt; 3 c_ps 0.319 0.321 -0.048 0.693 Happily, these results are closer to those in the text than with the previous example. 4.3.2 The completely standardized effect. Note. Hayes could have made this clearer in the text, but the estress model he referred to in this section was the one from way back in section 3.5, not the one from earlier in this chapter. One way to get a standardized solution is to standardize the variables in the data and then fit the model with those standardized variables. To do so, we’ll revisit our custom standardize(), put it to work, and fit the standardized version of the model from section 3.5, which we’ll call model4.With our y_model and m_model defined, we’re ready to fit. sandardize &lt;- function(x){ (x - mean(x))/sd(x) } estress &lt;- estress %&gt;% mutate(withdraw_z = sandardize(withdraw), estress_z = sandardize(estress), affect_z = sandardize(affect)) y_model &lt;- bf(withdraw_z ~ 1 + estress_z + affect_z) m_model &lt;- bf(affect_z ~ 1 + estress_z) model4 &lt;- brm(data = estress, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) Here they are, our newly standardized coefficients: fixef(model4) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; withdrawz_Intercept 0.001 0.058 -0.111 0.114 #&gt; affectz_Intercept 0.001 0.057 -0.112 0.115 #&gt; withdrawz_estress_z -0.088 0.058 -0.201 0.027 #&gt; withdrawz_affect_z 0.446 0.059 0.331 0.560 #&gt; affectz_estress_z 0.340 0.061 0.220 0.461 Here we do the wrangling necessary to spell out the standardized effects for \\(ab\\), \\(c&#39;\\), and \\(c\\). post &lt;- posterior_samples(model4) post %&gt;% mutate(ab_s = b_affectz_estress_z * b_withdrawz_affect_z, c_prime_s = b_withdrawz_estress_z) %&gt;% mutate(c_s = ab_s + c_prime_s) %&gt;% select(c_prime_s, ab_s, c_s) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ab_s 0.152 0.15 0.091 0.225 #&gt; 2 c_prime_s -0.088 -0.089 -0.201 0.027 #&gt; 3 c_s 0.064 0.063 -0.054 0.182 Let’s confirm that we can recover these values by applying the formulas on page 135 to the unstandardized model, which we’ll call model5. First, we’ll have to fit that model since we haven’t fit that one since Chapter 3. y_model &lt;- bf(withdraw ~ 1 + estress + affect) m_model &lt;- bf(affect ~ 1 + estress) model5 &lt;- brm(data = estress, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) Here are the unstandardized coefficients: fixef(model5) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; withdraw_Intercept 1.449 0.251 0.960 1.943 #&gt; affect_Intercept 0.798 0.138 0.528 1.074 #&gt; withdraw_estress -0.077 0.052 -0.181 0.027 #&gt; withdraw_affect 0.768 0.104 0.561 0.975 #&gt; affect_estress 0.173 0.028 0.118 0.230 On pages 135–136, Hayes provided the formulas to compute the standardized effects: \\[c&#39;_{cs} = \\frac{SD_X(c&#39;)}{SD_{Y}} = SD_{X}(c&#39;_{ps})\\] \\[ab_{cs} = \\frac{SD_X(ab)}{SD_{Y}} = SD_{X}(ab_{ps})\\] \\[c_{cs} = \\frac{SD_X(c)}{SD_{Y}} = c&#39;_{cs} + ab_{ps}\\] Here we put them in action to standardize the unstandardized results. post &lt;- posterior_samples(model5) SD_x &lt;- sd(estress$estress) SD_y &lt;- sd(estress$withdraw) post %&gt;% mutate(ab = b_affect_estress * b_withdraw_affect, c_prime = b_withdraw_estress) %&gt;% mutate(ab_s = (SD_x*ab)/SD_y, c_prime_s = (SD_x*c_prime)/SD_y) %&gt;% mutate(c_s = ab_s + c_prime_s) %&gt;% select(c_prime_s, ab_s, c_s) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 ab_s 0.152 0.15 0.093 0.219 #&gt; 2 c_prime_s -0.088 -0.088 -0.207 0.031 #&gt; 3 c_s 0.064 0.065 -0.053 0.181 Success! 4.3.3 Some (problematic) measures only for indirect effects. Hayes recommended against these, so I’m not going to bother working any examples. 4.4 Statistical power As Hayed discussed, power is an important but thorny issue within the frequentist paradigm. Given that we’re not particularly interested in rejecting the point-null hypothesis as Bayesians and that we bring in priors (which we’ve largely avoided explicitly mentioning in his project but have been quietly using all along), the issue is even more difficult for Bayesians. To learn more on the topic, check out Miočević, MacKinnon, and Levy’s paper on power in small-sample Bayesian analyses or Gelman and Carlin’s paper offering an alternative to the power paradigm. You might also look at Matti Vuorre’s Sample size planning with brms project. 4.5 Multiple \\(X\\)s or \\(Y\\)s: Analyze separately or simultaneously? 4.5.1 Multiple \\(X\\) variables. The same basic problems with multicollinearity applies to the Bayesian paradigm, too. 4.5.2 Estimation of a model with multiple \\(X\\) variables in PROCESS brms. Hayes discussed the limitation that his PROCESS program may only handle a single \\(X\\) variable in the x= part of the command line, for which he displayed a workaround. We don’t have such a limitation in brms. Using Hayes’s hypothetical data syntax for a model with three \\(X\\)s, the brms code would be: y_model &lt;- bf(dv ~ 1 + iv1 + iv2 + iv3 + med) m_model &lt;- bf(med ~ 1 + iv1 + iv2 + iv3) model6 &lt;- brm(data = data, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) To show it in action, let’s simulate some data. N &lt;- 1e3 set.seed(4.5) d &lt;- tibble(iv1 = rnorm(N, mean = 0, sd = 1), iv2 = rnorm(N, mean = 0, sd = 1), iv3 = rnorm(N, mean = 0, sd = 1), med = rnorm(N, mean = 0 + iv1*-1 + iv2*0 + iv3*1, sd = 1), dv = rnorm(N, mean = 0 + iv1*0 + iv2*.5 + iv3*1 + med*.5, sd = 1)) head(d) #&gt; # A tibble: 6 x 5 #&gt; iv1 iv2 iv3 med dv #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.217 0.177 -1.39 -0.755 -1.77 #&gt; 2 -0.542 1.69 0.0513 0.721 0.402 #&gt; 3 0.891 -1.35 1.10 0.777 -0.132 #&gt; 4 0.596 1.08 -0.203 -0.955 1.02 #&gt; 5 1.64 -0.456 -0.428 -2.89 -3.26 #&gt; 6 0.689 -0.681 -0.429 -0.462 -2.38 Before we proceed, if data simulation is new to you, you might check out Roger Peng’s helpful tutorial on the subject. Here are the sub-models. y_model &lt;- bf(dv ~ 1 + iv1 + iv2 + iv3 + med) m_model &lt;- bf(med ~ 1 + iv1 + iv2 + iv3) Now we fit. model7 &lt;- brm(data = d, family = gaussian, y_model + m_model + set_rescor(FALSE), chains = 4, cores = 4) And the results: print(model7) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: dv ~ 1 + iv1 + iv2 + iv3 + med #&gt; med ~ 1 + iv1 + iv2 + iv3 #&gt; Data: d (Number of observations: 1000) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; dv_Intercept -0.01 0.03 -0.07 0.05 4000 1.00 #&gt; med_Intercept 0.00 0.03 -0.06 0.06 4000 1.00 #&gt; dv_iv1 0.02 0.04 -0.06 0.11 2856 1.00 #&gt; dv_iv2 0.56 0.03 0.50 0.62 4000 1.00 #&gt; dv_iv3 1.01 0.04 0.92 1.09 2656 1.00 #&gt; dv_med 0.46 0.03 0.40 0.53 2423 1.00 #&gt; med_iv1 -0.93 0.03 -0.99 -0.87 4000 1.00 #&gt; med_iv2 0.03 0.03 -0.03 0.09 4000 1.00 #&gt; med_iv3 0.98 0.03 0.92 1.04 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_dv 1.00 0.02 0.96 1.05 4000 1.00 #&gt; sigma_med 0.97 0.02 0.93 1.02 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). brms came through just fine. If you wanted to simulate data with a particular correlation structure for the iv variables, you might use the mvnorm() function from the MASS package, which you can learn more about here. 4.5.3 Multiple \\(Y\\) variables. We’ve already been using the multivariate syntax in brms for our simple mediation models. Fitting a mediation model with multiple \\(Y\\) variables is a minor extension. Let’s simulate more data. N &lt;- 1e3 set.seed(4.5) d &lt;- tibble(iv = rnorm(N, mean = 0, sd = 1), med = rnorm(N, mean = 0 + iv*.5, sd = 1), dv1 = rnorm(N, mean = 0 + iv*-1 + med*0, sd = 1), dv2 = rnorm(N, mean = 0 + iv*0 + med*.5, sd = 1), dv3 = rnorm(N, mean = 0 + iv*1 + med*1, sd = 1)) head(d) #&gt; # A tibble: 6 x 5 #&gt; iv med dv1 dv2 dv3 #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.217 0.285 -1.61 0.999 0.420 #&gt; 2 -0.542 1.42 0.594 0.836 0.0208 #&gt; 3 0.891 -0.902 0.206 0.120 -0.954 #&gt; 4 0.596 1.37 -0.799 0.530 3.13 #&gt; 5 1.64 0.362 -2.06 -0.643 0.840 #&gt; 6 0.689 -0.337 -1.12 0.487 -1.03 Here are the sub-models. y_model_1 &lt;- bf(dv1 ~ 1 + iv + med) y_model_2 &lt;- bf(dv2 ~ 1 + iv + med) y_model_3 &lt;- bf(dv3 ~ 1 + iv + med) m_model &lt;- bf(med ~ 1 + iv) And we fit. model8 &lt;- brm(data = d, family = gaussian, y_model_1 + y_model_2 + y_model_3 + m_model + set_rescor(FALSE), chains = 4, cores = 4) print(model8) #&gt; Family: MV(gaussian, gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: dv1 ~ 1 + iv + med #&gt; dv2 ~ 1 + iv + med #&gt; dv3 ~ 1 + iv + med #&gt; med ~ 1 + iv #&gt; Data: d (Number of observations: 1000) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; dv1_Intercept 0.01 0.03 -0.04 0.07 4000 1.00 #&gt; dv2_Intercept 0.00 0.03 -0.06 0.06 4000 1.00 #&gt; dv3_Intercept -0.01 0.03 -0.08 0.05 4000 1.00 #&gt; med_Intercept 0.02 0.03 -0.04 0.09 4000 1.00 #&gt; dv1_iv -1.05 0.04 -1.12 -0.98 4000 1.00 #&gt; dv1_med 0.05 0.03 -0.01 0.11 4000 1.00 #&gt; dv2_iv 0.05 0.03 -0.01 0.12 4000 1.00 #&gt; dv2_med 0.53 0.03 0.47 0.59 4000 1.00 #&gt; dv3_iv 1.03 0.04 0.95 1.10 4000 1.00 #&gt; dv3_med 1.06 0.03 0.99 1.12 4000 1.00 #&gt; med_iv 0.53 0.03 0.46 0.59 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_dv1 0.98 0.02 0.93 1.02 4000 1.00 #&gt; sigma_dv2 0.97 0.02 0.93 1.02 4000 1.00 #&gt; sigma_dv3 1.00 0.02 0.96 1.05 4000 1.00 #&gt; sigma_med 1.00 0.02 0.96 1.04 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). brms to the rescue once again! References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] bindrcpp_0.2.2 viridis_0.5.1 viridisLite_0.3.0 brms_2.3.4 Rcpp_0.12.17 #&gt; [6] forcats_0.3.0 stringr_1.3.1 dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 #&gt; [11] tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 threejs_0.3.1 #&gt; [6] httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 tools_3.5.1 backports_1.1.2 #&gt; [11] utf8_1.1.4 R6_2.2.2 DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 #&gt; [16] withr_2.1.2 tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 xml2_1.2.0 #&gt; [26] labeling_0.3 colourpicker_1.0 bookdown_0.7 scales_0.5.0 dygraphs_1.1.1.5 #&gt; [31] mvtnorm_1.0-8 psych_1.8.4 ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 #&gt; [36] foreign_0.8-70 rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 shiny_1.1.0 #&gt; [46] bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 gtools_3.8.1 crosstalk_1.0.0 #&gt; [51] inline_0.3.15 magrittr_1.5 loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 #&gt; [56] munsell_0.5.0 abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 miniUI_0.1.1.1 #&gt; [66] lattice_0.20-35 haven_1.1.2 hms_0.4.2 knitr_1.20 pillar_1.2.3 #&gt; [71] igraph_1.2.1 markdown_0.8 shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 #&gt; [76] stats4_3.5.1 rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 xfun_0.3 #&gt; [86] mime_0.5 xtable_1.8-2 broom_0.4.5 coda_0.19-1 later_0.7.3 #&gt; [91] rsconnect_0.8.8 shinythemes_1.1.1 bridgesampling_0.4-0 "],
["more-than-one-mediator.html", "5 More Than One Mediator 5.1 The parallel multiple mediator model 5.2 Example using the presumed media influence study 5.3 Statistical inference 5.4 The serial multiple mediator model References Session info", " 5 More Than One Mediator 5.1 The parallel multiple mediator model 5.2 Example using the presumed media influence study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) pmi &lt;- read_csv(&quot;data/pmi/pmi.csv&quot;) glimpse(pmi) #&gt; Observations: 123 #&gt; Variables: 6 #&gt; $ cond &lt;int&gt; 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0... #&gt; $ pmi &lt;dbl&gt; 7.0, 6.0, 5.5, 6.5, 6.0, 5.5, 3.5, 6.0, 4.5, 7.0, 1.0, 6.0, 5.0, 7.0, 7.0, 7.0, 4.5, 3.5... #&gt; $ import &lt;int&gt; 6, 1, 6, 6, 5, 1, 1, 6, 6, 6, 3, 3, 4, 7, 1, 6, 3, 3, 2, 4, 4, 6, 7, 4, 5, 4, 6, 5, 5, 7... #&gt; $ reaction &lt;dbl&gt; 5.25, 1.25, 5.00, 2.75, 2.50, 1.25, 1.50, 4.75, 4.25, 6.25, 1.25, 2.75, 3.75, 5.00, 4.00... #&gt; $ gender &lt;int&gt; 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1... #&gt; $ age &lt;dbl&gt; 51.0, 40.0, 26.0, 21.0, 27.0, 25.0, 23.0, 25.0, 22.0, 24.0, 22.0, 21.0, 23.0, 21.0, 22.0... Let’s load brms. library(brms) Bayesian correlations, recall, just take an intercepts-only multivariate model. model1 &lt;- brm(data = pmi, family = gaussian, cbind(pmi, import) ~ 1, chains = 4, cores = 4) A little indexing with the posterior_summary() function will get us the Bayesian correlation with its posterior \\(SD\\) and intervals. posterior_summary(model1)[&quot;rescor__pmi__import&quot;, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.277 0.085 0.109 0.441 As with single mediation models, the multiple mediation model requires we carefully construct the formula for each criterion. We’ll continue to use the multiple bf() approach. m1_model &lt;- bf(import ~ 1 + cond) m2_model &lt;- bf(pmi ~ 1 + cond) y_model &lt;- bf(reaction ~ 1 + import + pmi + cond) And now we fit the model. model2 &lt;- brm(data = pmi, family = gaussian, y_model + m1_model + m2_model + set_rescor(FALSE), chains = 4, cores = 4) print(model2, digits = 3) #&gt; Family: MV(gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: reaction ~ 1 + import + pmi + cond #&gt; import ~ 1 + cond #&gt; pmi ~ 1 + cond #&gt; Data: pmi (Number of observations: 123) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; reaction_Intercept -0.156 0.552 -1.237 0.908 4000 1.000 #&gt; import_Intercept 3.904 0.210 3.478 4.313 4000 0.999 #&gt; pmi_Intercept 5.374 0.163 5.059 5.694 4000 0.999 #&gt; reaction_import 0.324 0.072 0.184 0.465 4000 0.999 #&gt; reaction_pmi 0.398 0.096 0.216 0.586 4000 1.000 #&gt; reaction_cond 0.101 0.237 -0.372 0.568 4000 0.999 #&gt; import_cond 0.632 0.313 0.025 1.285 4000 0.999 #&gt; pmi_cond 0.481 0.246 -0.007 0.959 4000 0.999 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_reaction 1.302 0.086 1.146 1.480 4000 0.999 #&gt; sigma_import 1.734 0.113 1.528 1.974 4000 0.999 #&gt; sigma_pmi 1.317 0.085 1.161 1.494 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Because we have three criteria, we’ll have three Bayesian \\(R^2\\) posteriors. library(ggthemes) bayes_R2(model2, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(key = str_remove(key, &quot;R2_&quot;)) %&gt;% ggplot(aes(x = value, color = key, fill = key)) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;Our &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions&quot;)), subtitle = &quot;The densities for import and pmi are asymmetric, small, and largely overlapping. The density for reaction is Gaussian and\\nmore impressive in magnitude.&quot;, x = NULL) + theme_minimal() + theme(legend.title = element_blank()) It’ll take a bit of data wrangling to rename our model parameters to the \\(a\\), \\(b\\)… configuration. We’ll compute the indirect effects and \\(c\\), too. post &lt;- posterior_samples(model2) post&lt;- post %&gt;% mutate(a1 = b_import_cond, a2 = b_pmi_cond, b1 = b_reaction_import, b2 = b_reaction_pmi, c_prime = b_reaction_cond) %&gt;% mutate(a1b1 = a1*b1, a2b2 = a2*b2) %&gt;% mutate(c = c_prime + a1b1 + a2b2) Here are their summaries. Since Bayesians use means, medians, and sometimes the mode to describe the central tendencies of a parameter, this time we’ll mix it up and just use the median. post %&gt;% select(a1:c) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 8 x 4 #&gt; key median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1 0.63 0.025 1.28 #&gt; 2 a1b1 0.195 0.008 0.452 #&gt; 3 a2 0.478 -0.007 0.959 #&gt; 4 a2b2 0.181 -0.003 0.428 #&gt; 5 b1 0.323 0.184 0.465 #&gt; 6 b2 0.398 0.216 0.586 #&gt; # ... with 2 more rows post %&gt;% mutate(dif = a1b1*b1) %&gt;% summarize(median = median(dif), ll = quantile(dif, probs = .025), ul = quantile(dif, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; median ll ul #&gt; 1 0.061 0.002 0.187 In the middle paragraph of page 158, Hayes showd how the mean difference in imprt between the two cond groups multiplied by b1, the coefficient of import predicting reaction, is equal to the a1b1 indirect effect. He does this with simple algebra using the group means and the point estimates. Let’s follow along. First, we’ll get those two group means and save them as numbers to arbitrary precision. ( import_means &lt;- pmi %&gt;% group_by(cond) %&gt;% summarize(mean = mean(import)) ) #&gt; # A tibble: 2 x 2 #&gt; cond mean #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 0 3.91 #&gt; 2 1 4.53 (cond_0_import_mean &lt;- import_means[1, 2] %&gt;% pull()) #&gt; [1] 3.91 (cond_1_import_mean &lt;- import_means[2, 2] %&gt;% pull()) #&gt; [1] 4.53 Here we follow the formula in the last sentence of the paragraph and then compare the results to the posterior for a1b1. post %&gt;% # Using his formula to make our new vector, `handmade a1b1` mutate(`handmade a1b1` = (cond_1_import_mean - cond_0_import_mean)*b1) %&gt;% # Here&#39;s all the usual data wrangling select(a1b1, `handmade a1b1`) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 2 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1b1 0.205 0.195 0.008 0.452 #&gt; 2 handmade a1b1 0.203 0.203 0.116 0.292 Yep, at the mean, Hayes’s formula is spot on. But the distributions are distinct. They differ slightly at the median and vastly in the widths of the posterior intervals. I’m no mathematician, so take this with a grain of salt, but I suspect this has to do with how we used fixed values (i.e., the difference of the subsample means) to compute handmade a1b1, but all the components in a1b1 were estimated. Here we’ll follow the same protocol for a2b2. ( pmi_means &lt;- pmi %&gt;% group_by(cond) %&gt;% summarize(mean = mean(pmi)) ) #&gt; # A tibble: 2 x 2 #&gt; cond mean #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 0 5.38 #&gt; 2 1 5.85 cond_0_pmi_mean &lt;- pmi_means[1, 2] %&gt;% pull() cond_1_pmi_mean &lt;- pmi_means[2, 2] %&gt;% pull() post %&gt;% mutate(`handmade a2b2` = (cond_1_pmi_mean - cond_0_pmi_mean)*b2) %&gt;% select(a2b2, `handmade a2b2`) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 2 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a2b2 0.191 0.181 -0.003 0.428 #&gt; 2 handmade a2b2 0.19 0.19 0.103 0.279 To get the total indirect effect as discussed on page 160, we simply add the a1b1 and a2b2 columns. post &lt;- post %&gt;% mutate(total_indirect_effect = a1b1 + a2b2) post %&gt;% select(total_indirect_effect) %&gt;% summarize(mean = mean(total_indirect_effect), median = median(total_indirect_effect), ll = quantile(total_indirect_effect, probs = .025), ul = quantile(total_indirect_effect, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; mean median ll ul #&gt; 1 0.395 0.389 0.11 0.725 To use the equations on the top of page 161, we’ll just work directly with the original vectors in post. post %&gt;% mutate(Y_bar_given_X_1 = b_import_Intercept + b_reaction_cond*1 + b_reaction_import*b_import_Intercept + b_reaction_pmi*b_pmi_Intercept, Y_bar_given_X_0 = b_import_Intercept + b_reaction_cond*0 + b_reaction_import*b_import_Intercept + b_reaction_pmi*b_pmi_Intercept) %&gt;% mutate(`c_prime by hand` = Y_bar_given_X_1 - Y_bar_given_X_0) %&gt;% select(c_prime, `c_prime by hand`) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) #&gt; # A tibble: 2 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 c_prime 0.101 0.0991 -0.372 0.568 #&gt; 2 c_prime by hand 0.101 0.0991 -0.372 0.568 We computed c a while ago. post %&gt;% summarize(mean = mean(c), median = median(c), ll = quantile(c, probs = .025), ul = quantile(c, probs = .975)) #&gt; mean median ll ul #&gt; 1 0.496 0.501 -0.0544 1.03 And c minus c_prime is straight subtraction. post %&gt;% mutate(`c minus c_prime` = c - c_prime) %&gt;% summarize(mean = mean(`c minus c_prime`), median = median(`c minus c_prime`), ll = quantile(`c minus c_prime`, probs = .025), ul = quantile(`c minus c_prime`, probs = .975)) #&gt; mean median ll ul #&gt; 1 0.395 0.389 0.11 0.725 5.3 Statistical inference 5.3.1 Inference about the direct and total effects. We’re not going to bother with \\(p\\)-values and we’ve already computed the 95% Bayesian credible intervals, above. But we can examine our parameters with a density plot. post %&gt;% select(c, c_prime) %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key, color = key)) + geom_vline(xintercept = 0, color = &quot;black&quot;) + geom_density(alpha = .5) + scale_color_ptol(NULL) + scale_fill_ptol(NULL) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;It appears zero is more credible for the direct effect, &quot;, italic(c), &quot;&#39;, than it is the total effect, &quot;, italic(c), &quot;.&quot;)), x = NULL) + coord_cartesian(xlim = -c(-1.5, 1.5)) + theme_minimal() 5.3.2 Inference about specific indirect effects. Again, no need to worry about bootstrapping within the Bayesian paradigm. We can compute high-quality percentile-based intervals with our HMC-based posterior samples. post %&gt;% select(a1b1, a2b2) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1b1 0.008 0.452 #&gt; 2 a2b2 -0.003 0.428 5.3.3 Pairwise comparisons between specific indirect effects. Within the Bayesian paradigm, it’s straightforward to compare indirect effects. All one has to do is compute a difference score and summarize it somehow. Here it is, a1b1 minus a2b2 post &lt;- post %&gt;% mutate(difference = a1b1 - a2b2) post %&gt;% summarize(mean = mean(difference), ll = quantile(difference, probs = .025), ul = quantile(difference, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; mean ll ul #&gt; 1 0.014 -0.308 0.335 Why not plot? post %&gt;% ggplot(aes(x = difference)) + geom_vline(xintercept = 0, color = &quot;black&quot;, linetype = 2) + geom_density(color = &quot;black&quot;, fill = &quot;black&quot;, alpha = .5) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The difference score between the indirect effects&quot;, subtitle = expression(paste(&quot;No &quot;, italic(p), &quot;-value or 95% intervals needed for this one.&quot;)), x = NULL) + coord_cartesian(xlim = -1:1) + theme_minimal() Although note well that this does not mean their difference is exactly zero. The shape of the posterior distribution testifies our uncertainty in their difference. Our best bet is that the difference is approximately zero, but it could easily be plus or minus a quarter of a point or more. 5.3.4 Inference about the total indirect effect. Here’s the plot. post %&gt;% ggplot(aes(x = total_indirect_effect, fill = factor(0), color = factor(0))) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The total indirect effect of condition on reaction&quot;, subtitle = expression(paste(&quot;This is the sum of &quot;, italic(a)[1], italic(b)[1], &quot; and &quot;, italic(a)[2], italic(b)[2], &quot;. It&#39;s wide and uncertain.&quot;)), x = NULL) + theme_minimal() + theme(legend.position = &quot;none&quot;) 5.4 The serial multiple mediator model 5.4.1 Direct and indirect effects in a serial multiple mediator model. 5.4.2 Statistical inference. 5.4.3 Example from the presumed media influence study. The model syntax is similar to the earlier multiple mediator model. All we change is adding import to the list of predictors in the m2_model. m1_model &lt;- bf(import ~ 1 + cond) m2_model &lt;- bf(pmi ~ 1 + import + cond) y_model &lt;- bf(reaction ~ 1 + import + pmi + cond) model3 &lt;- brm(data = pmi, family = gaussian, y_model + m1_model + m2_model + set_rescor(FALSE), chains = 4, cores = 4) print(model3) #&gt; Family: MV(gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: reaction ~ 1 + import + pmi + cond #&gt; import ~ 1 + cond #&gt; pmi ~ 1 + import + cond #&gt; Data: pmi (Number of observations: 123) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; reaction_Intercept -0.15 0.53 -1.20 0.89 4000 1.00 #&gt; import_Intercept 3.91 0.23 3.47 4.36 4000 1.00 #&gt; pmi_Intercept 4.61 0.31 3.99 5.23 4000 1.00 #&gt; reaction_import 0.32 0.07 0.19 0.47 4000 1.00 #&gt; reaction_pmi 0.40 0.09 0.22 0.58 4000 1.00 #&gt; reaction_cond 0.10 0.23 -0.36 0.55 4000 1.00 #&gt; import_cond 0.62 0.32 -0.01 1.25 4000 1.00 #&gt; pmi_import 0.20 0.07 0.06 0.33 4000 1.00 #&gt; pmi_cond 0.35 0.24 -0.12 0.83 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_reaction 1.30 0.08 1.15 1.47 4000 1.00 #&gt; sigma_import 1.73 0.11 1.53 1.97 4000 1.00 #&gt; sigma_pmi 1.28 0.08 1.13 1.45 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The \\(R^2\\) posterior densities: bayes_R2(model3, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(key = str_remove(key, &quot;R2_&quot;)) %&gt;% ggplot(aes(x = value, color = key, fill = key)) + geom_density(alpha = .5) + scale_color_ptol() + scale_fill_ptol() + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(&quot;R&quot;)^{2}, &quot; distributions for model3, the serial multiple mediator model&quot;)), subtitle = &quot;The density for reaction hasn&#39;t changed from model2. However, look how the pmi density separated from import.&quot;, x = NULL) + theme_minimal() + theme(legend.title = element_blank()) As before, here we’ll save the posterior samples into a data frame and rename the parameters a bit to match Hayes’s nomenclature. post &lt;- posterior_samples(model3) post &lt;- post %&gt;% mutate(a1 = b_import_cond, a2 = b_pmi_cond, b1 = b_reaction_import, b2 = b_reaction_pmi, c_prime = b_reaction_cond, d21 = b_pmi_import) Here are the parameter summaries for the pathways depicted in Figure 5.6. post %&gt;% select(a1:d21) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 6 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1 0.625 0.62 -0.014 1.25 #&gt; 2 a2 0.354 0.355 -0.121 0.833 #&gt; 3 b1 0.325 0.325 0.187 0.466 #&gt; 4 b2 0.396 0.397 0.217 0.582 #&gt; 5 c_prime 0.103 0.1 -0.363 0.554 #&gt; 6 d21 0.197 0.198 0.062 0.331 To get our version of the parameter summaries in Table 5.2, all you have to do is add the summaries for the intercepts to what we did above. post %&gt;% rename(im1 = b_import_Intercept, im2 = b_pmi_Intercept, iy = b_reaction_Intercept) %&gt;% select(a1:d21, starts_with(&quot;i&quot;)) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 9 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1 0.625 0.62 -0.014 1.25 #&gt; 2 a2 0.354 0.355 -0.121 0.833 #&gt; 3 b1 0.325 0.325 0.187 0.466 #&gt; 4 b2 0.396 0.397 0.217 0.582 #&gt; 5 c_prime 0.103 0.1 -0.363 0.554 #&gt; 6 d21 0.197 0.198 0.062 0.331 #&gt; # ... with 3 more rows Here we compute the four indirect effects. post &lt;- post %&gt;% mutate(a1b1 = a1*b1, a2b2 = a2*b2, a1d21b2 = a1*d21*b2) %&gt;% mutate(total_indirect_effect = a1b1 + a2b2 + a1d21b2) The summaries for the indirect effects are as follows. post %&gt;% select(a1b1:total_indirect_effect) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 4 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1b1 0.204 0.195 -0.004 0.467 #&gt; 2 a1d21b2 0.048 0.042 -0.001 0.13 #&gt; 3 a2b2 0.139 0.131 -0.048 0.369 #&gt; 4 total_indirect_effect 0.392 0.384 0.073 0.752 To get the contrasts Hayes presented in page 179, we just do a little subtraction. post %&gt;% transmute(C1 = a1b1 - a2b2, C2 = a1b1 - a1d21b2, C3 = a2b2 - a1d21b2) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is_double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 C1 0.065 0.063 -0.248 0.386 #&gt; 2 C2 0.156 0.143 -0.004 0.397 #&gt; 3 C3 0.091 0.086 -0.113 0.326 And just because it’s fun, we may as well plot our indirect effects. # this will help us save a little space with the plot code my_labels &lt;- c(expression(paste(italic(a)[1], italic(b)[1])), expression(paste(italic(a)[1], italic(d)[21], italic(b)[1])), expression(paste(italic(a)[2], italic(b)[2])), &quot;total indirect effect&quot;) post %&gt;% select(a1b1:total_indirect_effect) %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key, color = key)) + geom_density(alpha = .5) + scale_color_ptol(NULL, labels = my_labels, guide = guide_legend(label.hjust = 0)) + scale_fill_ptol(NULL, labels = my_labels, guide = guide_legend(label.hjust = 0)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The four indirect effects of the serial multiple mediator model&quot;, x = NULL) + theme_minimal() References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] bindrcpp_0.2.2 ggthemes_3.5.0 brms_2.3.4 Rcpp_0.12.17 forcats_0.3.0 stringr_1.3.1 #&gt; [7] dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 #&gt; [13] tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 threejs_0.3.1 #&gt; [6] httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 tools_3.5.1 backports_1.1.2 #&gt; [11] utf8_1.1.4 R6_2.2.2 DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 #&gt; [16] withr_2.1.2 tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 xml2_1.2.0 #&gt; [26] labeling_0.3 colourpicker_1.0 bookdown_0.7 scales_0.5.0 dygraphs_1.1.1.5 #&gt; [31] mvtnorm_1.0-8 psych_1.8.4 ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 #&gt; [36] foreign_0.8-70 rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 shiny_1.1.0 #&gt; [46] bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 gtools_3.8.1 crosstalk_1.0.0 #&gt; [51] inline_0.3.15 magrittr_1.5 loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 #&gt; [56] munsell_0.5.0 abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 miniUI_0.1.1.1 #&gt; [66] lattice_0.20-35 haven_1.1.2 hms_0.4.2 knitr_1.20 pillar_1.2.3 #&gt; [71] igraph_1.2.1 markdown_0.8 shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 #&gt; [76] stats4_3.5.1 rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 xfun_0.3 #&gt; [86] mime_0.5 xtable_1.8-2 broom_0.4.5 coda_0.19-1 later_0.7.3 #&gt; [91] rsconnect_0.8.8 shinythemes_1.1.1 bridgesampling_0.4-0 "],
["mediation-analysis-with-a-multicategorical-antecedent.html", "6 Mediation Analysis with a Multicategorical Antecedent 6.1 Relative total, direct, and indirect effects 6.2 An example: Sex discrimination in the workplace 6.3 Using a different group coding system References Session info", " 6 Mediation Analysis with a Multicategorical Antecedent 6.1 Relative total, direct, and indirect effects 6.2 An example: Sex discrimination in the workplace Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) #&gt; Observations: 129 #&gt; Variables: 6 #&gt; $ subnum &lt;int&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66, 168, 97,... #&gt; $ protest &lt;int&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, 1, 1, 0, 1... #&gt; $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, 5.87, 4.87... #&gt; $ angry &lt;int&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, 1, 1, 2, 1... #&gt; $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, 6.50, 4.50... #&gt; $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, 6.25, 5.00... Here are the ungrouped means and \\(SD\\)s for respappr and liking shown at the bottom of Table 6.1. protest %&gt;% select(liking:respappr) %&gt;% gather(key, value) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 liking 5.64 1.05 #&gt; 2 respappr 4.87 1.35 We compute the summaries for respappr and liking, grouped by protest, like so. protest %&gt;% select(protest, liking:respappr) %&gt;% gather(key, value, -protest) %&gt;% group_by(protest, key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 6 x 4 #&gt; # Groups: protest [3] #&gt; protest key mean sd #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 liking 5.31 1.30 #&gt; 2 0 respappr 3.88 1.46 #&gt; 3 1 liking 5.83 0.819 #&gt; 4 1 respappr 5.14 1.08 #&gt; 5 2 liking 5.75 0.936 #&gt; 6 2 respappr 5.49 0.936 It looks like Hayes has a typo in the \\(SD\\) for liking when protest == 0. It seemed he accidentally entered the value for when protest == 1 in that slot. You’ll have to wait a minute to see where the adjusted \\(Y\\) values came. With a little ifelse(), computing the dummies D1 and D2 is easy enough. protest &lt;- protest %&gt;% mutate(D1 = ifelse(protest == 1, 1, 0), D2 = ifelse(protest == 2, 1, 0)) We’re almost ready to fit the model. Let’s load brms. library(brms) This is the first time we’ve had a simple univariate regression model in a while. No special cbind() syntax or multiple bf() formulas. Just straight up brm(). model1 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + D1 + D2, chains = 4, cores = 4) fixef(model1) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 5.310 0.167 4.9815 5.644 #&gt; D1 0.517 0.232 0.0664 0.980 #&gt; D2 0.442 0.231 -0.0138 0.891 Our \\(R^2\\) differes a bit from the OLS version in the text. This shouldn’t be surprising when it’s near the boundary. bayes_R2(model1) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.0588 0.036 0.00534 0.14 Here’s its shape. For the plots in this chapter, we’ll take a few formatting cues from Edward Tufte, curtesy of the ggthemes package. The theme_tufte() function will change the default font and remove some chart junk. We will take our color palette from Pokemon via the palettetown package. library(ggthemes) library(palettetown) bayes_R2(model1, summary = F) %&gt;% as_tibble() %&gt;% ggplot(aes(x = R2)) + geom_density(size = 0, fill = pokepal(pokemon = &quot;plusle&quot;)[2]) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + xlab(expression(italic(R)^{2})) + theme_tufte() + theme(legend.title = element_blank(), plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) To use the model-implied equations to compute the means for each group on the criterion, we’ll extract the posterior samples. post &lt;- posterior_samples(model1) post %&gt;% transmute(Y_np = b_Intercept + b_D1*0 + b_D2*0, Y_ip = b_Intercept + b_D1*1 + b_D2*0, Y_cp = b_Intercept + b_D1*0 + b_D2*1) %&gt;% gather() %&gt;% # this line will order our output the same way Hayes did in the text (p. 197) mutate(key = factor(key, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 3 x 3 #&gt; key mean sd #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Y_np 5.31 0.167 #&gt; 2 Y_ip 5.83 0.163 #&gt; 3 Y_cp 5.75 0.160 What Hayes called the “relative total effects” \\(c_{1}\\) and \\(c_{2}\\) are the D1 and D2 lines in our fixef() output, above. Here are the sub-models for the mediation model. m_model &lt;- bf(respappr ~ 1 + D1 + D2) y_model &lt;- bf(liking ~ 1 + D1 + D2 + respappr) We fit. model2 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) print(model2) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: respappr ~ 1 + D1 + D2 #&gt; liking ~ 1 + D1 + D2 + respappr #&gt; Data: protest (Number of observations: 129) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; respappr_Intercept 3.88 0.19 3.51 4.25 4000 1.00 #&gt; liking_Intercept 3.71 0.32 3.08 4.32 4000 1.00 #&gt; respappr_D1 1.26 0.26 0.76 1.77 4000 1.00 #&gt; respappr_D2 1.61 0.26 1.08 2.11 4000 1.00 #&gt; liking_D1 -0.01 0.23 -0.46 0.43 3427 1.00 #&gt; liking_D2 -0.22 0.23 -0.67 0.23 3397 1.00 #&gt; liking_respappr 0.41 0.07 0.27 0.56 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_respappr 1.18 0.08 1.04 1.35 4000 1.00 #&gt; sigma_liking 0.93 0.06 0.82 1.05 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The Bayesian \\(R^2\\) posteriors: bayes_R2(model2, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(size = 0, alpha = 2/3) + annotate(&quot;text&quot;, x = .18, y = 6.75, label = &quot;liking&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[2], family = &quot;Times&quot;) + annotate(&quot;text&quot;, x = .355, y = 6.75, label = &quot;respappr&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[6], family = &quot;Times&quot;) + scale_y_continuous(NULL, breaks = NULL) + scale_fill_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(2, 6)]) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(R)^{2}, &quot; densities overlap near perfectly, both hovering around .25.&quot;)), x = NULL) + theme_tufte() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) To get the model summaries as presented in the second two columns in Table 6.2, we use posterior_samples(), rename a bit, and summarize() as usual. post &lt;- posterior_samples(model2) %&gt;% mutate(a1 = b_respappr_D1, a2 = b_respappr_D2, b = b_liking_respappr, c1_prime = b_liking_D1, c2_prime = b_liking_D2, i_m = b_respappr_Intercept, i_y = b_liking_Intercept) post %&gt;% select(a1:i_y) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 7 x 5 #&gt; key mean sd ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1 1.26 0.26 0.756 1.77 #&gt; 2 a2 1.61 0.258 1.08 2.11 #&gt; 3 b 0.413 0.073 0.268 0.559 #&gt; 4 c1_prime -0.008 0.227 -0.46 0.429 #&gt; 5 c2_prime -0.224 0.231 -0.668 0.226 #&gt; 6 i_m 3.88 0.186 3.51 4.25 #&gt; # ... with 1 more row Working with the \\(\\overline{M}_{ij}\\) formulas in page 199 is quite similar to what we did above. post %&gt;% transmute(M_np = b_respappr_Intercept + b_respappr_D1*0 + b_respappr_D2*0, M_ip = b_respappr_Intercept + b_respappr_D1*1 + b_respappr_D2*0, M_cp = b_respappr_Intercept + b_respappr_D1*0 + b_respappr_D2*1) %&gt;% gather() %&gt;% # this line will order our output the same way Hayes did in the text (p. 199) mutate(key = factor(key, levels = c(&quot;M_np&quot;, &quot;M_ip&quot;, &quot;M_cp&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 3 x 3 #&gt; key mean sd #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 M_np 3.88 0.186 #&gt; 2 M_ip 5.14 0.182 #&gt; 3 M_cp 5.49 0.177 The \\(\\overline{Y}^*_{ij}\\) formulas are more of the same. post &lt;- post %&gt;% mutate(Y_np = b_liking_Intercept + b_liking_D1*0 + b_liking_D2*0 + b_liking_respappr*mean(protest$respappr), Y_ip = b_liking_Intercept + b_liking_D1*1 + b_liking_D2*0 + b_liking_respappr*mean(protest$respappr), Y_cp = b_liking_Intercept + b_liking_D1*0 + b_liking_D2*1 + b_liking_respappr*mean(protest$respappr)) post %&gt;% select(starts_with(&quot;Y_&quot;)) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 3 x 3 #&gt; key mean sd #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Y_np 5.72 0.164 #&gt; 2 Y_ip 5.71 0.146 #&gt; 3 Y_cp 5.49 0.144 Note, these are where the adjusted \\(Y\\) values came from in Table 6.1. This is as fine a spot as any to introduce coefficient plots. Both brms and the bayesplot package offer convenience functions for coefficient plots. It’s good to know how to make them by hand. Here’s ours for those last three \\(\\overline{Y}^*_{ij}\\)-values. post %&gt;% select(starts_with(&quot;Y_&quot;)) %&gt;% gather() %&gt;% ggplot(aes(x = key, y = value, color = key)) + stat_summary(geom = &quot;pointrange&quot;, fun.y = median, fun.ymin = function(x){quantile(x, probs = .025)}, fun.ymax = function(x){quantile(x, probs = .975)}, size = .75) + stat_summary(geom = &quot;linerange&quot;, fun.ymin = function(x){quantile(x, probs = .25)}, fun.ymax = function(x){quantile(x, probs = .75)}, size = 1.5) + scale_color_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(3, 7, 9)]) + coord_flip() + theme_tufte() + labs(x = NULL, y = NULL) + theme(axis.ticks.y = element_blank(), legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) The points are the posterior medians, the thick inner lines the 50% intervals, and the thinner outer lines the 95% intervals. For kicks, we distinguished the three values by color. If we want to examine \\(R^2\\) change for dropping the dummy variables, we’ll first fit a model that omits them. model3 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + respappr, chains = 4, cores = 4) Here are the competing \\(R^2\\) distributions. R2s &lt;- bayes_R2(model2, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% rename(R2 = R2_liking) %&gt;% bind_rows( bayes_R2(model3, summary = F) %&gt;% as_tibble() ) %&gt;% mutate(fit = rep(c(&quot;model2&quot;, &quot;model3&quot;), each = 4000)) R2s %&gt;% ggplot(aes(x = R2, fill = fit)) + geom_density(size = 0, alpha = 2/3) + scale_fill_manual(values = pokepal(pokemon = &quot;plusle&quot;)[c(6, 7)]) + annotate(&quot;text&quot;, x = .15, y = 6.75, label = &quot;model3&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[7], family = &quot;Times&quot;) + annotate(&quot;text&quot;, x = .35, y = 6.75, label = &quot;model2&quot;, color = pokepal(pokemon = &quot;plusle&quot;)[6], family = &quot;Times&quot;) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;The &quot;, italic(R)^{2}, &quot; densities for LIKING overlap a lot.&quot;)), x = NULL) + theme_tufte() + theme(legend.position = &quot;none&quot;, plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) If you want to compare then with a change score, do something like this. R2s %&gt;% mutate(iter = rep(1:4000, times = 2)) %&gt;% spread(key = fit, value = R2) %&gt;% mutate(difference = model2 - model3) %&gt;% ggplot(aes(x = difference)) + geom_density(size = 0, fill = pokepal(pokemon = &quot;plusle&quot;)[4]) + geom_vline(xintercept = 0, color = pokepal(pokemon = &quot;plusle&quot;)[8]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The &quot;, Delta, italic(R)^{2}, &quot; distribution&quot;)), subtitle = &quot;Doesn&#39;t appear we have a lot of change.&quot;, x = NULL) + theme_tufte() + theme(legend.title = element_blank(), plot.background = element_rect(fill = pokepal(pokemon = &quot;plusle&quot;)[8])) Here’s how to compute the summaries for \\(a_{1}b\\) and \\(a_{2}b\\), including the Bayesian HMC intervals. post %&gt;% mutate(a1b = a1*b, a2b = a2*b) %&gt;% select(a1b:a2b) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 5 #&gt; key mean sd ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1b 0.523 0.146 0.264 0.831 #&gt; 2 a2b 0.667 0.163 0.37 1.02 6.3 Using a different group coding system Here we’ll make our alternative dummies, what we’ll call D_1 and D_2, with orthogonal contrast coding. protest &lt;- protest %&gt;% mutate(D_1 = ifelse(protest == 0, -2/3, 1/3), D_2 = ifelse(protest == 0, 0, ifelse(protest == 1, -1/2, 1/2))) Here are the sub-models. m_model &lt;- bf(respappr ~ 1 + D_1 + D_2) y_model &lt;- bf(liking ~ 1 + D_1 + D_2 + respappr) Now we fit. model4 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) Here are our intercepts and regression coefficient summaries. fixef(model4) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; respappr_Intercept 4.842 0.1046 4.633 5.045 #&gt; liking_Intercept 3.641 0.3515 2.954 4.345 #&gt; respappr_D_1 1.436 0.2230 0.996 1.867 #&gt; respappr_D_2 0.349 0.2532 -0.149 0.843 #&gt; liking_D_1 -0.114 0.2022 -0.506 0.283 #&gt; liking_D_2 -0.214 0.2002 -0.604 0.185 #&gt; liking_respappr 0.411 0.0708 0.271 0.550 It’s important to note that these will not correspond to the “TOTAL EFFECT MODEL” section of the PROCESS output of Figure 6.3. Hayes’s PROCESS has the mcx=3 command which tells the program to reparametrize the orthogonal contrasts. brms doesn’t have such a command. For now, we’ll have to jump to equation 6.8 towards the bottom of page 207. Those parameters are evident in our output. fixef(model4)[c(1, 3:4) , ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; respappr_Intercept 4.842 0.105 4.633 5.045 #&gt; respappr_D_1 1.436 0.223 0.996 1.867 #&gt; respappr_D_2 0.349 0.253 -0.149 0.843 Thus it’s easy to get the \\(\\overline{M}_{ij}\\) means with a little posterior manipulation. post &lt;- posterior_samples(model4) post &lt;- post %&gt;% mutate(M_np = b_respappr_Intercept + b_respappr_D_1*-2/3 + b_respappr_D_2*0, M_ip = b_respappr_Intercept + b_respappr_D_1*1/3 + b_respappr_D_2*-1/2, M_cp = b_respappr_Intercept + b_respappr_D_1*1/3 + b_respappr_D_2*1/2) post %&gt;% select(starts_with(&quot;M_&quot;)) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;M_np&quot;, &quot;M_ip&quot;, &quot;M_cp&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 3 x 3 #&gt; key mean sd #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 M_np 3.89 0.184 #&gt; 2 M_ip 5.15 0.179 #&gt; 3 M_cp 5.50 0.179 With these in hand, we can compute \\(a_{1}\\) and \\(a_{2}\\). post &lt;- post %&gt;% mutate(a1 = (M_ip + M_cp)/2 - M_np, a2 = M_cp - M_ip) post %&gt;% select(a1:a2) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1 1.44 0.223 #&gt; 2 a2 0.349 0.253 Happily, our model output will allow us to work with Hayes’s \\(\\overline{Y}^*_{ij}\\) equations in the middle of page 210. post &lt;- post %&gt;% mutate(Y_np = b_liking_Intercept + b_liking_D_1*-2/3 + b_liking_D_2*0 + b_liking_respappr*mean(protest$respappr), Y_ip = b_liking_Intercept + b_liking_D_1*1/3 + b_liking_D_2*-1/2 + b_liking_respappr*mean(protest$respappr), Y_cp = b_liking_Intercept + b_liking_D_1*1/3 + b_liking_D_2*1/2 + b_liking_respappr*mean(protest$respappr)) post %&gt;% select(starts_with(&quot;Y_&quot;)) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Y_np&quot;, &quot;Y_ip&quot;, &quot;Y_cp&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 3 x 3 #&gt; key mean sd #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Y_np 5.72 0.163 #&gt; 2 Y_ip 5.71 0.145 #&gt; 3 Y_cp 5.50 0.147 And with these in hand, we can compute \\(c&#39;_{1}\\) and \\(c&#39;_{2}\\). post &lt;- post %&gt;% mutate(c1_prime = (Y_ip + Y_cp)/2 - Y_np, c2_prime = Y_cp - Y_ip) post %&gt;% select(c1_prime:c2_prime) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 c1_prime -0.114 0.202 #&gt; 2 c2_prime -0.214 0.200 It appears Hayes has a typo in the formula for \\(c&#39;_{2}\\) on page 211. The value he has down for \\(\\overline{Y}^*_{IP}\\), 5.145, is incorrect. It’s not the one he displayed at the bottom of the previous page and it also contradicts the analyses herein. So it goes… These things happen. We haven’t spelled out, but the \\(b\\) parameter is currently labeled b_liking_respappr in our post object. Here we’ll make a b column to make things easier. While we’re at it, we’ll compute the indirect effects, too. post &lt;- post %&gt;% mutate(b = b_liking_respappr) %&gt;% mutate(a1b = a1*b, a2b = a2*b) post %&gt;% select(a1b:a2b) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 5 #&gt; key mean sd ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a1b 0.589 0.134 0.34 0.866 #&gt; 2 a2b 0.143 0.108 -0.061 0.364 Now we can compute and summarize() our \\(c_{1}\\) and \\(c_{1}\\). post &lt;- post %&gt;% mutate(c1 = c1_prime + a1b, c2 = c2_prime + a2b) post %&gt;% select(c1:c2) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 c1 0.475 0.195 #&gt; 2 c2 -0.0706 0.227 References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] palettetown_0.1.1 ggthemes_3.5.0 brms_2.3.4 Rcpp_0.12.17 bindrcpp_0.2.2 #&gt; [6] forcats_0.3.0 stringr_1.3.1 dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 #&gt; [11] tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 threejs_0.3.1 #&gt; [6] httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 tools_3.5.1 backports_1.1.2 #&gt; [11] utf8_1.1.4 R6_2.2.2 DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 #&gt; [16] withr_2.1.2 tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 xml2_1.2.0 #&gt; [26] labeling_0.3 colourpicker_1.0 bookdown_0.7 scales_0.5.0 dygraphs_1.1.1.5 #&gt; [31] mvtnorm_1.0-8 psych_1.8.4 ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 #&gt; [36] foreign_0.8-70 rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 shiny_1.1.0 #&gt; [46] bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 gtools_3.8.1 crosstalk_1.0.0 #&gt; [51] inline_0.3.15 magrittr_1.5 loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 #&gt; [56] munsell_0.5.0 abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 miniUI_0.1.1.1 #&gt; [66] lattice_0.20-35 haven_1.1.2 hms_0.4.2 knitr_1.20 pillar_1.2.3 #&gt; [71] igraph_1.2.1 markdown_0.8 shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 #&gt; [76] stats4_3.5.1 rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 xfun_0.3 #&gt; [86] mime_0.5 xtable_1.8-2 broom_0.4.5 coda_0.19-1 later_0.7.3 #&gt; [91] rsconnect_0.8.8 shinythemes_1.1.1 bridgesampling_0.4-0 "],
["fundamentals-of-moderation-analysis.html", "7 Fundamentals of Moderation Analysis 7.1 Conditional and unconditional effects 7.2 An example: Climate change disasters and humanitarianism 7.3 Visualizing moderation 7.4 Probing an interaction 7.5 The difference between testing for moderation and probing it 7.6 Artificial categorization and subgroups References Session info", " 7 Fundamentals of Moderation Analysis 7.1 Conditional and unconditional effects You might reproduce Hayes’s Table 7.1 data like this. library(tidyverse) d &lt;- tibble(x = rep(-1:2, each = 3), w = rep(0:2, times = 4)) %&gt;% mutate(A = 4 + 1*x + 2*w, B = 4 + 1*x + 2*w + 1.5*x*w) In previous chapters, we alteried our plot themes using either built-in settings from ggplot2 or extra themes from the ggthemes package. When we wanted to change them further, we did so with extra theme() arguments. One, it’s nice to be know how to make one’s own custom theme and, two, it’d be handy to condense our code a bit. Here we’ll take a few cues from the Building a New Theme and from Peng, Kross, and Anderson’s Mastering Software Development in R. We’ll make our own theme, theme_07 by saving a handful of augmentations from the default theme_gray() theme. library(dutchmasters) theme_07 &lt;- theme_gray() + theme(plot.background = element_rect(fill = dutchmasters$little_street[7]), panel.background = element_rect(fill = dutchmasters$little_street[2]), strip.background = element_rect(fill = alpha(dutchmasters$little_street[5], 2/3), color = &quot;transparent&quot;), legend.background = element_rect(fill = &quot;transparent&quot;), legend.key = element_rect(fill = &quot;transparent&quot;, color = &quot;transparent&quot;), panel.grid = element_blank(), text = element_text(family = &quot;Courier&quot;, color = dutchmasters$little_street[6], size = 14), axis.text = element_text(color = dutchmasters$little_street[6])) This chapter’s color palette comes from the dutchmasters package, which was itself based of Vermeer’s The Little Street. To get a quick glance at the full palette, we’ll also use viz_palette(), a convenience function from the ochRe package. library(ochRe) viz_palette(dutchmasters$little_street) With our new theme_07 in hand, we’re ready for our version of Figure 7.2. library(directlabels) d %&gt;% gather(key, value, -x, -w) %&gt;% rename(y = value) %&gt;% mutate(label = str_c(&quot;W = &quot;, w)) %&gt;% ggplot(aes(x = x, y = y, group = w, size = w %&gt;% as.factor(), label = label)) + geom_line(color = dutchmasters$little_street[9]) + geom_dl(method = list(dl.trans(x = x + 0.2), &quot;last.points&quot;, cex = 1, color = dutchmasters$little_street[9], fontfamily = &quot;Courier&quot;)) + scale_size_manual(values = c(.5, .75, 1)) + coord_cartesian(xlim = c(-1, 2.6), ylim = 0:16) + labs(x = expression(italic(&quot;X&quot;)), y = expression(italic(&quot;Y&quot;))) + facet_wrap(~key) + theme_07 + # because we didn&#39;t alter the `legend.position` argument in our `theme_07`, we need to use `theme()` to remove it theme(legend.position = &quot;none&quot;) We borrowed geom_dl() form the directlabels package, which made it easy to insert the “W = \\(i\\)” labels to the right of the lines. I played around with the annotation in Figure 7.4 for a while and it was just way more trouble than it was worth. If you’re ever inspired to work it out, please share your code. 7.2 An example: Climate change disasters and humanitarianism Here we load a couple necessary packages, load the data, and take a glimpse(). disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) #&gt; Observations: 211 #&gt; Variables: 5 #&gt; $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25... #&gt; $ frame &lt;int&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1,... #&gt; $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8, 5.4, 3.4,... #&gt; $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2.65, 3.15,... #&gt; $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6, 1.0, 6.4,... Here is how to get the ungrouped mean and \\(SD\\) values for justify and skeptic, as presented in Table 7.3. disaster %&gt;% select(justify, skeptic) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 justify 2.87 0.93 #&gt; 2 skeptic 3.38 2.03 And here we get the same summary values, this time grouped by frame. disaster %&gt;% select(frame, justify, skeptic) %&gt;% gather(key, value, -frame) %&gt;% group_by(frame, key) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 4 x 4 #&gt; # Groups: frame [2] #&gt; frame key mean sd #&gt; &lt;int&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 justify 2.80 0.849 #&gt; 2 0 skeptic 3.34 2.04 #&gt; 3 1 justify 2.94 1.01 #&gt; 4 1 skeptic 3.42 2.03 Let’s open brms. library(brms) Anticipating Table 7.4 on page 234, we’ll name this first model model1. model1 &lt;- brm(data = disaster, family = gaussian, justify ~ 1 + frame, chains = 4, cores = 4) print(model1) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: justify ~ 1 + frame #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 2.80 0.09 2.63 2.97 3987 1.00 #&gt; frame 0.13 0.13 -0.12 0.38 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.93 0.05 0.85 1.03 3841 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The ‘Estimate’ (i.e., posterior mean) of the model intercept is the expected justify value for when frame is 0. The ‘Estimate’ for frame is the expected difference when frame is a 1. If all you care about is the posterior mean, you could do fixef(model1)[&quot;Intercept&quot;, 1] + fixef(model1)[&quot;frame&quot;, 1] #&gt; [1] 2.94 which matches up nicely with the equation on page 233. But this wouldn’t be very Bayesian of us. It’d be more satisfying if we had an expression of the uncertainty in the value. For that, we’ll follow our usual practice of extracting the posterior samples, making nicely-named vectors, and summarizing a bit. post &lt;- posterior_samples(model1) %&gt;% mutate(when_x_is_0 = b_Intercept, when_x_is_1 = b_Intercept + b_frame) post %&gt;% select(when_x_is_0, when_x_is_1) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 when_x_is_0 2.80 0.088 #&gt; 2 when_x_is_1 2.94 0.091 Hayes referenced a \\(t\\)-test and accompanying \\(p\\)-value in the lower part of page 233. We, of course, aren’t going to do that. But we do have the 95% intervals in our print() output, above, which we can also look at like so. posterior_interval(model1)[&quot;b_frame&quot;, ] #&gt; 2.5% 97.5% #&gt; -0.118 0.376 And we can always plot. post %&gt;% ggplot(aes(x = b_frame)) + geom_density(size = 0, fill = dutchmasters$little_street[1]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[11]) + scale_x_continuous(breaks = c(-.3, 0, .6)) + scale_y_continuous(NULL, breaks = NULL) + theme_07 + theme(legend.position = &quot;none&quot;) We’ll use the update() function to hastily fit model2 and model3. model2 &lt;- update(model1, newdata = disaster, formula = justify ~ 1 + frame + skeptic, chains = 4, cores = 4) model3 &lt;- update(model1, newdata = disaster, formula = justify ~ 1 + frame + skeptic + frame:skeptic, chains = 4, cores = 4) Note our use of the frame:skeptic syntax in model3. With that syntax we didn’t need to make an interaction variable in the data by hand. The brms package just handled it for us. An alternative syntax would have been frame*skeptic. But if you really wanted to make the interaction variable by hand, you’d do this. disaster &lt;- disaster %&gt;% mutate(interaction_variable = frame*skeptic) Once you have interaction_variable in the data, you’d specify a model formula within the brm() function like formula = justify ~ 1 + frame + skeptic + interaction_variable. I’m not going to do that, here, but you can play around yourself if so inclined. Here are the quick and dirty coefficient summaries for our two new models. posterior_summary(model2) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; b_Intercept 2.131 0.1254 1.881 2.378 #&gt; b_frame 0.118 0.1215 -0.120 0.356 #&gt; b_skeptic 0.201 0.0291 0.144 0.258 #&gt; sigma 0.841 0.0420 0.764 0.927 #&gt; lp__ -268.422 1.4635 -272.052 -266.579 posterior_summary(model3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; b_Intercept 2.452 0.1476 2.1652 2.742 #&gt; b_frame -0.568 0.2163 -0.9841 -0.141 #&gt; b_skeptic 0.105 0.0384 0.0315 0.181 #&gt; b_frame:skeptic 0.203 0.0550 0.0960 0.309 #&gt; sigma 0.817 0.0412 0.7396 0.902 #&gt; lp__ -262.390 1.5867 -266.2424 -260.248 Just focusing on our primary model, model3, here’s another way to look at the coefficients. stanplot(model3) + theme_07 By default, brms::stanplot() makes coefficient plots which depict the parameters of a model by their posterior means (i.e., dots), 50% intervals (i.e., thick horizontal lines), and 95% intervals (i.e., thin horizontal lines). As stanplot() returns a ggplot2 object, one can customize the theme and so forth. We’ll extract the \\(R^2\\) iterations in the usual way once for each model, and then combine them for a plot. # for each of the three models, we create a separare R2 tibble R2_model1 &lt;- bayes_R2(model1, summary = F) %&gt;% as_tibble() R2_model2 &lt;- bayes_R2(model2, summary = F) %&gt;% as_tibble() R2_model3 &lt;- bayes_R2(model3, summary = F) %&gt;% as_tibble() # here we combine them into one tibble, indexed by `model` R2s &lt;- R2_model1 %&gt;% bind_rows(R2_model2) %&gt;% bind_rows(R2_model3) %&gt;% mutate(model = rep(c(&quot;model1&quot;, &quot;model2&quot;, &quot;model3&quot;), each = 4000)) # now we plot R2s %&gt;% ggplot(aes(x = R2)) + geom_density(aes(fill = model), size = 0, alpha = 2/3) + scale_fill_manual(NULL, values = dutchmasters$little_street[c(3, 4, 8)] %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(italic(R)^2, &quot; distribution&quot;))) + coord_cartesian(xlim = 0:1) + theme_07 Here’s the \\(\\Delta R^2\\) distribution for model3 minus model2. R2_model2 %&gt;% rename(model2 = R2) %&gt;% bind_cols(R2_model3) %&gt;% rename(model3 = R2) %&gt;% mutate(dif = model3 - model2) %&gt;% ggplot(aes(x = dif)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The &quot;, Delta, italic(R)^2)), subtitle = &quot;Like in the text, the posterior\\nmean is about 0.05.&quot;, x = NULL) + theme_07 In addition to the \\(R^2\\), one can use information criteria to compare the models. Here we’ll use the LOO to compare all three. loo(model1, model2, model3) #&gt; LOOIC SE #&gt; model1 572.2 24.0 #&gt; model2 529.7 22.4 #&gt; model3 518.4 21.8 #&gt; model1 - model2 42.5 16.2 #&gt; model1 - model3 53.8 19.0 #&gt; model2 - model3 11.3 8.3 The point estimate for both multivariable models were clearly lower than that for model1. The point estimate for the moderation model, model3, was within the double-digit range lower than that for model2, which typically suggests better fit. But notice how wide the standard error was. There’s a lot of uncertainty, there. Hopefully this isn’t surprising. Our \\(R^2\\) difference was small and uncertain, too. We can also compare them with AIC-type model weighting, which you can learn more about starting at this point in this lecture or this related vignette for the loo package. Here we’ll keep things simple and weight with the LOO. model_weights(model1, model2, model3, weights = &quot;loo&quot;) #&gt; model1 model2 model3 #&gt; 2.05e-12 3.43e-03 9.97e-01 The model_weights() results put almost all the relative weight on model3. This doesn’t mean model3 is the “true model” or anything like that. It just suggests that it’s the better of the three with respect to the data. Here are the results of the equations in the second half of page 237. post &lt;- posterior_samples(model3) post %&gt;% transmute(if_2 = b_frame + `b_frame:skeptic`*2, if_3.5 = b_frame + `b_frame:skeptic`*3.5, if_5 = b_frame + `b_frame:skeptic`*5) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarise(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 if_2 -0.163 0.136 #&gt; 2 if_3.5 0.141 0.115 #&gt; 3 if_5 0.445 0.146 7.2.1 Estimation using PROCESS brms. Similar to what Hayes advertised with PROCESS, with our formula = justify ~ 1 + frame + skeptic + frame:skeptic code in model3, we didn’t need to hard code an interaction variable into the data. brms handled that for us. 7.2.2 Interpreting the regression coefficients. 7.2.3 Variable scaling and the interpretation of \\(b_{1}\\) and \\(b_{3}\\). Making the mean-centered version of our \\(W\\) variable, skeptic, is a simple mutate() operation. We’ll just call it skeptic_c. disaster &lt;- disaster %&gt;% mutate(skeptic_c = skeptic - mean(skeptic)) And here’s how we might fit the model. model4 &lt;- update(model3, newdata = disaster, formula = justify ~ 1 + frame + skeptic_c + frame:skeptic_c, chains = 4, cores = 4) Here are the summaries of our fixed effects. fixef(model4) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 2.805 0.0798 2.6490 2.962 #&gt; frame 0.117 0.1168 -0.1106 0.346 #&gt; skeptic_c 0.105 0.0383 0.0310 0.181 #&gt; frame:skeptic_c 0.202 0.0553 0.0913 0.308 Here are the \\(R^2\\) distributions for model3 and model4. They’re the same within simulaiton variance. bayes_R2(model3) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.251 0.044 0.164 0.334 bayes_R2(model4) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.249 0.044 0.161 0.334 If you’re bothered by the differences resulting from sampling variation, you might increase the number of HMC iterations from the 2000-per-chain default. Doing so might look something like this: model3 &lt;- update(model3, chains = 4, cores = 4, warmup = 1000, iter = 10000) model4 &lt;- update(model4, chains = 4, cores = 4, warmup = 1000, iter = 10000) Before we fit model5, we’ll recode frame to a -.5/.5 metric and name it frame_.5. disaster &lt;- disaster %&gt;% mutate(frame_.5 = ifelse(frame == 0, -.5, .5)) Time to fit model5. model5 &lt;- update(model4, newdata = disaster, formula = justify ~ 1 + frame_.5 + skeptic_c + frame_.5:skeptic_c, chains = 4, cores = 4) Our posterior summaries match up nicely with the output in Hayes’s Table 7.4. fixef(model5) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 2.864 0.0571 2.7506 2.975 #&gt; frame_.5 0.117 0.1126 -0.0980 0.330 #&gt; skeptic_c 0.205 0.0274 0.1513 0.259 #&gt; frame_.5:skeptic_c 0.201 0.0566 0.0913 0.310 7.3 Visualizing moderation To get quick plots for the interaction effect in brms, you might use the marginal_effects() function. marginal_effects(model3) By default, margional_effects() will show three levels of the variable on the right side of the interaction term. The formula in model3 was justify ~ frame + skeptic + frame:skeptic, with frame:skeptic as the interaction term and skeptic making up the right hand side of the term. The three levels of skeptic in the plot, above, are the mean \\(\\pm\\) 1 \\(SD\\). See the brms reference manual for details on marginal_effects(). On page 244, Hayes discussed using the 16th, 50th, and 84th percentiles for the moderator variable. We can compute those with quantile(). quantile(disaster$skeptic, probs = c(.16, .5, .84)) #&gt; 16% 50% 84% #&gt; 1.6 2.8 5.2 The first two columns in Hayes’s Table 7.5 contain the values he combined with the point estimates of his model to get the \\(\\hat{Y}\\) column. The way we’ll push those values through model3’s posterior is with brms::fitted(). As a preparatory step, we’ll put the predictor values in a data object, nd. ( nd &lt;- tibble(frame = rep(0:1, times = 3), skeptic = rep(quantile(disaster$skeptic, probs = c(.16, .5, .84)), each = 2)) ) #&gt; # A tibble: 6 x 2 #&gt; frame skeptic #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 0 1.6 #&gt; 2 1 1.6 #&gt; 3 0 2.8 #&gt; 4 1 2.8 #&gt; 5 0 5.2 #&gt; 6 1 5.2 Now we’ve go our nd, we’ll get our posterior estimates for \\(Y\\) with fitted(). fitted(model3, newdata = nd) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 2.62 0.1013 2.42 2.82 #&gt; [2,] 2.38 0.1109 2.16 2.59 #&gt; [3,] 2.75 0.0810 2.58 2.90 #&gt; [4,] 2.74 0.0869 2.58 2.91 #&gt; [5,] 3.00 0.1090 2.78 3.21 #&gt; [6,] 3.48 0.1091 3.28 3.70 When using the default summary = TRUE settings in fitted(), the function returns posterior means, \\(SD\\)s and 95% intervals for \\(Y\\) based on each row in the nd data we specified in the newdata = nd argument. You don’t have to name your newdata nd or anything like that; it’s just my convention. Here’ a quick plot of what those values imply. fitted(model3, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(color = frame %&gt;% as.character())) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + theme_07 That plot is okay, but we can do better. In order to plot the model-implied effects across the full range of skeptic values presented in Figure 7.7, you need to change the range of those values in the nd data. Also, although the effect is subtle in the above example, 95% intervals often follow a bowtie shape. In order to insure the contours of that shape are smooth, it’s often helpful to specify 30 or so evenly-spaced values in the variable on the x-axis, skeptic in this case. We’ll employ the seq() function for that and specify length.out = 30. And in order to use those 30 values for both levels of frame, we’ll nest the seq() function within rep(). In addition, we add a few other flourishes to make our plot more closely resemble the one in the text. Here’s our Figure 7.7. nd &lt;- tibble(frame = rep(0:1, times = 30), skeptic = rep(seq(from = 0, to = 7, length.out = 30), each = 2)) fitted(model3, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(color = frame %&gt;% as.character())) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 2:4) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) 7.4 Probing an interaction 7.4.1 The pick-a-point approach. 7.4.1.1 The pick-a-point approach implimented by regression centering working directly with the posterior. Yes, if you wanted to use the regression centering approach, you could do that in brms. Just center the necessary variables in the way Hayes described in the text, refit the model, and summarize(). I suspect this would be particularly approachable for someone new to R and to the ins and outs of data wrangling. But I’m going leave that as an exercise for the interested reader. Now that we’ve already got a posterior for our model, we can just either algebraically manipulate the vectors yielded by posterior_samples() or push predictions through fitted(). To give a sense, we’ll start off with the 16th percentile for skeptic. Recall we can get that with the quantile() function. quantile(disaster$skeptic, probs = .16) #&gt; 16% #&gt; 1.6 Now we just need to feed that value and different values of frame into the posterior samples of the model coefficients. We then create a difference score for the model-implied estimates given frame is either 0 or 1 and then plot that difference. post %&gt;% mutate(Y_given_frame_0_skeptic_1.6 = b_Intercept + b_frame*0 + b_skeptic*1.6 + `b_frame:skeptic`*0*1.6, Y_given_frame_1_skeptic_1.6 = b_Intercept + b_frame*1 + b_skeptic*1.6 + `b_frame:skeptic`*1*1.6) %&gt;% mutate(difference = Y_given_frame_1_skeptic_1.6 - Y_given_frame_0_skeptic_1.6) %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[7], linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify\\ngiven skeptic = 1.6&quot;, x = NULL) + theme_07 Note how nicely that distribution corresponds to the output in the lower left corner of Hayes’s Figure 7.8. If we wanted the values for other values of skeptic (e.g., 2.8 and 5.2 as in the text), we’d just rinse, wash, and repeat. A nice quality of this method is it requires you to work explicitly with the model formula. But it’s also clunky if you want to do this over many values. The fitted() function offers an alternative. Recall how the default fitted() settings are to return summaries of a model’s \\(Y\\)-variable given values of the predictor variables. In the previous section we put our prefered frame and skeptic values into a data object named nd and used the newdata argument to push those values through fitted(). Buy default, this yielded the typical posterior means, \\(SD\\)s, and 95% intervals for the predictions. However, if one sets summary = F, the output will differ. First. Let’s revisit what nd looks like. ( nd &lt;- tibble(frame = rep(0:1, times = 3), skeptic = rep(quantile(disaster$skeptic, probs = c(.16, .5, .84)), each = 2)) %&gt;% # This will make our lives easier in just a bit arrange(frame) ) #&gt; # A tibble: 6 x 2 #&gt; frame skeptic #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 0 1.6 #&gt; 2 0 2.8 #&gt; 3 0 5.2 #&gt; 4 1 1.6 #&gt; 5 1 2.8 #&gt; 6 1 5.2 Here’s what happens when we use summary = F. f_model3 &lt;- fitted(model3, newdata = nd, summary = F) f_model3 %&gt;% str() #&gt; num [1:4000, 1:6] 2.55 2.69 2.75 2.68 2.55 ... f_model3 %&gt;% head() #&gt; [,1] [,2] [,3] [,4] [,5] [,6] #&gt; [1,] 2.55 2.70 3.00 2.37 2.73 3.45 #&gt; [2,] 2.69 2.77 2.94 2.48 2.79 3.43 #&gt; [3,] 2.75 2.85 3.06 2.31 2.67 3.37 #&gt; [4,] 2.68 2.77 2.94 2.37 2.74 3.48 #&gt; [5,] 2.55 2.70 2.99 2.50 2.87 3.60 #&gt; [6,] 2.58 2.63 2.73 2.38 2.71 3.37 With summary = F, fitted() returned a matrix of 4000 rows (i.e., one for each posterior iteration) and 6 vectors (i.e., one for each row in our nd data). So now instead of summary information, we have a full expression of the uncertainty in terms of 4000 draws. If you prefer working within the tidyverse and plotting with ggplot2, matrices aren’t the most useful data type. Let’s wrangle a bit. f_model3 &lt;- f_model3 %&gt;% as_tibble() %&gt;% gather() %&gt;% select(-key) %&gt;% # We multiply 4000 (i.e., the # of iterations) by 3 because there are 3 distinct `skeptic` values mutate(frame = rep(0:1, each = 4000*3), # Note how we have `rep()` nested within `rep()`. skeptic = rep(rep(quantile(disaster$skeptic, probs = c(.16, .5, .84)), each = 4000), # We repeate the first `rep()` output 2 times because ther are 2 values of `frame` we&#39;d like them for times = 2), # We need an iteration index, `iter`, in order to help with `spread()`, below. iter = rep(1:4000, times = 6)) %&gt;% spread(key = frame, value = value) %&gt;% mutate(difference = `1` - `0`, # This isnt&#39; necessary, but will help with the facet labels skeptic = str_c(&quot;skeptic = &quot;, skeptic)) f_model3 %&gt;% head() #&gt; # A tibble: 6 x 5 #&gt; skeptic iter `0` `1` difference #&gt; &lt;chr&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 skeptic = 1.6 1 2.55 2.37 -0.182 #&gt; 2 skeptic = 1.6 2 2.69 2.48 -0.209 #&gt; 3 skeptic = 1.6 3 2.75 2.31 -0.436 #&gt; 4 skeptic = 1.6 4 2.68 2.37 -0.309 #&gt; 5 skeptic = 1.6 5 2.55 2.50 -0.0520 #&gt; 6 skeptic = 1.6 6 2.58 2.38 -0.197 And here’s a plot of what we’ve done. f_model3 %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + geom_vline(xintercept = 0, color = dutchmasters$little_street[7], linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify given three different values of skeptic&quot;, x = NULL) + theme_07 + facet_wrap(~skeptic) And if you prefered summary information instead of plots, you’d use summarize() as usual. f_model3 %&gt;% group_by(skeptic) %&gt;% summarize(median = median(difference), ll = quantile(difference, probs = .025), ul = quantile(difference, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; skeptic median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 skeptic = 1.6 -0.246 -0.528 0.047 #&gt; 2 skeptic = 2.8 0.001 -0.231 0.232 #&gt; 3 skeptic = 5.2 0.487 0.185 0.781 7.4.2 The Johnson-Neyman technique. The JN technique generalizes this approach over many values of \\(W\\) (i.e., skeptic in this example) in order to get a sense of the trend and summarize regions of the trend in terms of \\(p\\)-value thresholds. Since we’re emphasizing modeling and deemphasizing null-hypothesis testing in this project, I’ll show a Bayesian version of the approach without the \\(p\\)-values. 7.4.2.1 Implementation in PROCESS brms. Since Figure 7.9 had skeptic values ranging from 1 to 6 with ticks on the 0.5s, we’ll use a similar approach for our version. We’ll estimate posterior samples with fitted() for skeptic values ranging from .5 to 6.5, one for each 0.5—13 in total. But since we have two levels of frame (i.e., 0 and 1), that really gives us 26. And we don’t just want 26 summaries; we want full posterior distributions for each of those 26. We’ve got a lot of moving parts in the code, below. To help make sure everything adds up, we’ll save several important values as R objects. iter &lt;- 4000 # this number comes from the total number of post-warmup posterior iterations from the `brm()` function n_frame_values &lt;- 2 # there are 2 levels of `frame`, 0 and 1 n_skeptic_values &lt;- 13 # we&#39;re choosing 13 in this example to follow some of the sensibilities in Figure 7.9. You&#39;ll see. # as before, we&#39;ll make `nd` to feed in to `fitted()` nd &lt;- tibble(frame = rep(0:1, each = n_skeptic_values), skeptic = rep(seq(from = .5, to = 6.5, length.out = n_skeptic_values), times = n_frame_values)) # after the initial `fitted()` action, we need a few steps to wrangle the data into a useful format f_model3 &lt;- fitted(model3, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(frame = rep(0:1, each = iter*n_skeptic_values), skeptic = rep(rep(seq(from = .5, to = 6.5, length.out = n_skeptic_values), each = iter), times = n_frame_values)) %&gt;% select(-key) %&gt;% rename(estimate = value) %&gt;% mutate(iter = rep(1:iter, times = n_frame_values*n_skeptic_values)) %&gt;% spread(key = frame, value = estimate) %&gt;% mutate(difference = `1` - `0`) # finally, here&#39;s the plot f_model3 %&gt;% ggplot(aes(x = skeptic %&gt;% as.character, y = difference)) + geom_hline(yintercept = 0, color = dutchmasters$little_street[7]) + geom_violin(size = 0, fill = dutchmasters$little_street[6]) + stat_summary(fun.y = median, fun.ymin = function(x){quantile(x, probs = .025)}, fun.ymax = function(x){quantile(x, probs = .975)}, color = dutchmasters$little_street[5]) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 [Note. I got the atop() trick for the label for the y-axis from Drew Steen’s answer to this stackoverflow question.] This isn’t quite our version of Figure 7.9, but I’m hoping it’ll add some pedagogical value for what we’re doing. Since we used summary = F in fitted(), we got full posterior distributions for each of our 26 conditions. Because Figure 7.9 is all about differences between each frame pair across the various values of skeptic, we needed to make a difference score for each pair; this is what we did with the last mutate() line before the plot code. This initial version of the plot shows the full posterior distribution for each difference score. The posteriors are depicted with violin plots, which are density plots set on their side and symmetrically reflected as if by a mirror to give a pleasing leaf- or violin-like shape (though beware). The light dots and vertical lines are the posterior medians and 95% intervals for each. Going from left to right, it appears we have a clearly emerging trend. We can more simply express the trend by summarizing each posterior with medians and 95% intervals. f_model3 %&gt;% group_by(skeptic) %&gt;% summarize(median = median(difference), ll = quantile(difference, probs = .025), ul = quantile(difference, probs = .975)) %&gt;% ggplot(aes(x = skeptic)) + geom_hline(yintercept = 0, color = dutchmasters$little_street[7]) + geom_vline(xintercept = c(1.171, 3.934), color = dutchmasters$little_street[7]) + geom_ribbon(aes(ymin = ll, ymax = ul), fill = dutchmasters$little_street[5], alpha = 1/2) + geom_line(aes(y = median), color = dutchmasters$little_street[5], size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(-1, 1.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 Notice how the contour boundaries of the 95% intervals are a little clunky. That’s because our bowtie-shape is based on only 13 x-axis values. If you wanted a smoother shape, you’d specify more skeptic values in the data object you feed into fitted()’s newdata argument. For linear effects, 30 or so usually does it. Anyway, I got the values for the two vertical lines directly out of the text. It’s not clear to me how one might elegantly determine those values within the paradigm we’ve been using. But that leads to an important digression. The two vertical lines are quite \\(p\\)-value centric. They are an attempt to separate the x-axis into areas where the difference trend either is or is not statistically-significantly different from zero. That is, we’re dichotomizing—or “trichotomizing”, depending on how you look at it—a continuous phenomenon. This is somewhat at odds with the sensibilities of the Bayesians associated with Stan and brms (e.g., here). On page 259, Hayes wrote: Although the JN technique eliminates the need to select arbitrary values of \\(W\\) when probing an interaction, it does not eliminate your need to keep your brain turned into the task and thinking critically about the answer the method gives you. I think this is valuable advice, particularly when working within the Bayesian paradigm. Our version of Figure 7.9 gives some interesting insights into the moderation model, model3. I’m just not so sure I’d want to encourage people to interpret a continuous phenomenon by heuristically dividing it into discrete regions. 7.5 The difference between testing for moderation and probing it This is another section where the NHST-type paradigm contrasts with many within the contemporary Bayesian paradigm. E.g., Hayes opened the section with: “We test for evidence of moderation when we want to know whether the relationship between \\(X\\) and \\(Y\\) varies systematically as a function of a proposed moderator \\(W\\)”. His use of “whether” suggests we are talking about a binary answer–either there is an effect or there isn’t. But, as Gelman argued, the default presumption in social science [and warning, I’m a psychologist and thus biased towards thinking in terms of social science] is that treatment effects–and more generally, causal effects–vary across contexts. As such, asking “whether” there’s a difference or an interaction effect isn’t really the right question. Rather, we should presume variation at the outset and ask instead what the magnitude of that variation is and how much accounting for it matters for our given purposes. If the variation–read interaction effect–is tiny and of little theoretical interest, perhaps we might just ignore it and not include it in the model. Alternatively, if the variation is large or of theoretical interest, we might should include it in the model regardless of statistical significance. Another way into this topic is posterior predictive checking. We’ve already done a bit of this in previous chapters. The basic idea, recall, is that better models should give us a better sense of the patterns in the data. In the plot below, we continue to show the interaction effect with two regression lines, but this time we separate them into their own panels by frame. In addition, we add the original data which we also separate and color code by frame. nd &lt;- tibble(frame = rep(0:1, times = 30), skeptic = rep(seq(from = 0, to = 10, length.out = 30), each = 2)) fitted(model3, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(color = frame %&gt;% as.character())) + geom_point(data = disaster, aes(x = skeptic, y = justify, color = frame %&gt;% as.character()), alpha = 3/4) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:9) + coord_cartesian(xlim = 1:9) + labs(title = &quot;model3, the interaction model&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) + facet_wrap(~frame) When we separate out the data this way, it really does appear that when frame == 1, the justify values do increase as the skeptic values increase, but not so much when frame == 0. We can use the same plotting approach, but this time with the results from the non-interaction multivariable model, model2. fitted(model2, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame %&gt;% as.character()), alpha = 1/3) + geom_line(aes(color = frame %&gt;% as.character())) + geom_point(data = disaster, aes(x = skeptic, y = justify, color = frame %&gt;% as.character()), alpha = 3/4) + scale_fill_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_color_manual(&quot;frame&quot;, values = dutchmasters$little_street[c(10, 5)] %&gt;% as.character()) + scale_x_continuous(breaks = 1:9) + coord_cartesian(xlim = 1:9) + labs(title = &quot;model2, the multivariable model&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Strength of Justification\\nfor Withholding Aid&quot;) + theme_07 + theme(legend.position = &quot;top&quot;) + facet_wrap(~frame) This time when we allow the intercept but not the slope to vary by frame, it appears the regression lines are missing part of the story. They look okay, but it appears that the red line on the left is sloping up to quickly and that the cream line on the right isn’t sloping steeply enough. We have missed an insight. Now imagine scenarios in which the differences by frame are more or less pronounced. Imagine those scenarios fall along a continuum. It’s not so much that you can say with certainty where on such a continuous an interaction effect would exist or not, but rather, such a continuum suggests it would appear more or less important, of greater or smaller magnitude. It’s not that the effect exists or is non-zero. It’s that it’s orderly enough and of a large enough magnitude, and perhaps of theoretical interest, that it appears to matter in terms of explaining the data. And none of this is to serve as a harsh criticism of Andrew Hayes. His text is a fine effort to teach mediation and moderation from a frequentist OLS perspective. I’ve benefited tremendously from his work. Yet I’d also like to connect his work to some other sensibilities. Building further, consider this sentence from the text (pp. 259–260): Rather, probing moderation involves ascertaining whether the conditional effect of \\(X\\) on \\(Y\\) is different from zero at certain specified values of \\(W\\) (if using the pick-a-point approach) or exploring where in the distribution of \\(W\\) the conditional effect of \\(X\\) on \\(Y\\) transitions between statistically significant and non-significant (if using the Johnson-Neyman technique). From an NHST/frequentist perspective, this makes clear sense. But we’re dealing with an entire posterior distribution. Consider again a figure from above. nd &lt;- tibble(frame = rep(0:1, times = 3), skeptic = rep(quantile(disaster$skeptic, probs = c(.16, .5, .84)), each = 2)) %&gt;% arrange(frame) fitted(model3, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% select(-key) %&gt;% mutate(frame = rep(0:1, each = 4000*3), skeptic = rep(rep(quantile(disaster$skeptic, probs = c(.16, .5, .84)), each = 4000), times = 2), iter = rep(1:4000, times = 6)) %&gt;% spread(key = frame, value = value) %&gt;% mutate(difference = `1` - `0`, skeptic = str_c(&quot;skeptic = &quot;, skeptic)) %&gt;% ggplot(aes(x = difference)) + geom_density(color = &quot;transparent&quot;, fill = dutchmasters$little_street[9]) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The effect of frame on justify given three different values of skeptic&quot;, x = NULL) + theme_07 + facet_wrap(~skeptic) With the pick pick-a-point approach one could fixate on whether zero was a credible value within the posterior, given a particular skeptic value. And yet zero is just one point in the parameter space. One might also focus on the whole shapes of the posteriors of these three skeptic values. You could focus on where the most credible values (i.e., those at and around their peaks) are on the number line (i.e., the effect sizes) and you could also focus on the relative widths of the distributions (i.e., the precision with which the effect sizes are estimated). These sensibilities can apply to the JN technique, as well. Sure, we might be interested in how credible zero is. But there’s a lot more to notice, too. Now consider a modified version of our JN technique plot, from above. f_model3 %&gt;% group_by(skeptic) %&gt;% # There are more elegant ways to do this. Hopefully this gives some pedagogical insights summarize(median = median(difference), ll_10 = quantile(difference, probs = .45), ul_10 = quantile(difference, probs = .55), ll_20 = quantile(difference, probs = .40), ul_20 = quantile(difference, probs = .60), ll_30 = quantile(difference, probs = .35), ul_30 = quantile(difference, probs = .65), ll_40 = quantile(difference, probs = .30), ul_40 = quantile(difference, probs = .70), ll_50 = quantile(difference, probs = .25), ul_50 = quantile(difference, probs = .75), ll_60 = quantile(difference, probs = .20), ul_60 = quantile(difference, probs = .80), ll_70 = quantile(difference, probs = .15), ul_70 = quantile(difference, probs = .85), ll_80 = quantile(difference, probs = .10), ul_80 = quantile(difference, probs = .90), ll_90 = quantile(difference, probs = .05), ul_90 = quantile(difference, probs = .95), ll_99 = quantile(difference, probs = .005), ul_99 = quantile(difference, probs = .995)) %&gt;% ggplot(aes(x = skeptic)) + geom_ribbon(aes(ymin = ll_10, ymax = ul_10), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_20, ymax = ul_20), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_30, ymax = ul_30), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_40, ymax = ul_40), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_50, ymax = ul_50), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_60, ymax = ul_60), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_70, ymax = ul_70), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_80, ymax = ul_80), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_90, ymax = ul_90), fill = dutchmasters$little_street[5], alpha = 1/4) + geom_ribbon(aes(ymin = ll_99, ymax = ul_99), fill = dutchmasters$little_street[5], alpha = 1/4) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = c(1, 6), ylim = c(-1, 1.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = expression(atop(theta[paste(italic(X), &quot; on &quot;, italic(Y))], paste(&quot;Conditional Effect of Disaster Frame&quot;)))) + theme_07 This time we emphasized the shape of the posterior with stacked semitransparent 10, 20, 30, 40, 50, 60, 70, 80, 90, and 99% intervals. We also deemphasized the central tendency–our analogue to the OLS point estimate–by removing the median line. Yes, one could focus on where the 95% intervals cross zero. And yes one could request we emphasize central tendency. But such focuses miss a lot of information about the shape–the entire smooth, seamless distribution of credible values. I suppose you could consider this our version of Figure 7.10. 7.6 Artificial categorization and subgroups There are multiple ways to dichotomize the data by skeptic. A quick simple way is to use ifelse() to make a skeptic_hi dummy. disaster &lt;- disaster %&gt;% mutate(skeptic_hi = ifelse(skeptic &gt;= mean(skeptic), 1, 0)) With our dummy in hand, we’re ready to fit the two models. model6_low &lt;- brm(data = disaster %&gt;% filter(skeptic_hi == 0), family = gaussian, justify ~ 1 + frame, chains = 4, cores = 4) model6_high &lt;- update(model6_low, newdata = disaster %&gt;% filter(skeptic_hi == 1), chains = 4, cores = 4) The coefficient summaries: fixef(model6_low) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 2.621 0.097 2.424 2.819 #&gt; frame -0.103 0.143 -0.385 0.185 fixef(model6_high) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 3.070 0.142 2.791 3.345 #&gt; frame 0.482 0.204 0.093 0.887 You can use fitted() to get the posterior means and other summaries for the two frame groups, by model. fitted(model6_low, newdata = tibble(frame = 0:1)) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 2.62 0.097 2.42 2.82 #&gt; [2,] 2.52 0.104 2.32 2.73 fitted(model6_high, newdata = tibble(frame = 0:1)) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 3.07 0.142 2.79 3.35 #&gt; [2,] 3.55 0.143 3.27 3.83 Do note that though brms ‘Est.Error’ is the posterior \\(SD\\) for the coefficient, it is not the same thing as descriptive statistic \\(SD\\) of a subset of the data. Thus, although our ‘Estimates’ correspond nicely to the mean values Hayes reported in the middle of page 264, his \\(SD\\)s will not match up with our ‘Est.Error’ values, and nor should they. Anyway, our results don’t yield \\(t\\)-tests. But you don’t need those anyway. We’re working within the regression paradigm! But if you’re really interested in the sub-model-implied differences between the two levels of frame by skeptic_hi subgroup, all you need is the frame coefficient of model6_low and model6_high. Here we’ll use bind_rows() to combine their posterior samples and then plot. posterior_samples(model6_low) %&gt;% select(b_frame) %&gt;% bind_rows( posterior_samples(model6_high) %&gt;% select(b_frame) ) %&gt;% mutate(model = rep(c(&quot;model6_low&quot;, &quot;model6_high&quot;), each = 4000)) %&gt;% ggplot(aes(x = b_frame, fill = model)) + geom_density(size = 0, alpha = .8) + scale_fill_manual(NULL, values = dutchmasters$little_street[c(1, 9)] %&gt;% as.character()) + scale_y_continuous(NULL, breaks = NULL) + labs(subtitle = &quot;The difference score distributions between frame levels,\\ncolor coded by mean-split skeptic&quot;, x = NULL) + theme_07 As within the frequentist paradigm, please don’t mean split as a Bayesian. When possible, use all available data and use the regression formula to model theoretically-meaningful variables in your analyses. References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] ochRe_1.0.0 dutchmasters_0.1.0 brms_2.3.4 Rcpp_0.12.17 #&gt; [5] ggthemr_1.1.0 directlabels_2018.05.22 bindrcpp_0.2.2 forcats_0.3.0 #&gt; [9] stringr_1.3.1 dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 #&gt; [13] tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 threejs_0.3.1 #&gt; [6] httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 tools_3.5.1 backports_1.1.2 #&gt; [11] utf8_1.1.4 DT_0.4 R6_2.2.2 lazyeval_0.2.1 colorspace_1.3-2 #&gt; [16] withr_2.1.2 tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 xml2_1.2.0 #&gt; [26] labeling_0.3 colourpicker_1.0 bookdown_0.7 scales_0.5.0 dygraphs_1.1.1.5 #&gt; [31] mvtnorm_1.0-8 psych_1.8.4 quadprog_1.5-5 ggridges_0.5.0 digest_0.6.15 #&gt; [36] StanHeaders_2.17.2 foreign_0.8-70 rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 #&gt; [41] htmltools_0.3.6 htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 #&gt; [46] shiny_1.1.0 bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 gtools_3.8.1 #&gt; [51] crosstalk_1.0.0 inline_0.3.15 magrittr_1.5 loo_2.0.0 bayesplot_1.5.0 #&gt; [56] Matrix_1.2-14 munsell_0.5.0 abind_1.4-5 stringi_1.2.3 yaml_2.1.19 #&gt; [61] plyr_1.8.4 grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 #&gt; [66] miniUI_0.1.1.1 lattice_0.20-35 haven_1.1.2 hms_0.4.2 knitr_1.20 #&gt; [71] pillar_1.2.3 igraph_1.2.1 markdown_0.8 shinystan_2.5.0 codetools_0.2-15 #&gt; [76] reshape2_1.4.3 stats4_3.5.1 rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 #&gt; [81] modelr_0.1.2 httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 #&gt; [86] xfun_0.3 mime_0.5 xtable_1.8-2 broom_0.4.5 coda_0.19-1 #&gt; [91] later_0.7.3 rsconnect_0.8.8 shinythemes_1.1.1 bridgesampling_0.4-0 "],
["extending-the-fundamental-principles-of-moderation-analysis.html", "8 Extending the Fundamental Principles of Moderation Analysis 8.1 Moderation with a dichotomous moderator 8.2 Interaction between two quantitative variables 8.3 Hierarchical versus simultaneous entry 8.4 The equivalence between moderated regression analysis and a 2 X 2 factorial analysis of variance References Session info", " 8 Extending the Fundamental Principles of Moderation Analysis 8.1 Moderation with a dichotomous moderator Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) library(brms) disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) #&gt; Observations: 211 #&gt; Variables: 5 #&gt; $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, ... #&gt; $ frame &lt;int&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0... #&gt; $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8, 6.2, 6.0, 4.2, 4.4, 5.8,... #&gt; $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, 3.55, 1.55, 1.60, 1.65, 2... #&gt; $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0, 5.4, 2.2, 3.6, 7.8, 1.6,... Our first moderation model is: model1 &lt;- brm(data = disaster, family = gaussian, justify ~ 1 + skeptic + frame + frame:skeptic, chains = 4, cores = 4) print(model1) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: justify ~ 1 + skeptic + frame + frame:skeptic #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 2.45 0.15 2.16 2.73 2501 1.00 #&gt; skeptic 0.11 0.04 0.03 0.18 2422 1.00 #&gt; frame -0.57 0.22 -0.98 -0.14 2186 1.00 #&gt; skeptic:frame 0.20 0.05 0.10 0.31 2200 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.82 0.04 0.74 0.90 2936 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). We’ll compute our Bayeisan \\(R^2\\) in the typical way. bayes_R2(model1) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.251 0.043 0.166 0.333 8.1.1 Visualizing and probing the interaction. For the plots in this chapter, we’ll take our color palette from the ochRe package, which provides Australia-inspired colors. We’ll also use a few theme settings from good-old ggthemes. As in the last chapter, we’ll save our adjusted theme settings as an object, theme_08. library(ggthemes) library(ochRe) theme_08 &lt;- theme_minimal() + theme(panel.grid.minor = element_blank(), plot.background = element_rect(fill = ochre_palettes[[&quot;olsen_seq&quot;]][8], color = &quot;transparent&quot;)) Happily, the ochRe package has a handy convenience function, viz_palette(), that makes it easy to preview the colors available in a given palette. We’ll be using “olsen_qual” and “olsen_seq”. viz_palette(ochre_palettes[[&quot;olsen_qual&quot;]]) viz_palette(ochre_palettes[[&quot;olsen_seq&quot;]]) Here’s our Figure 8.3. # these will come in handy with `geom_text()`, below green_slope &lt;- (fixef(model1)[&quot;skeptic&quot;, 1] + fixef(model1)[4, 1]) %&gt;% round(digits = 3) blue_slope &lt;- fixef(model1)[&quot;skeptic&quot;, 1] %&gt;% round(digits = 3) ( nd &lt;- tibble(frame = rep(0:1, times = 2), skeptic = rep(c(0, 7), each = 2)) ) #&gt; # A tibble: 4 x 2 #&gt; frame skeptic #&gt; &lt;int&gt; &lt;dbl&gt; #&gt; 1 0 0 #&gt; 2 1 0 #&gt; 3 0 7 #&gt; 4 1 7 fitted(model1, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(iter = rep(1:4000, times = 4), frame = rep(rep(0:1, each = 4000), times = 2), skeptic = rep(c(0, 7), each = 4000*2)) %&gt;% ggplot(aes(x = skeptic, y = value, group = interaction(frame, iter), color = frame %&gt;% as.character())) + geom_line(aes(color = frame %&gt;% as.character()), size = 1/6, alpha = 1/25) + geom_text(data = tibble(skeptic = c(4, 4.6), value = c(3.5, 2.6), frame = 1:0, iter = 0, label = c(paste(&quot;the slope when frame = 1 is about&quot;, green_slope), paste(&quot;the slope when frame = 0 is about&quot;, blue_slope)), angle = c(28, 6)), aes(label = label, angle = angle)) + scale_color_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][(5:6)]) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 2:4) + labs(title = &quot;The moderation effect in a spaghetti plot&quot;, subtitle = &quot;Using brms defaults, we have 4000 posterior draws. Much like we have\\n4000 draws for each model parameter, when we combine those draws\\nacross parameters, we end up with 4000 model equations. The\\nconsequence is we can also express the line plot as 4000\\nsemitransparent lines, one for each level of our moderator, frame.&quot;, x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = &quot;Strength of Justification for Withholding Aid&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) In addition to our fancy Australia-inspired colors, we’ll also play around a bit with spaghetti plots in this chapter. To my knowledge, this use of spaghetti plots is uniquely Bayesian. If you’re trying to wrap your head around what on earth we just did, take a look at the first few rows from posterior_samples() object, post. post &lt;- posterior_samples(model1) head(post) #&gt; b_Intercept b_skeptic b_frame b_skeptic:frame sigma lp__ #&gt; 1 2.24 0.170 -0.511 0.213 0.832 -264 #&gt; 2 2.42 0.143 -0.621 0.153 0.844 -263 #&gt; 3 2.31 0.148 -0.565 0.168 0.849 -262 #&gt; 4 2.44 0.109 -0.537 0.184 0.827 -260 #&gt; 5 2.33 0.133 -0.263 0.127 0.778 -261 #&gt; 6 2.30 0.142 -0.458 0.186 0.783 -261 We’ve got six rows, each one corresponding to the credible parameter values from a given posterior draw. The lp__ is uniquely Bayesian and beyond the scope of this project. You might think of sigma as the Bayesian analogue to what the OLS folks often refer to as error or the residual variance. Hayes doesn’t tend to emphasize it in this text, but it’s something you’ll want to pay increasing attention to as you move along in your Bayesian career. All the columns starting with b_ are the regression parameters, the model coefficients or the fixed effects. But anyways, notice that those b_ columns correspond to the four parameter values in formula 8.2 on page 270. Here they are, but reformatted to more closely mimic the text: \\(\\hat{Y}\\) = 2.242 + 0.17\\(X\\) + -0.511\\(W\\) + 0.213XW \\(\\hat{Y}\\) = 2.417 + 0.143\\(X\\) + -0.621\\(W\\) + 0.153XW \\(\\hat{Y}\\) = 2.307 + 0.148\\(X\\) + -0.565\\(W\\) + 0.168XW \\(\\hat{Y}\\) = 2.444 + 0.109\\(X\\) + -0.537\\(W\\) + 0.184XW \\(\\hat{Y}\\) = 2.334 + 0.133\\(X\\) + -0.263\\(W\\) + 0.127XW \\(\\hat{Y}\\) = 2.298 + 0.142\\(X\\) + -0.458\\(W\\) + 0.186XW Each row of post, each iteration or posterior draw, yields a full model equation that is a credible description of the data—or at least as credible as we can get within the limits of the model we have specified, our priors (which we typically cop out on and just use defaults in this project), and how well those fit when applied to the data at hand. So when we use brms convenience functions like fitted(), we pass specific predictor values through those 4000 unique model equations, which produces 4000 similar but distinct expected \\(Y\\)-values. So although a nice way to summarize those 4000 values is with summaries such as the posterior mean/median and 95% intervals, another way is to just plot an individual regression line for each of the iterations. That is what’s going on when we depict out models with a spaghetti plot. The thing I like about spaghetti plots is that they give a three-dimensional sense of the posterior. Note that each individual line is very skinny and semitransparent. When you pile a whole bunch of them atop each other, the peaked or most credible regions of the posterior are the most saturated in color. Less credible posterior regions almost seamlessly merge into the background. Also, note how the combination of many similar but distinct straight lines results in a bowtie shape. Hopefully this clarifies where that shape’s been coming from when we use geom_ribbon() to plot the 95% intervals. But anyways, you could recode frame in a number of ways, including ifelse() or, in this case, by simple arithmetic. disaster &lt;- disaster %&gt;% mutate(frame_ep = 1 - frame) With frame_ep in hand, we’re ready to refit the model. model2 &lt;- update(model1, newdata = disaster, formula = justify ~ 1 + skeptic + frame_ep + frame_ep:skeptic, chains = 4, cores = 4) print(model2) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: justify ~ skeptic + frame_ep + skeptic:frame_ep #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 1.89 0.16 1.58 2.20 2392 1.00 #&gt; skeptic 0.31 0.04 0.23 0.39 2272 1.00 #&gt; frame_ep 0.56 0.22 0.12 1.00 1988 1.00 #&gt; skeptic:frame_ep -0.20 0.06 -0.31 -0.09 1854 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.82 0.04 0.74 0.90 3032 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Our results match nicely with the formula on page 275. If you want to follow along with Hayes on pate 276 and isolate the 95% credible intervals for the skeptic parameter, you can use posterior_interval(). posterior_interval(model2)[&quot;b_skeptic&quot;, ] %&gt;% round(digits = 3) #&gt; 2.5% 97.5% #&gt; 0.227 0.387 8.2 Interaction between two quantitative variables Here’s the glbwarm data. glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) #&gt; Observations: 815 #&gt; Variables: 7 #&gt; $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2... #&gt; $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, ... #&gt; $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, ... #&gt; $ ideology &lt;int&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, ... #&gt; $ age &lt;int&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48... #&gt; $ sex &lt;int&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, ... #&gt; $ partyid &lt;int&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, ... Although Hayes made a distinction between the \\(X\\), \\(M\\), and \\(C\\) variables in the text, that distinction is conceptual and doesn’t impact the way we enter them into brm(). Rather, the brm() formula clarifies they’re all just predictors. model3 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + age + negemot:age + posemot + ideology + sex, chains = 4, cores = 4) Our results cohere nicely with the Hayes’s formula in the middle of page 278 or in Table 8.2. print(model3, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ 1 + negemot + age + negemot:age + posemot + ideology + sex #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 5.182 0.333 4.526 5.824 2468 1.000 #&gt; negemot 0.117 0.080 -0.038 0.268 2251 1.001 #&gt; age -0.024 0.006 -0.035 -0.013 2214 1.000 #&gt; posemot -0.021 0.028 -0.076 0.035 3935 0.999 #&gt; ideology -0.212 0.027 -0.265 -0.157 3656 1.000 #&gt; sex -0.011 0.075 -0.156 0.137 4000 0.999 #&gt; negemot:age 0.006 0.002 0.003 0.009 2212 1.001 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.058 0.026 1.007 1.113 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Here’s the \\(R^2\\). bayes_R2(model3) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.401 0.021 0.359 0.439 As the \\(R^2\\) is a good bit away from the boundaries, it’s nicely Gaussian. bayes_R2(model3, summary = F) %&gt;% as_tibble() %&gt;% ggplot(aes(x = R2)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_qual&quot;]][(1)]) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = 0:1) + labs(title = expression(paste(&quot;Loot at how Gaussian our &quot;, italic(R)^2, &quot; is!&quot;)), subtitle = expression(paste(&quot;No need to put a &quot;, italic(p), &quot;-value on that sucker.&quot;)), x = NULL) + theme_08 8.2.1 Visualizing and probing the interaction. For our version of Figure 8.5, we’ll need to adjust our nd data for fitted(). ( nd &lt;- tibble(negemot = rep(c(1, 6), each = 3), age = rep(c(30, 50, 70), times = 2), posemot = mean(glbwarm$posemot), ideology = mean(glbwarm$ideology), sex = mean(glbwarm$sex)) ) #&gt; # A tibble: 6 x 5 #&gt; negemot age posemot ideology sex #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 1 30 3.13 4.08 0.488 #&gt; 2 1 50 3.13 4.08 0.488 #&gt; 3 1 70 3.13 4.08 0.488 #&gt; 4 6 30 3.13 4.08 0.488 #&gt; 5 6 50 3.13 4.08 0.488 #&gt; 6 6 70 3.13 4.08 0.488 Our fitted() and ggplot2 code will be quite similar to the last spaghetti plot. Only this time we’ll use filter() to reduce the number of posterior draws we show in the plot. # these will come in handy with `geom_text()`, below slope_30 &lt;- (fixef(model3)[&quot;negemot&quot;, 1] + fixef(model3)[&quot;negemot:age&quot;, 1]*30) %&gt;% round(digits = 3) slope_50 &lt;- (fixef(model3)[&quot;negemot&quot;, 1] + fixef(model3)[&quot;negemot:age&quot;, 1]*50) %&gt;% round(digits = 3) slope_70 &lt;- (fixef(model3)[&quot;negemot&quot;, 1] + fixef(model3)[&quot;negemot:age&quot;, 1]*70) %&gt;% round(digits = 3) fitted(model3, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(iter = rep(1:4000, times = 6), negemot = rep(rep(c(1, 6), each = 3), each = 4000), age = rep(rep(c(30, 50, 70), times = 2), each = 4000)) %&gt;% # here we&#39;ll reduce our spaghetti plot lines to 100 per age category filter(iter &lt;= 100) %&gt;% ggplot(aes(x = negemot, y = value, group = interaction(age, iter), color = age %&gt;% as.character())) + geom_line(aes(color = age %&gt;% as.character()), size = 3/4, alpha = 1/8) + geom_text(data = tibble(negemot = 6.1, value = c(5.4, 5.7, 6), age = c(30, 50, 70), iter = 0, label = c(paste(&quot;the slope for 30 year olds is about&quot;, slope_30), paste(&quot;the slope for 50 year olds is about&quot;, slope_50), paste(&quot;the slope for 70 year olds is about&quot;, slope_70))), aes(label = label), hjust = 0) + scale_color_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][c(4, 1, 3)]) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:9, ylim = c(2.9, 6.1)) + labs(title = &quot;The moderation effect of age on negemot&quot;, x = expression(paste(&quot;Negative Emotions about Climate Change (&quot;, italic(&quot;X&quot;), &quot;)&quot;)), y = &quot;Support for Government Action&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) When we reduce the number of lines depicted in the plot, we lose some of the three-dimensional illusion. It’s nice, however, to get a closer look to each individual line. To each their own. We’ll continue with our spaghetti plot approach for Figure 8.7. Again, when we did the JN technique plot for Chapter 7, we computed values for the posterior mean and the 95% intervals. Because the intervals follow a bowtie shape, we had to compute the \\(Y\\)-values for many values across the x-axis in order to make the curve look smooth. But as long as we stick with the spaghetti plot approach, all we need are the values at the endpoints of each iteration. Although each line is straight, the combination of many lines is what produces the bowtie effect. # here is our primary data object post &lt;- posterior_samples(model3) %&gt;% transmute(at_15 = b_negemot + `b_negemot:age`*15, at_90 = b_negemot + `b_negemot:age`*90, iter = 1:n()) %&gt;% gather(key, value, -iter) %&gt;% rename(age = key) %&gt;% mutate(age = str_remove(age, &quot;at_&quot;) %&gt;% as.double()) # Here we compute the points for the posterior mean post_means &lt;- post %&gt;% group_by(age) %&gt;% summarize(value = mean(value)) %&gt;% mutate(iter = 0) # the plot post %&gt;% filter(iter &lt; 501) %&gt;% ggplot(aes(x = age, y = value, group = iter)) + geom_line(color = ochre_palettes[[&quot;olsen_qual&quot;]][1], alpha = 1/12) + geom_line(data = post_means, color = ochre_palettes[[&quot;olsen_qual&quot;]][3], size = 1.1) + scale_y_continuous(breaks = seq(from = -.25, to = 1, by = .25)) + coord_cartesian(xlim = c(20, 85), ylim = c(-.25, 1)) + labs(subtitle = &quot;Each orange line is the consequence of one of 1000 posterior draws. All are\\ncredible regression lines for the data, but because they are semitransparent,\\nthe most credible regions are the ones with the darkest color. The line\\ncorresponding to the posterior mean is in red-orange.&quot;, x = expression(paste(&quot;Age (&quot;, italic(&quot;W&quot;), &quot;)&quot;)), y = &quot;Conditional Effects of Negative Emotions on\\nSupport for Government Action&quot;) + theme_08 8.3 Hierarchical versus simultaneous entry Here’s our multivariable but non-moderation model, model4. model4 &lt;- update(model1, formula = justify ~ 1 + skeptic + frame, chains = 4, cores = 4) Here we’ll compute the corresponding \\(R^2\\) and compare it with the one for the original interaction model with a difference score. # the moderation model&#39;s R2 R2s &lt;- bayes_R2(model1, summary = F) %&gt;% as_tibble() %&gt;% rename(moderation_model = R2) %&gt;% # here we add the multivaraible model&#39;s R2 bind_cols( bayes_R2(model4, summary = F) %&gt;% as_tibble() %&gt;% rename(multivariable_model = R2) ) %&gt;% # we&#39;ll need a difference score mutate(difference = moderation_model - multivariable_model) %&gt;% # putting the data in the long format and grouping will make summarizing easier gather(R2, value) R2s %&gt;% group_by(R2) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; R2 median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 difference 0.053 -0.066 0.164 #&gt; 2 moderation_model 0.252 0.166 0.333 #&gt; 3 multivariable_model 0.202 0.117 0.282 Note that the Bayesian \\(R^2\\) performed differently than the \\(F\\)-test in the text. R2s %&gt;% filter(R2 == &quot;difference&quot;) %&gt;% ggplot(aes(x = value)) + geom_density(aes(fill = model), size = 0, fill = ochre_palettes[[&quot;olsen_seq&quot;]][14]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = expression(paste(&quot;The Bayesian &quot;, Delta, italic(R)^2, &quot; distribution&quot;)), subtitle = &quot;Although most of the posterior mass is positive--suggesting the moderation model accounted for more variance than\\nthe simple multivariable model--, a substantial portion of the postrior is within the negative parameter space. Sure,\\nif we had to bet, the safer bet is on the moderation model. But that bet wouled be quite uncertain and we might well\\nloose our shirts. Also, note the width of the distribution; credible values range from -0.1 to nearly 0.2.&quot;, x = NULL) + coord_cartesian(xlim = c(-.4, .4)) + theme_08 We can also compare these with the LOO, which, as is typical of information criteria, corrects for model coplexity. (l_model1 &lt;- loo(model1)) #&gt; #&gt; Computed from 4000 by 211 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -259.1 10.9 #&gt; p_loo 5.5 0.9 #&gt; looic 518.1 21.8 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. (l_model4 &lt;- loo(model4)) #&gt; #&gt; Computed from 4000 by 211 log-likelihood matrix #&gt; #&gt; Estimate SE #&gt; elpd_loo -264.6 11.2 #&gt; p_loo 4.6 0.9 #&gt; looic 529.2 22.4 #&gt; ------ #&gt; Monte Carlo SE of elpd_loo is 0.0. #&gt; #&gt; All Pareto k estimates are good (k &lt; 0.5). #&gt; See help(&#39;pareto-k-diagnostic&#39;) for details. The LOO values aren’t of interest in and of themselves. However, the bottom of the loo() output was useful because for both models we learned that “All Pareto k estimates are good (k &lt; 0.5).”, which assures us that we didn’t have a problem with overly-influential outlier values. But even though the LOO values weren’t interesting themselves, their difference score is. We’ll use compare_ic() to get that. compare_ic(l_model1, l_model4) #&gt; LOOIC SE #&gt; model1 518.1 21.76 #&gt; model4 529.2 22.37 #&gt; model1 - model4 -11.1 8.35 As a reminder, we generally prefer models with lower information criteria, which in this case is clearly the moderation model (i.e., model1). However, the standard error value for the difference is quite large, which suggests that the model with the lowest value isn’t the clear winner. Happily, these results match nicely with the Bayesian \\(R^2\\) difference score. The moderation model appears somewhat better than the multivariable model, but its superiority is hardly decisive. 8.4 The equivalence between moderated regression analysis and a 2 X 2 factorial analysis of variance I’m just not going to encourage ANOVA \\(F\\)-testing methodology. However, I will show the Bayesian regression model. First, here are the data. caskets &lt;- read_csv(&quot;data/caskets/caskets.csv&quot;) glimpse(caskets) #&gt; Observations: 541 #&gt; Variables: 7 #&gt; $ policy &lt;int&gt; 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, ... #&gt; $ interest &lt;dbl&gt; 4.0, 2.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.5, 3.0, 1.0, 2.0, 3.5, 1.0, 1.0, 1.5, 3.0... #&gt; $ age &lt;int&gt; 39, 57, 63, 56, 50, 87, 33, 64, 82, 28, 18, 52, 42, 39, 64, 72, 54, 84, 55, 27... #&gt; $ educ &lt;int&gt; 3, 3, 2, 5, 3, 2, 7, 2, 3, 3, 1, 1, 5, 4, 3, 2, 3, 4, 7, 2, 3, 5, 4, 5, 5, 3, ... #&gt; $ male &lt;int&gt; 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, ... #&gt; $ conserv &lt;int&gt; 4, 3, 6, 3, 3, 5, 6, 3, 6, 7, 4, 2, 7, 6, 5, 6, 6, 3, 7, 6, 5, 5, 3, 4, 6, 2, ... #&gt; $ kerry &lt;int&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, ... The model: model5 &lt;- brm(data = caskets, family = gaussian, interest ~ 1 + policy + kerry + policy:kerry, chains = 4, cores = 4) print(model5) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: interest ~ 1 + policy + kerry + policy:kerry #&gt; Data: caskets (Number of observations: 541) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 1.79 0.09 1.62 1.96 2392 1.00 #&gt; policy -0.39 0.13 -0.63 -0.15 2288 1.00 #&gt; kerry 0.60 0.13 0.35 0.84 2274 1.00 #&gt; policy:kerry 0.37 0.18 0.02 0.71 2015 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.03 0.03 0.97 1.10 3583 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Those results don’t look anything like what Hayes reported in Tables 8.3 or 8.4. However, a little deft manipulation of the posterior samples can yield equivalent results to Hayes’s Table 8.3. post &lt;- posterior_samples(model5) %&gt;% mutate(Y_bar_1 = b_Intercept + b_policy*0 + b_kerry*0 + `b_policy:kerry`*0*0, Y_bar_3 = b_Intercept + b_policy*0 + b_kerry*1 + `b_policy:kerry`*0*1, Y_bar_2 = b_Intercept + b_policy*1 + b_kerry*0 + `b_policy:kerry`*1*0, Y_bar_4 = b_Intercept + b_policy*1 + b_kerry*1 + `b_policy:kerry`*1*1, Y_bar_12 = b_Intercept + b_policy*.5 + b_kerry*0 + `b_policy:kerry`*.5*0, Y_bar_34 = b_Intercept + b_policy*.5 + b_kerry*1 + `b_policy:kerry`*.5*1, Y_bar_13 = b_Intercept + b_policy*0 + b_kerry*.5 + `b_policy:kerry`*0*.5, Y_bar_24 = b_Intercept + b_policy*1 + b_kerry*.5 + `b_policy:kerry`*1*.5) Here are the cell-specific means in Table 8.3. post %&gt;% select(Y_bar_1:Y_bar_4) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 4 x 4 #&gt; key median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Y_bar_1 1.78 1.62 1.96 #&gt; 2 Y_bar_2 1.39 1.22 1.57 #&gt; 3 Y_bar_3 2.38 2.21 2.56 #&gt; 4 Y_bar_4 2.36 2.19 2.52 And here are the marginal means from Table 8.3. post %&gt;% select(Y_bar_12:Y_bar_24) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 4 x 4 #&gt; key median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Y_bar_12 1.59 1.47 1.72 #&gt; 2 Y_bar_13 2.08 1.96 2.21 #&gt; 3 Y_bar_24 1.88 1.76 2.00 #&gt; 4 Y_bar_34 2.37 2.25 2.49 For kicks and giggles, here are what the cell-specific means look like in box plots. post %&gt;% select(Y_bar_1:Y_bar_4) %&gt;% gather() %&gt;% ggplot(aes(x = key, y = value, fill = key)) + geom_boxplot(size = 1/3) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + labs(title = &quot;Cell-specific effects&quot;, x = NULL, y = &quot;interest&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) And here are the same for the marginal means. This time we’ll show the shapes of the posteriors with violin plots with horizontal lines depicting the median and interquartile ranges. post %&gt;% select(Y_bar_12:Y_bar_24) %&gt;% gather() %&gt;% ggplot(aes(x = key, y = value, fill = key)) + geom_violin(draw_quantiles = c(.25, .5, .75), color = ochre_palettes[[&quot;olsen_seq&quot;]][8]) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + labs(title = &quot;Marginal means&quot;, x = NULL, y = &quot;interest&quot;) + theme_08 + theme(legend.position = &quot;none&quot;) On page 294, Hayes used point estimates to compute the simple effect of policy information among Kerry supporters and then the same thing among Bush supporters. Here’s how we’d do that when working with the full vector of posterior iterations: post %&gt;% transmute(simple_effect_Kerry = Y_bar_4 - Y_bar_3, simple_effect_Bush = Y_bar_2 - Y_bar_1) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 4 #&gt; key median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 simple_effect_Bush -0.392 -0.635 -0.147 #&gt; 2 simple_effect_Kerry -0.026 -0.274 0.211 So then computing the main effect for policy information using the simple effects is little more than an extension of those steps. post %&gt;% transmute(main_effect = ((Y_bar_4 - Y_bar_3) + (Y_bar_2 - Y_bar_1))/2) %&gt;% summarize(median = median(main_effect), ll = quantile(main_effect, probs = .025), ul = quantile(main_effect, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; median ll ul #&gt; 1 -0.208 -0.383 -0.032 And we get the same results by strategically subtracting the marginal means. post %&gt;% transmute(main_effect = Y_bar_24 - Y_bar_13) %&gt;% summarize(median = median(main_effect), ll = quantile(main_effect, probs = .025), ul = quantile(main_effect, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; median ll ul #&gt; 1 -0.208 -0.383 -0.032 So then the main effect of for candidate is similarly computed using either approach: post %&gt;% transmute(main_effect = ((Y_bar_4 - Y_bar_2) + (Y_bar_3 - Y_bar_1))/2) %&gt;% summarize(median = median(main_effect), ll = quantile(main_effect, probs = .025), ul = quantile(main_effect, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; median ll ul #&gt; 1 0.78 0.605 0.95 post %&gt;% transmute(main_effect = Y_bar_34 - Y_bar_12) %&gt;% summarize(median = median(main_effect), ll = quantile(main_effect, probs = .025), ul = quantile(main_effect, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; median ll ul #&gt; 1 0.78 0.605 0.95 We don’t have an \\(F\\)-test for our Bayesian moderation model. But we do have an interaction term. Here’s its distribution: post %&gt;% ggplot(aes(x = `b_policy:kerry`)) + geom_density(size = 0, fill = ochre_palettes[[&quot;olsen_qual&quot;]][2]) + geom_vline(xintercept = fixef(model5)[&quot;policy:kerry&quot;, c(1, 3, 4)], color = ochre_palettes[[&quot;olsen_seq&quot;]][8], linetype = c(1, 2, 2)) + scale_x_continuous(breaks = fixef(model5)[&quot;policy:kerry&quot;, c(1, 3, 4)], labels = fixef(model5)[&quot;policy:kerry&quot;, c(1, 3, 4)] %&gt;% round(digits = 2)) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The interaction term, `policy:kerry`&quot;, subtitle = &quot;The solid vertical line is the posterior mean\\nand the dashed lines to either end denote the\\npercentile- based 95% intervals.&quot;, x = NULL) + theme_08 + theme(legend.position = &quot;none&quot;) Following Hayes’s work on the bottom of page 295, here’s how you’d reproduce that by manipulating our \\(\\overline{Y}\\) vectors. post %&gt;% transmute(reproduced_interaction_term = (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)) %&gt;% summarize(median = median(reproduced_interaction_term), ll = quantile(reproduced_interaction_term, probs = .025), ul = quantile(reproduced_interaction_term, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 2) #&gt; median ll ul #&gt; 1 0.37 0.02 0.71 Extending that logic, we also get: post %&gt;% transmute(reproduced_interaction_term = (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)) %&gt;% summarize(median = median(reproduced_interaction_term), ll = quantile(reproduced_interaction_term, probs = .025), ul = quantile(reproduced_interaction_term, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 2) #&gt; median ll ul #&gt; 1 0.37 0.02 0.71 8.4.1 Simple effects parameterization. We might reacquaint ourselves with the formula from model5. model5$formula #&gt; interest ~ 1 + policy + kerry + policy:kerry The results cohere nicely with the “Model 1” results at the top of Table 8.5. fixef(model5) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 1.786 0.088 1.615 1.964 #&gt; policy -0.391 0.126 -0.635 -0.147 #&gt; kerry 0.596 0.126 0.354 0.844 #&gt; policy:kerry 0.366 0.176 0.018 0.709 The Bayesian \\(R^2\\) portion looks on point, too. bayes_R2(model5) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.14 0.025 0.092 0.191 Our various Y_bar transformations from before continue to cohere with the coefficients, above, just like in the text. E.g., the policy coefficient may be returned like so: post %&gt;% transmute(b1 = b_policy, `Y_bar_2 - Y_bar_1` = Y_bar_2 - Y_bar_1) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 b1 -0.391 0.126 #&gt; 2 Y_bar_2 - Y_bar_1 -0.391 0.126 We can continue to use Hayes’s Y_bar transformations to return the kerry coefficient, too. post %&gt;% transmute(b2 = b_kerry, `Y_bar_3 - Y_bar_1` = Y_bar_3 - Y_bar_1) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 b2 0.596 0.126 #&gt; 2 Y_bar_3 - Y_bar_1 0.596 0.126 Here we compute \\(b_{3}\\) with the difference between the simple effects of \\(X\\) at levels of \\(W\\). post %&gt;% transmute(b3 = `b_policy:kerry`, `(Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)` = (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1)) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Y_bar_4 - Y_bar_3) - (Y_bar_2 - Y_bar_1) 0.366 0.176 #&gt; 2 b3 0.366 0.176 And now \\(b_{3}\\) with the difference between the simple effects of \\(W\\) at levels of \\(X\\). post %&gt;% transmute(b3 = `b_policy:kerry`, `(Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)` = (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1)) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 (Y_bar_4 - Y_bar_2) - (Y_bar_3 - Y_bar_1) 0.366 0.176 #&gt; 2 b3 0.366 0.176 8.4.2 Main effects parameterization. A nice feature of brms is you transform your data right within the brm() or update() functions. Here we’ll make our two new main-effects-coded variables, policy_me and kerry_me, with the mutate() function right within update(). model6 &lt;- update(model5, newdata = caskets %&gt;% mutate(policy_me = policy - .5, kerry_me = kerry - .5), family = gaussian, interest ~ 1 + policy_me + kerry_me + policy_me:kerry_me, chains = 4, cores = 4) Here’s our analogue to the “Model 2” portion of Table 8.5. fixef(model6) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 1.980 0.045 1.893 2.068 #&gt; policy_me -0.209 0.090 -0.388 -0.030 #&gt; kerry_me 0.780 0.089 0.610 0.954 #&gt; policy_me:kerry_me 0.356 0.175 0.020 0.698 bayes_R2(model6) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.141 0.025 0.093 0.192 Like with model6, above, we’ll need a bit of algebra to compute our \\(\\overline{Y_{i}}\\) vectors. post &lt;- posterior_samples(model6) %&gt;% mutate(Y_bar_1 = b_Intercept + b_policy_me*-.5 + b_kerry_me*-.5 + `b_policy_me:kerry_me`*-.5*-.5, Y_bar_3 = b_Intercept + b_policy_me*-.5 + b_kerry_me*.5 + `b_policy_me:kerry_me`*-.5*.5, Y_bar_2 = b_Intercept + b_policy_me*.5 + b_kerry_me*-.5 + `b_policy_me:kerry_me`*.5*-.5, Y_bar_4 = b_Intercept + b_policy_me*.5 + b_kerry_me*.5 + `b_policy_me:kerry_me`*.5*.5) With our post for fit5 in hand, we’ll follow the formulas at the top of page 298 to compute our \\(b_{1}\\) and \\(b_{2}\\) distributions. post %&gt;% transmute(b1 = ((Y_bar_4 - Y_bar_3) + (Y_bar_2 - Y_bar_1))/2, b2 = ((Y_bar_4 - Y_bar_2) + (Y_bar_3 - Y_bar_1))/2) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 3 #&gt; key mean sd #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 b1 -0.209 0.09 #&gt; 2 b2 0.78 0.089 Hayes pointed out that the interaction effect, \\(b_{3}\\), is the same across models his OLS Models 1 and 2. This is largely true for our Bayesian HMC fit4 adn fit5 models: fixef(model5)[4, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.366 0.176 0.018 0.709 fixef(model6)[4, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.356 0.175 0.020 0.698 However, the results aren’t exactly the same because of simulation error. If you were working on a project requiring high precision, increase the number of posterior iterations. To demonstrate, here we’ll increase each chain’s post-warmup iteration count by an order of magnitude, resulting in 80,000 post-warmup iterations rather than the defuault 4,000. model5 &lt;- update(model5, chains = 4, cores = 4, warmup = 1000, iter = 21000) model6 &lt;- update(model6, chains = 4, cores = 4, warmup = 1000, iter = 21000) Now they’re quite a bit closer. fixef(model5)[4, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.362 0.179 0.012 0.712 fixef(model6)[4, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.360 0.180 0.003 0.714 And before you get fixate on how there are still differences after 80,000 iterations, each, consider comparing the two density plots: posterior_samples(model5) %&gt;% as_tibble() %&gt;% select(`b_policy:kerry`) %&gt;% rename(iteraction = `b_policy:kerry`) %&gt;% bind_rows( posterior_samples(model6) %&gt;% as_tibble() %&gt;% select(`b_policy_me:kerry_me`) %&gt;% rename(iteraction = `b_policy_me:kerry_me`) ) %&gt;% mutate(model = rep(c(&quot;model5&quot;, &quot;model6&quot;), each = 80000)) %&gt;% ggplot(aes(x = iteraction, fill = model)) + geom_density(size = 0, alpha = 1/2) + scale_fill_manual(values = ochre_palettes[[&quot;olsen_qual&quot;]][c(3, 6)]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;The interaction densities, by model&quot;, subtitle = &quot;Yes, they are indeed different. And yet that difference is so\\ntrivial that we&#39;d expect greater variability from measurement\\nerror than we still have from simulation error.&quot;, x = NULL) + theme_08 8.4.3 Conducting a 2 X 2 between-participants factorial ANOVA using PROCESS another regression model with brms. Since we’re square in regression land with brms, there’s no direct analogue for us, here. However, notice the post-ANOVA \\(t\\)-tests Hayes presented on page 300. If we just want to consider the 2 X 2 structure of our two dummy variables as indicative of four groups, we have one more coding system available for the job. With the handy str_c() function, we’ll concatenate the policy and kerry values into a nominal variable, policy_kerry. Here’s what that looks like: caskets &lt;- caskets %&gt;% mutate(policy_kerry = str_c(policy, kerry)) head(caskets) #&gt; # A tibble: 6 x 8 #&gt; policy interest age educ male conserv kerry policy_kerry #&gt; &lt;int&gt; &lt;dbl&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;int&gt; &lt;chr&gt; #&gt; 1 1 4 39 3 1 4 1 11 #&gt; 2 0 2 57 3 1 3 1 01 #&gt; 3 1 3 63 2 0 6 1 11 #&gt; 4 1 1 56 5 1 3 1 11 #&gt; 5 1 1 50 3 0 3 1 11 #&gt; 6 0 2 87 2 1 5 0 00 Now check out what happens if we reformat our formula to interest ~ 0 + policy_kerry. model7 &lt;- brm(data = caskets, family = gaussian, interest ~ 0 + policy_kerry, chains = 4, cores = 4) The brm() function recnognized policy_kerry was a character vector and treated it as a nominal variable. The 0 + part of the function removed the model intercept. Here’s how that effects the output: print(model7) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: interest ~ 0 + policy_kerry #&gt; Data: caskets (Number of observations: 541) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; policy_kerry00 1.78 0.09 1.61 1.96 4000 1.00 #&gt; policy_kerry01 2.38 0.09 2.20 2.56 4000 1.00 #&gt; policy_kerry10 1.40 0.09 1.23 1.58 4000 1.00 #&gt; policy_kerry11 2.36 0.08 2.19 2.52 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.04 0.03 0.98 1.10 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Without the typical intercept, brm() estimated the means for each of the four policy_kerry groups. It’s kinda like an intercept-only model, but with four intercepts. Here’s what their densities look like: post &lt;- posterior_samples(model7) post %&gt;% select(b_policy_kerry00:b_policy_kerry11) %&gt;% gather() %&gt;% mutate(key = str_remove(key, &quot;b_&quot;)) %&gt;% ggplot(aes(x = value, fill = key)) + geom_density(color = &quot;transparent&quot;, alpha = 2/3) + scale_fill_manual(NULL, values = ochre_palettes[[&quot;olsen_qual&quot;]][c(5, 6, 4, 3)]) + scale_y_continuous(NULL, breaks = NULL) + labs(title = &quot;Group means&quot;, x = NULL) + theme_08 Since each of the four primary vectors in our post object is of a group mean, it’s trivial to compute difference scores. To compute the difference score analogous to Hayes’s two \\(t\\)-tests, we’d do the following. post %&gt;% transmute(difference_1 = b_policy_kerry10 - b_policy_kerry00, difference_2 = b_policy_kerry11 - b_policy_kerry01) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 4 #&gt; key median ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 difference_1 -0.381 -0.625 -0.14 #&gt; 2 difference_2 -0.027 -0.264 0.214 References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] bindrcpp_0.2.2 ochRe_1.0.0 ggthemes_3.5.0 brms_2.3.4 Rcpp_0.12.17 forcats_0.3.0 #&gt; [7] stringr_1.3.1 dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 tidyr_0.8.1 tibble_1.4.2 #&gt; [13] ggplot2_3.0.0 tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 #&gt; [5] threejs_0.3.1 httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 #&gt; [9] tools_3.5.1 backports_1.1.2 utf8_1.1.4 R6_2.2.2 #&gt; [13] DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 withr_2.1.2 #&gt; [17] tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 #&gt; [25] xml2_1.2.0 labeling_0.3 colourpicker_1.0 bookdown_0.7 #&gt; [29] scales_0.5.0 dygraphs_1.1.1.5 mvtnorm_1.0-8 psych_1.8.4 #&gt; [33] ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 foreign_0.8-70 #&gt; [37] rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 #&gt; [45] shiny_1.1.0 bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 #&gt; [49] gtools_3.8.1 crosstalk_1.0.0 inline_0.3.15 magrittr_1.5 #&gt; [53] loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 munsell_0.5.0 #&gt; [57] abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 #&gt; [65] miniUI_0.1.1.1 lattice_0.20-35 haven_1.1.2 hms_0.4.2 #&gt; [69] knitr_1.20 pillar_1.2.3 igraph_1.2.1 markdown_0.8 #&gt; [73] shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 stats4_3.5.1 #&gt; [77] rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 #&gt; [85] xfun_0.3 mime_0.5 xtable_1.8-2 broom_0.4.5 #&gt; [89] coda_0.19-1 later_0.7.3 rsconnect_0.8.8 shinythemes_1.1.1 #&gt; [93] bridgesampling_0.4-0 "],
["some-myths-and-additional-extensions-of-moderation-analysis.html", "9 Some Myths and Additional Extensions of Moderation Analysis 9.1 Truths and myths about mean-centering 9.2 The estimation and interpretation of standardized regression coefficients in a moderation analysis 9.3 A caution on manual centering and standardization 9.4 More than one moderator 9.5 Comparing conditional effects References Session info", " 9 Some Myths and Additional Extensions of Moderation Analysis 9.1 Truths and myths about mean-centering Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) glbwarm &lt;- read_csv(&quot;data/glbwarm/glbwarm.csv&quot;) glimpse(glbwarm) #&gt; Observations: 815 #&gt; Variables: 7 #&gt; $ govact &lt;dbl&gt; 3.6, 5.0, 6.6, 1.0, 4.0, 7.0, 6.8, 5.6, 6.0, 2.6, 1.4, 5.6, 7.0, 3.8, 3.4, 4.2, 1.0... #&gt; $ posemot &lt;dbl&gt; 3.67, 2.00, 2.33, 5.00, 2.33, 1.00, 2.33, 4.00, 5.00, 5.00, 1.00, 4.00, 1.00, 5.67,... #&gt; $ negemot &lt;dbl&gt; 4.67, 2.33, 3.67, 5.00, 1.67, 6.00, 4.00, 5.33, 6.00, 2.00, 1.00, 4.00, 5.00, 4.67,... #&gt; $ ideology &lt;int&gt; 6, 2, 1, 1, 4, 3, 4, 5, 4, 7, 6, 4, 2, 4, 5, 2, 6, 4, 2, 4, 4, 2, 6, 4, 4, 3, 4, 5,... #&gt; $ age &lt;int&gt; 61, 55, 85, 59, 22, 34, 47, 65, 50, 60, 71, 60, 71, 59, 32, 36, 69, 70, 41, 48, 38,... #&gt; $ sex &lt;int&gt; 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0,... #&gt; $ partyid &lt;int&gt; 2, 1, 1, 1, 1, 2, 1, 1, 2, 3, 2, 1, 1, 1, 1, 1, 2, 3, 1, 3, 2, 1, 3, 2, 1, 1, 1, 3,... Before we fit our models, we’ll go ahead and make our mean-centered predictors, negemot_c and age_c. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_c = negemot - mean(negemot), age_c = age - mean(age)) Now we’re ready to fit Models 1 and 2. But before we do, it’s worth repeating part of the text: Mean-centering has been recommended in a few highly regarded books on regression analysis (e.g., Aiken &amp; West, 1991; Cohen et al., 2003), and several explanations have been offered for why mean-centering should be undertaken prior to computation of the product and model estimation. The explanation that seems to have resulted in the most misunderstanding is that \\(X\\) and \\(W\\) are likely to be highly correlated with \\(XW\\) and this will produce estimation problems caused by collinearity and result in poor or “strange” estimates of regression coefficients, large standard errors, and reduced power of the statistical test of the interaction. But his is, in large part, simply a myth. (p. 304) Let’s load brms. library(brms) As we’ll see in just a bit, there are some important reasons for Bayesians using HMC to mean center that wouldn’t pop up within the OLS paradigm. First let’s fit model1 and model2. model1 &lt;- brm(data = glbwarm, family = gaussian, govact ~ 1 + negemot + age + negemot:age, chains = 4, cores = 4) model2 &lt;- update(model1, newdata = glbwarm, govact ~ 1 + negemot_c + age_c + negemot_c:age_c, chains = 4, cores = 4) As with Hayes’s OLS models, our HMC models yield the same Bayesian \\(R^2\\) distributions, within simulation error. bayes_R2(model1) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.354 0.021 0.31 0.393 bayes_R2(model2) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.353 0.022 0.308 0.394 Our model summaries also correspond nicely with those in Table 9.1. print(model1, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ 1 + negemot + age + negemot:age #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 4.325 0.333 3.681 4.962 1535 1.007 #&gt; negemot 0.149 0.085 -0.017 0.321 1504 1.006 #&gt; age -0.030 0.006 -0.042 -0.018 1511 1.006 #&gt; negemot:age 0.007 0.002 0.004 0.010 1513 1.006 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.097 0.028 1.042 1.153 2272 1.002 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). print(model2, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ negemot_c + age_c + negemot_c:age_c #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 4.597 0.039 4.522 4.672 3628 1.000 #&gt; negemot_c 0.500 0.025 0.450 0.549 3603 1.000 #&gt; age_c -0.005 0.002 -0.010 -0.001 4000 1.000 #&gt; negemot_c:age_c 0.007 0.002 0.004 0.010 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.097 0.028 1.046 1.152 2918 1.002 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). However, notice the ‘Eff.Sample’ columns. The values for model2 were substantially larger than those for model1. ‘Eff.Sample’ is Bürkner’s term for the number of effective samples. Recall that because we’ve been using brms defaults, we have 4 HMC chains, each of which contains 2000 draws (iterations), the first 1000 of which are warmup values. After we discard the warmup values, that leaves 1000 draws from each chain–4000 total. As it turns out, Markov chains, and thus HMC chains, are typically autocorrelated, which means that each draw is partially dependent on the previous draw. Ideally, the autocorrelations are near zero. That’s often not the case. The bayesplot package offers a variety of diagnostic plots. Here we’ll use the mcmc_acf() function to make autocorrelation plots for all model parameters. Note that when we add add_chain = T to brms::posterior_samples(), we add an index to the data that allows us to keep track of which iteration comes from which chain. That index will come in handy for our mcmc_acf() plots. But before we get there, we’ll be using an xkcd-inspired theme with help from the xkcd package for our plots in this chapter. # install.packages(&quot;xkcd&quot;, dependencies = T) library(xkcd) If you haven’t used the xkcd package, before, you might also need to take a few extra steps outlined here, part of which requires help from the extrafont package, library(extrafont) download.file(&quot;http://simonsoftware.se/other/xkcd.ttf&quot;, dest = &quot;xkcd.ttf&quot;, mode = &quot;wb&quot;) system(&quot;mkdir ~/.fonts&quot;) system(&quot;cp xkcd.ttf ~/.fonts&quot;) # This line of code returned an error message # font_import(pattern = &quot;[X/x]kcd&quot;, prompt = FALSE) # This line from (https://stackoverflow.com/questions/49221040/error-in-font-import-while-installing-xkcd-font) fixed the problem font_import(path = &quot;~/.fonts&quot;, pattern = &quot;[X/x]kcd&quot;, prompt=FALSE) fonts() fonttable() if(.Platform$OS.type != &quot;unix&quot;) { ## Register fonts for Windows bitmap output loadfonts(device=&quot;win&quot;) } else { loadfonts() } After installing, I still experienced error messages, which were alleviated after I followed these steps outlined by Remi.b. You may or may not need them. But anyways, here are our mcmc_acf() plots. library(bayesplot) post1 &lt;- posterior_samples(model1, add_chain = T) mcmc_acf(post1, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot&quot;, &quot;b_age&quot;, &quot;b_negemot:age&quot;, &quot;sigma&quot;), lags = 4) + theme_xkcd() post2 &lt;- posterior_samples(model2, add_chain = T) mcmc_acf(post2, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot_c&quot;, &quot;b_age_c&quot;, &quot;b_negemot_c:age_c&quot;, &quot;sigma&quot;), lags = 4) + theme_xkcd() As it turns out, theme_xkcd() can’t handle special characters like “_“, so it returns rectangles instead. So it goes… But again, high autocorrelations in the HMC chains have consequences for the effective sample size. In the Visual MCMC diagnostics using the bayesplot package vignette, Gabry wrote: The effective sample size is an estimate of the number of independent draws from the posterior distribution of the estimand of interest. Because the draws within a Markov chain are not independent if there is autocorrelation, the effective sample size, \\(n_{eff}\\), will be smaller than the total sample size, \\(N\\). The larger the ratio of \\(n_{eff}\\) to \\(N\\) the better. The ‘Eff.Sample’ values were all close to 4000 with model2 and the autocorrelations were very low, too. The reverse was true for model1. The upshot is that even though we have 4000 samples for each parameter, those samples don’t necessarily give us the same quality of information fully independent samples would. ‘Eff.Sample’ helps you determine how concerned you should be. And, as it turns out, things like centering can help increase a models ‘Eff.Sample’ values. Wading in further, we can use the neff_ratio() function to collect the \\(n_{eff}\\) to \\(N\\) ratio for each model parameter and then use mcmc_neff() to make a visual diagnostic. Here we do so for model1 and model2. ratios_model1 &lt;- neff_ratio(model1, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot&quot;, &quot;b_age&quot;, &quot;b_negemot:age&quot;, &quot;sigma&quot;)) ratios_model2 &lt;- neff_ratio(model2, pars = c(&quot;b_Intercept&quot;, &quot;b_negemot_c&quot;, &quot;b_age_c&quot;, &quot;b_negemot_c:age_c&quot;, &quot;sigma&quot;)) mcmc_neff(ratios_model1) + yaxis_text(hjust = 0) + theme_xkcd() mcmc_neff(ratios_model2) + yaxis_text(hjust = 0) + theme_xkcd() Although none of the \\(n_{eff}\\) to \\(N\\) ratios were in the shockingly-low range for either model, there were substantially closer to 1 for model2. In addition to autocorrelations and \\(n_{eff}\\) to \\(N\\) ratios, there is also the issue that the parameters in the model can themselves be correlated. If you like a visual approach, you can use brms::pairs() to retrieve histograms for each parameter along with scatter plots showing the shape of their correlations. Here we’ll use the off_diag_args argument to customize some of the plot settings. pairs(model1, off_diag_args = list(size = 1/10, alpha = 1/5)) pairs(model2, off_diag_args = list(size = 1/10, alpha = 1/5)) When fitting models with HMC, centering can make a difference for the parameter correlations. If you prefer a more numeric approach, vcov() will yield the variance/covariance matrix–or correlation matrix when using correlation = T–for the parameters in a model. vcov(model1, correlation = T) %&gt;% round(digits = 2) #&gt; Intercept negemot age negemot:age #&gt; Intercept 1.00 -0.93 -0.96 0.88 #&gt; negemot -0.93 1.00 0.89 -0.96 #&gt; age -0.96 0.89 1.00 -0.93 #&gt; negemot:age 0.88 -0.96 -0.93 1.00 vcov(model2, correlation = T) %&gt;% round(digits = 2) #&gt; Intercept negemot_c age_c negemot_c:age_c #&gt; Intercept 1.00 -0.03 0.03 0.05 #&gt; negemot_c -0.03 1.00 0.05 -0.09 #&gt; age_c 0.03 0.05 1.00 0.01 #&gt; negemot_c:age_c 0.05 -0.09 0.01 1.00 And so wait, what does that even mean for a parameter to correlate with another parameter? you might ask. Fair enough. Let’s compute a correlation step by step. First, posterior_samples(): post &lt;- posterior_samples(model1) head(post) #&gt; b_Intercept b_negemot b_age b_negemot:age sigma lp__ #&gt; 1 3.90 0.267 -0.0266 0.00602 1.13 -1239 #&gt; 2 4.23 0.199 -0.0317 0.00708 1.08 -1237 #&gt; 3 3.86 0.256 -0.0197 0.00453 1.07 -1237 #&gt; 4 3.97 0.248 -0.0236 0.00514 1.07 -1236 #&gt; 5 3.95 0.239 -0.0224 0.00514 1.06 -1236 #&gt; 6 4.07 0.228 -0.0257 0.00575 1.14 -1237 Now we’ve put our posterior iterations into a data object, post, we can make a scatter plot of two parameters. Here we’ll choose b_negemot and the interaction coefficient, b_negemot:age. post %&gt;% ggplot(aes(x = b_negemot, y = `b_negemot:age`)) + geom_point(size = 1/10, alpha = 1/5) + labs(subtitle = &quot;Each dot is the parameter pair\\nfrom a single iteration. Looking\\nacross the 4,000 total posterior\\niterations, it becomes clear the\\ntwo parameters are highly\\nnegatively correlated.&quot;) + theme_xkcd() And indeed, the Pearson’s correlation is: cor(post$b_negemot, post$`b_negemot:age`) #&gt; [1] -0.955 And what was that part from the vcov() output, again? vcov(model1, correlation = T)[&quot;negemot&quot;, &quot;negemot:age&quot;] #&gt; [1] -0.955 Boom! That’s where the correlations come from. This entire topic of HMC diagnostics can seem baffling, especially when compared to the simplicity of OLS. If this is your first introduction, you might want to watch lectures 10 and 11 from McElreath’s Statistical Rethinking Fall 2017 lecture series. Accordingly, you might check out chapter 8 of his Statistical Rethinking text and my project explaining how to reproduce the analyses in that chapter in brms. 9.1.1 The effect of mean-centering on multicollinearity and the standard error of \\(b_{3}\\). This can be difficult to keep track of, but what we just looked at were the correlations among model parameters. These are not the same as correlations among variables. As such, those correlations are not the same as those in Table 9.2. But we can get those, too. First we’ll have to do a little more data processing to get all the necessary mean-centered variables and standardized variables. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_x_age = negemot*age, negemot_c_x_age_c = negemot_c*age_c, negemot_z = (negemot - mean(negemot))/sd(negemot), age_z = (age - mean(age) )/sd(age)) %&gt;% mutate(negemot_z_x_age_z = negemot_z*age_z) And recall that to get our sweet Bayesian correlations, we use the multivariate cbind() syntax to fit an intercepts-only model. Here we do that for all three of the Table 9.2 sections. correlations1 &lt;- brm(data = glbwarm, family = gaussian, cbind(negemot, age, negemot_x_age) ~ 1, chains = 4, cores = 4) correlations2 &lt;- brm(data = glbwarm, family = gaussian, cbind(negemot_c, age_c, negemot_c_x_age_c) ~ 1, chains = 4, cores = 4) correlations3 &lt;- brm(data = glbwarm, family = gaussian, cbind(negemot_z, age_z, negemot_z_x_age_z) ~ 1, chains = 4, cores = 4) Their summaries: print(correlations1, digits = 3) #&gt; Family: MV(gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: negemot ~ 1 #&gt; age ~ 1 #&gt; negemot_x_age ~ 1 #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; negemot_Intercept 3.556 0.051 3.455 3.657 3301 1.000 #&gt; age_Intercept 49.541 0.586 48.405 50.709 3610 1.002 #&gt; negemotxage_Intercept 174.758 3.361 168.213 181.396 2871 1.001 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_negemot 1.531 0.038 1.459 1.607 2662 1.000 #&gt; sigma_age 16.362 0.402 15.605 17.174 3120 1.000 #&gt; sigma_negemotxage 97.525 2.419 92.870 102.556 2257 1.001 #&gt; rescor(negemot,age) -0.058 0.036 -0.127 0.012 2914 1.000 #&gt; rescor(negemot,negemotxage) 0.766 0.015 0.736 0.793 2155 1.000 #&gt; rescor(age,negemotxage) 0.547 0.025 0.497 0.594 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). print(correlations2, digits = 3) #&gt; Family: MV(gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: negemot_c ~ 1 #&gt; age_c ~ 1 #&gt; negemot_c_x_age_c ~ 1 #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; negemotc_Intercept 0.000 0.054 -0.108 0.108 4000 1.000 #&gt; agec_Intercept -0.002 0.569 -1.146 1.094 4000 1.000 #&gt; negemotcxagec_Intercept -1.425 0.835 -3.059 0.172 4000 0.999 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_negemotc 1.533 0.040 1.456 1.614 4000 1.000 #&gt; sigma_agec 16.364 0.408 15.594 17.182 4000 0.999 #&gt; sigma_negemotcxagec 24.233 0.592 23.121 25.426 4000 0.999 #&gt; rescor(negemotc,agec) -0.057 0.035 -0.126 0.012 4000 0.999 #&gt; rescor(negemotc,negemotcxagec) 0.092 0.034 0.024 0.157 4000 1.000 #&gt; rescor(agec,negemotcxagec) -0.015 0.035 -0.084 0.053 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). print(correlations3, digits = 3) #&gt; Family: MV(gaussian, gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: negemot_z ~ 1 #&gt; age_z ~ 1 #&gt; negemot_z_x_age_z ~ 1 #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; negemotz_Intercept 0.000 0.034 -0.066 0.068 4000 0.999 #&gt; agez_Intercept -0.000 0.035 -0.068 0.068 4000 0.999 #&gt; negemotzxagez_Intercept -0.057 0.034 -0.124 0.010 4000 0.999 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_negemotz 1.003 0.025 0.956 1.053 4000 1.000 #&gt; sigma_agez 1.003 0.025 0.956 1.053 4000 0.999 #&gt; sigma_negemotzxagez 0.971 0.023 0.928 1.017 4000 1.000 #&gt; rescor(negemotz,agez) -0.056 0.035 -0.126 0.013 4000 0.999 #&gt; rescor(negemotz,negemotzxagez) 0.092 0.035 0.022 0.161 4000 0.999 #&gt; rescor(agez,negemotzxagez) -0.014 0.035 -0.083 0.053 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). A more condensed way to get that information might be with the VarCorr() function. Just make sure to tack $residual__$cor onto the end. VarCorr(correlations1)$residual__$cor %&gt;% round(digits = 3) #&gt; , , negemot #&gt; #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; negemot 1.000 0.000 1.000 1.000 #&gt; age -0.058 0.036 -0.127 0.012 #&gt; negemotxage 0.766 0.015 0.736 0.793 #&gt; #&gt; , , age #&gt; #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; negemot -0.058 0.036 -0.127 0.012 #&gt; age 1.000 0.000 1.000 1.000 #&gt; negemotxage 0.547 0.025 0.497 0.594 #&gt; #&gt; , , negemotxage #&gt; #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; negemot 0.766 0.015 0.736 0.793 #&gt; age 0.547 0.025 0.497 0.594 #&gt; negemotxage 1.000 0.000 1.000 1.000 For the sake of space, I’ll let you check that out for correlations2 and correlations3. If you’re tricky with your VarCorr() indexing, you can also get the model-implied variances. VarCorr(correlations1)$residual__$cov[1, , &quot;negemot&quot;] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 2.346 0.116 2.128 2.584 VarCorr(correlations1)$residual__$cov[2, , &quot;age&quot;] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 267.9 13.2 243.5 294.9 VarCorr(correlations1)$residual__$cov[3, , &quot;negemotxage&quot;] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 9517 473 8625 10518 And if you’re like totally lost with all this indexing, you might code VarCorr(correlations1) %&gt;% str() and spend a little time looking at what VarCorr() produces. On page 309, Hayes explained why the OLS variance for \\(b_{3}\\) is unaffected by mean centering. The story was similar for our HMC model, too: fixef(model1)[&quot;negemot:age&quot;, &quot;Est.Error&quot;] #&gt; [1] 0.00159 fixef(model2)[&quot;negemot_c:age_c&quot;, &quot;Est.Error&quot;] #&gt; [1] 0.00162 For more details, you might also see the 28.11. Standardizing Predictors and Outputs subsection of the Stan Modeling Language User’s Guide and Reference Manual, 2.17.0–Stan, of course, being the computational engine underneath our brms hood. 9.1.2 The effect of mean-centering on \\(b_{1}\\), \\(b_{2}\\), and their standard errors posterior \\(SD\\)s. If you only care about posterior means, you can reproduce the results at the bottom of page 310 like: fixef(model1)[&quot;negemot&quot;, 1] + fixef(model1)[&quot;negemot:age&quot;, 1]*mean(glbwarm$age) #&gt; [1] 0.501 But we’re proper Bayesians and like a summary of the spread in the posterior. So we’ll evoke posterior_samples() and the other usual steps. post &lt;- posterior_samples(model1) post %&gt;% transmute(our_contidional_effect_given_W_bar = b_negemot + `b_negemot:age`*mean(glbwarm$age)) %&gt;% summarize(mean = mean(our_contidional_effect_given_W_bar), sd = sd(our_contidional_effect_given_W_bar)) %&gt;% round(digits = 3) #&gt; mean sd #&gt; 1 0.501 0.025 And note how the standard error Hayes computed at the top of page 311 corresponds nicely with the posterior \\(SD\\) we just computed. Hayes employed a fancy formula; we just used sd(). 9.1.3 The centering option in PROCESS. I’m not aware of a similar function in brms. You’ll have to use your data wrangling skills. 9.2 The estimation and interpretation of standardized regression coefficients in a moderation analysis 9.2.1 Variant 1. We’ve already computed standardized predictors. Now we just need to standardize the criterion, govact. glbwarm &lt;- glbwarm %&gt;% mutate(govact_z = (govact - mean(govact))/sd(govact)) Fit: model3 &lt;- update(model1, newdata = glbwarm, govact_z ~ 1 + negemot_z + age_z + negemot_z:age_z, chains = 4, cores = 4) bayes_R2(model3) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.354 0.021 0.311 0.395 print(model3, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact_z ~ negemot_z + age_z + negemot_z:age_z #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 0.008 0.028 -0.046 0.061 4000 1.000 #&gt; negemot_z 0.563 0.028 0.507 0.617 4000 0.999 #&gt; age_z -0.063 0.029 -0.119 -0.008 4000 1.000 #&gt; negemot_z:age_z 0.130 0.029 0.073 0.188 4000 0.999 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.806 0.020 0.768 0.847 4000 0.999 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). 9.2.2 Variant 2. This time we need to standardize our interaction term, negemot_x_age_z, by hand. glbwarm &lt;- glbwarm %&gt;% mutate(negemot_x_age_z = (negemot_x_age - mean(negemot_x_age))/sd(negemot_x_age)) Now we’re ready to fit. model4 &lt;- update(model1, newdata = glbwarm, govact_z ~ 1 + negemot_z + age_z + negemot_x_age_z, chains = 4, cores = 4) bayes_R2(model4) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.354 0.022 0.31 0.396 print(model4, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact_z ~ negemot_z + age_z + negemot_x_age_z #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept -0.000 0.028 -0.055 0.054 2814 1.002 #&gt; negemot_z 0.169 0.094 -0.019 0.358 1377 1.002 #&gt; age_z -0.365 0.072 -0.509 -0.222 1397 1.003 #&gt; negemot_x_age_z 0.506 0.113 0.284 0.728 1371 1.002 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.806 0.020 0.768 0.848 2705 1.001 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The results correspond nicely to those in Table 9.1. 9.3 A caution on manual centering and standardization It’s worthwhile considering the issue of listwise deletion when data are partially missing. The brms default is to delete rows with missingness, “NA” in R, for the predictors. However, brms allows users to perform one-step Bayesian imputation for missing values using the mi() syntax. First we’ll fit see what happens when you fit a model in brms when some of the negemot_z values are missing, but without using the mi() syntax. And of course before we do that, we’ll make a negemot_z_missing variable, which is identical to negemot_z, but about 10% of the values are missing. set.seed(815) glbwarm &lt;- glbwarm %&gt;% mutate(missing = rbinom(n = 815, size = 1, prob = .1)) %&gt;% mutate(negemot_z_missing = ifelse(missing == 1, NA, negemot_z)) If you’ve never used rbinom() before, code ?rbinom or look it up in your favorite web search engine. Here’s our listwise deletion model, which corresponds to what you’d get from a typical OLS-based program. model5 &lt;- update(model3, newdata = glbwarm, govact_z ~ 1 + negemot_z_missing + age_z + negemot_z_missing:age_z, chains = 4, cores = 4) Let’s compare the listwise deletion results with the model based on all the data. print(model3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact_z ~ negemot_z + age_z + negemot_z:age_z #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 0.01 0.03 -0.05 0.06 4000 1.00 #&gt; negemot_z 0.56 0.03 0.51 0.62 4000 1.00 #&gt; age_z -0.06 0.03 -0.12 -0.01 4000 1.00 #&gt; negemot_z:age_z 0.13 0.03 0.07 0.19 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.81 0.02 0.77 0.85 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). print(model5) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact_z ~ negemot_z_missing + age_z + negemot_z_missing:age_z #&gt; Data: glbwarm (Number of observations: 719) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 0.00 0.03 -0.06 0.06 4000 1.00 #&gt; negemot_z_missing 0.56 0.03 0.51 0.62 4000 1.00 #&gt; age_z -0.05 0.03 -0.11 0.01 4000 1.00 #&gt; negemot_z_missing:age_z 0.12 0.03 0.06 0.18 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 0.81 0.02 0.77 0.86 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). In this case, the model results were similar to those based on all the data because we used rbinom() to delete the predictor values completely at random. With real data and real-live missing data mechanisms, the situation isn’t often so rosy. But anyway, the real story, here, is the Data: glbwarm (Number of observations: n) line at the top of the print() outputs. The number, \\(n\\), was 815 in the model using all the data and 719 for the one based on listwise deletion. That’s a lot of missing information. The mi() syntax will allow us to use all the rows in a model, even if one or more of the predictors contain missing values. The syntax makes the model a multivariate model in that now we’ll be modeling both govact_z and negemot_z_missing. There are multiple ways to write a multivariate model in brms. One nice way is to write the model for each criterion separately in a bf() statement. You combine the bf() statements together with the + operator. And for models like the ones in Hayes’s text, you’ll also want to tack on set_rescor(FALSE). You can do this within the brm() function, as usual. But I find that this clutters the code up more than I like. So another approach is to save the combination of bf() statements as an object. my_model &lt;- bf(govact_z ~ 1 + mi(negemot_z_missing) + age_z + mi(negemot_z_missing):age_z) + bf(negemot_z_missing | mi() ~ 1) + set_rescor(FALSE) With our multivariate formula saved as my_model, we’re ready to plug it into brm() and fit. model6 &lt;- brm(data = glbwarm, family = gaussian, my_model, chains = 4, cores = 4) Let’s see what we’ve done. print(model6) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: govact_z ~ 1 + mi(negemot_z_missing) + age_z + mi(negemot_z_missing):age_z #&gt; negemot_z_missing | mi() ~ 1 #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; govactz_Intercept 0.00 0.03 -0.05 0.06 4000 1.00 #&gt; negemotzmissing_Intercept 0.00 0.04 -0.07 0.07 4000 1.00 #&gt; govactz_age_z -0.07 0.03 -0.12 -0.01 4000 1.00 #&gt; govactz_minegemot_z_missing 0.56 0.03 0.50 0.62 4000 1.00 #&gt; govactz_minegemot_z_missing:age_z 0.13 0.03 0.07 0.19 4000 1.00 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_govactz 0.81 0.02 0.77 0.85 4000 1.00 #&gt; sigma_negemotzmissing 1.00 0.03 0.95 1.05 4000 1.00 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). When using the multivariate mi() syntax, your print() output becomes more complicated. Now we have a regression model for both govact_z and negemot_z_missing. At a minimum, each has its own intercept and residual variance (i.e., sigma). In the ‘Population-Level Effects’ section, the first part of the names for each regression coefficient clarifies which \\(Y\\)-variable it corresponds to (e.g., govactz_Intercept is the intercept for our primary \\(Y\\)-variable, govact_z). In the ‘Family Specific Parameters’ section, the sigmas are similarly labeled. Perhaps most importantly, we see “Data: glbwarm (Number of observations: 815)” at the top of the output. The multivariate mi() syntax used all the available data. No listwise deletion necessary. The print() output for our model obscured some of the results. To clarify what the mi() syntax did, let’s peek at the first columns returned by posterior_samples(). post &lt;- posterior_samples(model6) post[, 1:20] %&gt;% glimpse() #&gt; Observations: 4,000 #&gt; Variables: 20 #&gt; $ b_govactz_Intercept &lt;dbl&gt; 0.04989, 0.00791, -0.01523, -0.06286, -0.05566, 0.04... #&gt; $ b_negemotzmissing_Intercept &lt;dbl&gt; 0.00996, 0.01728, 0.04135, -0.03303, -0.03438, 0.067... #&gt; $ b_govactz_age_z &lt;dbl&gt; -0.1068, -0.0486, -0.0882, -0.0837, -0.1047, -0.0329... #&gt; $ bsp_govactz_minegemot_z_missing &lt;dbl&gt; 0.532, 0.556, 0.509, 0.515, 0.534, 0.560, 0.600, 0.5... #&gt; $ `bsp_govactz_minegemot_z_missing:age_z` &lt;dbl&gt; 0.1363, 0.0955, 0.1696, 0.1018, 0.1027, 0.1357, 0.07... #&gt; $ sigma_govactz &lt;dbl&gt; 0.818, 0.840, 0.785, 0.823, 0.835, 0.804, 0.812, 0.8... #&gt; $ sigma_negemotzmissing &lt;dbl&gt; 1.025, 1.004, 0.984, 1.031, 1.025, 0.969, 1.010, 1.0... #&gt; $ `Ymi_negemotzmissing[7]` &lt;dbl&gt; -0.732, 2.007, 1.397, 1.716, 1.563, 0.284, 0.783, 1.... #&gt; $ `Ymi_negemotzmissing[22]` &lt;dbl&gt; 0.6030, -0.7665, 0.5277, 1.1402, 1.1237, -0.3344, 0.... #&gt; $ `Ymi_negemotzmissing[31]` &lt;dbl&gt; 0.29320, -2.25086, 0.11291, 0.31718, 0.64534, -0.735... #&gt; $ `Ymi_negemotzmissing[55]` &lt;dbl&gt; 0.0732, 0.7305, 0.6328, 0.0807, -0.2962, -0.1087, -1... #&gt; $ `Ymi_negemotzmissing[60]` &lt;dbl&gt; 0.7151, -0.2980, 2.9397, 2.0080, 2.0664, -0.9437, 1.... #&gt; $ `Ymi_negemotzmissing[66]` &lt;dbl&gt; -0.77131, -0.38676, 0.00424, 0.04842, 0.15883, -0.56... #&gt; $ `Ymi_negemotzmissing[72]` &lt;dbl&gt; 0.2910, 0.6595, -0.3722, 0.8790, 1.3735, -0.6493, 1.... #&gt; $ `Ymi_negemotzmissing[86]` &lt;dbl&gt; 0.7676, 0.2360, 0.4749, -0.2269, 0.0454, -0.8055, 1.... #&gt; $ `Ymi_negemotzmissing[87]` &lt;dbl&gt; -0.9997, 0.7594, -1.6664, -0.1146, -0.4297, -0.9470,... #&gt; $ `Ymi_negemotzmissing[98]` &lt;dbl&gt; -0.2878, -0.3807, 0.7597, -0.1947, -0.3714, 0.0536, ... #&gt; $ `Ymi_negemotzmissing[103]` &lt;dbl&gt; 1.8292, 0.0277, 1.7674, 0.5286, 0.2319, 0.9420, 1.18... #&gt; $ `Ymi_negemotzmissing[107]` &lt;dbl&gt; 0.7279, -2.7320, 0.0811, -2.2104, -1.7479, 0.6883, -... #&gt; $ `Ymi_negemotzmissing[131]` &lt;dbl&gt; -1.2702, -1.0011, -0.5789, -0.9845, -1.4775, 0.3450,... Columns b_govactz_Intercept through sigma_negemotzmissing were business as usual. But notice all the Ymi_negemotzmissing[i] columns. In each of these we see 4,000 posterior draws for the missing negemot_z_missing values. The [i] part of the column names indexes which row number the iterations correspond to. Since we made a lot of missing values in the data, I won’t go through them all. But we can focus on a few to get a sense of the results. post %&gt;% select(`Ymi_negemotzmissing[7]`:`Ymi_negemotzmissing[131]`) %&gt;% gather(row, value) %&gt;% group_by(row) %&gt;% # Yep, that&#39;s right, we&#39;re summarizing as usual summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 2) %&gt;% mutate(row = str_extract(row, &quot;\\\\d+&quot;) %&gt;% as.integer()) # this line just makes the row names easier to read #&gt; # A tibble: 13 x 5 #&gt; row mean sd ll ul #&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 103 0.65 0.83 -0.93 2.32 #&gt; 2 107 -0.580 0.77 -2.07 0.9 #&gt; 3 131 -0.48 0.74 -1.88 1 #&gt; 4 22 0.38 0.79 -1.11 1.95 #&gt; 5 31 -0.13 0.76 -1.62 1.34 #&gt; 6 55 -0.26 0.83 -1.9 1.38 #&gt; # ... with 7 more rows In conventional mean-imputation, you just plug the sample mean into the missing value slot (which is a sin against data; don’t do this). With multiple imputation, you create a small number of alternative data sets, typically 5, into which you impute plausible values into the missing value slots. With one-step Bayesian imputation using the mi() syntax, you get an entire posterior distribution for each missing value. And if you have variables in the data set that might help predict what those missing values are, you’d just plug that into the model. For more on the topic, see Bürkner’s vignette, McElreath’s lecture on the topic, or my effort to translate the chapter 14 code in McElreath’s text into brms. The take home message is there is no need to ignore missing data or use outdated procedures like listwise deletion. Be a champion and model your missing data with brms. 9.4 More than one moderator None of this is a problem for brms. But instead of using the model=i syntax in Hayes’s PROCESS, you just have to specify your model formula in brm(). 9.4.1 Additive multiple moderation. It’s trivial to add sex, its interaction with negemot, and the two covariates (i.e., posemot and ideology) to the model. We can even do it within update(). model7 &lt;- update(model1, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex + negemot:age, chains = 4, cores = 4) Our output matches nicely with the formula at the bottom of page 232 and the PROCESS output in Figure 9.2. print(model7, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ negemot + sex + age + posemot + ideology + negemot:sex + negemot:age #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 5.261 0.334 4.597 5.909 2354 1.000 #&gt; negemot 0.095 0.080 -0.057 0.258 2207 1.001 #&gt; sex -0.744 0.196 -1.121 -0.365 2267 1.002 #&gt; age -0.018 0.006 -0.030 -0.006 2111 1.002 #&gt; posemot -0.025 0.028 -0.078 0.031 4000 1.001 #&gt; ideology -0.206 0.026 -0.258 -0.155 3548 1.000 #&gt; negemot:sex 0.205 0.051 0.109 0.304 2301 1.002 #&gt; negemot:age 0.005 0.002 0.002 0.008 2190 1.002 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.048 0.026 0.997 1.101 3640 1.001 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). On page 325, Hayes discussed the unique variance each of the two moderation terms accounted for after controlling for the other covariates. In order to get our Bayesian version of these, we’ll have to fit two additional models, one after removing each of the interaction terms. model8 &lt;- update(model7, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex, chains = 4, cores = 4) model9 &lt;- update(model7, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:age, chains = 4, cores = 4) Here we’ll extract the bayes_R2() iterations for each of the three models, place them all in a single tibble, and then do a little arithmetic to get the difference scores. After all that data wrangling, we’ll summarize() as usual. r2_without_age_interaction &lt;- bayes_R2(model8, summary = F) %&gt;% as_tibble() r2_without_sex_interaction &lt;- bayes_R2(model9, summary = F) %&gt;% as_tibble() r2_with_both_interactions &lt;- bayes_R2(model7, summary = F) %&gt;% as_tibble() r2s &lt;- tibble(r2_without_age_interaction = r2_without_age_interaction$R2, r2_without_sex_interaction = r2_without_sex_interaction$R2, r2_with_both_interactions = r2_with_both_interactions$R2) %&gt;% mutate(`delta R2 due to age interaction` = r2_with_both_interactions - r2_without_age_interaction, `delta R2 due to sex interaction` = r2_with_both_interactions - r2_without_sex_interaction) r2s %&gt;% select(`delta R2 due to age interaction`:`delta R2 due to sex interaction`) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 4 #&gt; key mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 delta R2 due to age interaction 0.007 -0.049 0.064 #&gt; 2 delta R2 due to sex interaction 0.012 -0.044 0.07 Recall that \\(R^2\\) is in a 0-to-1 metric. It’s a proportion. If you want to convert that to a percentage, as in percent of variance explained, you’d just multiply by 100. To make it explicit, let’s do that. r2s %&gt;% select(`delta R2 due to age interaction`:`delta R2 due to sex interaction`) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value)*100, ll = quantile(value, probs = .025)*100, ul = quantile(value, probs = .975)*100) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 4 #&gt; key mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 delta R2 due to age interaction 0.691 -4.86 6.43 #&gt; 2 delta R2 due to sex interaction 1.23 -4.40 6.96 Hopefully it’s clear how our proportions turned percentages correspond to the figures on page 325. However, note how our 95% credible intervals do not cohere with the \\(p\\)-values from Hayes’s \\(F\\)-tests. If we want to prep for our version of Figure 9.3, we’ll need to carefully specify the predictor values we’ll pass through the fitted() function. Here we do so and save them in nd. nd &lt;- tibble(negemot = rep(seq(from = .5, to = 6.5, length.out = 30), times = 6), sex = rep(rep(0:1, each = 30), times = 3), age = rep(c(30, 50, 70), each = 60), posemot = mean(glbwarm$posemot), ideology = mean(glbwarm$ideology)) head(nd) #&gt; # A tibble: 6 x 5 #&gt; negemot sex age posemot ideology #&gt; &lt;dbl&gt; &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.5 0 30 3.13 4.08 #&gt; 2 0.707 0 30 3.13 4.08 #&gt; 3 0.914 0 30 3.13 4.08 #&gt; 4 1.12 0 30 3.13 4.08 #&gt; 5 1.33 0 30 3.13 4.08 #&gt; 6 1.53 0 30 3.13 4.08 With our nd values in hand, we’re ready to make our version of Figure 9.3. fitted(model7, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% # These lines will make the strip text match with those with Hayes&#39;s Figure mutate(sex = ifelse(sex == 0, str_c(&quot;Females, W = &quot;, sex), str_c(&quot;Males, W = &quot;, sex)), age = str_c(&quot;Age, Z, = &quot;, age)) %&gt;% # finally, the plot! ggplot(aes(x = negemot, group = sex)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = sex), alpha = 1/3, color = &quot;transparent&quot;) + geom_line(aes(y = Estimate, color = sex), size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 3:6) + labs(x = expression(paste(&quot;Negative Emotions about Climate Change, &quot;, italic(X))), y = expression(paste(&quot;Support for Government Action to Mitigate Climate Change, &quot;, italic(Y)))) + theme_xkcd() + theme(legend.position = &quot;top&quot;, legend.title = element_blank()) + facet_grid(age ~ .) 9.4.2 Moderated moderation. To fit the moderated moderation model in brms, just add to two new interaction terms to the formula. model10 &lt;- update(model7, newdata = glbwarm, govact ~ 1 + negemot + sex + age + posemot + ideology + negemot:sex + negemot:age + sex:age + negemot:sex:age, chains = 4, cores = 4) print(model10, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: govact ~ negemot + sex + age + posemot + ideology + negemot:sex + negemot:age + sex:age + negemot:sex:age #&gt; Data: glbwarm (Number of observations: 815) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 4.581 0.476 3.640 5.495 1179 1.001 #&gt; negemot 0.268 0.116 0.044 0.496 1181 1.002 #&gt; sex 0.502 0.626 -0.689 1.759 1038 1.002 #&gt; age -0.004 0.009 -0.022 0.014 1191 1.002 #&gt; posemot -0.021 0.028 -0.075 0.033 3109 1.000 #&gt; ideology -0.206 0.027 -0.259 -0.155 3245 1.001 #&gt; negemot:sex -0.123 0.164 -0.451 0.196 1073 1.002 #&gt; negemot:age 0.001 0.002 -0.004 0.006 1201 1.003 #&gt; sex:age -0.025 0.012 -0.049 -0.002 1028 1.002 #&gt; negemot:sex:age 0.007 0.003 0.001 0.013 1060 1.003 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.047 0.026 0.998 1.102 3099 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Our print() output matches fairly well with the OLS results on pages 332 and 333. Our new Bayesian \\(R^2\\) is: bayes_R2(model10) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.417 0.02 0.376 0.454 Because we haven’t changed the predictor variables in the model–just added interactions among them–there’s no need to redo our nd values. Rather, all we need to do is pass them through fitted() based on our new model10 and plot. Without further ado, here our Figure 9.6. fitted(model10, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% # These lines will make the strip text match with those with Hayes&#39;s Figure mutate(sex = ifelse(sex == 0, str_c(&quot;Females, W = &quot;, sex), str_c(&quot;Males, W = &quot;, sex)), age = str_c(&quot;Age, Z, = &quot;, age)) %&gt;% # behold, Figure 9.6! ggplot(aes(x = negemot, group = sex)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = sex), alpha = 1/3, color = &quot;transparent&quot;) + geom_line(aes(y = Estimate, color = sex), size = 1) + scale_x_continuous(breaks = 1:6) + coord_cartesian(xlim = 1:6, ylim = 3:6) + labs(x = expression(paste(&quot;Negative Emotions about Climate Change, &quot;, italic(X))), y = expression(paste(&quot;Support for Government Action to Mitigate Climate Change, &quot;, italic(Y)))) + theme_xkcd() + theme(legend.position = &quot;top&quot;, legend.title = element_blank()) + facet_grid(age ~ .) For the pick-a-point values Hayes covered on page 338, recall that when using posterior_sample(), our \\(b_{4}\\) is b_negemot:sex and our \\(b_{7}\\) is b_negemot:sex:age. post &lt;- posterior_samples(model10) post %&gt;% transmute(`age = 30` = `b_negemot:sex` + `b_negemot:sex:age`*30, `age = 50` = `b_negemot:sex` + `b_negemot:sex:age`*50, `age = 70` = `b_negemot:sex` + `b_negemot:sex:age`*70) %&gt;% gather(theta_XW_on_Y_given, value) %&gt;% group_by(theta_XW_on_Y_given) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; theta_XW_on_Y_given mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 age = 30 0.073 -0.091 0.225 #&gt; 2 age = 50 0.204 0.102 0.302 #&gt; 3 age = 70 0.334 0.177 0.491 The way we made a JN technique plot with fitted() way back in chapter 7 isn’t going to work, here. At least not as far as I can see. Rather, we’re going to have to skillfully manipulate our post object. For those new to R, this might be a little confusing at first. So I’m going to make a crude attempt first and then get more sophisticated. Crude attempt: post %&gt;% transmute(`age = 30` = `b_negemot:sex` + `b_negemot:sex:age`*30, `age = 50` = `b_negemot:sex` + `b_negemot:sex:age`*50, `age = 70` = `b_negemot:sex` + `b_negemot:sex:age`*70) %&gt;% gather(theta_XW_on_Y_given, value) %&gt;% mutate(`theta XW on Y given` = str_extract(theta_XW_on_Y_given, &quot;\\\\d+&quot;) %&gt;% as.double()) %&gt;% group_by(`theta XW on Y given`) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% # the plot ggplot(aes(x = `theta XW on Y given`)) + geom_hline(yintercept = 0) + geom_vline(xintercept = 38.114) + geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 1/2) + geom_line(aes(y = mean), size = 1) + coord_cartesian(xlim = 20:85, ylim = c(-.25, .75)) + theme_xkcd() Notice how we just took the code from our pick-a-point analysis, left out the mutate_if() rounding part, and dumped it into a plot. So one obvious approach would be to pick like 30 or 50 age values to plug into transmute() and just do the same thing. If you’re super afraid of coding, that’d be one intuitive but extremely verbose attempt. And I’ve done stuff like that earlier in my R career. There’s no shame in being extremely verbose and redundant if that’s what makes sense. Another way is to think in terms of functions. When we made age = 30 within transmute(), we took a specific age value (i.e., 30) and plugged it into the formula b_negemot:sex + b_negemot:sex:age*i where \\(i\\) = 30. And when we made age = 50 we did exactly the same thing but switched out the 30 for a 50. So what we need is a function that will take a range of values for \\(i\\), plug them into our b_negemot:sex + b_negemot:sex:age*i formula, and then neatly return the output. A nice base R function for that is sapply(). sapply(15:90, function(i){ post$`b_negemot:sex` + post$`b_negemot:sex:age`*i }) %&gt;% as_tibble() %&gt;% str() #&gt; Classes &#39;tbl_df&#39;, &#39;tbl&#39; and &#39;data.frame&#39;: 4000 obs. of 76 variables: #&gt; $ V1 : num -0.15182 -0.075 -0.10869 -0.05951 0.00328 ... #&gt; $ V2 : num -0.14322 -0.06816 -0.10258 -0.0527 0.00684 ... #&gt; $ V3 : num -0.1346 -0.0613 -0.0965 -0.0459 0.0104 ... #&gt; $ V4 : num -0.126 -0.0545 -0.0904 -0.0391 0.0139 ... #&gt; $ V5 : num -0.1174 -0.0477 -0.0843 -0.0323 0.0175 ... #&gt; $ V6 : num -0.1088 -0.0408 -0.0782 -0.0255 0.0211 ... #&gt; $ V7 : num -0.1002 -0.034 -0.0721 -0.0187 0.0246 ... #&gt; $ V8 : num -0.0916 -0.0272 -0.066 -0.0119 0.0282 ... #&gt; $ V9 : num -0.08304 -0.02032 -0.05987 -0.00508 0.03172 ... #&gt; $ V10: num -0.07445 -0.01348 -0.05377 0.00173 0.03527 ... #&gt; $ V11: num -0.06585 -0.00665 -0.04767 0.00853 0.03883 ... #&gt; $ V12: num -0.057253 0.000185 -0.041568 0.015336 0.042384 ... #&gt; $ V13: num -0.04866 0.00702 -0.03547 0.02214 0.04594 ... #&gt; $ V14: num -0.0401 0.0139 -0.0294 0.0289 0.0495 ... #&gt; $ V15: num -0.0315 0.0207 -0.0233 0.0357 0.053 ... #&gt; $ V16: num -0.0229 0.0275 -0.0172 0.0426 0.0566 ... #&gt; $ V17: num -0.0143 0.0344 -0.0111 0.0494 0.0602 ... #&gt; $ V18: num -0.00567 0.04119 -0.00496 0.05616 0.06371 ... #&gt; $ V19: num 0.00293 0.04803 0.00114 0.06296 0.06727 ... #&gt; $ V20: num 0.01152 0.05486 0.00724 0.06977 0.07082 ... #&gt; $ V21: num 0.0201 0.0617 0.0133 0.0766 0.0744 ... #&gt; $ V22: num 0.0287 0.0685 0.0194 0.0834 0.0779 ... #&gt; $ V23: num 0.0373 0.0754 0.0255 0.0902 0.0815 ... #&gt; $ V24: num 0.0459 0.0822 0.0317 0.097 0.085 ... #&gt; $ V25: num 0.0545 0.089 0.0378 0.1038 0.0886 ... #&gt; $ V26: num 0.0631 0.0959 0.0439 0.1106 0.0922 ... #&gt; $ V27: num 0.0717 0.1027 0.05 0.1174 0.0957 ... #&gt; $ V28: num 0.0803 0.1095 0.0561 0.1242 0.0993 ... #&gt; $ V29: num 0.0889 0.1164 0.0622 0.131 0.1028 ... #&gt; $ V30: num 0.0975 0.1232 0.0683 0.1378 0.1064 ... #&gt; $ V31: num 0.1061 0.13 0.0744 0.1446 0.1099 ... #&gt; $ V32: num 0.1147 0.1369 0.0805 0.1514 0.1135 ... #&gt; $ V33: num 0.1233 0.1437 0.0866 0.1582 0.117 ... #&gt; $ V34: num 0.1319 0.1505 0.0927 0.165 0.1206 ... #&gt; $ V35: num 0.1405 0.1574 0.0988 0.1718 0.1241 ... #&gt; $ V36: num 0.149 0.164 0.105 0.179 0.128 ... #&gt; $ V37: num 0.158 0.171 0.111 0.185 0.131 ... #&gt; $ V38: num 0.166 0.178 0.117 0.192 0.135 ... #&gt; $ V39: num 0.175 0.185 0.123 0.199 0.138 ... #&gt; $ V40: num 0.183 0.192 0.129 0.206 0.142 ... #&gt; $ V41: num 0.192 0.198 0.135 0.213 0.145 ... #&gt; $ V42: num 0.201 0.205 0.141 0.219 0.149 ... #&gt; $ V43: num 0.209 0.212 0.148 0.226 0.153 ... #&gt; $ V44: num 0.218 0.219 0.154 0.233 0.156 ... #&gt; $ V45: num 0.226 0.226 0.16 0.24 0.16 ... #&gt; $ V46: num 0.235 0.233 0.166 0.247 0.163 ... #&gt; $ V47: num 0.244 0.239 0.172 0.253 0.167 ... #&gt; $ V48: num 0.252 0.246 0.178 0.26 0.17 ... #&gt; $ V49: num 0.261 0.253 0.184 0.267 0.174 ... #&gt; $ V50: num 0.269 0.26 0.19 0.274 0.177 ... #&gt; $ V51: num 0.278 0.267 0.196 0.281 0.181 ... #&gt; $ V52: num 0.287 0.274 0.202 0.287 0.185 ... #&gt; $ V53: num 0.295 0.28 0.209 0.294 0.188 ... #&gt; $ V54: num 0.304 0.287 0.215 0.301 0.192 ... #&gt; $ V55: num 0.312 0.294 0.221 0.308 0.195 ... #&gt; $ V56: num 0.321 0.301 0.227 0.315 0.199 ... #&gt; $ V57: num 0.33 0.308 0.233 0.322 0.202 ... #&gt; $ V58: num 0.338 0.315 0.239 0.328 0.206 ... #&gt; $ V59: num 0.347 0.321 0.245 0.335 0.209 ... #&gt; $ V60: num 0.355 0.328 0.251 0.342 0.213 ... #&gt; $ V61: num 0.364 0.335 0.257 0.349 0.217 ... #&gt; $ V62: num 0.373 0.342 0.264 0.356 0.22 ... #&gt; $ V63: num 0.381 0.349 0.27 0.362 0.224 ... #&gt; $ V64: num 0.39 0.356 0.276 0.369 0.227 ... #&gt; $ V65: num 0.398 0.362 0.282 0.376 0.231 ... #&gt; $ V66: num 0.407 0.369 0.288 0.383 0.234 ... #&gt; $ V67: num 0.416 0.376 0.294 0.39 0.238 ... #&gt; $ V68: num 0.424 0.383 0.3 0.396 0.241 ... #&gt; $ V69: num 0.433 0.39 0.306 0.403 0.245 ... #&gt; $ V70: num 0.441 0.397 0.312 0.41 0.249 ... #&gt; $ V71: num 0.45 0.403 0.318 0.417 0.252 ... #&gt; $ V72: num 0.459 0.41 0.325 0.424 0.256 ... #&gt; $ V73: num 0.467 0.417 0.331 0.43 0.259 ... #&gt; $ V74: num 0.476 0.424 0.337 0.437 0.263 ... #&gt; $ V75: num 0.484 0.431 0.343 0.444 0.266 ... #&gt; $ V76: num 0.493 0.438 0.349 0.451 0.27 ... Okay, to that looks a little monstrous. But what we did in the first argument in sapply() was tell the function which values we’d like to use in some function. We chose each integer ranging from 15 to 90–which, if you do the math, is 76 values. We then told sapply() to plug those values into a custom function, which we defined as function(i){post$b_negemot:sex + post$b_negemot:sex:age*i}. In our custom function, i was a placeholder for each of those 76 integers. But remember that post has 4000 rows, each one corresponding to one of the 4000 posterior iterations. Thus, for each of our 76 i-values, we got 4000 results. The sapply() function returns a matrix. Since we like to work within the tidyverse and use ggplot2, we just went ahead and put those results in a tibble. Anyway, with our sapply() output in hand, all we need to do is a little more indexing and summarizing and we’re ready to plot. The result is our very own version of Figure 9.7. sapply(15:90, function(i){ post$`b_negemot:sex` + post$`b_negemot:sex:age`*i }) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(age = rep(15:90, each = 4000)) %&gt;% group_by(age) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% ggplot(aes(x = age)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_vline(xintercept = 38.114, color = &quot;grey75&quot;) + geom_ribbon(aes(ymin = ll, ymax = ul), alpha = 1/2) + geom_line(aes(y = mean), size = 1) + coord_cartesian(xlim = 20:85, ylim = c(-.25, .75)) + labs(x = expression(paste(&quot;Age, &quot;, italic(Z))), y = &quot;Conditional Two-way Interaction Between\\nNegative Emotions and Sex&quot;) + theme_xkcd() Or for kicks and giggles, another way to get a clearer sense of how our data informed the shape of the plot, here we replace our geom_ribbon() + geom_line() code with geom_pointrange(). sapply(15:90, function(i){ post$`b_negemot:sex` + post$`b_negemot:sex:age`*i }) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(age = rep(15:90, each = 4000)) %&gt;% group_by(age) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% ggplot(aes(x = age)) + geom_hline(yintercept = 0, color = &quot;grey75&quot;) + geom_vline(xintercept = 38.114, color = &quot;grey75&quot;) + geom_pointrange(aes(y = mean, ymin = ll, ymax = ul), shape = 16, size = 1/3) + coord_cartesian(xlim = 20:85, ylim = c(-.25, .75)) + labs(x = expression(paste(&quot;Age, &quot;, italic(Z))), y = &quot;Conditional Two-way Interaction Between\\nNegative Emotions and Sex&quot;) + theme_xkcd() Although I probably wouldn’t try to use a plot like this in a manuscript, I hope it makes clear how the way we’ve been implementing the JN technique is just the pick-a-point approach in bulk. No magic. For all you tidyverse fanatics out there, don’t worry. There are more tidyverse-centric ways to get the plot values than with sapply(). We’ll get to them soon enough. It’s advantageous to have good old base R sapply() up your sleeve, too. And new R users, it’s helpful to know that sapply() is one part of the apply() family of base R functions, which you might learn more about here or here or here. 9.5 Comparing conditional effects 9.5.1 Comparing conditional effects in the additive multiple moderation model. 9.5.2 Comparing conditional effects in the moderated moderation model. 9.5.3 Implementation in PROCESS brms. Since we don’t have the contrast feature automated like in PROCESS, we’ll have to carefully follow the equations at the bottom of page 344 to specify the values properly in R. post %&gt;% transmute(`30-year-old men` = b_negemot + `b_negemot:sex`*1 + `b_negemot:age`*30 + `b_negemot:sex:age`*1*30, `50-year-old women` = b_negemot + `b_negemot:sex`*0 + `b_negemot:age`*50 + `b_negemot:sex:age`*0*30) %&gt;% mutate(contrast = `30-year-old men` - `50-year-old women`) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean sd ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 30-year-old men 0.371 0.062 0.245 0.492 #&gt; 2 50-year-old women 0.318 0.037 0.246 0.391 #&gt; 3 contrast 0.053 0.072 -0.089 0.186 Notice how our posterior \\(SD\\) corresponded nicely to the standard error in Hayes’s contrast test. And we didn’t even have to worry about using the frightening formula 9.21 on page 345. That information was contained in the posterior distribution all along. All we had to do was combine the parameter iterations with a little algebra and then summarize(). References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] bayesplot_1.5.0 xkcd_0.0.6 extrafont_0.17 brms_2.3.4 Rcpp_0.12.17 bindrcpp_0.2.2 #&gt; [7] forcats_0.3.0 stringr_1.3.1 dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 tidyr_0.8.1 #&gt; [13] tibble_1.4.2 ggplot2_3.0.0 tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] colorspace_1.3-2 ggridges_0.5.0 rsconnect_0.8.8 rprojroot_1.3-2 #&gt; [5] htmlTable_1.12 markdown_0.8 base64enc_0.1-3 rstudioapi_0.7 #&gt; [9] rstan_2.17.3 DT_0.4 mvtnorm_1.0-8 lubridate_1.7.4 #&gt; [13] xml2_1.2.0 codetools_0.2-15 bridgesampling_0.4-0 splines_3.5.1 #&gt; [17] mnormt_1.5-5 knitr_1.20 shinythemes_1.1.1 Formula_1.2-3 #&gt; [21] jsonlite_1.5 broom_0.4.5 Rttf2pt1_1.3.7 cluster_2.0.7-1 #&gt; [25] shiny_1.1.0 compiler_3.5.1 httr_1.3.1 backports_1.1.2 #&gt; [29] assertthat_0.2.0 Matrix_1.2-14 lazyeval_0.2.1 cli_1.0.0 #&gt; [33] later_0.7.3 acepack_1.4.1 htmltools_0.3.6 tools_3.5.1 #&gt; [37] igraph_1.2.1 coda_0.19-1 gtable_0.2.0 glue_1.2.0 #&gt; [41] reshape2_1.4.3 cellranger_1.1.0 nlme_3.1-137 extrafontdb_1.0 #&gt; [45] crosstalk_1.0.0 psych_1.8.4 xfun_0.3 rvest_0.3.2 #&gt; [49] mime_0.5 miniUI_0.1.1.1 gtools_3.8.1 zoo_1.8-2 #&gt; [53] scales_0.5.0 colourpicker_1.0 hms_0.4.2 promises_1.0.1 #&gt; [57] Brobdingnag_1.2-5 parallel_3.5.1 inline_0.3.15 shinystan_2.5.0 #&gt; [61] RColorBrewer_1.1-2 yaml_2.1.19 gridExtra_2.3 loo_2.0.0 #&gt; [65] StanHeaders_2.17.2 rpart_4.1-13 latticeExtra_0.6-28 stringi_1.2.3 #&gt; [69] dygraphs_1.1.1.5 checkmate_1.8.5 rlang_0.2.1 pkgconfig_2.0.1 #&gt; [73] matrixStats_0.53.1 evaluate_0.10.1 lattice_0.20-35 bindr_0.1.1 #&gt; [77] labeling_0.3 rstantools_1.5.0 htmlwidgets_1.2 tidyselect_0.2.4 #&gt; [81] plyr_1.8.4 magrittr_1.5 bookdown_0.7 R6_2.2.2 #&gt; [85] Hmisc_4.1-1 pillar_1.2.3 haven_1.1.2 foreign_0.8-70 #&gt; [89] withr_2.1.2 xts_0.10-2 nnet_7.3-12 survival_2.42-3 #&gt; [93] abind_1.4-5 modelr_0.1.2 crayon_1.3.4 utf8_1.1.4 #&gt; [97] rmarkdown_1.10 grid_3.5.1 readxl_1.1.0 data.table_1.11.4 #&gt; [101] threejs_0.3.1 digest_0.6.15 xtable_1.8-2 httpuv_1.4.4.2 #&gt; [105] stats4_3.5.1 munsell_0.5.0 shinyjs_1.0 "],
["multicategorical-focal-antecedents-and-moderators.html", "10 Multicategorical Focal Antecedents and Moderators 10.1 Moderation of the effect of a multicategorical antecedent variable 10.2 An example from the sex disrimination in the workplace study 10.3 Visualizing the model 10.4 Probing the interaction 10.5 When the moderator is multicategorical References Session info", " 10 Multicategorical Focal Antecedents and Moderators 10.1 Moderation of the effect of a multicategorical antecedent variable 10.2 An example from the sex disrimination in the workplace study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) #&gt; Observations: 129 #&gt; Variables: 6 #&gt; $ subnum &lt;int&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109, 122, 69, 45, 28, 170, 66... #&gt; $ protest &lt;int&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2, 2, 1, 2, 1, 1, 2, 2, 0, ... #&gt; $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75, 4.62, 4.75, 6.12, 4.87, ... #&gt; $ angry &lt;int&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1, 3, 4, 1, 1, 1, 5, 1, 5, ... #&gt; $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00, 6.83, 5.00, 5.66, 5.83, ... #&gt; $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00, 5.75, 5.25, 7.00, 4.50, ... With a little ifelse(), computing the dummies D1 and D2 is easy enough. protest &lt;- protest %&gt;% mutate(D1 = ifelse(protest == 1, 1, 0), D2 = ifelse(protest == 2, 1, 0)) Load brms. library(brms) With model1 and model2 we fit the multicategorical multivariable model and the multicategorical moderation models, respectively. model1 &lt;- brm(data = protest, family = gaussian, liking ~ 1 + D1 + D2 + sexism, chains = 4, cores = 4) model2 &lt;- update(model1, newdata = protest, liking ~ 1 + D1 + D2 + sexism + D1:sexism + D2:sexism, chains = 4, cores = 4) r2s &lt;- bayes_R2(model1, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model 1` = R2) %&gt;% bind_cols( bayes_R2(model2, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model 2` = R2) ) %&gt;% mutate(`The R2 difference` = `Model 2` - `Model 1`) r2s %&gt;% gather() %&gt;% # This line isn&#39;t necessary, but it sets the order the summaries appear in mutate(key = factor(key, levels = c(&quot;Model 1&quot;, &quot;Model 2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean median ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Model 1 0.071 0.067 0.011 0.156 #&gt; 2 Model 2 0.155 0.155 0.066 0.252 #&gt; 3 The R2 difference 0.084 0.085 -0.033 0.201 Interestingly, even though our posterior means and medians for the model-specific \\(R^2\\) values differed some from the OLS estimates in the text, their difference corresponded quite nicely to the one in the text. Let’s take a look at their values. r2s %&gt;% gather() %&gt;% ggplot(aes(x = value)) + geom_density(size = 0, fill = &quot;grey33&quot;) + scale_y_continuous(NULL, breaks = NULL) + facet_wrap(~key, scales = &quot;free_y&quot;) + theme_minimal() The coefficient summaries cohere well with those in Table 10.1. print(model1, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: liking ~ 1 + D1 + D2 + sexism #&gt; Data: protest (Number of observations: 129) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 4.747 0.640 3.475 5.989 4000 1.000 #&gt; D1 0.498 0.228 0.048 0.932 4000 1.000 #&gt; D2 0.443 0.221 0.023 0.872 4000 1.000 #&gt; sexism 0.111 0.122 -0.127 0.354 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.044 0.068 0.919 1.184 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). print(model2, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: liking ~ D1 + D2 + sexism + D1:sexism + D2:sexism #&gt; Data: protest (Number of observations: 129) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 7.660 1.032 5.697 9.701 1584 1.000 #&gt; D1 -4.071 1.465 -6.933 -1.150 1624 1.000 #&gt; D2 -3.439 1.405 -6.239 -0.730 1466 1.000 #&gt; sexism -0.464 0.201 -0.863 -0.077 1565 1.000 #&gt; D1:sexism 0.890 0.280 0.334 1.427 1604 1.000 #&gt; D2:sexism 0.769 0.274 0.238 1.315 1442 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.005 0.066 0.882 1.143 2748 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). 10.3 Visualizing the model To get our version of the values in Table 10.2, we’ll first recreate columns \\(D_{1}\\) through \\(W\\) (SEXISM) and save then as a tibble, nd. ( nd &lt;- tibble(D1 = rep(c(0, 1, 0), each = 3), D2 = rep(c(0, 0, 1), each = 3), sexism = rep(quantile(protest$sexism, probs = c(.16, .5, .84)), times = 3)) ) #&gt; # A tibble: 9 x 3 #&gt; D1 D2 sexism #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 0 4.31 #&gt; 2 0 0 5.12 #&gt; 3 0 0 5.87 #&gt; 4 1 0 4.31 #&gt; 5 1 0 5.12 #&gt; 6 1 0 5.87 #&gt; # ... with 3 more rows With nd in hand, we’ll feed the predictor values into fitted() for the typical posterior summaries. fitted(model2, newdata = nd) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 5.66 0.218 5.25 6.10 #&gt; [2,] 5.29 0.155 4.98 5.60 #&gt; [3,] 4.94 0.223 4.49 5.37 #&gt; [4,] 5.43 0.245 4.94 5.92 #&gt; [5,] 5.77 0.155 5.48 6.08 #&gt; [6,] 6.09 0.195 5.72 6.48 #&gt; [7,] 5.53 0.202 5.14 5.92 #&gt; [8,] 5.78 0.151 5.49 6.07 #&gt; [9,] 6.01 0.215 5.59 6.42 But is we want to make a decent line plot, we’ll need many more values for sexism, which will appear on the x-axis. nd &lt;- tibble(sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), times = 9), D1 = rep(rep(c(0, 1, 0), each = 3), each = 30), D2 = rep(rep(c(0, 0, 1), each = 3), each = 30)) This time we’ll save the results from fitted() as a tlbble and wrangle a bit to get ready for Figure 10.3. model2_fitted &lt;- fitted(model2, newdata = nd, probs = c(.025, .25, .75, .975)) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(condition = rep(c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;), each = 3*30)) %&gt;% # This line is not necessary, but it will help order the facets of the plot mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) glimpse(model2_fitted) #&gt; Observations: 270 #&gt; Variables: 10 #&gt; $ Estimate &lt;dbl&gt; 6.04, 5.99, 5.94, 5.89, 5.84, 5.80, 5.75, 5.70, 5.65, 5.60, 5.56, 5.51, 5.46,... #&gt; $ Est.Error &lt;dbl&gt; 0.352, 0.333, 0.315, 0.297, 0.280, 0.263, 0.246, 0.230, 0.215, 0.202, 0.189, ... #&gt; $ Q2.5 &lt;dbl&gt; 5.35, 5.34, 5.33, 5.31, 5.30, 5.28, 5.27, 5.26, 5.24, 5.22, 5.20, 5.17, 5.14,... #&gt; $ Q25 &lt;dbl&gt; 5.80, 5.76, 5.73, 5.69, 5.65, 5.62, 5.58, 5.54, 5.50, 5.46, 5.43, 5.39, 5.35,... #&gt; $ Q75 &lt;dbl&gt; 6.27, 6.21, 6.15, 6.09, 6.03, 5.97, 5.91, 5.85, 5.80, 5.74, 5.68, 5.63, 5.57,... #&gt; $ Q97.5 &lt;dbl&gt; 6.72, 6.64, 6.56, 6.48, 6.39, 6.32, 6.24, 6.17, 6.09, 6.01, 5.94, 5.86, 5.80,... #&gt; $ sexism &lt;dbl&gt; 3.50, 3.60, 3.71, 3.81, 3.91, 4.02, 4.12, 4.22, 4.33, 4.43, 4.53, 4.64, 4.74,... #&gt; $ D1 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... #&gt; $ D2 &lt;dbl&gt; 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,... #&gt; $ condition &lt;fct&gt; No Protest, No Protest, No Protest, No Protest, No Protest, No Protest, No Pr... For Figure 10.3 and many to follow for this chapter, we’ll superimpose 50% intervals on top of 95% intervals. # This will help us add the original data points to the plot protest &lt;- protest %&gt;% mutate(condition = ifelse(protest == 0, &quot;No Protest&quot;, ifelse(protest == 1, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # This will help us with the x-axis breaks &lt;- tibble(values = quantile(protest$sexism, probs = c(.16, .5, .84))) %&gt;% mutate(labels = values %&gt;% round(2) %&gt;% as.character()) # Here we plot model2_fitted %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/3) + geom_ribbon(aes(ymin = Q25, ymax = Q75), alpha = 1/3) + geom_line(aes(y = Estimate)) + geom_point(data = protest, aes(y = liking), size = 2/3) + scale_x_continuous(breaks = breaks$values, labels = breaks$labels) + coord_cartesian(xlim = 4:6, ylim = c(2.5, 7.2)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + facet_wrap(~condition) + theme_minimal() By adding the data to the plots, they are both more informative and now serve as a posterior predictive check. 10.4 Probing the interaction 10.4.1 The pick-a-point approach. 10.4.1.1 Omnibus inference. Hayes used the omnibus testing framework to assess how important coefficients \\(b_{1}\\) and \\(b_{2}\\) were to our interaction model, model1. Before fitting the models, he discussed why he preferred to fit models after centering sexism (i.e., \\(W\\)) to 4.25. Here we’ll call our centered variable sexism_p, where _p stands in for “prime”. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 4.25) From here on, model3 is the moderation model without the lower-order D1 and D2 terms; model4 is the full moderation model. # The model without D1 + D2 model3 &lt;- update(model2, newdata = protest, liking ~ 1 + sexism_p + D1:sexism_p + D2:sexism_p, chains = 4, cores = 4) # The full model with D1 + D2 model4 &lt;- update(model2, newdata = protest, liking ~ 1 + D1 + D2 + sexism_p + D1:sexism_p + D2:sexism_p, chains = 4, cores = 4) The coefficient summaries for model4 correspond to the top section of Table 10.3 (p. 373). fixef(model4) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 5.702 0.233 5.238 6.170 #&gt; D1 -0.307 0.343 -0.988 0.377 #&gt; D2 -0.197 0.311 -0.830 0.407 #&gt; sexism_p -0.478 0.207 -0.887 -0.070 #&gt; D1:sexism_p 0.911 0.291 0.332 1.489 #&gt; D2:sexism_p 0.788 0.275 0.260 1.322 We can compare their Bayesian \\(R^2\\) distributions like we usually do. r2s &lt;- bayes_R2(model3, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model without D1 + D2` = R2) %&gt;% bind_cols( bayes_R2(model4, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model with D1 + D2` = R2) ) %&gt;% mutate(`The R2 difference` = `Model with D1 + D2` - `Model without D1 + D2`) r2s %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Model without D1 + D2&quot;, &quot;Model with D1 + D2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; key median ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Model without D1 + D2 0.142 0.052 0.242 #&gt; 2 Model with D1 + D2 0.156 0.065 0.255 #&gt; 3 The R2 difference 0.013 -0.126 0.149 Our results differ a bit from those in the text, but the substantive interpretation is the same. The D1 and D2 parameters added little predictive power to the model in terms of \\(R^2\\). We can also use information criteria to compare the models. Here are the results from using the LOO-CV. loo(model3, model4, reloo = T) #&gt; LOOIC SE #&gt; model3 371.93 22.15 #&gt; model4 374.69 21.76 #&gt; model3 - model4 -2.76 1.76 [When I ran the loo() without the reloo argument, I got a warning message about an observation with an overly-large pareto \\(k\\) value. Setting reloo = T fixed the problem.] The LOO-CV difference between the two models was pretty small and its standard error was of about the same magnitude of its difference. Thus, the LOO-CV gives the same general message as the \\(R^2\\). The D1 and D2 parameters were sufficiently small and uncertain enough that constraining them to zero did little in terms of reducing the explanatory power of the statistical model. Here’s the same thing all over again, but this time after centering sexism on 5.120. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 5.120) # The model without D1 + D2 model3 &lt;- update(model2, newdata = protest, liking ~ 1 + sexism_p + D1:sexism_p + D2:sexism_p, chains = 4, cores = 4) # The full model with D1 + D2 model4 &lt;- update(model2, newdata = protest, liking ~ 1 + D1 + D2 + sexism_p + D1:sexism_p + D2:sexism_p, chains = 4, cores = 4) These coefficient summaries correspond to the middle section of Table 10.3 (p. 373). fixef(model4) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 5.288 0.160 4.975 5.598 #&gt; D1 0.481 0.222 0.042 0.909 #&gt; D2 0.488 0.219 0.054 0.910 #&gt; sexism_p -0.475 0.215 -0.897 -0.057 #&gt; D1:sexism_p 0.906 0.299 0.320 1.488 #&gt; D2:sexism_p 0.780 0.284 0.219 1.352 Here are the Bayesian \\(R^2\\) summaries and the summary for their difference. r2s &lt;- bayes_R2(model3, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model without D1 + D2` = R2) %&gt;% bind_cols( bayes_R2(model4, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model with D1 + D2` = R2) ) %&gt;% mutate(`The R2 difference` = `Model with D1 + D2` - `Model without D1 + D2`) r2s %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Model without D1 + D2&quot;, &quot;Model with D1 + D2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; key median ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Model without D1 + D2 0.099 0.026 0.196 #&gt; 2 Model with D1 + D2 0.155 0.065 0.258 #&gt; 3 The R2 difference 0.054 -0.075 0.182 loo(model3, model4) #&gt; LOOIC SE #&gt; model3 377.35 23.74 #&gt; model4 375.16 21.77 #&gt; model3 - model4 2.19 6.04 Here again our Bayesian \\(R^2\\) and loo() results cohere, both suggesting the D1 and D2 parameters were of little predictive utility. Note how this differs a little from the second \\(F\\)-test on page 370. Here’s what happens when we center sexism on 5.896. protest &lt;- protest %&gt;% mutate(sexism_p = sexism - 5.896) # The model without D1 + D2 model3 &lt;- update(model2, newdata = protest, liking ~ 1 + sexism_p + D1:sexism_p + D2:sexism_p, chains = 4, cores = 4) # The full model with D1 + D2 model4 &lt;- update(model2, newdata = protest, liking ~ 1 + D1 + D2 + sexism_p + D1:sexism_p + D2:sexism_p, chains = 4, cores = 4) These coefficient summaries correspond to the lower section of Table 10.3 (p. 373). fixef(model4) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; Intercept 4.921 0.230 4.460 5.361 #&gt; D1 1.180 0.307 0.585 1.795 #&gt; D2 1.096 0.315 0.505 1.721 #&gt; sexism_p -0.470 0.204 -0.862 -0.077 #&gt; D1:sexism_p 0.900 0.286 0.340 1.462 #&gt; D2:sexism_p 0.775 0.272 0.261 1.321 Again, the \\(R^2\\) distributions and their difference-score distribution. r2s &lt;- bayes_R2(model3, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model without D1 + D2` = R2) %&gt;% bind_cols( bayes_R2(model4, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model with D1 + D2` = R2) ) %&gt;% mutate(`The R2 difference` = `Model with D1 + D2` - `Model without D1 + D2`) r2s %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Model without D1 + D2&quot;, &quot;Model with D1 + D2&quot;, &quot;The R2 difference&quot;))) %&gt;% group_by(key) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; key median ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Model without D1 + D2 0.027 0.003 0.089 #&gt; 2 Model with D1 + D2 0.154 0.063 0.256 #&gt; 3 The R2 difference 0.124 0.022 0.232 loo(model3, model4) #&gt; LOOIC SE #&gt; model3 387.2 26.7 #&gt; model4 374.6 21.9 #&gt; model3 - model4 12.7 11.1 Although our Bayesian \\(R^2\\) difference is now predominantly positive, the LOO-CV difference for the two models remains uncertain. Here’s a look at the two parameters in question using a handmade coefficient plot. posterior_samples(model4) %&gt;% select(b_D1:b_D2) %&gt;% gather() %&gt;% mutate(key = str_remove(key, &quot;b_&quot;)) %&gt;% ggplot(aes(key, y = value)) + stat_summary(fun.y = median, fun.ymin = function(i){quantile(i, probs = .025)}, fun.ymax = function(i){quantile(i, probs = .975)}, color = &quot;grey33&quot;) + stat_summary(geom = &quot;linerange&quot;, fun.ymin = function(i){quantile(i, probs = .25)}, fun.ymax = function(i){quantile(i, probs = .75)}, color = &quot;grey33&quot;, size = 1.25) + xlab(NULL) + coord_flip(ylim = 0:2) + theme_minimal() For Figure 10.4, we’ll drop our faceting approach and just make one big plot. Heads up: I’m going to drop the 50% intervals from this plot. They’d just make it too busy. model2_fitted %&gt;% ggplot(aes(x = sexism, alpha = condition)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), size = 0) + geom_line(aes(y = Estimate)) + scale_alpha_manual(values = c(.2, .5, .8)) + scale_x_continuous(breaks = breaks$values, labels = breaks$labels) + coord_cartesian(xlim = 4:6, ylim = c(4.5, 6.7)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + theme_minimal() + theme(legend.title = element_blank(), legend.position = &quot;top&quot;, legend.direction = &quot;vertical&quot;) 10.4.1.2 Pairwise inference. To “consider the effect of Catherine’s behavior on how she is perceived among people who are relatively high in their perceptions of the pervasiveness of sex discrimination in society (p. 372)”, we’ll use fitted(). Since the number of unique predictor values is small for this example, we’ll just plug them directly into the newdata argument rather than first saving them as a nd object. fitted(model2, newdata = tibble(D1 = c(0, 1, 0), D2 = c(0, 0, 1), sexism = 5.896)) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; [1,] 4.92 0.227 4.47 5.36 #&gt; [2,] 6.10 0.199 5.72 6.50 #&gt; [3,] 6.02 0.219 5.59 6.44 Note that for these analyses, we just used model2, the model based on the un-centered sexism variable. We can also continue using fitted() in conjunction with the original model2 to get the group comparisons for when \\(W\\) = 4.250. Since these involve computing difference scores, we’ll have to use summary = F and do some wrangling. fitted(model2, newdata = tibble(D1 = c(0, 1, 0), D2 = c(0, 0, 1), sexism = 4.25), summary = F) %&gt;% as_tibble() %&gt;% rename(`No Protest` = V1, `Individual Protest` = V2, `Collective Protest` = V3) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 5 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 No Protest 5.69 0.227 5.26 6.15 #&gt; 2 Individual Protest 5.40 0.254 4.9 5.91 #&gt; 3 Collective Protest 5.52 0.21 5.12 5.92 #&gt; 4 difference_a -0.287 0.341 -0.962 0.392 #&gt; 5 difference_b -0.172 0.312 -0.802 0.434 Here’s the same thing for when \\(W\\) = 5.120. fitted(model2, newdata = tibble(D1 = c(0, 1, 0), D2 = c(0, 0, 1), sexism = 5.120), summary = F) %&gt;% as_tibble() %&gt;% rename(`No Protest` = V1, `Individual Protest` = V2, `Collective Protest` = V3) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 5 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 No Protest 5.28 0.155 4.98 5.60 #&gt; 2 Individual Protest 5.77 0.155 5.48 6.08 #&gt; 3 Collective Protest 5.78 0.151 5.49 6.07 #&gt; 4 difference_a 0.488 0.221 0.044 0.907 #&gt; 5 difference_b 0.497 0.22 0.053 0.915 Finally, here it is for when \\(W\\) = 5.986. fitted(model2, newdata = tibble(D1 = c(0, 1, 0), D2 = c(0, 0, 1), sexism = 5.986), summary = F) %&gt;% as_tibble() %&gt;% rename(`No Protest` = V1, `Individual Protest` = V2, `Collective Protest` = V3) %&gt;% mutate(difference_a = `Individual Protest` - `No Protest`, difference_b = `Collective Protest` - `No Protest`) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;difference_a&quot;, &quot;difference_b&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 5 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 No Protest 4.88 0.24 4.40 5.35 #&gt; 2 Individual Protest 6.14 0.211 5.73 6.56 #&gt; 3 Collective Protest 6.05 0.231 5.60 6.49 #&gt; 4 difference_a 1.26 0.315 0.639 1.87 #&gt; 5 difference_b 1.16 0.335 0.497 1.82 10.4.2 The Johnson-Neyman technique. 10.4.2.1 Omnibus inference. Consider the first sentence of the section: Applied to probing an interaction between a multicategorical \\(X\\) and a continuous \\(W\\), an omnibus version of the JM technique involves finding the value or values of \\(W\\) where their \\(F\\)-ratio comparing the \\(g\\) estimated values of \\(Y\\) is just statistically significant. Since we’re not using \\(F\\)-tests with our approach to Bayesian modeling, the closest we might have is a series of \\(R^2\\) difference tests, which would require refitting the model multiple times over many ways of centering the \\(W\\)-variable, sexism. I suppose you could do this if you wanted, but it just seems silly, to me. I’ll leave this one up to the interested reader. 10.4.2.2 Pairwise inference. Hayes didn’t make plots for this section, but if you’re careful constructing your nd and with the subsequent wrangling, you can make the usual plots. Since we have two conditions we’d like to compare with No Protest, we’ll make two plots. Here’s the comparison using Individual Protest, first. # the transition value Hayes identified in the text Hayes_value &lt;- 5.065 nd &lt;- tibble(D1 = rep(0:1, each = 30), D2 = rep(0, times = 30*2), sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), times = 2)) # we need some new data fitted(model2, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(sexism = rep(rep(seq(from = 3.5, to = 6.5, length.out = 30), each = 4000), times = 2)) %&gt;% mutate(condition = rep(c(&quot;No Protest&quot;, &quot;Individual Protest&quot;), each = 4000*30)) %&gt;% mutate(iter = rep(1:4000, times = 30*2)) %&gt;% select(-key) %&gt;% rename(estimate = value) %&gt;% spread(key = condition, value = estimate) %&gt;% mutate(difference = `Individual Protest` - `No Protest`) %&gt;% # the plot ggplot(aes(x = sexism, y = difference)) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i){quantile(i, probs = .025)}, fun.ymax = function(i){quantile(i, probs = .975)}, alpha = 1/3) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i){quantile(i, probs = .25)}, fun.ymax = function(i){quantile(i, probs = .75)}, alpha = 1/3) + stat_summary(geom = &quot;line&quot;, fun.y = median) + scale_x_continuous(breaks = c(4, Hayes_value, 6), labels = c(&quot;4&quot;, Hayes_value, &quot;6&quot;)) + coord_cartesian(xlim = 4:6) + labs(subtitle = expression(paste(&quot;Our JN-technique plot for &quot;, italic(&quot;Individual Protest&quot;), &quot; compared with &quot;, italic(&quot;No Protest&quot;)))) + theme_minimal() Now we’re ready to compare No Protest to Collective Protest. The main difference is with the rep() code in the D1 and D2 columns in nd. Other than that, we just switched out a few “Individual” labels with “Collective”. # the transition value Hayes identified in the text Hayes_value &lt;- 5.036 nd &lt;- tibble(D1 = rep(0, times = 30*2), D2 = rep(0:1, each = 30), sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), times = 2)) fitted(model2, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(sexism = rep(rep(seq(from = 3.5, to = 6.5, length.out = 30), each = 4000), times = 2)) %&gt;% mutate(condition = rep(c(&quot;No Protest&quot;, &quot;Collective Protest&quot;), each = 4000*30)) %&gt;% mutate(iter = rep(1:4000, times = 30*2)) %&gt;% select(-key) %&gt;% rename(estimate = value) %&gt;% spread(key = condition, value = estimate) %&gt;% mutate(difference = `Collective Protest` - `No Protest`) %&gt;% ggplot(aes(x = sexism, y = difference)) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i){quantile(i, probs = .025)}, fun.ymax = function(i){quantile(i, probs = .975)}, alpha = 1/3) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i){quantile(i, probs = .25)}, fun.ymax = function(i){quantile(i, probs = .75)}, alpha = 1/3) + stat_summary(geom = &quot;line&quot;, fun.y = median) + scale_x_continuous(breaks = c(4, Hayes_value, 6), labels = c(&quot;4&quot;, Hayes_value, &quot;6&quot;)) + coord_cartesian(xlim = 4:6) + labs(subtitle = expression(paste(&quot;Our JN-technique plot for &quot;, italic(&quot;Collective Protest&quot;), &quot; compared with &quot;, italic(&quot;No Protest&quot;)))) + theme_minimal() And here we do it one last time between the two active protest conditions. nd &lt;- tibble(D1 = rep(1:0, each = 30), D2 = rep(0:1, each = 30), sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), times = 2)) fitted(model2, newdata = nd, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(sexism = rep(rep(seq(from = 3.5, to = 6.5, length.out = 30), each = 4000), times = 2)) %&gt;% mutate(condition = rep(c(&quot;Individual Protest&quot;, &quot;Collective Protest&quot;), each = 4000*30)) %&gt;% mutate(iter = rep(1:4000, times = 30*2)) %&gt;% select(-key) %&gt;% rename(estimate = value) %&gt;% spread(key = condition, value = estimate) %&gt;% mutate(difference = `Collective Protest` - `Individual Protest`) %&gt;% ggplot(aes(x = sexism, y = difference)) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i){quantile(i, probs = .025)}, fun.ymax = function(i){quantile(i, probs = .975)}, alpha = 1/3) + stat_summary(geom = &quot;ribbon&quot;, fun.ymin = function(i){quantile(i, probs = .25)}, fun.ymax = function(i){quantile(i, probs = .75)}, alpha = 1/3) + stat_summary(geom = &quot;line&quot;, fun.y = median) + coord_cartesian(xlim = 4:6) + labs(subtitle = expression(paste(&quot;Our JN-technique plot for &quot;, italic(&quot;Collective Protest&quot;), &quot; compared with &quot;, italic(&quot;Individual Protest&quot;)))) + theme_minimal() Not much difference there. 10.5 When the moderator is multicategorical 10.5.1 An example. Just as a refresher, here’s the print() output for model2. print(model2, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: liking ~ D1 + D2 + sexism + D1:sexism + D2:sexism #&gt; Data: protest (Number of observations: 129) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 7.660 1.032 5.697 9.701 1584 1.000 #&gt; D1 -4.071 1.465 -6.933 -1.150 1624 1.000 #&gt; D2 -3.439 1.405 -6.239 -0.730 1466 1.000 #&gt; sexism -0.464 0.201 -0.863 -0.077 1565 1.000 #&gt; D1:sexism 0.890 0.280 0.334 1.427 1604 1.000 #&gt; D2:sexism 0.769 0.274 0.238 1.315 1442 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.005 0.066 0.882 1.143 2748 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The Bayesian \\(R^2\\): bayes_R2(model2) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2 0.155 0.048 0.066 0.252 And the \\(R^2\\) difference between this and the model excluding the interaction terms: bayes_R2(model1, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model 1` = R2) %&gt;% bind_cols( bayes_R2(model2, summary = F) %&gt;% as_tibble() %&gt;% rename(`Model 2` = R2) ) %&gt;% transmute(difference = `Model 2` - `Model 1`) %&gt;% summarize(mean = mean(difference), ll = quantile(difference, probs = .025), ul = quantile(difference, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 1 x 3 #&gt; mean ll ul #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0.084 -0.033 0.201 Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3. # This will help us with the `geom_text()` annotation slopes &lt;- tibble(slope = c(fixef(model2)[&quot;sexism&quot;, &quot;Estimate&quot;] + fixef(model2)[&quot;D1:sexism&quot;, &quot;Estimate&quot;], fixef(model2)[&quot;sexism&quot;, &quot;Estimate&quot;] + fixef(model2)[&quot;D2:sexism&quot;, &quot;Estimate&quot;], fixef(model2)[&quot;sexism&quot;, &quot;Estimate&quot;]), x = c(4.8, 4.6, 5), y = c(6.37, 6.25, 4.5), condition = c(&quot;Individual Protest&quot;, &quot;Collective Protest&quot;, &quot;No Protest&quot;)) %&gt;% mutate(label = str_c(&quot;This slope is about &quot;, slope %&gt;% round(digits = 3)), condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) # Here we plot model2_fitted %&gt;% ggplot(aes(x = sexism)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), alpha = 1/3) + geom_ribbon(aes(ymin = Q25, ymax = Q75), alpha = 1/3) + geom_line(aes(y = Estimate)) + geom_text(data = slopes, aes(x = x, y = y, label = label)) + coord_cartesian(xlim = 4:6) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(X), &quot;)&quot;)), y = &quot;Evaluation of the Attorney&quot;) + facet_wrap(~condition) + theme_minimal() 10.5.2 Probing the interaction and interpreting the regression coefficients. We computed the posterior means for the slopes when prepping for the figure, above. Here’s how we might get more complete posterior summaries. Much like in the text, our Figure 10.7 is just a little different from what we did with Figure 10.3. post &lt;- posterior_samples(model2) %&gt;% transmute(`No Protest` = b_sexism + `b_D1:sexism`*0 + `b_D2:sexism`*0, `Individual Protest` = b_sexism + `b_D1:sexism`*1 + `b_D2:sexism`*0, `Collective Protest` = b_sexism + `b_D1:sexism`*0 + `b_D2:sexism`*1) post %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% group_by(key) %&gt;% summarise(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 No Protest -0.464 0.201 -0.863 -0.077 #&gt; 2 Individual Protest 0.427 0.201 0.036 0.821 #&gt; 3 Collective Protest 0.305 0.185 -0.07 0.67 Here are the differences among the three protest groups. post %&gt;% transmute(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Individual Protest - Collective Protest` = `Individual Protest` - `Collective Protest`) %&gt;% gather() %&gt;% # again, not necessary, but useful for reordering the summaries mutate(key = factor(key, levels = c(&quot;Individual Protest - No Protest&quot;, &quot;Collective Protest - No Protest&quot;, &quot;Individual Protest - Collective Protest&quot;))) %&gt;% group_by(key) %&gt;% summarise(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Individual Protest - No Protest 0.89 0.28 0.334 1.43 #&gt; 2 Collective Protest - No Protest 0.769 0.274 0.238 1.32 #&gt; 3 Individual Protest - Collective Protest 0.122 0.274 -0.4 0.667 References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] brms_2.3.4 Rcpp_0.12.17 bindrcpp_0.2.2 forcats_0.3.0 stringr_1.3.1 dplyr_0.7.6 #&gt; [7] purrr_0.2.5 readr_1.1.1 tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 xts_0.10-2 lubridate_1.7.4 #&gt; [5] threejs_0.3.1 httr_1.3.1 rprojroot_1.3-2 rstan_2.17.3 #&gt; [9] tools_3.5.1 backports_1.1.2 utf8_1.1.4 R6_2.2.2 #&gt; [13] DT_0.4 lazyeval_0.2.1 colorspace_1.3-2 withr_2.1.2 #&gt; [17] tidyselect_0.2.4 gridExtra_2.3 mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [21] compiler_3.5.1 cli_1.0.0 rvest_0.3.2 shinyjs_1.0 #&gt; [25] xml2_1.2.0 labeling_0.3 colourpicker_1.0 bookdown_0.7 #&gt; [29] scales_0.5.0 dygraphs_1.1.1.5 mvtnorm_1.0-8 psych_1.8.4 #&gt; [33] ggridges_0.5.0 digest_0.6.15 StanHeaders_2.17.2 foreign_0.8-70 #&gt; [37] rmarkdown_1.10 base64enc_0.1-3 pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [41] htmlwidgets_1.2 rlang_0.2.1 readxl_1.1.0 rstudioapi_0.7 #&gt; [45] shiny_1.1.0 bindr_0.1.1 zoo_1.8-2 jsonlite_1.5 #&gt; [49] gtools_3.8.1 crosstalk_1.0.0 inline_0.3.15 magrittr_1.5 #&gt; [53] loo_2.0.0 bayesplot_1.5.0 Matrix_1.2-14 munsell_0.5.0 #&gt; [57] abind_1.4-5 stringi_1.2.3 yaml_2.1.19 plyr_1.8.4 #&gt; [61] grid_3.5.1 parallel_3.5.1 promises_1.0.1 crayon_1.3.4 #&gt; [65] miniUI_0.1.1.1 lattice_0.20-35 haven_1.1.2 hms_0.4.2 #&gt; [69] knitr_1.20 pillar_1.2.3 igraph_1.2.1 markdown_0.8 #&gt; [73] shinystan_2.5.0 codetools_0.2-15 reshape2_1.4.3 stats4_3.5.1 #&gt; [77] rstantools_1.5.0 glue_1.2.0 evaluate_0.10.1 modelr_0.1.2 #&gt; [81] httpuv_1.4.4.2 cellranger_1.1.0 gtable_0.2.0 assertthat_0.2.0 #&gt; [85] xfun_0.3 mime_0.5 xtable_1.8-2 broom_0.4.5 #&gt; [89] coda_0.19-1 later_0.7.3 rsconnect_0.8.8 shinythemes_1.1.1 #&gt; [93] bridgesampling_0.4-0 "],
["fundamentals-of-conditional-process-analysis.html", "11 Fundamentals of Conditional Process Analysis 11.1 Examples of conditional process models in the literature 11.2 Conditional direct and indirect effects 11.3 Example: Hiding your feelings from your work team 11.4 Estimation of a conditional process model using PROCESS 11.5 Quantifying and visualizing (conditional) indirect and direct effects. 11.6 Statistical inference References Session info", " 11 Fundamentals of Conditional Process Analysis 11.1 Examples of conditional process models in the literature 11.2 Conditional direct and indirect effects 11.3 Example: Hiding your feelings from your work team Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) teams &lt;- read_csv(&quot;data/teams/teams.csv&quot;) glimpse(teams) #&gt; Observations: 60 #&gt; Variables: 4 #&gt; $ dysfunc &lt;dbl&gt; -0.23, -0.13, 0.00, -0.33, 0.39, 1.02, -0.35, -0.23, 0... #&gt; $ negtone &lt;dbl&gt; -0.51, 0.22, -0.08, -0.11, -0.48, 0.72, -0.18, -0.13, ... #&gt; $ negexp &lt;dbl&gt; -0.49, -0.49, 0.84, 0.84, 0.17, -0.82, -0.66, -0.16, -... #&gt; $ perform &lt;dbl&gt; 0.12, 0.52, -0.08, -0.08, 0.12, 1.12, -0.28, 0.32, -1.... Load the brms package. library(brms) Recall that we fit mediation models in brms using multivariate syntax. In previous attempts, we’ve defined and saved the model components outside of the brm() function and then plugged then into brm() using their identifier. Just to shake things up a bit, we’ll just do all the steps right in brm(), this time. model1 &lt;- brm(data = teams, family = gaussian, bf(negtone ~ 1 + dysfunc) + bf(perform ~ 1 + dysfunc + negtone + negexp + negtone:negexp) + set_rescor(FALSE), chains = 4, cores = 4) print(model1, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: negtone ~ 1 + dysfunc #&gt; perform ~ 1 + dysfunc + negtone + negexp + negtone:negexp #&gt; Data: teams (Number of observations: 60) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample #&gt; negtone_Intercept 0.025 0.064 -0.102 0.153 4000 #&gt; perform_Intercept -0.012 0.060 -0.129 0.104 4000 #&gt; negtone_dysfunc 0.618 0.178 0.276 0.960 4000 #&gt; perform_dysfunc 0.367 0.182 0.001 0.720 4000 #&gt; perform_negtone -0.436 0.133 -0.689 -0.176 4000 #&gt; perform_negexp -0.022 0.120 -0.261 0.220 4000 #&gt; perform_negtone:negexp -0.513 0.255 -1.006 -0.006 4000 #&gt; Rhat #&gt; negtone_Intercept 1.000 #&gt; perform_Intercept 0.999 #&gt; negtone_dysfunc 1.000 #&gt; perform_dysfunc 0.999 #&gt; perform_negtone 1.000 #&gt; perform_negexp 0.999 #&gt; perform_negtone:negexp 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_negtone 0.487 0.046 0.408 0.586 4000 1.000 #&gt; sigma_perform 0.459 0.047 0.378 0.561 4000 0.999 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Our model summary coheres nicely with Table 11.1 and the formulas on page 409. Here are the \\(R^2\\) distribution summaries. bayes_R2(model1) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2_negtone 0.192 0.081 0.042 0.347 #&gt; R2_perform 0.320 0.079 0.148 0.456 On page 410 we get two sample means. Here they are: mean(teams$negexp) %&gt;% round(digits = 3) #&gt; [1] -0.008 mean(teams$perform) %&gt;% round(digits = 3) #&gt; [1] -0.032 For our Figure 11.4 and other similar figures in this chapter, we’ll use spaghetti plots. Recall that with a spaghetti plots for linear models, we only need two values for the variable on the x-axis, rather than the typical 30+. nd &lt;- tibble(dysfunc = mean(teams$dysfunc), negtone = rep(c(-.8, .8), times = 3), negexp = rep(quantile(teams$negexp, probs = c(.16, .50, .84)), each = 2)) Here’s our Figure 11.4, which uses only the first 40 HMC iterations for the spaghetti-plot lines. fitted(model1, newdata = nd, resp = &quot;perform&quot;, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(iter = rep(1:4000, times = 2*3), negtone = rep(rep(c(-.8, .8), times = 3), each = 4000), negexp = rep(rep(quantile(teams$negexp, probs = c(.16, .50, .84)), each = 2), each = 4000)) %&gt;% mutate(negexp = str_c(&quot;expresivity = &quot;, negexp)) %&gt;% mutate(negexp = factor(negexp, levels = c(&quot;expresivity = -0.49&quot;, &quot;expresivity = -0.06&quot;, &quot;expresivity = 0.6&quot;))) %&gt;% filter(iter &lt; 41) %&gt;% ggplot(aes(x = negtone, y = value, group = iter)) + geom_line(color = &quot;skyblue3&quot;, size = 1/4) + coord_cartesian(xlim = c(-.5, .5), ylim = c(-.6, .6)) + labs(x = expression(paste(&quot;Negative Tone of the Work Climate (&quot;, italic(M), &quot;)&quot;)), y = &quot;Team Performance&quot;) + theme_bw() + theme(panel.grid = element_blank(), strip.background = element_rect(color = &quot;transparent&quot;, fill = &quot;transparent&quot;)) + facet_wrap(~negexp) Also, the plot theme in this chapter is a nod to John Kruschke. 11.4 Estimation of a conditional process model using PROCESS We just fit the model, above. 11.5 Quantifying and visualizing (conditional) indirect and direct effects. 11.5.0.1 The conditional indirect effect of \\(X\\). Here’s how to get the posterior summaries corresponding to the last two columns in Table 11.2. post &lt;- posterior_samples(model1) %&gt;% mutate(`Conditional effect of M when W is -0.531` = b_perform_negtone + `b_perform_negtone:negexp`*-0.531, `Conditional effect of M when W is -0.006` = b_perform_negtone + `b_perform_negtone:negexp`*-0.060, `Conditional effect of M when W is 0.600` = b_perform_negtone + `b_perform_negtone:negexp`*0.600, `Conditional indirect effect when W is -0.531` = b_negtone_dysfunc*(b_perform_negtone + `b_perform_negtone:negexp`*-0.531), `Conditional indirect effect when W is -0.006` = b_negtone_dysfunc*(b_perform_negtone + `b_perform_negtone:negexp`*-0.060), `Conditional indirect effect when W is 0.600` = b_negtone_dysfunc*(b_perform_negtone + `b_perform_negtone:negexp`*0.600)) post %&gt;% select(starts_with(&quot;Conditional&quot;)) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Conditional effect of M when W is -0.531&quot;, &quot;Conditional effect of M when W is -0.006&quot;, &quot;Conditional effect of M when W is 0.600&quot;, &quot;Conditional indirect effect when W is -0.531&quot;, &quot;Conditional indirect effect when W is -0.006&quot;, &quot;Conditional indirect effect when W is 0.600&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 6 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Conditional effect of M when W is -0.531 -0.163 0.217 -0.586 0.258 #&gt; 2 Conditional effect of M when W is -0.006 -0.405 0.138 -0.669 -0.134 #&gt; 3 Conditional effect of M when W is 0.600 -0.743 0.169 -1.08 -0.405 #&gt; 4 Conditional indirect effect when W is -0.531 -0.102 0.143 -0.403 0.155 #&gt; 5 Conditional indirect effect when W is -0.006 -0.251 0.117 -0.504 -0.062 #&gt; 6 Conditional indirect effect when W is 0.600 -0.46 0.172 -0.825 -0.169 11.5.0.2 The direct effect. The direct effect for his model is b_perform_dysfunc in brms. Here’s how to get it’s summary values from posterior_summary(). posterior_summary(model1)[&quot;b_perform_dysfunc&quot;, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; 0.367 0.182 0.001 0.720 11.5.1 Visualizing the direct and indirect effects. For Figure 11.7 we’ll use the first 400 HMC iterations. post &lt;- post %&gt;% mutate(`-0.7` = b_negtone_dysfunc*(b_perform_negtone + `b_perform_negtone:negexp`*-0.7), `0.7` = b_negtone_dysfunc*(b_perform_negtone + `b_perform_negtone:negexp`*0.7)) post %&gt;% select(b_perform_dysfunc, `-0.7`:`0.7`) %&gt;% gather(key, value, -b_perform_dysfunc) %&gt;% mutate(negexp = key %&gt;% as.double(), iter = rep(1:4000, times = 2)) %&gt;% filter(iter &lt; 401) %&gt;% ggplot(aes(x = negexp, group = iter)) + geom_hline(aes(yintercept = b_perform_dysfunc), color = &quot;skyblue3&quot;, size = .3, alpha = .3) + geom_line(aes(y = value), color = &quot;skyblue3&quot;, size = .3, alpha = .3) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(paste(&quot;Nonverbal Negative Expressivity (&quot;, italic(W), &quot;)&quot;)), y = &quot;Effect of Dysfunctional Behavior on Team Performance&quot;) + theme_bw() + theme(panel.grid = element_blank()) Since the b_perform_dysfunc values are constant across \\(W\\), the individual HMC iterations end up perfectly parallel in the spaghetti plot. This is an example of a visualization I’d avoid making with a spaghetti plot for a professional presentation. But hopefully it has some pedagogical value, here. 11.6 Statistical inference 11.6.1 Inference about the direct effect. We’ve already seen the 95% percentile-based crecible intervals for the direct effect, b_perform_dysfunc, which we can get with print(), posterior_summary(), or even fixef(). Here we’ll go beyond summaries and plot using geom_histogram(). library(tidybayes) post %&gt;% ggplot(aes(x = b_perform_dysfunc)) + geom_histogram(binwidth = .025, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointintervalh(aes(y = 0), point_interval = mode_hdi, .prob = .95) + scale_x_continuous(breaks = mode_hdi(post$b_perform_dysfunc, .prob = .95)[1, 1:3], labels = mode_hdi(post$b_perform_dysfunc, .prob = .95)[1, 1:3] %&gt;% round(3)) + scale_y_continuous(NULL, breaks = NULL) + xlab(&quot;The direct effect (i.e., b_perform_dysfunc)&quot;) + theme_bw() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line.x = element_line(size = 1/4)) Since we’re plotting in a style similar to Kruschke, we switched from emphasizing the posterior mean or median to marking off the posterior mode, which is Kruschkes’ preferred metric of central tendency. We also ditched our typical percentile-based 95% intervals for highest posterior density intervals. The stat_pointintervalh() function from the Matthew Kay’s tidybayes package made it easy to compute those values with the point_interval = mode_hdi argument. Note how we also used tidybayes::mode_hdi() to compute those values and plug them into scale_x_continuous(). 11.6.2 Inference about the indirect effect. Much like above, we can make a plot of the conditional indirect effect \\(ab_{3}\\). post &lt;- post %&gt;% mutate(ab_3 = b_negtone_dysfunc*`b_perform_negtone:negexp`) post %&gt;% ggplot(aes(x = ab_3)) + geom_histogram(binwidth = .025, boundary = 0, color = &quot;white&quot;, fill = &quot;skyblue3&quot;, size = 1/4) + stat_pointintervalh(aes(y = 0), point_interval = mode_hdi, .prob = .95) + scale_x_continuous(breaks = mode_hdi(post$ab_3, .prob = .95)[1, 1:3], labels = mode_hdi(post$ab_3, .prob = .95)[1, 1:3] %&gt;% round(3)) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(&quot;The indirect effect, &quot;, italic(ab)[3]))) + theme_bw() + theme(panel.grid = element_blank(), panel.border = element_blank(), axis.line.x = element_line(size = 1/4)) 11.6.3 Probing moderation of mediation. 11.6.3.1 Normal theory approach. As we’re square within the Bayesian modeling paradigm, we have no need to appeal to normal theory for the posterior \\(SD\\)s or 95% intervals. 11.6.3.2 Bootstrap confidence intervals Percentile-based Bayesian credible intervals. We produced the summary values corresponding to those in Table 11.3 some time ago. Here they are, again. post %&gt;% select(starts_with(&quot;Conditional indirect&quot;)) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Conditional indirect effect when W is -0.531&quot;, &quot;Conditional indirect effect when W is -0.006&quot;, &quot;Conditional indirect effect when W is 0.600&quot;))) %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), sd = sd(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; key mean sd ll ul #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Conditional indirect effect when W is -0.531 -0.102 0.143 -0.403 0.155 #&gt; 2 Conditional indirect effect when W is -0.006 -0.251 0.117 -0.504 -0.062 #&gt; 3 Conditional indirect effect when W is 0.600 -0.46 0.172 -0.825 -0.169 And if we wanted to summarize those same effects with posterior modes and 95% highest posterior density intervals, instead, we’d replace our summarize() code with a mode_hdi() statement. post %&gt;% select(starts_with(&quot;Conditional indirect&quot;)) %&gt;% gather() %&gt;% mutate(key = factor(key, levels = c(&quot;Conditional indirect effect when W is -0.531&quot;, &quot;Conditional indirect effect when W is -0.006&quot;, &quot;Conditional indirect effect when W is 0.600&quot;))) %&gt;% group_by(key) %&gt;% mode_hdi(value, .prob = .95) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; # Groups: key [3] #&gt; key value conf.low conf.high .prob #&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Conditional indirect effect when W is -… -0.071 -0.384 0.173 0.95 #&gt; 2 Conditional indirect effect when W is -… -0.202 -0.481 -0.051 0.95 #&gt; 3 Conditional indirect effect when W is 0… -0.378 -0.805 -0.149 0.95 And we might plot these with something like: post %&gt;% select(starts_with(&quot;Conditional indirect&quot;)) %&gt;% gather() %&gt;% mutate(key = str_remove(key, &quot;Conditional indirect effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = key, y = value, group = key)) + stat_pointinterval(point_interval = mode_hdi, .prob = c(.95, .5), color = &quot;skyblue3&quot;) + scale_x_continuous(breaks = c(-.531, -.006, .6)) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(italic(W)), y = &quot;The conditional indirect effect&quot;) + theme_bw() + theme(panel.grid = element_blank()) This time we used the prob = c(.95, .5) argument within stat_pointinterval() to return both 95% and 50% highest posterior density intervals—which are the outer and inner lines, respectively. This, of course, leads us right into 11.6.3.3 A Johnson-Neyman approach. On page 429, Hayes discussed how Preacher et al. (2007)’s attempt to apply the JN technique in this context presumed the sampling distribution of the conditional indirect effect is normal. Given that the sampling distribution of the conditional indirect effect is not normal, the approach they describe yields, at best, an approximate solution. To [Hayes’s] knowledge, no one has ever proposed a bootstrapping-based analogue of the Johnson-Neyman method for probing the moderation of an indirect effect. However, our Bayesian HMC approach makes no such assumption. All we need to do is manipulate the posterior as usual. Here it is, this time using all 4000 iterations: post %&gt;% transmute(`-0.8` = b_perform_negtone + `b_perform_negtone:negexp`*-0.8, `0.8` = b_perform_negtone + `b_perform_negtone:negexp`*0.8) %&gt;% gather() %&gt;% mutate(key = key %&gt;% as.double, iter = rep(1:4000, times = 2)) %&gt;% ggplot(aes(x = key, y = value, group = iter)) + geom_line(color = &quot;skyblue3&quot;, size = 1/6, alpha = 1/15) + coord_cartesian(xlim = c(-.5, .6), ylim = c(-1.25, .75)) + labs(x = expression(italic(W)), y = &quot;The conditional indirect effect&quot;) + theme_bw() + theme(panel.grid = element_blank()) References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] tidybayes_0.12.1.9000 bindrcpp_0.2.2 brms_2.3.4 #&gt; [4] Rcpp_0.12.17 forcats_0.3.0 stringr_1.3.1 #&gt; [7] dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 #&gt; [10] tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 #&gt; [13] tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 #&gt; [3] xts_0.10-2 lubridate_1.7.4 #&gt; [5] threejs_0.3.1 httr_1.3.1 #&gt; [7] LaplacesDemon_16.1.1 rprojroot_1.3-2 #&gt; [9] rstan_2.17.3 tools_3.5.1 #&gt; [11] backports_1.1.2 utf8_1.1.4 #&gt; [13] R6_2.2.2 DT_0.4 #&gt; [15] lazyeval_0.2.1 colorspace_1.3-2 #&gt; [17] withr_2.1.2 tidyselect_0.2.4 #&gt; [19] gridExtra_2.3 mnormt_1.5-5 #&gt; [21] Brobdingnag_1.2-5 compiler_3.5.1 #&gt; [23] cli_1.0.0 rvest_0.3.2 #&gt; [25] HDInterval_0.2.0 arrayhelpers_1.0-20160527 #&gt; [27] shinyjs_1.0 xml2_1.2.0 #&gt; [29] labeling_0.3 colourpicker_1.0 #&gt; [31] bookdown_0.7 scales_0.5.0 #&gt; [33] dygraphs_1.1.1.5 mvtnorm_1.0-8 #&gt; [35] psych_1.8.4 ggridges_0.5.0 #&gt; [37] digest_0.6.15 StanHeaders_2.17.2 #&gt; [39] foreign_0.8-70 rmarkdown_1.10 #&gt; [41] base64enc_0.1-3 pkgconfig_2.0.1 #&gt; [43] htmltools_0.3.6 htmlwidgets_1.2 #&gt; [45] rlang_0.2.1 readxl_1.1.0 #&gt; [47] rstudioapi_0.7 shiny_1.1.0 #&gt; [49] svUnit_0.7-12 bindr_0.1.1 #&gt; [51] zoo_1.8-2 jsonlite_1.5 #&gt; [53] gtools_3.8.1 crosstalk_1.0.0 #&gt; [55] inline_0.3.15 magrittr_1.5 #&gt; [57] loo_2.0.0 bayesplot_1.5.0 #&gt; [59] Matrix_1.2-14 munsell_0.5.0 #&gt; [61] abind_1.4-5 stringi_1.2.3 #&gt; [63] yaml_2.1.19 MASS_7.3-50 #&gt; [65] ggstance_0.3 plyr_1.8.4 #&gt; [67] grid_3.5.1 parallel_3.5.1 #&gt; [69] promises_1.0.1 crayon_1.3.4 #&gt; [71] miniUI_0.1.1.1 lattice_0.20-35 #&gt; [73] haven_1.1.2 hms_0.4.2 #&gt; [75] knitr_1.20 pillar_1.2.3 #&gt; [77] igraph_1.2.1 markdown_0.8 #&gt; [79] shinystan_2.5.0 codetools_0.2-15 #&gt; [81] reshape2_1.4.3 stats4_3.5.1 #&gt; [83] rstantools_1.5.0 glue_1.2.0 #&gt; [85] evaluate_0.10.1 modelr_0.1.2 #&gt; [87] httpuv_1.4.4.2 cellranger_1.1.0 #&gt; [89] gtable_0.2.0 assertthat_0.2.0 #&gt; [91] xfun_0.3 mime_0.5 #&gt; [93] xtable_1.8-2 broom_0.4.5 #&gt; [95] coda_0.19-1 later_0.7.3 #&gt; [97] rsconnect_0.8.8 shinythemes_1.1.1 #&gt; [99] bridgesampling_0.4-0 "],
["further-examples-of-conditional-process-analysis.html", "12 Further Examples of Conditional Process Analysis 12.1 Revisiting the disaster framing study 12.2 Moderation of the direct and indirect effects in a conditional process model 12.3 Statistical inference 12.4 Mediated moderation References Session info", " 12 Further Examples of Conditional Process Analysis 12.1 Revisiting the disaster framing study Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) disaster &lt;- read_csv(&quot;data/disaster/disaster.csv&quot;) glimpse(disaster) #&gt; Observations: 211 #&gt; Variables: 5 #&gt; $ id &lt;int&gt; 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16,... #&gt; $ frame &lt;int&gt; 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, ... #&gt; $ donate &lt;dbl&gt; 5.6, 4.2, 4.2, 4.6, 3.0, 5.0, 4.8, 6.0, 4.2, 4.4, 5.8,... #&gt; $ justify &lt;dbl&gt; 2.95, 2.85, 3.00, 3.30, 5.00, 3.20, 2.90, 1.40, 3.25, ... #&gt; $ skeptic &lt;dbl&gt; 1.8, 5.2, 3.2, 1.0, 7.6, 4.2, 4.2, 1.2, 1.8, 8.8, 1.0,... Load brms. library(brms) Our model1 is the simple moderation model. model1 &lt;- brm(data = disaster, family = gaussian, donate ~ 1 + frame + skeptic + frame:skeptic, chains = 4, cores = 4) Our model1 summary matches nicely with the text. print(model1, digits = 3) #&gt; Family: gaussian #&gt; Links: mu = identity; sigma = identity #&gt; Formula: donate ~ 1 + frame + skeptic + frame:skeptic #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; Intercept 5.027 0.228 4.586 5.471 2471 1.000 #&gt; frame 0.679 0.328 0.027 1.322 2088 1.001 #&gt; skeptic -0.139 0.059 -0.255 -0.027 2367 1.000 #&gt; frame:skeptic -0.170 0.085 -0.334 -0.009 1969 1.001 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma 1.241 0.062 1.127 1.369 3014 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). For the figures in this chapter, we’ll take theme cues from Matthew Kay’s tidybayes package. Otherwise, our Figure 12.2 is business as usual at this point. theme_set(theme_light()) nd &lt;- tibble(frame = rep(0:1, each = 30), skeptic = rep(seq(from = 0, to = 7, length.out = 30), times = 2)) fitted(model1, newdata = nd) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(frame = ifelse(frame == 0, str_c(&quot;Natural causes (X = &quot;, frame, &quot;)&quot;), str_c(&quot;Climate change (X = &quot;, frame, &quot;)&quot;))) %&gt;% ggplot(aes(x = skeptic, y = Estimate)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5, fill = frame), alpha = 1/3) + geom_line(aes(color = frame)) + scale_fill_brewer(type = &quot;qual&quot;) + scale_color_brewer(type = &quot;qual&quot;) + coord_cartesian(xlim = 1:6, ylim = c(3.5, 5.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Willingness to Donate to Victims&quot;) + theme(legend.position = &quot;top&quot;, legend.direction = &quot;horizontal&quot;, legend.title = element_blank()) In Hayes’s Figure 12.2, he emphasized the differences at the three levels of skeptic. If you want the full difference score distributions in a pick-a-point-approach sort of way, you might plot the densities with tidybayes::geom_halfeyeh(), which places coefficient plots at the base of the densities. In this case, we show the posterior medians with the dots, the 50% intervals with the thick horizontal lines, and the 95% intervals with the thinner horizontal lines. library(tidybayes) nd &lt;- tibble(frame = rep(0:1, times = 3), skeptic = rep(quantile(disaster$skeptic, probs = c(.16, .5, .86)), times = 2)) fitted(model1, summary = F, newdata = nd) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(frame = rep(rep(0:1, times = 3), each = 4000), skeptic = rep(rep(quantile(disaster$skeptic, probs = c(.16, .5, .86)), times = 2), each = 4000), iter = rep(1:4000, times = 6)) %&gt;% select(-key) %&gt;% spread(key = frame, value = value) %&gt;% mutate(difference = `1` - `0`) %&gt;% ggplot(aes(x = difference, y = skeptic, group = skeptic, fill = skeptic %&gt;% as.character())) + geom_halfeyeh(point_interval = median_qi, .prob = c(0.95, 0.5)) + scale_fill_brewer() + scale_y_continuous(breaks = quantile(disaster$skeptic, probs = c(.16, .5, .86)), labels = quantile(disaster$skeptic, probs = c(.16, .5, .86)) %&gt;% round(2)) + theme(legend.position = &quot;none&quot;, panel.grid.minor.y = element_blank()) Here’s our simple mediation model, model2, using the multivariate syntax right in the brm() function. model2 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame) + bf(donate ~ 1 + frame + justify) + set_rescor(FALSE), chains = 4, cores = 4) print(model2, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: justify ~ 1 + frame #&gt; donate ~ 1 + frame + justify #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; justify_Intercept 2.802 0.087 2.632 2.972 4000 1.000 #&gt; donate_Intercept 7.236 0.232 6.777 7.684 4000 1.000 #&gt; justify_frame 0.134 0.132 -0.124 0.394 4000 0.999 #&gt; donate_frame 0.215 0.138 -0.055 0.486 4000 1.000 #&gt; donate_justify -0.954 0.075 -1.097 -0.809 4000 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_justify 0.935 0.046 0.850 1.029 4000 0.999 #&gt; sigma_donate 0.986 0.049 0.898 1.088 4000 0.999 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The Bayesian \\(R^2\\) bayes_R2(model2) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2_justify 0.01 0.012 0.00 0.043 #&gt; R2_donate 0.45 0.039 0.37 0.517 If you want the indirect effect with its intervals, you use posterior_samples() and data wrangle, as usual. posterior_samples(model2) %&gt;% mutate(ab = b_justify_frame*b_donate_justify) %&gt;% summarize(mean = mean(ab), ll = quantile(ab, probs = .025), ul = quantile(ab, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; mean ll ul #&gt; 1 -0.128 -0.386 0.119 We might also streamline our code a touch using tidybayes::mean_qi() in place of tidyverse::summarize(). posterior_samples(model2) %&gt;% mutate(ab = b_justify_frame*b_donate_justify) %&gt;% mean_qi(ab, .prob = .95) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 1 x 4 #&gt; ab conf.low conf.high .prob #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 -0.128 -0.386 0.119 0.95 Note that the last column explicates what interval level we used. 12.2 Moderation of the direct and indirect effects in a conditional process model We don’t need to do anything particularly special to fit a model like this in brms. It just requires we do a careful job specifying the formulas in our bf() arguments. If you find this syntax a little too cumbersome, you can always specify the formulas outside of brm(), save them as one or multiple objects, and plug those objects into brm(). model3 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame + skeptic + frame:skeptic) + bf(donate ~ 1 + frame + justify + skeptic + frame:skeptic) + set_rescor(FALSE), chains = 4, cores = 4) The model summary: print(model3, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: justify ~ 1 + frame + skeptic + frame:skeptic #&gt; donate ~ 1 + frame + justify + skeptic + frame:skeptic #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample #&gt; justify_Intercept 2.454 0.150 2.157 2.747 3295 #&gt; donate_Intercept 7.289 0.277 6.746 7.846 4000 #&gt; justify_frame -0.563 0.223 -1.007 -0.134 3092 #&gt; justify_skeptic 0.104 0.039 0.030 0.180 3051 #&gt; justify_frame:skeptic 0.201 0.056 0.094 0.311 2932 #&gt; donate_frame 0.156 0.276 -0.400 0.691 3265 #&gt; donate_justify -0.921 0.083 -1.080 -0.759 4000 #&gt; donate_skeptic -0.043 0.048 -0.137 0.051 4000 #&gt; donate_frame:skeptic 0.016 0.072 -0.123 0.159 3111 #&gt; Rhat #&gt; justify_Intercept 1.000 #&gt; donate_Intercept 1.000 #&gt; justify_frame 0.999 #&gt; justify_skeptic 1.000 #&gt; justify_frame:skeptic 1.000 #&gt; donate_frame 1.000 #&gt; donate_justify 1.000 #&gt; donate_skeptic 1.000 #&gt; donate_frame:skeptic 1.001 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_justify 0.819 0.041 0.745 0.905 4000 0.999 #&gt; sigma_donate 0.988 0.048 0.901 1.086 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). 12.2.1 Estimation using PROCESS. We just fit the model. Next. 12.2.2 Quantifying direct and indirect effects. Here are \\(a_{1}\\) through \\(a_{3}\\). fixef(model3)[c(3:5), ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; justify_frame -0.563 0.223 -1.007 -0.134 #&gt; justify_skeptic 0.104 0.039 0.030 0.180 #&gt; justify_frame:skeptic 0.201 0.056 0.094 0.311 This is \\(b\\). fixef(model3)[7, ] %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; -0.921 0.083 -1.080 -0.759 We’ll need to employ posterior_samples() to compute \\((a_{1} + a_{3}W)b\\). post &lt;- posterior_samples(model3) %&gt;% mutate(`indirect effect when W is 1.592` = (b_justify_frame + `b_justify_frame:skeptic`*1.592)*b_donate_justify, `indirect effect when W is 2.800` = (b_justify_frame + `b_justify_frame:skeptic`*2.800)*b_donate_justify, `indirect effect when W is 5.200` = (b_justify_frame + `b_justify_frame:skeptic`*5.200)*b_donate_justify) post %&gt;% select(starts_with(&quot;indirect&quot;)) %&gt;% gather() %&gt;% group_by(key) %&gt;% median_qi(value, .prob = .95) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; # Groups: key [3] #&gt; key value conf.low conf.high .prob #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 indirect effect when W is 1.592 0.221 -0.047 0.515 0.95 #&gt; 2 indirect effect when W is 2.800 -0.002 -0.214 0.224 0.95 #&gt; 3 indirect effect when W is 5.200 -0.445 -0.736 -0.166 0.95 12.2.2.1 The conditional direct effect of \\(X\\). This process is very similar. post &lt;- post %&gt;% mutate(`direct effect when W is 1.592` = b_donate_frame + `b_donate_frame:skeptic`*1.592, `direct effect when W is 2.800` = b_donate_frame + `b_donate_frame:skeptic`*2.800, `direct effect when W is 5.200` = b_donate_frame + `b_donate_frame:skeptic`*5.200) post %&gt;% select(starts_with(&quot;direct&quot;)) %&gt;% gather() %&gt;% group_by(key) %&gt;% median_qi(value, .prob = .95) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 5 #&gt; # Groups: key [3] #&gt; key value conf.low conf.high .prob #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 direct effect when W is 1.592 0.184 -0.191 0.542 0.95 #&gt; 2 direct effect when W is 2.800 0.203 -0.085 0.478 0.95 #&gt; 3 direct effect when W is 5.200 0.24 -0.15 0.614 0.95 12.2.3 Visualizing the direct and indirect effects. In order to make Figure 12.7, we’ll use sapply() to get the conditional effects for justify and donate. justify_effects &lt;- sapply(seq(from = 0, to = 6, length.out = 30), function(w){ (post$b_justify_frame + post$`b_justify_frame:skeptic`*w)*post$b_donate_justify }) %&gt;% as_tibble() %&gt;% gather() %&gt;% select(-key) %&gt;% mutate(skeptic = seq(from = 0, to = 6, length.out = 30) %&gt;% rep(., each = 4000)) %&gt;% group_by(skeptic) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) donate_effects &lt;- sapply(seq(from = 0, to = 6, length.out = 30), function(w){ post$b_donate_frame + post$`b_donate_frame:skeptic`*w }) %&gt;% as_tibble() %&gt;% gather() %&gt;% select(-key) %&gt;% mutate(skeptic = seq(from = 0, to = 6, length.out = 30) %&gt;% rep(., each = 4000)) %&gt;% group_by(skeptic) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) # here&#39;s what they look like: glimpse(justify_effects) #&gt; Observations: 30 #&gt; Variables: 4 #&gt; $ skeptic &lt;dbl&gt; 0.000, 0.207, 0.414, 0.621, 0.828, 1.034, 1.241, 1.448... #&gt; $ median &lt;dbl&gt; 0.5148, 0.4760, 0.4383, 0.4018, 0.3625, 0.3250, 0.2863... #&gt; $ ll &lt;dbl&gt; 0.12312, 0.10012, 0.07942, 0.06102, 0.03874, 0.01624, ... #&gt; $ ul &lt;dbl&gt; 0.9497, 0.8929, 0.8367, 0.7790, 0.7175, 0.6577, 0.6064... glimpse(donate_effects) #&gt; Observations: 30 #&gt; Variables: 4 #&gt; $ skeptic &lt;dbl&gt; 0.000, 0.207, 0.414, 0.621, 0.828, 1.034, 1.241, 1.448... #&gt; $ median &lt;dbl&gt; 0.160, 0.164, 0.169, 0.174, 0.176, 0.177, 0.180, 0.182... #&gt; $ ll &lt;dbl&gt; -0.3996, -0.3717, -0.3418, -0.3125, -0.2849, -0.2547, ... #&gt; $ ul &lt;dbl&gt; 0.691, 0.669, 0.650, 0.631, 0.608, 0.589, 0.573, 0.556... Here we’ll combine those two tibbles by stacking donate_effects underneath justify_effects and then indexing them by effect. Then we’re ready to plot. # combining the tibbles figure_12.7 &lt;- justify_effects %&gt;% bind_rows(donate_effects) %&gt;% mutate(effect = rep(c(&quot;Indirect effect&quot;, &quot;Direct effect&quot;), each = nrow(justify_effects))) # we&#39;ll need this for `geom_text()` text_tibble &lt;- tibble(x = c(4.2, 4.7), y = c(.28, -.28), angle = c(3.6, 335), effect = c(&quot;Direct effect&quot;, &quot;Indirect effect&quot;)) # the plot figure_12.7 %&gt;% ggplot(aes(x = skeptic, group = effect)) + geom_ribbon(aes(ymin = ll, ymax = ul, fill = effect), alpha = 1/3) + geom_line(aes(y = median, color = effect)) + geom_text(data = text_tibble, aes(x = x, y = y, angle = angle, color = effect, label = effect), size = 5) + scale_fill_brewer(type = &quot;qual&quot;) + scale_color_brewer(type = &quot;qual&quot;) + coord_cartesian(xlim = c(1, 5.5), ylim = c(-.6, .4)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Effects of Disaster Frame on Willingness to Donate&quot;) + theme(legend.position = &quot;none&quot;) Note how wide those 95% intervals are relative to the scale of the y-axis. I specifically kept the y-axis within the same range as Figure 12.7 in the text. To me the message is clear: include credible-interval ribbons in your regression slope plots. They help depict how uncertain the posterior is in a way a simple line slopes just don’t. 12.2.4 Bonus: Let’s replace sapply() with map(). Good old sapply() worked just fine for our purposes, above. However, we can use map() to accomplish those goals in a more tidyverse-consistent fashion. First we’ll define two custom functions to do what our two sapply() statements did for us. # defining two custom functions make_justify &lt;- function(w){ (post$b_justify_frame + post$`b_justify_frame:skeptic`*w)*post$b_donate_justify } make_donate &lt;-function(w){ post$b_donate_frame + post$`b_donate_frame:skeptic`*w } Next, we’ll make a 30-row tibble with each row a value for skeptic, ranging from 0 ot 6, just like what we did with sapply(), above. Because we’ll be performing a nested operation for each value of skeptic, we’ll group the tibble by skeptic. Then with the mutate() function, we’ll use map() to apply our custom make_justify and make_donate functions to each of the 30 skeptic values. tidyverse_style_tibble &lt;- tibble(skeptic = seq(from = 0, to = 6, length.out = 30)) %&gt;% group_by(skeptic) %&gt;% mutate(`indirect effect` = map(skeptic, make_justify), `direct effect` = map(skeptic, make_donate)) tidyverse_style_tibble #&gt; # A tibble: 30 x 3 #&gt; # Groups: skeptic [30] #&gt; skeptic `indirect effect` `direct effect` #&gt; &lt;dbl&gt; &lt;list&gt; &lt;list&gt; #&gt; 1 0 &lt;dbl [4,000]&gt; &lt;dbl [4,000]&gt; #&gt; 2 0.207 &lt;dbl [4,000]&gt; &lt;dbl [4,000]&gt; #&gt; 3 0.414 &lt;dbl [4,000]&gt; &lt;dbl [4,000]&gt; #&gt; 4 0.621 &lt;dbl [4,000]&gt; &lt;dbl [4,000]&gt; #&gt; 5 0.828 &lt;dbl [4,000]&gt; &lt;dbl [4,000]&gt; #&gt; 6 1.03 &lt;dbl [4,000]&gt; &lt;dbl [4,000]&gt; #&gt; # ... with 24 more rows This yielded a nested tibble. At one level of investigation, we have 30 rows–one for each of the 30 skeptic values. However, for both the idirect effect and direct effect columns, we’ve packed an entire 4000-row list into each of those rows. The lists are 4000-rows long because both of our custom functions entailed pushing those skeptic values through the posterior, which itself had 4000 iterations. Next we’ll use unnest() to unnest the tibble. tidyverse_style_tibble &lt;- tidyverse_style_tibble %&gt;% unnest() head(tidyverse_style_tibble) #&gt; # A tibble: 6 x 3 #&gt; # Groups: skeptic [1] #&gt; skeptic `indirect effect` `direct effect` #&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 0 0.294 -0.165 #&gt; 2 0 -0.00503 -0.119 #&gt; 3 0 0.607 -0.0181 #&gt; 4 0 0.535 0.147 #&gt; 5 0 0.384 0.0707 #&gt; 6 0 0.481 0.187 After un-nesting, the tibble is now \\(4000\\times30 = 120,000\\) rows long. With just a little more wrangling, we’ll have our familiar summaries for each level of skeptic. tidyverse_style_tibble &lt;- tidyverse_style_tibble %&gt;% ungroup() %&gt;% mutate(iter = rep(1:4000, times = 30)) %&gt;% gather(effect, value, -skeptic, -iter) %&gt;% group_by(effect, skeptic) %&gt;% median_qi(value, .prob = .95) head(tidyverse_style_tibble) #&gt; # A tibble: 6 x 6 #&gt; # Groups: effect, skeptic [6] #&gt; effect skeptic value conf.low conf.high .prob #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 direct effect 0 0.160 -0.400 0.691 0.95 #&gt; 2 direct effect 0.207 0.164 -0.372 0.669 0.95 #&gt; 3 direct effect 0.414 0.169 -0.342 0.650 0.95 #&gt; 4 direct effect 0.621 0.174 -0.312 0.631 0.95 #&gt; 5 direct effect 0.828 0.176 -0.285 0.608 0.95 #&gt; 6 direct effect 1.03 0.177 -0.255 0.589 0.95 Now we have 60 row, 30 for direct effect and another 30 for indirect effect. Each has the typical summary values for all 30 levels of skeptic. Now we’re ready to plot. tidyverse_style_tibble %&gt;% ggplot(aes(x = skeptic, group = effect)) + geom_ribbon(aes(ymin = conf.low, ymax = conf.high, fill = effect), alpha = 1/3) + geom_line(aes(y = value, color = effect)) + scale_fill_brewer(type = &quot;qual&quot;, palette = 2) + scale_color_brewer(type = &quot;qual&quot;, palette = 2) + coord_cartesian(xlim = c(1, 5.5), ylim = c(-.6, .4)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Effects of Disaster Frame on Willingness to Donate&quot;) + theme(legend.position = &quot;none&quot;) Do note how, in our plot above, we used tidybayes terms value (i.e., median–the specified measure of central tendency), conf.low and conf.high, the lower- and upper-levels of the 95% interval. To learn more about nested data and using the map() function, check out this subsection of Grolemund and Wickham’s R4DS or starting from this point on in this video of one of Wickham’s workshops. 12.3 Statistical inference 12.3.1 Inference about the direct effect. We’ve already computed the 95% intervals for these. Here they are as stat_pointinterval() plots. post %&gt;% select(starts_with(&quot;direct&quot;)) %&gt;% gather() %&gt;% mutate(key = str_remove(key, &quot;direct effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = key, y = value, group = key)) + stat_pointinterval(point_interval = median_qi, .prob = c(.95, .5)) + coord_cartesian(xlim = c(1, 5.5)) + labs(x = expression(paste(&quot;Climate Change Skepticism (&quot;, italic(W), &quot;)&quot;)), y = &quot;Conditional Direct Effect of Disaster Frame on\\nWillingness to Donate&quot;) 12.3.2 Inference about the indirect effect. 12.3.2.1 A statistical test of moderated mediation. To get a sense of \\(a_{3}b\\), we just: post &lt;- post %&gt;% mutate(a3b = `b_justify_frame:skeptic`*b_donate_justify) post %&gt;% select(a3b) %&gt;% summarize(median = median(a3b), sd = sd(a3b), ll = quantile(a3b, probs = .025), ul = quantile(a3b, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; median sd ll ul #&gt; 1 -0.184 0.054 -0.297 -0.084 We might use stat_pointintervalh() to visualize \\(a_{3}b\\) with a coefficient plot. post %&gt;% ggplot(aes(x = a3b, y = 1)) + stat_pointintervalh(point_interval = median_qi, .prob = c(.95, .5)) + scale_y_discrete(NULL, breaks = NULL) + coord_cartesian(xlim = c(-.5, 0)) + labs(title = expression(paste(&quot;Coefficient plot for &quot;, italic(a)[3], italic(b), &quot; (i.e., the index of moderated mediation)&quot;)), x = NULL) 12.3.2.2 Probing moderation of mediation. As discussed in my manuscript for Chapter 11, our Bayesian version of the JN technique should be fine because HMC does not impose the normality assumption on the parameter posteriors. In this instance, I’ll leave the JN technique plot as an exercise for the interested reader. Here we’ll just follow along with the text and pick a few points. We computed and inspected these 95% intervals, above. Here we look at the entire densities with geom_halfeyeh(). post %&gt;% select(starts_with(&quot;indirect&quot;)) %&gt;% gather() %&gt;% rename(`indirect effect` = value) %&gt;% mutate(W = str_remove(key, &quot;indirect effect when W is &quot;) %&gt;% as.double()) %&gt;% ggplot(aes(x = `indirect effect`, y = W, group = W, fill = W %&gt;% as.character())) + geom_halfeyeh(point_interval = median_qi, .prob = c(0.95, 0.5)) + scale_fill_brewer() + scale_y_continuous(breaks = c(1.592, 2.8, 5.2), labels = c(1.6, 2.8, 5.2)) + coord_cartesian(xlim = -1:1) + theme(legend.position = &quot;none&quot;, panel.grid.minor.y = element_blank()) 12.3.3 Pruning the model. Fitting the model without the interaction term is just a small change to one of our formula arguments. model4 &lt;- brm(data = disaster, family = gaussian, bf(justify ~ 1 + frame + skeptic + frame:skeptic) + bf(donate ~ 1 + frame + justify + skeptic) + set_rescor(FALSE), chains = 4, cores = 4) Here are the results. print(model4, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: justify ~ 1 + frame + skeptic + frame:skeptic #&gt; donate ~ 1 + frame + justify + skeptic #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample #&gt; justify_Intercept 2.447 0.149 2.158 2.741 3121 #&gt; donate_Intercept 7.258 0.226 6.816 7.703 4000 #&gt; justify_frame -0.557 0.217 -0.973 -0.113 2587 #&gt; justify_skeptic 0.106 0.038 0.029 0.179 2675 #&gt; justify_frame:skeptic 0.200 0.055 0.089 0.305 2397 #&gt; donate_frame 0.213 0.132 -0.045 0.471 4000 #&gt; donate_justify -0.918 0.082 -1.076 -0.756 4000 #&gt; donate_skeptic -0.036 0.038 -0.109 0.038 4000 #&gt; Rhat #&gt; justify_Intercept 1.000 #&gt; donate_Intercept 1.000 #&gt; justify_frame 1.000 #&gt; justify_skeptic 0.999 #&gt; justify_frame:skeptic 1.000 #&gt; donate_frame 1.000 #&gt; donate_justify 1.000 #&gt; donate_skeptic 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_justify 0.819 0.040 0.746 0.902 4000 1.000 #&gt; sigma_donate 0.986 0.048 0.899 1.088 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). Since we’re altering the model, we may as well use information criteria to compare the two versions. loo(model3, model4) #&gt; LOOIC SE #&gt; model3 1117.5 33.13 #&gt; model4 1115.0 33.02 #&gt; model3 - model4 2.4 0.54 The difference in LOO-CV values for the two models was modest. There’s little predictive reason to choose one over the other. You could argue that model4 is simpler than model3. Since we’ve got a complex model either way, one might also consider which one was of primary theoretical interest. 12.4 Mediated moderation 12.4.1 Mediated moderation as the indirect effect of a product. Hayes explains this in the next subsection, but we’ve already fit this model, which we called model3. Here’s the summary. print(model3, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: justify ~ 1 + frame + skeptic + frame:skeptic #&gt; donate ~ 1 + frame + justify + skeptic + frame:skeptic #&gt; Data: disaster (Number of observations: 211) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample #&gt; justify_Intercept 2.454 0.150 2.157 2.747 3295 #&gt; donate_Intercept 7.289 0.277 6.746 7.846 4000 #&gt; justify_frame -0.563 0.223 -1.007 -0.134 3092 #&gt; justify_skeptic 0.104 0.039 0.030 0.180 3051 #&gt; justify_frame:skeptic 0.201 0.056 0.094 0.311 2932 #&gt; donate_frame 0.156 0.276 -0.400 0.691 3265 #&gt; donate_justify -0.921 0.083 -1.080 -0.759 4000 #&gt; donate_skeptic -0.043 0.048 -0.137 0.051 4000 #&gt; donate_frame:skeptic 0.016 0.072 -0.123 0.159 3111 #&gt; Rhat #&gt; justify_Intercept 1.000 #&gt; donate_Intercept 1.000 #&gt; justify_frame 0.999 #&gt; justify_skeptic 1.000 #&gt; justify_frame:skeptic 1.000 #&gt; donate_frame 1.000 #&gt; donate_justify 1.000 #&gt; donate_skeptic 1.000 #&gt; donate_frame:skeptic 1.001 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_justify 0.819 0.041 0.745 0.905 4000 0.999 #&gt; sigma_donate 0.988 0.048 0.901 1.086 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). 12.4.2 Why mediated moderation is neither interesting nor meaningful. If it helps interpret this section, take a long look at the model formula. model3$formula #&gt; justify ~ 1 + frame + skeptic + frame:skeptic #&gt; donate ~ 1 + frame + justify + skeptic + frame:skeptic References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] tidybayes_0.12.1.9000 bindrcpp_0.2.2 brms_2.3.4 #&gt; [4] Rcpp_0.12.17 forcats_0.3.0 stringr_1.3.1 #&gt; [7] dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 #&gt; [10] tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 #&gt; [13] tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 #&gt; [3] xts_0.10-2 lubridate_1.7.4 #&gt; [5] RColorBrewer_1.1-2 threejs_0.3.1 #&gt; [7] httr_1.3.1 LaplacesDemon_16.1.1 #&gt; [9] rprojroot_1.3-2 rstan_2.17.3 #&gt; [11] tools_3.5.1 backports_1.1.2 #&gt; [13] utf8_1.1.4 R6_2.2.2 #&gt; [15] DT_0.4 lazyeval_0.2.1 #&gt; [17] colorspace_1.3-2 withr_2.1.2 #&gt; [19] tidyselect_0.2.4 gridExtra_2.3 #&gt; [21] mnormt_1.5-5 Brobdingnag_1.2-5 #&gt; [23] compiler_3.5.1 cli_1.0.0 #&gt; [25] rvest_0.3.2 arrayhelpers_1.0-20160527 #&gt; [27] shinyjs_1.0 xml2_1.2.0 #&gt; [29] labeling_0.3 colourpicker_1.0 #&gt; [31] bookdown_0.7 scales_0.5.0 #&gt; [33] dygraphs_1.1.1.5 mvtnorm_1.0-8 #&gt; [35] psych_1.8.4 ggridges_0.5.0 #&gt; [37] digest_0.6.15 StanHeaders_2.17.2 #&gt; [39] foreign_0.8-70 rmarkdown_1.10 #&gt; [41] base64enc_0.1-3 pkgconfig_2.0.1 #&gt; [43] htmltools_0.3.6 htmlwidgets_1.2 #&gt; [45] rlang_0.2.1 readxl_1.1.0 #&gt; [47] rstudioapi_0.7 shiny_1.1.0 #&gt; [49] svUnit_0.7-12 bindr_0.1.1 #&gt; [51] zoo_1.8-2 jsonlite_1.5 #&gt; [53] gtools_3.8.1 crosstalk_1.0.0 #&gt; [55] inline_0.3.15 magrittr_1.5 #&gt; [57] loo_2.0.0 bayesplot_1.5.0 #&gt; [59] Matrix_1.2-14 munsell_0.5.0 #&gt; [61] abind_1.4-5 stringi_1.2.3 #&gt; [63] yaml_2.1.19 MASS_7.3-50 #&gt; [65] ggstance_0.3 plyr_1.8.4 #&gt; [67] grid_3.5.1 parallel_3.5.1 #&gt; [69] promises_1.0.1 crayon_1.3.4 #&gt; [71] miniUI_0.1.1.1 lattice_0.20-35 #&gt; [73] haven_1.1.2 hms_0.4.2 #&gt; [75] knitr_1.20 pillar_1.2.3 #&gt; [77] igraph_1.2.1 markdown_0.8 #&gt; [79] shinystan_2.5.0 codetools_0.2-15 #&gt; [81] reshape2_1.4.3 stats4_3.5.1 #&gt; [83] rstantools_1.5.0 glue_1.2.0 #&gt; [85] evaluate_0.10.1 modelr_0.1.2 #&gt; [87] httpuv_1.4.4.2 cellranger_1.1.0 #&gt; [89] gtable_0.2.0 assertthat_0.2.0 #&gt; [91] xfun_0.3 mime_0.5 #&gt; [93] xtable_1.8-2 broom_0.4.5 #&gt; [95] coda_0.19-1 later_0.7.3 #&gt; [97] rsconnect_0.8.8 shinythemes_1.1.1 #&gt; [99] bridgesampling_0.4-0 "],
["conditional-process-analysis-with-a-multicategorical-antecedent.html", "13 Conditional Process Analysis with a Multicategorical Antecedent 13.1 Revisiting sexual discrimination in the workplace 13.2 Looking at the components of the indirect effect of \\(X\\) 13.3 Relative conditional indirect effects 13.4 Testing and probing moderation of mediation 13.5 Relative conditional direct effects References Session info", " 13 Conditional Process Analysis with a Multicategorical Antecedent 13.1 Revisiting sexual discrimination in the workplace Here we load a couple necessary packages, load the data, and take a glimpse(). library(tidyverse) protest &lt;- read_csv(&quot;data/protest/protest.csv&quot;) glimpse(protest) #&gt; Observations: 129 #&gt; Variables: 6 #&gt; $ subnum &lt;int&gt; 209, 44, 124, 232, 30, 140, 27, 64, 67, 182, 85, 109,... #&gt; $ protest &lt;int&gt; 2, 0, 2, 2, 2, 1, 2, 0, 0, 0, 2, 2, 0, 1, 1, 0, 1, 2,... #&gt; $ sexism &lt;dbl&gt; 4.87, 4.25, 5.00, 5.50, 5.62, 5.75, 5.12, 6.62, 5.75,... #&gt; $ angry &lt;int&gt; 2, 1, 3, 1, 1, 1, 2, 1, 6, 1, 2, 5, 2, 1, 1, 1, 2, 1,... #&gt; $ liking &lt;dbl&gt; 4.83, 4.50, 5.50, 5.66, 6.16, 6.00, 4.66, 6.50, 1.00,... #&gt; $ respappr &lt;dbl&gt; 4.25, 5.75, 4.75, 7.00, 6.75, 5.50, 5.00, 6.25, 3.00,... With a little ifelse(), we can make the D1 and D2 contrast-coded dummies. protest &lt;- protest %&gt;% mutate(D1 = ifelse(protest == 0, -2/3, 1/3), D2 = ifelse(protest == 0, 0, ifelse(protest == 1, -1/2, 1/2))) Load brms. library(brms) Here are the sub-model formulas. m_model &lt;- bf(respappr ~ 1 + D1 + D2 + sexism + D1:sexism + D2:sexism) y_model &lt;- bf(liking ~ 1 + D1 + D2 + respappr + sexism + D1:sexism + D2:sexism) Now we’re ready to fit our primary model, the conditional process model with a multicategorical antecedent. model1 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) Here’s the model summary, which coheres reasonably well with the output in Table 13.1. print(model1, digits = 3) #&gt; Family: MV(gaussian, gaussian) #&gt; Links: mu = identity; sigma = identity #&gt; mu = identity; sigma = identity #&gt; Formula: respappr ~ 1 + D1 + D2 + sexism + D1:sexism + D2:sexism #&gt; liking ~ 1 + D1 + D2 + respappr + sexism + D1:sexism + D2:sexism #&gt; Data: protest (Number of observations: 129) #&gt; Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; #&gt; total post-warmup samples = 4000 #&gt; #&gt; Population-Level Effects: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; respappr_Intercept 4.617 0.688 3.245 5.961 4000 1.000 #&gt; liking_Intercept 3.479 0.633 2.233 4.682 4000 1.000 #&gt; respappr_D1 -2.949 1.460 -5.859 -0.099 2529 1.001 #&gt; respappr_D2 1.706 1.667 -1.574 4.976 3382 0.999 #&gt; respappr_sexism 0.039 0.134 -0.221 0.307 4000 1.000 #&gt; respappr_D1:sexism 0.857 0.284 0.304 1.419 2544 1.001 #&gt; respappr_D2:sexism -0.251 0.320 -0.886 0.382 3395 0.999 #&gt; liking_D1 -2.720 1.237 -5.099 -0.333 3208 1.000 #&gt; liking_D2 0.043 1.329 -2.531 2.669 3196 1.000 #&gt; liking_respappr 0.367 0.073 0.229 0.510 4000 0.999 #&gt; liking_sexism 0.071 0.106 -0.131 0.277 4000 1.000 #&gt; liking_D1:sexism 0.524 0.244 0.047 0.983 3221 1.000 #&gt; liking_D2:sexism -0.037 0.254 -0.527 0.467 3214 1.000 #&gt; #&gt; Family Specific Parameters: #&gt; Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat #&gt; sigma_respappr 1.148 0.073 1.016 1.301 4000 1.000 #&gt; sigma_liking 0.918 0.059 0.814 1.046 4000 1.000 #&gt; #&gt; Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample #&gt; is a crude measure of effective sample size, and Rhat is the potential #&gt; scale reduction factor on split chains (at convergence, Rhat = 1). The tidybayes::geom_halfeyeh() function gives us a nice way to look at the output with a coefficient plot. library(tidybayes) post &lt;- posterior_samples(model1) post %&gt;% select(starts_with(&quot;b_&quot;)) %&gt;% gather() %&gt;% mutate(criterion = ifelse(str_detect(key, &quot;respappr&quot;), &quot;criterion: respappr&quot;, &quot;criterion: liking&quot;), criterion = factor(criterion, levels = c(&quot;criterion: respappr&quot;, &quot;criterion: liking&quot;)), key = str_remove(key, &quot;b_respappr_&quot;), key = str_remove(key, &quot;b_liking_&quot;), key = factor(key, levels = c(&quot;Intercept&quot;, &quot;respappr&quot;, &quot;D2:sexism&quot;, &quot;D1:sexism&quot;, &quot;sexism&quot;, &quot;D2&quot;, &quot;D1&quot;))) %&gt;% ggplot(aes(x = value, y = key, group = key)) + geom_halfeyeh(.prob = c(0.95, 0.5), scale = &quot;width&quot;, relative_scale = .75, color = &quot;white&quot;) + coord_cartesian(xlim = c(-7, 6)) + labs(x = NULL, y = NULL) + theme_black() + theme(axis.text.y = element_text(hjust = 0), axis.ticks.y = element_blank(), panel.grid.minor = element_blank(), panel.grid.major = element_line(color = &quot;grey20&quot;)) + facet_wrap(~criterion) The Bayesian \\(R^2\\) distributions are reasonably close to the estimates in the text. bayes_R2(model1) %&gt;% round(digits = 3) #&gt; Estimate Est.Error Q2.5 Q97.5 #&gt; R2_respappr 0.321 0.054 0.211 0.420 #&gt; R2_liking 0.297 0.054 0.188 0.399 13.2 Looking at the components of the indirect effect of \\(X\\) 13.2.1 Examiing the first stage of the mediation process. When making a newdata object to feed into fitted() with more complicated models, it can be useful to review the model formula like so: model1$formula #&gt; respappr ~ 1 + D1 + D2 + sexism + D1:sexism + D2:sexism #&gt; liking ~ 1 + D1 + D2 + respappr + sexism + D1:sexism + D2:sexism Now we’ll prep for and make our version of Figure 13.3. nd &lt;- tibble(D1 = rep(c(1/3, -2/3, 1/3), each = 30), D2 = rep(c(1/2, 0, -1/2), each = 30), sexism = rep(seq(from = 3.5, to = 6.5, length.out = 30), times = 3)) model1_fitted &lt;- fitted(model1, newdata = nd, resp = &quot;respappr&quot;) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(condition = ifelse(D2 == 0, &quot;No Protest&quot;, ifelse(D2 == -1/2, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) protest &lt;- protest %&gt;% mutate(condition = ifelse(protest == 0, &quot;No Protest&quot;, ifelse(protest == 1, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) model1_fitted %&gt;% ggplot(aes(x = sexism, group = condition)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), linetype = 3, color = &quot;white&quot;, fill = &quot;transparent&quot;) + geom_line(aes(y = Estimate), color = &quot;white&quot;) + geom_point(data = protest, aes(x = sexism, y = respappr), color = &quot;red&quot;, size = 2/3) + coord_cartesian(xlim = 4:6) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = expression(paste(&quot;Perceived Appropriateness of Response (&quot;, italic(M), &quot;)&quot;))) + theme_black() + theme(panel.grid = element_blank()) + facet_wrap(~condition) In order to get the \\(\\Delta R^2\\) distribution analogous to the change in \\(R^2\\) \\(F\\)-test Hayes discussed on page 482, we’ll have to first refit the model without the interaction for the \\(M\\) criterion. Here are the sub-models. m_model &lt;- bf(respappr ~ 1 + D1 + D2 + sexism) y_model &lt;- bf(liking ~ 1 + D1 + D2 + respappr + sexism + D1:sexism + D2:sexism) Now we fit model2. model2 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) Now we’re ready to compare \\(R^2\\) distributions. R2s &lt;- bayes_R2(model1, resp = &quot;respappr&quot;, summary = F) %&gt;% as_tibble() %&gt;% rename(model1 = R2_respappr) %&gt;% bind_cols( bayes_R2(model2, resp = &quot;respappr&quot;, summary = F) %&gt;% as_tibble() %&gt;% rename(model2 = R2_respappr) ) %&gt;% mutate(difference = model1 - model2) R2s %&gt;% ggplot(aes(x = difference)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .prob = 0.95) + scale_x_continuous(breaks = median_qi(R2s$difference, .prob = .95)[1, 1:3], labels = median_qi(R2s$difference, .prob = .95)[1, 1:3] %&gt;% round(2)) + scale_y_continuous(NULL, breaks = NULL) + xlab(expression(paste(Delta, italic(R)^2))) + theme_black() + theme(panel.grid = element_blank()) And we might also compare the models by their information criteria. loo(model1, model2) #&gt; LOOIC SE #&gt; model1 761.20 29.63 #&gt; model2 765.84 29.77 #&gt; model1 - model2 -4.64 8.18 waic(model1, model2) #&gt; WAIC SE #&gt; model1 760.71 29.51 #&gt; model2 765.46 29.66 #&gt; model1 - model2 -4.74 8.11 The Bayesian \\(R^2\\), the LOO-CV, and the WAIC all suggest there’s little difference between the two models with respect to their predictive utility. In such a case, I’d lean on theory to choose between them. If inclined, one could also do Bayesian model averaging. Within our Bayesian modeling paradigm, we don’t have a direct analogue to the \\(F\\)-tests Hayes presented on page 483. But a little fitted() and follow-up wrangling will give us some difference scores. # we need new `nd` data nd &lt;- tibble(D1 = rep(c(1/3, -2/3, 1/3), each = 3), D2 = rep(c(1/2, 0, -1/2), each = 3), sexism = rep(c(4.250, 5.120, 5.896), times = 3)) # this time we&#39;ll use `summary = F` model1_fitted &lt;- fitted(model1, newdata = nd, resp = &quot;respappr&quot;, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(condition = rep(c(&quot;Collective Protest&quot;, &quot;No Protest&quot;, &quot;Individual Protest&quot;), each = 3*4000), sexism = rep(c(4.250, 5.120, 5.896), times = 3) %&gt;% rep(., each = 4000), iter = rep(1:4000, times = 9)) %&gt;% select(-key) %&gt;% spread(key = condition, value = value) %&gt;% mutate(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Collective Protest - Individual Protest` = `Collective Protest` - `Individual Protest`) # a tiny bit more wrangling and we&#39;re ready to plot the difference distributions model1_fitted %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% gather(key, value, -sexism) %&gt;% ggplot(aes(x = value)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .prob = 0.95) + geom_vline(xintercept = 0, color = &quot;grey25&quot;, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + facet_grid(sexism~key) + theme_black() + theme(panel.grid = element_blank()) Now we have model1_fitted, it’s easy to get the typical numeric summaries for the differences. model1_fitted %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% gather(key, value, -sexism) %&gt;% group_by(key, sexism) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 9 x 5 #&gt; # Groups: key [3] #&gt; key sexism mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Collective Protest - Individual Protest 4.25 0.639 -0.112 1.38 #&gt; 2 Collective Protest - Individual Protest 5.12 0.421 -0.073 0.91 #&gt; 3 Collective Protest - Individual Protest 5.90 0.226 -0.473 0.898 #&gt; 4 Collective Protest - No Protest 4.25 1.01 0.317 1.70 #&gt; 5 Collective Protest - No Protest 5.12 1.65 1.17 2.15 #&gt; 6 Collective Protest - No Protest 5.90 2.22 1.48 2.94 #&gt; # ... with 3 more rows The three levels of Collective Protest - Individual Protest correspond nicely with some of the analyses Hayes presented on pages 484–486. However, they don’t get at the differences Hayes expressed as \\(\\theta_{D_{1}\\rightarrow M}\\) to . For those, we’ll have to work directly with the posterior_samples(). post &lt;- posterior_samples(model1) post %&gt;% mutate(`Difference in how Catherine&#39;s behavior is perceived between being told she protested or not when W is 4.250` = b_respappr_D1 + `b_respappr_D1:sexism`*4.250, `Difference in how Catherine&#39;s behavior is perceived between being told she protested or not when W is 5.210` = b_respappr_D1 + `b_respappr_D1:sexism`*5.120, `Difference in how Catherine&#39;s behavior is perceived between being told she protested or not when W is 5.896` = b_respappr_D1 + `b_respappr_D1:sexism`*5.896) %&gt;% select(contains(&quot;Difference&quot;)) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 3 x 4 #&gt; key mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Difference in how Catherine&#39;s behavior is perceived b… 0.695 0.057 1.33 #&gt; 2 Difference in how Catherine&#39;s behavior is perceived b… 1.44 1.02 1.86 #&gt; 3 Difference in how Catherine&#39;s behavior is perceived b… 2.11 1.48 2.73 13.2.2 Estimating the second stage of the mediation process. Here’s \\(b\\). post %&gt;% ggplot(aes(x = b_liking_respappr)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .prob = 0.95) + scale_x_continuous(breaks = c(-1, median(post$b_liking_respappr), 1), labels = c(-1, median(post$b_liking_respappr) %&gt;% round(3), 1)) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = -1:1) + xlab(expression(paste(&quot;b_liking_respappr (i.e., &quot;, italic(b), &quot;)&quot;))) + theme_black() + theme(panel.grid = element_blank()) 13.3 Relative conditional indirect effects Before we use Hayes’s formulas at the top of pate 488 to re-express the posterior in terms of the relative conditional indirect effects, we might want to clarify which of the post columns correspond to the relevant parameters. \\(a_{1}\\) = b_respappr_D1 \\(a_{2}\\) = b_respappr_D2 \\(a_{4}\\) = b_respappr_D1:sexism \\(a_{5}\\) = b_respappr_D2:sexism \\(b\\) = b_liking_respappr To get our posterior transformations, we’ll use the tidyverse::map() approach, which first requires we define two custom functions. # (a1 + a4W)*b D1_function &lt;- function(w){ (post$b_respappr_D1 + post$`b_respappr_D1:sexism`*w)*post$b_liking_respappr } # (a2 + a5W)*b D2_function &lt;- function(w){ (post$b_respappr_D2 + post$`b_respappr_D2:sexism`*w)*post$b_liking_respappr } Next, we’ll make a 30-row tibble with each row a value for sexism, ranging from 3.5 to 6.5. We’ll then apply our two custom functions to the sexism values and wrangle the results a bit to make them useful for our purposes. rcie_tibble &lt;- tibble(sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% group_by(sexism) %&gt;% mutate(`Protest vs. No Protest` = map(sexism, D1_function), `Collective vs. Individual Protest` = map(sexism, D2_function)) %&gt;% unnest() %&gt;% ungroup() %&gt;% mutate(iter = rep(1:4000, times = 30)) %&gt;% gather(`indirect effect`, value, -sexism, -iter) %&gt;% mutate(`indirect effect` = factor(`indirect effect`, levels = c(&quot;Protest vs. No Protest&quot;, &quot;Collective vs. Individual Protest&quot;))) head(rcie_tibble) #&gt; # A tibble: 6 x 4 #&gt; sexism iter `indirect effect` value #&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 3.5 1 Protest vs. No Protest 0.271 #&gt; 2 3.5 2 Protest vs. No Protest 0.294 #&gt; 3 3.5 3 Protest vs. No Protest 0.186 #&gt; 4 3.5 4 Protest vs. No Protest 0.181 #&gt; 5 3.5 5 Protest vs. No Protest -0.0172 #&gt; 6 3.5 6 Protest vs. No Protest -0.0435 Here is our variant of Figure 13.4, with respect to the relative conditional indirect effects. rcie_tibble %&gt;% group_by(`indirect effect`, sexism) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% ggplot(aes(x = sexism, group = `indirect effect`)) + geom_ribbon(aes(ymin = ll, ymax = ul), color = &quot;white&quot;, fill = &quot;transparent&quot;, linetype = 3) + geom_line(aes(y = median), color = &quot;white&quot;) + coord_cartesian(xlim = 4:6, ylim = c(-.6, .8)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Relative Conditional Effect on Liking&quot;) + theme_black() + theme(panel.grid = element_blank(), legend.position = &quot;none&quot;) + facet_grid(~ `indirect effect`) Here are the indirect effect summaries relevant to the contents of Table 13.2. rcie_tibble_pick_a_point &lt;- # notice how we&#39;ve restricted ourselves to only 3 values for `sexism` tibble(sexism = c(4.25, 5.125, 5.896)) %&gt;% group_by(sexism) %&gt;% mutate(`Protest vs. No Protest` = map(sexism, D1_function), `Collective vs. Individual Protest` = map(sexism, D2_function)) %&gt;% unnest() %&gt;% ungroup() %&gt;% # because we only have 3 `sexism` values, we only need to repeat `times = 3` mutate(iter = rep(1:4000, times = 3)) %&gt;% gather(`indirect effect`, value, -sexism, -iter) %&gt;% mutate(`indirect effect` = factor(`indirect effect`, levels = c(&quot;Protest vs. No Protest&quot;, &quot;Collective vs. Individual Protest&quot;))) rcie_tibble_pick_a_point %&gt;% group_by(sexism, `indirect effect`) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 6 x 5 #&gt; # Groups: sexism [3] #&gt; sexism `indirect effect` median ll ul #&gt; &lt;dbl&gt; &lt;fct&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 4.25 Protest vs. No Protest 0.243 0.02 0.536 #&gt; 2 4.25 Collective vs. Individual Protest 0.223 -0.04 0.555 #&gt; 3 5.12 Protest vs. No Protest 0.522 0.289 0.821 #&gt; 4 5.12 Collective vs. Individual Protest 0.148 -0.026 0.365 #&gt; 5 5.90 Protest vs. No Protest 0.762 0.422 1.18 #&gt; 6 5.90 Collective vs. Individual Protest 0.08 -0.167 0.348 13.4 Testing and probing moderation of mediation 13.4.1 A test of moderation of the relative indirect effect. To get the slopes of Protest vs. No Protest and Collective vs. Individual Protest (i.e., \\(a_{4}b\\) and \\(a_{5}b\\), respectively), we just work directly with the posterior_samples(), which we’ve saved as post. post &lt;- post %&gt;% mutate(a4b = `b_respappr_D1:sexism`*b_liking_respappr, a5b = `b_respappr_D2:sexism`*b_liking_respappr) post %&gt;% select(a4b:a5b) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 2 x 4 #&gt; key mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 a4b 0.314 0.1 0.589 #&gt; 2 a5b -0.091 -0.341 0.14 Here they are in a geom_halfeyeh() plot. post %&gt;% select(a4b:a5b) %&gt;% gather() %&gt;% ggplot(aes(x = value, y = key, group = key)) + geom_halfeyeh(point_interval = median_qi, .prob = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_y_discrete(expand = c(.1, .1)) + labs(x = NULL, y = NULL) + theme_black() + theme(axis.ticks.y = element_blank(), panel.grid.minor.y = element_blank(), panel.grid.major.y = element_blank()) 13.4.2 Probing moderation of mediation. We already computed the relevant 95% credible intervals at the end of section 13.3 Relative conditional indirect effects. We could inspect those in a geom_halfeyeh() plot, too. rcie_tibble_pick_a_point %&gt;% ggplot(aes(x = value, y = sexism, group = sexism)) + geom_halfeyeh(point_interval = median_qi, .prob = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + labs(x = &quot;Relative Conditional Effect on Liking&quot;, y = NULL) + theme_black() + theme(axis.text.y = element_text(hjust = 0), panel.grid.minor.y = element_blank(), panel.grid.major.y = element_blank()) + facet_wrap(~`indirect effect`) 13.5 Relative conditional direct effects In order to get the \\(R^2\\) difference distribution analogous to the change in \\(R^2\\) \\(F\\)-test Hayes discussed on pages 495–496, we’ll have to first refit the model without the interaction for the \\(Y\\) criterion, liking. m_model &lt;- bf(respappr ~ 1 + D1 + D2 + sexism + D1:sexism + D2:sexism) y_model &lt;- bf(liking ~ 1 + D1 + D2 + respappr + sexism) model3 &lt;- brm(data = protest, family = gaussian, m_model + y_model + set_rescor(FALSE), chains = 4, cores = 4) Here’s the \\(\\Delta R^2\\) density. R2s &lt;- bayes_R2(model1, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% rename(model1 = R2_liking) %&gt;% bind_cols( bayes_R2(model3, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% rename(model3 = R2_liking) ) %&gt;% mutate(difference = model1 - model3) R2s %&gt;% ggplot(aes(x = difference, y = 0)) + geom_halfeyeh(point_interval = median_qi, .prob = c(0.95, 0.5), fill = &quot;grey50&quot;, color = &quot;white&quot;) + scale_x_continuous(breaks = c(-.5, median(R2s$difference) %&gt;% round(2), .5)) + scale_y_continuous(NULL, breaks = NULL) + coord_cartesian(xlim = c(-.5, .5)) + xlab(expression(paste(Delta, italic(R)^2))) + theme_black() + theme(panel.grid = element_blank()) We’ll also compare the models by their information criteria. loo(model1, model3) #&gt; LOOIC SE #&gt; model1 761.20 29.63 #&gt; model3 761.73 31.21 #&gt; model1 - model3 -0.53 5.67 waic(model1, model3) #&gt; WAIC SE #&gt; model1 760.71 29.5 #&gt; model3 761.34 31.1 #&gt; model1 - model3 -0.62 5.6 As when we went through these steps for resp = &quot;respappr&quot;, above, the Bayesian \\(R^2\\), the LOO-CV, and the WAIC all suggest there’s little difference between the two models with respect to predictive utility. In such a case, I’d lean on theory to choose between them. If inclined, one could also do Bayesian model averaging. Our approach to plotting the relative conditional direct effects will mirror what we did for the relative conditional indirect effects, above. Here are the brm() parameters that correspond to the parameter names of Hayes’s notation. \\(c_{1}\\) = b_liking_D1 \\(c_{2}\\) = b_liking_D2 \\(c_{4}\\) = b_liking_D1:sexism \\(c_{5}\\) = b_liking_D2:sexism With all clear, we’re off to the races. # c1 + c4W D1_function &lt;- function(w){ post$b_liking_D1 + post$`b_liking_D1:sexism`*w } # c2 + c5W D2_function &lt;- function(w){ post$b_liking_D2 + post$`b_liking_D2:sexism`*w } rcde_tibble &lt;- tibble(sexism = seq(from = 3.5, to = 6.5, length.out = 30)) %&gt;% group_by(sexism) %&gt;% mutate(`Protest vs. No Protest` = map(sexism, D1_function), `Collective vs. Individual Protest` = map(sexism, D2_function)) %&gt;% unnest() %&gt;% ungroup() %&gt;% mutate(iter = rep(1:4000, times = 30)) %&gt;% gather(`direct effect`, value, -sexism, -iter) %&gt;% mutate(`direct effect` = factor(`direct effect`, levels = c(&quot;Protest vs. No Protest&quot;, &quot;Collective vs. Individual Protest&quot;))) head(rcde_tibble) #&gt; # A tibble: 6 x 4 #&gt; sexism iter `direct effect` value #&gt; &lt;dbl&gt; &lt;int&gt; &lt;fct&gt; &lt;dbl&gt; #&gt; 1 3.5 1 Protest vs. No Protest -0.752 #&gt; 2 3.5 2 Protest vs. No Protest -0.794 #&gt; 3 3.5 3 Protest vs. No Protest -0.339 #&gt; 4 3.5 4 Protest vs. No Protest -0.527 #&gt; 5 3.5 5 Protest vs. No Protest -0.913 #&gt; 6 3.5 6 Protest vs. No Protest -0.824 Here is our variant of Figure 13.4, with respect to the relative conditional direct effects. rcde_tibble %&gt;% group_by(`direct effect`, sexism) %&gt;% summarize(median = median(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% ggplot(aes(x = sexism, group = `direct effect`)) + geom_ribbon(aes(ymin = ll, ymax = ul), color = &quot;white&quot;, fill = &quot;transparent&quot;, linetype = 3) + geom_line(aes(y = median), color = &quot;white&quot;) + coord_cartesian(xlim = 4:6, ylim = c(-.6, .8)) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = &quot;Relative Conditional Effect on Liking&quot;) + theme_black() + theme(panel.grid = element_blank(), legend.position = &quot;none&quot;) + facet_grid(~ `direct effect`) Holy smokes, them are some wide 95% CIs! No wonder the information criteria and \\(R^2\\) comparisons were so uninspiring. Notice that the y-axis is on the parameter space. In Hayes’s Figure 13.5, the y-axis is on the liking space, instead. When we want things in the parameter space, we work with the output of posterior_samples(); when we want them in the criterion space, we use fitted(). # we need new `nd` data nd &lt;- tibble(D1 = rep(c(1/3, -2/3, 1/3), each = 30), D2 = rep(c(1/2, 0, -1/2), each = 30), respappr = mean(protest$respappr), sexism = seq(from = 3.5, to = 6.5, length.out = 30) %&gt;% rep(., times = 3)) # we feed `nd` into `fitted()` model1_fitted &lt;- fitted(model1, newdata = nd, resp = &quot;liking&quot;, summary = T) %&gt;% as_tibble() %&gt;% bind_cols(nd) %&gt;% mutate(condition = ifelse(D2 == 0, &quot;No Protest&quot;, ifelse(D2 == -1/2, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) %&gt;% mutate(condition = factor(condition, levels = c(&quot;No Protest&quot;, &quot;Individual Protest&quot;, &quot;Collective Protest&quot;))) model1_fitted %&gt;% ggplot(aes(x = sexism, group = condition)) + geom_ribbon(aes(ymin = Q2.5, ymax = Q97.5), linetype = 3, color = &quot;white&quot;, fill = &quot;transparent&quot;) + geom_line(aes(y = Estimate), color = &quot;white&quot;) + geom_point(data = protest, aes(x = sexism, y = liking), color = &quot;red&quot;, size = 2/3) + coord_cartesian(xlim = 4:6, ylim = 4:7) + labs(x = expression(paste(&quot;Perceived Pervasiveness of Sex Discrimination in Society (&quot;, italic(W), &quot;)&quot;)), y = expression(paste(&quot;Evaluation of the Attorney (&quot;, italic(Y), &quot;)&quot;))) + theme_black() + theme(panel.grid = element_blank()) + facet_wrap(~condition) We expanded the range of the y-axis, a bit, to show more of that data (and there’s even more data outside of our expanded range). Also note how after doing so and after including the 95% CI bands, the crossing regression line effect in Hayes’s Figure 13.5 isn’t as impressive looking any more. On pages 497–498, Hayes discussed more omnibus \\(F\\)-tests. Much like with the \\(M\\) criterion, we won’t come up with Bayesian \\(F\\)-tests, but we might go ahead and make pairwise comparisons at the three percentiles Hayes prefers. # we need new `nd` data nd &lt;- tibble(D1 = rep(c(1/3, -2/3, 1/3), each = 3), D2 = rep(c(1/2, 0, -1/2), each = 3), respappr = mean(protest$respappr), sexism = rep(c(4.250, 5.120, 5.896), times = 3)) # this tie we&#39;ll use `summary = F` model1_fitted &lt;- fitted(model1, newdata = nd, resp = &quot;liking&quot;, summary = F) %&gt;% as_tibble() %&gt;% gather() %&gt;% mutate(condition = rep(c(&quot;Collective Protest&quot;, &quot;No Protest&quot;, &quot;Individual Protest&quot;), each = 3*4000), sexism = rep(c(4.250, 5.120, 5.896), times = 3) %&gt;% rep(., each = 4000), iter = rep(1:4000, times = 9)) %&gt;% select(-key) %&gt;% spread(key = condition, value = value) %&gt;% mutate(`Individual Protest - No Protest` = `Individual Protest` - `No Protest`, `Collective Protest - No Protest` = `Collective Protest` - `No Protest`, `Collective Protest - Individual Protest` = `Collective Protest` - `Individual Protest`) # a tiny bit more wrangling and we&#39;re ready to plot the difference distributions model1_fitted %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% gather(key, value, -sexism) %&gt;% ggplot(aes(x = value)) + geom_halfeyeh(aes(y = 0), fill = &quot;grey50&quot;, color = &quot;white&quot;, point_interval = median_qi, .prob = 0.95) + geom_vline(xintercept = 0, color = &quot;grey25&quot;, linetype = 2) + scale_y_continuous(NULL, breaks = NULL) + facet_grid(sexism~key) + theme_black() + theme(panel.grid = element_blank()) Now we have model1_fitted, it’s easy to get the typical numeric summaries for the differences. model1_fitted %&gt;% select(sexism, contains(&quot;-&quot;)) %&gt;% gather(key, value, -sexism) %&gt;% group_by(key, sexism) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 9 x 5 #&gt; # Groups: key [3] #&gt; key sexism mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Collective Protest - Individual Protest 4.25 -0.114 -0.715 0.498 #&gt; 2 Collective Protest - Individual Protest 5.12 -0.146 -0.55 0.263 #&gt; 3 Collective Protest - Individual Protest 5.90 -0.174 -0.719 0.362 #&gt; 4 Collective Protest - No Protest 4.25 -0.55 -1.14 0.048 #&gt; 5 Collective Protest - No Protest 5.12 -0.11 -0.591 0.368 #&gt; 6 Collective Protest - No Protest 5.90 0.282 -0.367 0.95 #&gt; # ... with 3 more rows We don’t have \\(p\\)-values, but all the differences are small in magnitude and have wide 95% intervals straddling zero. To get the difference scores Hayes presented on pages 498–500, one might: post %&gt;% mutate(`Difference in liking between being told she protested or not when W is 4.250` = b_liking_D1 + `b_liking_D1:sexism`*4.250, `Difference in liking between being told she protested or not when W is 5.120` = b_liking_D1 + `b_liking_D1:sexism`*5.120, `Difference in liking between being told she protested or not when W is 5.896` = b_liking_D1 + `b_liking_D1:sexism`*5.896, `Difference in liking between collective vs. individual protest when W is 4.250` = b_liking_D2 + `b_liking_D2:sexism`*4.250, `Difference in liking between collective vs. individual protest when W is 5.120` = b_liking_D2 + `b_liking_D2:sexism`*5.120, `Difference in liking between collective vs. individual protest when W is 5.896` = b_liking_D2 + `b_liking_D2:sexism`*5.896) %&gt;% select(contains(&quot;Difference in liking&quot;)) %&gt;% gather() %&gt;% group_by(key) %&gt;% summarize(mean = mean(value), ll = quantile(value, probs = .025), ul = quantile(value, probs = .975)) %&gt;% mutate_if(is.double, round, digits = 3) #&gt; # A tibble: 6 x 4 #&gt; key mean ll ul #&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; #&gt; 1 Difference in liking between being told she protest… -0.493 -1.03 0.049 #&gt; 2 Difference in liking between being told she protest… -0.038 -0.45 0.371 #&gt; 3 Difference in liking between being told she protest… 0.369 -0.218 0.961 #&gt; 4 Difference in liking between collective vs. individ… -0.114 -0.715 0.498 #&gt; 5 Difference in liking between collective vs. individ… -0.146 -0.55 0.263 #&gt; 6 Difference in liking between collective vs. individ… -0.174 -0.719 0.362 References Hayes, A. F. (2018). Introduction to mediation, moderation, and conditional process analysis: A regression-based approach. (2nd ed.). New York, NY, US: The Guilford Press. Session info sessionInfo() #&gt; R version 3.5.1 (2018-07-02) #&gt; Platform: x86_64-apple-darwin15.6.0 (64-bit) #&gt; Running under: macOS High Sierra 10.13.4 #&gt; #&gt; Matrix products: default #&gt; BLAS: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRblas.0.dylib #&gt; LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib #&gt; #&gt; locale: #&gt; [1] en_US.UTF-8/en_US.UTF-8/en_US.UTF-8/C/en_US.UTF-8/en_US.UTF-8 #&gt; #&gt; attached base packages: #&gt; [1] stats graphics grDevices utils datasets methods base #&gt; #&gt; other attached packages: #&gt; [1] tidybayes_0.12.1.9000 brms_2.3.4 Rcpp_0.12.17 #&gt; [4] bindrcpp_0.2.2 forcats_0.3.0 stringr_1.3.1 #&gt; [7] dplyr_0.7.6 purrr_0.2.5 readr_1.1.1 #&gt; [10] tidyr_0.8.1 tibble_1.4.2 ggplot2_3.0.0 #&gt; [13] tidyverse_1.2.1 #&gt; #&gt; loaded via a namespace (and not attached): #&gt; [1] nlme_3.1-137 matrixStats_0.53.1 #&gt; [3] xts_0.10-2 lubridate_1.7.4 #&gt; [5] threejs_0.3.1 httr_1.3.1 #&gt; [7] LaplacesDemon_16.1.1 rprojroot_1.3-2 #&gt; [9] rstan_2.17.3 tools_3.5.1 #&gt; [11] backports_1.1.2 utf8_1.1.4 #&gt; [13] R6_2.2.2 DT_0.4 #&gt; [15] lazyeval_0.2.1 colorspace_1.3-2 #&gt; [17] withr_2.1.2 tidyselect_0.2.4 #&gt; [19] gridExtra_2.3 mnormt_1.5-5 #&gt; [21] Brobdingnag_1.2-5 compiler_3.5.1 #&gt; [23] cli_1.0.0 rvest_0.3.2 #&gt; [25] arrayhelpers_1.0-20160527 shinyjs_1.0 #&gt; [27] xml2_1.2.0 labeling_0.3 #&gt; [29] colourpicker_1.0 bookdown_0.7 #&gt; [31] scales_0.5.0 dygraphs_1.1.1.5 #&gt; [33] mvtnorm_1.0-8 psych_1.8.4 #&gt; [35] ggridges_0.5.0 digest_0.6.15 #&gt; [37] StanHeaders_2.17.2 foreign_0.8-70 #&gt; [39] rmarkdown_1.10 base64enc_0.1-3 #&gt; [41] pkgconfig_2.0.1 htmltools_0.3.6 #&gt; [43] htmlwidgets_1.2 rlang_0.2.1 #&gt; [45] readxl_1.1.0 rstudioapi_0.7 #&gt; [47] shiny_1.1.0 svUnit_0.7-12 #&gt; [49] bindr_0.1.1 zoo_1.8-2 #&gt; [51] jsonlite_1.5 gtools_3.8.1 #&gt; [53] crosstalk_1.0.0 inline_0.3.15 #&gt; [55] magrittr_1.5 loo_2.0.0 #&gt; [57] bayesplot_1.5.0 Matrix_1.2-14 #&gt; [59] munsell_0.5.0 abind_1.4-5 #&gt; [61] stringi_1.2.3 yaml_2.1.19 #&gt; [63] MASS_7.3-50 ggstance_0.3 #&gt; [65] plyr_1.8.4 grid_3.5.1 #&gt; [67] parallel_3.5.1 promises_1.0.1 #&gt; [69] crayon_1.3.4 miniUI_0.1.1.1 #&gt; [71] lattice_0.20-35 haven_1.1.2 #&gt; [73] hms_0.4.2 knitr_1.20 #&gt; [75] pillar_1.2.3 igraph_1.2.1 #&gt; [77] markdown_0.8 shinystan_2.5.0 #&gt; [79] codetools_0.2-15 reshape2_1.4.3 #&gt; [81] stats4_3.5.1 rstantools_1.5.0 #&gt; [83] glue_1.2.0 evaluate_0.10.1 #&gt; [85] modelr_0.1.2 httpuv_1.4.4.2 #&gt; [87] cellranger_1.1.0 gtable_0.2.0 #&gt; [89] assertthat_0.2.0 xfun_0.3 #&gt; [91] mime_0.5 xtable_1.8-2 #&gt; [93] broom_0.4.5 coda_0.19-1 #&gt; [95] later_0.7.3 rsconnect_0.8.8 #&gt; [97] shinythemes_1.1.1 bridgesampling_0.4-0 "]
]
